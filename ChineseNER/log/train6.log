2019-02-21 16:00:25,476 - log/train6.log - INFO - num_chars      :	4412
2019-02-21 16:00:25,476 - log/train6.log - INFO - char_dim       :	100
2019-02-21 16:00:25,476 - log/train6.log - INFO - num_tags       :	13
2019-02-21 16:00:25,476 - log/train6.log - INFO - seg_dim        :	20
2019-02-21 16:00:25,476 - log/train6.log - INFO - lstm_dim       :	100
2019-02-21 16:00:25,476 - log/train6.log - INFO - batch_size     :	20.0
2019-02-21 16:00:25,477 - log/train6.log - INFO - emb_file       :	wiki_100.utf8
2019-02-21 16:00:25,477 - log/train6.log - INFO - clip           :	5.0
2019-02-21 16:00:25,477 - log/train6.log - INFO - dropout_keep   :	0.5
2019-02-21 16:00:25,477 - log/train6.log - INFO - optimizer      :	adam
2019-02-21 16:00:25,477 - log/train6.log - INFO - lr             :	0.001
2019-02-21 16:00:25,477 - log/train6.log - INFO - tag_schema     :	iobes
2019-02-21 16:00:25,477 - log/train6.log - INFO - pre_emb        :	True
2019-02-21 16:00:25,477 - log/train6.log - INFO - zeros          :	False
2019-02-21 16:00:25,477 - log/train6.log - INFO - lower          :	True
2019-02-21 16:00:27,533 - log/train6.log - INFO - Created model with fresh parameters.
2019-02-21 16:00:28,857 - log/train6.log - INFO - Load pre-trained embedding.
2019-02-21 16:00:28,857 - log/train6.log - INFO - start training
2019-02-21 16:00:32,042 - log/train6.log - INFO - iteration:1 step:100/10100, NER loss:118.410690
2019-02-21 16:00:34,459 - log/train6.log - INFO - iteration:1 step:200/10100, NER loss:120.920700
2019-02-21 16:00:36,980 - log/train6.log - INFO - iteration:1 step:300/10100, NER loss:161.230865
2019-02-21 16:00:39,276 - log/train6.log - INFO - iteration:1 step:400/10100, NER loss:125.384903
2019-02-21 16:00:41,330 - log/train6.log - INFO - iteration:1 step:500/10100, NER loss:100.687531
2019-02-21 16:00:43,686 - log/train6.log - INFO - iteration:1 step:600/10100, NER loss:99.626091
2019-02-21 16:00:46,687 - log/train6.log - INFO - iteration:1 step:700/10100, NER loss:174.178696
2019-02-21 16:00:48,990 - log/train6.log - INFO - iteration:1 step:800/10100, NER loss:103.049835
2019-02-21 16:00:51,746 - log/train6.log - INFO - iteration:1 step:900/10100, NER loss:131.462433
2019-02-21 16:00:53,974 - log/train6.log - INFO - iteration:1 step:1000/10100, NER loss:83.321068
2019-02-21 16:00:56,271 - log/train6.log - INFO - iteration:1 step:1100/10100, NER loss:96.035789
2019-02-21 16:00:58,833 - log/train6.log - INFO - iteration:1 step:1200/10100, NER loss:91.151482
2019-02-21 16:01:01,396 - log/train6.log - INFO - iteration:1 step:1300/10100, NER loss:81.600777
2019-02-21 16:01:04,459 - log/train6.log - INFO - iteration:1 step:1400/10100, NER loss:98.211891
2019-02-21 16:01:07,052 - log/train6.log - INFO - iteration:1 step:1500/10100, NER loss:111.672539
2019-02-21 16:01:09,993 - log/train6.log - INFO - iteration:1 step:1600/10100, NER loss:108.379601
2019-02-21 16:01:12,603 - log/train6.log - INFO - iteration:1 step:1700/10100, NER loss:113.275383
2019-02-21 16:01:14,909 - log/train6.log - INFO - iteration:1 step:1800/10100, NER loss:83.473259
2019-02-21 16:01:17,156 - log/train6.log - INFO - iteration:1 step:1900/10100, NER loss:78.091438
2019-02-21 16:01:19,608 - log/train6.log - INFO - iteration:1 step:2000/10100, NER loss:124.500702
2019-02-21 16:01:22,463 - log/train6.log - INFO - iteration:1 step:2100/10100, NER loss:152.701187
2019-02-21 16:01:24,580 - log/train6.log - INFO - iteration:1 step:2200/10100, NER loss:72.092819
2019-02-21 16:01:26,955 - log/train6.log - INFO - iteration:1 step:2300/10100, NER loss:98.959015
2019-02-21 16:01:29,346 - log/train6.log - INFO - iteration:1 step:2400/10100, NER loss:121.583153
2019-02-21 16:01:31,911 - log/train6.log - INFO - iteration:1 step:2500/10100, NER loss:141.250504
2019-02-21 16:01:34,339 - log/train6.log - INFO - iteration:1 step:2600/10100, NER loss:112.991661
2019-02-21 16:01:36,699 - log/train6.log - INFO - iteration:1 step:2700/10100, NER loss:91.541153
2019-02-21 16:01:39,094 - log/train6.log - INFO - iteration:1 step:2800/10100, NER loss:121.318047
2019-02-21 16:01:41,949 - log/train6.log - INFO - iteration:1 step:2900/10100, NER loss:127.116219
2019-02-21 16:01:44,235 - log/train6.log - INFO - iteration:1 step:3000/10100, NER loss:93.670830
2019-02-21 16:01:46,718 - log/train6.log - INFO - iteration:1 step:3100/10100, NER loss:105.629524
2019-02-21 16:01:48,818 - log/train6.log - INFO - iteration:1 step:3200/10100, NER loss:80.163795
2019-02-21 16:01:51,219 - log/train6.log - INFO - iteration:1 step:3300/10100, NER loss:94.579910
2019-02-21 16:01:53,721 - log/train6.log - INFO - iteration:1 step:3400/10100, NER loss:95.334404
2019-02-21 16:01:56,366 - log/train6.log - INFO - iteration:1 step:3500/10100, NER loss:137.461853
2019-02-21 16:01:58,765 - log/train6.log - INFO - iteration:1 step:3600/10100, NER loss:109.122940
2019-02-21 16:02:00,996 - log/train6.log - INFO - iteration:1 step:3700/10100, NER loss:101.495354
2019-02-21 16:02:03,111 - log/train6.log - INFO - iteration:1 step:3800/10100, NER loss:85.132530
2019-02-21 16:02:05,379 - log/train6.log - INFO - iteration:1 step:3900/10100, NER loss:74.898727
2019-02-21 16:02:07,660 - log/train6.log - INFO - iteration:1 step:4000/10100, NER loss:111.210274
2019-02-21 16:02:09,554 - log/train6.log - INFO - iteration:1 step:4100/10100, NER loss:89.195808
2019-02-21 16:02:11,668 - log/train6.log - INFO - iteration:1 step:4200/10100, NER loss:94.730179
2019-02-21 16:02:13,936 - log/train6.log - INFO - iteration:1 step:4300/10100, NER loss:107.460510
2019-02-21 16:02:15,969 - log/train6.log - INFO - iteration:1 step:4400/10100, NER loss:86.203056
2019-02-21 16:02:18,130 - log/train6.log - INFO - iteration:1 step:4500/10100, NER loss:89.124954
2019-02-21 16:02:22,919 - log/train6.log - INFO - iteration:1 step:4600/10100, NER loss:263.936890
2019-02-21 16:02:25,239 - log/train6.log - INFO - iteration:1 step:4700/10100, NER loss:95.936302
2019-02-21 16:02:27,455 - log/train6.log - INFO - iteration:1 step:4800/10100, NER loss:93.922829
2019-02-21 16:02:29,564 - log/train6.log - INFO - iteration:1 step:4900/10100, NER loss:112.575645
2019-02-21 16:02:31,686 - log/train6.log - INFO - iteration:1 step:5000/10100, NER loss:118.796234
2019-02-21 16:02:33,966 - log/train6.log - INFO - iteration:1 step:5100/10100, NER loss:119.599709
2019-02-21 16:02:36,323 - log/train6.log - INFO - iteration:1 step:5200/10100, NER loss:108.449745
2019-02-21 16:02:38,461 - log/train6.log - INFO - iteration:1 step:5300/10100, NER loss:104.862068
2019-02-21 16:02:40,536 - log/train6.log - INFO - iteration:1 step:5400/10100, NER loss:84.662079
2019-02-21 16:02:42,796 - log/train6.log - INFO - iteration:1 step:5500/10100, NER loss:128.589783
2019-02-21 16:02:44,922 - log/train6.log - INFO - iteration:1 step:5600/10100, NER loss:145.877014
2019-02-21 16:02:46,970 - log/train6.log - INFO - iteration:1 step:5700/10100, NER loss:108.244553
2019-02-21 16:02:49,210 - log/train6.log - INFO - iteration:1 step:5800/10100, NER loss:132.925858
2019-02-21 16:02:51,351 - log/train6.log - INFO - iteration:1 step:5900/10100, NER loss:92.819916
2019-02-21 16:02:53,539 - log/train6.log - INFO - iteration:1 step:6000/10100, NER loss:87.966034
2019-02-21 16:02:55,689 - log/train6.log - INFO - iteration:1 step:6100/10100, NER loss:84.452019
2019-02-21 16:02:57,791 - log/train6.log - INFO - iteration:1 step:6200/10100, NER loss:110.436386
2019-02-21 16:03:00,010 - log/train6.log - INFO - iteration:1 step:6300/10100, NER loss:96.573288
2019-02-21 16:03:02,089 - log/train6.log - INFO - iteration:1 step:6400/10100, NER loss:55.566742
2019-02-21 16:03:04,156 - log/train6.log - INFO - iteration:1 step:6500/10100, NER loss:86.055176
2019-02-21 16:03:06,278 - log/train6.log - INFO - iteration:1 step:6600/10100, NER loss:116.245705
2019-02-21 16:03:08,354 - log/train6.log - INFO - iteration:1 step:6700/10100, NER loss:93.324661
2019-02-21 16:03:10,627 - log/train6.log - INFO - iteration:1 step:6800/10100, NER loss:99.522255
2019-02-21 16:03:12,820 - log/train6.log - INFO - iteration:1 step:6900/10100, NER loss:115.213112
2019-02-21 16:03:15,136 - log/train6.log - INFO - iteration:1 step:7000/10100, NER loss:139.568253
2019-02-21 16:03:17,421 - log/train6.log - INFO - iteration:1 step:7100/10100, NER loss:87.418205
2019-02-21 16:03:21,791 - log/train6.log - INFO - iteration:1 step:7200/10100, NER loss:243.470886
2019-02-21 16:03:26,168 - log/train6.log - INFO - iteration:1 step:7300/10100, NER loss:886.044006
2019-02-21 16:03:28,571 - log/train6.log - INFO - iteration:1 step:7400/10100, NER loss:102.458046
2019-02-21 16:03:30,877 - log/train6.log - INFO - iteration:1 step:7500/10100, NER loss:127.202789
2019-02-21 16:03:33,344 - log/train6.log - INFO - iteration:1 step:7600/10100, NER loss:105.344994
2019-02-21 16:03:35,699 - log/train6.log - INFO - iteration:1 step:7700/10100, NER loss:96.578674
2019-02-21 16:03:38,072 - log/train6.log - INFO - iteration:1 step:7800/10100, NER loss:119.765167
2019-02-21 16:03:40,148 - log/train6.log - INFO - iteration:1 step:7900/10100, NER loss:107.451996
2019-02-21 16:03:42,515 - log/train6.log - INFO - iteration:1 step:8000/10100, NER loss:96.870544
2019-02-21 16:03:44,768 - log/train6.log - INFO - iteration:1 step:8100/10100, NER loss:105.322357
2019-02-21 16:03:46,985 - log/train6.log - INFO - iteration:1 step:8200/10100, NER loss:89.260986
2019-02-21 16:03:49,527 - log/train6.log - INFO - iteration:1 step:8300/10100, NER loss:63.261406
2019-02-21 16:03:51,903 - log/train6.log - INFO - iteration:1 step:8400/10100, NER loss:94.297997
2019-02-21 16:03:54,135 - log/train6.log - INFO - iteration:1 step:8500/10100, NER loss:72.486649
2019-02-21 16:03:56,608 - log/train6.log - INFO - iteration:1 step:8600/10100, NER loss:122.997597
2019-02-21 16:03:59,129 - log/train6.log - INFO - iteration:1 step:8700/10100, NER loss:112.661903
2019-02-21 16:04:01,299 - log/train6.log - INFO - iteration:1 step:8800/10100, NER loss:90.725693
2019-02-21 16:04:03,862 - log/train6.log - INFO - iteration:1 step:8900/10100, NER loss:91.752502
2019-02-21 16:04:06,568 - log/train6.log - INFO - iteration:1 step:9000/10100, NER loss:89.811798
2019-02-21 16:04:08,778 - log/train6.log - INFO - iteration:1 step:9100/10100, NER loss:108.375832
2019-02-21 16:04:11,006 - log/train6.log - INFO - iteration:1 step:9200/10100, NER loss:87.157341
2019-02-21 16:04:13,259 - log/train6.log - INFO - iteration:1 step:9300/10100, NER loss:90.756142
2019-02-21 16:04:15,732 - log/train6.log - INFO - iteration:1 step:9400/10100, NER loss:91.018372
2019-02-21 16:04:18,226 - log/train6.log - INFO - iteration:1 step:9500/10100, NER loss:105.307510
2019-02-21 16:04:20,768 - log/train6.log - INFO - iteration:1 step:9600/10100, NER loss:112.173088
2019-02-21 16:04:23,013 - log/train6.log - INFO - iteration:1 step:9700/10100, NER loss:94.294510
2019-02-21 16:04:25,519 - log/train6.log - INFO - iteration:1 step:9800/10100, NER loss:80.049721
2019-02-21 16:04:28,062 - log/train6.log - INFO - iteration:1 step:9900/10100, NER loss:114.786835
2019-02-21 16:04:30,204 - log/train6.log - INFO - iteration:1 step:10000/10100, NER loss:94.032082
2019-02-21 16:04:32,492 - log/train6.log - INFO - iteration:2 step:0/10100, NER loss:89.188545
2019-02-21 16:04:32,492 - log/train6.log - INFO - evaluate:dev
2019-02-21 16:05:50,578 - log/train6.log - INFO - num_chars      :	4412
2019-02-21 16:05:50,578 - log/train6.log - INFO - char_dim       :	100
2019-02-21 16:05:50,579 - log/train6.log - INFO - num_tags       :	13
2019-02-21 16:05:50,579 - log/train6.log - INFO - seg_dim        :	20
2019-02-21 16:05:50,579 - log/train6.log - INFO - lstm_dim       :	100
2019-02-21 16:05:50,579 - log/train6.log - INFO - batch_size     :	20.0
2019-02-21 16:05:50,579 - log/train6.log - INFO - emb_file       :	wiki_100.utf8
2019-02-21 16:05:50,579 - log/train6.log - INFO - clip           :	5.0
2019-02-21 16:05:50,579 - log/train6.log - INFO - dropout_keep   :	0.5
2019-02-21 16:05:50,579 - log/train6.log - INFO - optimizer      :	adam
2019-02-21 16:05:50,579 - log/train6.log - INFO - lr             :	0.001
2019-02-21 16:05:50,579 - log/train6.log - INFO - tag_schema     :	iobes
2019-02-21 16:05:50,579 - log/train6.log - INFO - pre_emb        :	True
2019-02-21 16:05:50,579 - log/train6.log - INFO - zeros          :	False
2019-02-21 16:05:50,580 - log/train6.log - INFO - lower          :	True
2019-02-21 16:05:52,395 - log/train6.log - INFO - Created model with fresh parameters.
2019-02-21 16:05:53,553 - log/train6.log - INFO - Load pre-trained embedding.
2019-02-21 16:05:53,554 - log/train6.log - INFO - start training
2019-02-21 16:05:56,898 - log/train6.log - INFO - iteration:1 step:100/10100, NER loss:161.285660
2019-02-21 16:05:58,742 - log/train6.log - INFO - iteration:1 step:200/10100, NER loss:117.368698
2019-02-21 16:06:00,740 - log/train6.log - INFO - iteration:1 step:300/10100, NER loss:98.444168
2019-02-21 16:06:02,954 - log/train6.log - INFO - iteration:1 step:400/10100, NER loss:87.227409
2019-02-21 16:06:04,862 - log/train6.log - INFO - iteration:1 step:500/10100, NER loss:110.812744
2019-02-21 16:06:07,024 - log/train6.log - INFO - iteration:1 step:600/10100, NER loss:134.742630
2019-02-21 16:06:08,973 - log/train6.log - INFO - iteration:1 step:700/10100, NER loss:92.609451
2019-02-21 16:06:11,007 - log/train6.log - INFO - iteration:1 step:800/10100, NER loss:101.684074
2019-02-21 16:06:12,971 - log/train6.log - INFO - iteration:1 step:900/10100, NER loss:87.478134
2019-02-21 16:06:15,034 - log/train6.log - INFO - iteration:1 step:1000/10100, NER loss:90.365547
2019-02-21 16:06:17,120 - log/train6.log - INFO - iteration:1 step:1100/10100, NER loss:130.594894
2019-02-21 16:06:19,178 - log/train6.log - INFO - iteration:1 step:1200/10100, NER loss:111.635696
2019-02-21 16:06:21,732 - log/train6.log - INFO - iteration:1 step:1300/10100, NER loss:155.173752
2019-02-21 16:06:23,906 - log/train6.log - INFO - iteration:1 step:1400/10100, NER loss:105.939987
2019-02-21 16:06:26,153 - log/train6.log - INFO - iteration:1 step:1500/10100, NER loss:99.123085
2019-02-21 16:06:28,264 - log/train6.log - INFO - iteration:1 step:1600/10100, NER loss:107.452057
2019-02-21 16:06:30,192 - log/train6.log - INFO - iteration:1 step:1700/10100, NER loss:106.196358
2019-02-21 16:06:32,373 - log/train6.log - INFO - iteration:1 step:1800/10100, NER loss:101.509453
2019-02-21 16:06:34,734 - log/train6.log - INFO - iteration:1 step:1900/10100, NER loss:128.476929
2019-02-21 16:06:37,078 - log/train6.log - INFO - iteration:1 step:2000/10100, NER loss:138.535095
2019-02-21 16:06:39,388 - log/train6.log - INFO - iteration:1 step:2100/10100, NER loss:106.299095
2019-02-21 16:06:41,631 - log/train6.log - INFO - iteration:1 step:2200/10100, NER loss:82.578514
2019-02-21 16:06:43,800 - log/train6.log - INFO - iteration:1 step:2300/10100, NER loss:103.202148
2019-02-21 16:06:46,010 - log/train6.log - INFO - iteration:1 step:2400/10100, NER loss:101.555710
2019-02-21 16:06:48,015 - log/train6.log - INFO - iteration:1 step:2500/10100, NER loss:89.839645
2019-02-21 16:06:49,909 - log/train6.log - INFO - iteration:1 step:2600/10100, NER loss:74.176384
2019-02-21 16:06:52,067 - log/train6.log - INFO - iteration:1 step:2700/10100, NER loss:90.879990
2019-02-21 16:06:54,281 - log/train6.log - INFO - iteration:1 step:2800/10100, NER loss:105.604637
2019-02-21 16:06:56,661 - log/train6.log - INFO - iteration:1 step:2900/10100, NER loss:108.109421
2019-02-21 16:06:58,844 - log/train6.log - INFO - iteration:1 step:3000/10100, NER loss:97.487350
2019-02-21 16:07:00,986 - log/train6.log - INFO - iteration:1 step:3100/10100, NER loss:130.606247
2019-02-21 16:07:03,210 - log/train6.log - INFO - iteration:1 step:3200/10100, NER loss:96.092552
2019-02-21 16:07:07,356 - log/train6.log - INFO - iteration:1 step:3300/10100, NER loss:918.690796
2019-02-21 16:07:09,508 - log/train6.log - INFO - iteration:1 step:3400/10100, NER loss:113.727325
2019-02-21 16:07:11,463 - log/train6.log - INFO - iteration:1 step:3500/10100, NER loss:84.941589
2019-02-21 16:07:13,653 - log/train6.log - INFO - iteration:1 step:3600/10100, NER loss:85.468788
2019-02-21 16:07:15,849 - log/train6.log - INFO - iteration:1 step:3700/10100, NER loss:92.886765
2019-02-21 16:07:17,844 - log/train6.log - INFO - iteration:1 step:3800/10100, NER loss:113.701508
2019-02-21 16:07:20,141 - log/train6.log - INFO - iteration:1 step:3900/10100, NER loss:111.618675
2019-02-21 16:07:22,354 - log/train6.log - INFO - iteration:1 step:4000/10100, NER loss:102.971161
2019-02-21 16:07:24,588 - log/train6.log - INFO - iteration:1 step:4100/10100, NER loss:130.039093
2019-02-21 16:07:26,833 - log/train6.log - INFO - iteration:1 step:4200/10100, NER loss:81.450272
2019-02-21 16:07:29,016 - log/train6.log - INFO - iteration:1 step:4300/10100, NER loss:90.251854
2019-02-21 16:07:31,041 - log/train6.log - INFO - iteration:1 step:4400/10100, NER loss:103.231384
2019-02-21 16:07:33,315 - log/train6.log - INFO - iteration:1 step:4500/10100, NER loss:103.402367
2019-02-21 16:07:35,483 - log/train6.log - INFO - iteration:1 step:4600/10100, NER loss:94.371201
2019-02-21 16:07:39,916 - log/train6.log - INFO - iteration:1 step:4700/10100, NER loss:234.657669
2019-02-21 16:07:42,139 - log/train6.log - INFO - iteration:1 step:4800/10100, NER loss:113.644295
2019-02-21 16:07:44,379 - log/train6.log - INFO - iteration:1 step:4900/10100, NER loss:113.213318
2019-02-21 16:07:46,459 - log/train6.log - INFO - iteration:1 step:5000/10100, NER loss:96.306786
2019-02-21 16:07:48,684 - log/train6.log - INFO - iteration:1 step:5100/10100, NER loss:115.372360
2019-02-21 16:07:50,679 - log/train6.log - INFO - iteration:1 step:5200/10100, NER loss:81.480896
2019-02-21 16:07:52,847 - log/train6.log - INFO - iteration:1 step:5300/10100, NER loss:105.782898
2019-02-21 16:07:55,057 - log/train6.log - INFO - iteration:1 step:5400/10100, NER loss:93.583611
2019-02-21 16:07:57,240 - log/train6.log - INFO - iteration:1 step:5500/10100, NER loss:105.763611
2019-02-21 16:07:59,276 - log/train6.log - INFO - iteration:1 step:5600/10100, NER loss:86.276367
2019-02-21 16:08:01,508 - log/train6.log - INFO - iteration:1 step:5700/10100, NER loss:99.904228
2019-02-21 16:08:03,894 - log/train6.log - INFO - iteration:1 step:5800/10100, NER loss:111.041992
2019-02-21 16:08:06,191 - log/train6.log - INFO - iteration:1 step:5900/10100, NER loss:113.643112
2019-02-21 16:08:08,672 - log/train6.log - INFO - iteration:1 step:6000/10100, NER loss:124.914589
2019-02-21 16:08:10,956 - log/train6.log - INFO - iteration:1 step:6100/10100, NER loss:165.975815
2019-02-21 16:08:13,191 - log/train6.log - INFO - iteration:1 step:6200/10100, NER loss:80.049080
2019-02-21 16:08:15,398 - log/train6.log - INFO - iteration:1 step:6300/10100, NER loss:126.669083
2019-02-21 16:08:18,029 - log/train6.log - INFO - iteration:1 step:6400/10100, NER loss:192.407944
2019-02-21 16:08:20,185 - log/train6.log - INFO - iteration:1 step:6500/10100, NER loss:106.137939
2019-02-21 16:08:22,400 - log/train6.log - INFO - iteration:1 step:6600/10100, NER loss:117.581940
2019-02-21 16:08:24,418 - log/train6.log - INFO - iteration:1 step:6700/10100, NER loss:78.014679
2019-02-21 16:08:26,511 - log/train6.log - INFO - iteration:1 step:6800/10100, NER loss:96.649620
2019-02-21 16:08:28,503 - log/train6.log - INFO - iteration:1 step:6900/10100, NER loss:106.835808
2019-02-21 16:08:30,743 - log/train6.log - INFO - iteration:1 step:7000/10100, NER loss:88.601410
2019-02-21 16:08:33,160 - log/train6.log - INFO - iteration:1 step:7100/10100, NER loss:103.777138
2019-02-21 16:08:35,115 - log/train6.log - INFO - iteration:1 step:7200/10100, NER loss:86.382217
2019-02-21 16:08:39,784 - log/train6.log - INFO - iteration:1 step:7300/10100, NER loss:200.295822
2019-02-21 16:08:42,043 - log/train6.log - INFO - iteration:1 step:7400/10100, NER loss:92.837738
2019-02-21 16:08:44,171 - log/train6.log - INFO - iteration:1 step:7500/10100, NER loss:105.257431
2019-02-21 16:08:46,174 - log/train6.log - INFO - iteration:1 step:7600/10100, NER loss:90.311058
2019-02-21 16:08:48,559 - log/train6.log - INFO - iteration:1 step:7700/10100, NER loss:136.771042
2019-02-21 16:08:50,729 - log/train6.log - INFO - iteration:1 step:7800/10100, NER loss:82.698395
2019-02-21 16:08:52,851 - log/train6.log - INFO - iteration:1 step:7900/10100, NER loss:78.710983
2019-02-21 16:08:55,075 - log/train6.log - INFO - iteration:1 step:8000/10100, NER loss:99.746269
2019-02-21 16:08:57,458 - log/train6.log - INFO - iteration:1 step:8100/10100, NER loss:81.744637
2019-02-21 16:08:59,814 - log/train6.log - INFO - iteration:1 step:8200/10100, NER loss:144.148865
2019-02-21 16:09:02,155 - log/train6.log - INFO - iteration:1 step:8300/10100, NER loss:89.617149
2019-02-21 16:09:04,808 - log/train6.log - INFO - iteration:1 step:8400/10100, NER loss:95.462868
2019-02-21 16:09:07,052 - log/train6.log - INFO - iteration:1 step:8500/10100, NER loss:101.523781
2019-02-21 16:09:09,530 - log/train6.log - INFO - iteration:1 step:8600/10100, NER loss:97.987282
2019-02-21 16:09:11,840 - log/train6.log - INFO - iteration:1 step:8700/10100, NER loss:98.694473
2019-02-21 16:09:13,795 - log/train6.log - INFO - iteration:1 step:8800/10100, NER loss:76.492332
2019-02-21 16:09:16,158 - log/train6.log - INFO - iteration:1 step:8900/10100, NER loss:106.802315
2019-02-21 16:09:18,325 - log/train6.log - INFO - iteration:1 step:9000/10100, NER loss:93.710663
2019-02-21 16:09:20,537 - log/train6.log - INFO - iteration:1 step:9100/10100, NER loss:64.048805
2019-02-21 16:09:22,552 - log/train6.log - INFO - iteration:1 step:9200/10100, NER loss:71.909836
2019-02-21 16:09:24,847 - log/train6.log - INFO - iteration:1 step:9300/10100, NER loss:113.290634
2019-02-21 16:09:27,074 - log/train6.log - INFO - iteration:1 step:9400/10100, NER loss:106.096397
2019-02-21 16:09:29,251 - log/train6.log - INFO - iteration:1 step:9500/10100, NER loss:114.479500
2019-02-21 16:09:31,623 - log/train6.log - INFO - iteration:1 step:9600/10100, NER loss:104.062386
2019-02-21 16:09:33,724 - log/train6.log - INFO - iteration:1 step:9700/10100, NER loss:99.364899
2019-02-21 16:09:35,967 - log/train6.log - INFO - iteration:1 step:9800/10100, NER loss:114.284180
2019-02-21 16:09:38,255 - log/train6.log - INFO - iteration:1 step:9900/10100, NER loss:144.694397
2019-02-21 16:09:40,847 - log/train6.log - INFO - iteration:1 step:10000/10100, NER loss:124.667686
2019-02-21 16:09:42,967 - log/train6.log - INFO - iteration:2 step:0/10100, NER loss:89.979393
2019-02-21 16:09:42,967 - log/train6.log - INFO - evaluate:dev
2019-02-21 16:09:49,707 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 4903 phrases; correct: 3766.

2019-02-21 16:09:49,707 - log/train6.log - INFO - accuracy:  94.59%; precision:  76.81%; recall:  64.41%; FB1:  70.07

2019-02-21 16:09:49,707 - log/train6.log - INFO -                 C: precision:  86.32%; recall:  85.63%; FB1:  85.97  3362

2019-02-21 16:09:49,707 - log/train6.log - INFO -               IND: precision:  46.60%; recall:  23.53%; FB1:  31.27  206

2019-02-21 16:09:49,707 - log/train6.log - INFO -               INS: precision:  72.93%; recall:  67.55%; FB1:  70.14  351

2019-02-21 16:09:49,707 - log/train6.log - INFO -                 L: precision:   0.53%; recall:   0.33%; FB1:   0.41  378

2019-02-21 16:09:49,707 - log/train6.log - INFO -                 P: precision:  87.30%; recall:  89.87%; FB1:  88.57  559

2019-02-21 16:09:49,708 - log/train6.log - INFO -               PRO: precision:  46.81%; recall:   4.21%; FB1:   7.73  47

2019-02-21 16:09:49,815 - log/train6.log - INFO - new best dev f1 score:70.070
2019-02-21 16:09:50,184 - log/train6.log - INFO - model saved
2019-02-21 16:09:50,184 - log/train6.log - INFO - evaluate:test
2019-02-21 16:09:51,666 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1458 phrases; correct: 1187.

2019-02-21 16:09:51,667 - log/train6.log - INFO - accuracy:  95.73%; precision:  81.41%; recall:  72.07%; FB1:  76.46

2019-02-21 16:09:51,667 - log/train6.log - INFO -                 C: precision:  88.62%; recall:  88.53%; FB1:  88.58  1028

2019-02-21 16:09:51,667 - log/train6.log - INFO -               IND: precision:  47.83%; recall:  46.81%; FB1:  47.31  46

2019-02-21 16:09:51,667 - log/train6.log - INFO -               INS: precision:  67.47%; recall:  58.95%; FB1:  62.92  83

2019-02-21 16:09:51,667 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  71

2019-02-21 16:09:51,667 - log/train6.log - INFO -                 P: precision:  86.70%; recall:  92.65%; FB1:  89.57  218

2019-02-21 16:09:51,667 - log/train6.log - INFO -               PRO: precision:  75.00%; recall:   5.33%; FB1:   9.94  12

2019-02-21 16:09:51,763 - log/train6.log - INFO - new best test f1 score:76.460
2019-02-21 16:09:53,728 - log/train6.log - INFO - iteration:2 step:100/10100, NER loss:84.049011
2019-02-21 16:09:55,969 - log/train6.log - INFO - iteration:2 step:200/10100, NER loss:111.919670
2019-02-21 16:09:57,891 - log/train6.log - INFO - iteration:2 step:300/10100, NER loss:91.250565
2019-02-21 16:09:59,917 - log/train6.log - INFO - iteration:2 step:400/10100, NER loss:86.082230
2019-02-21 16:10:02,049 - log/train6.log - INFO - iteration:2 step:500/10100, NER loss:110.092064
2019-02-21 16:10:04,211 - log/train6.log - INFO - iteration:2 step:600/10100, NER loss:114.751846
2019-02-21 16:10:06,416 - log/train6.log - INFO - iteration:2 step:700/10100, NER loss:77.874092
2019-02-21 16:10:08,753 - log/train6.log - INFO - iteration:2 step:800/10100, NER loss:80.669807
2019-02-21 16:10:10,733 - log/train6.log - INFO - iteration:2 step:900/10100, NER loss:84.140862
2019-02-21 16:10:12,959 - log/train6.log - INFO - iteration:2 step:1000/10100, NER loss:93.080231
2019-02-21 16:10:15,160 - log/train6.log - INFO - iteration:2 step:1100/10100, NER loss:65.673607
2019-02-21 16:10:17,104 - log/train6.log - INFO - iteration:2 step:1200/10100, NER loss:102.477577
2019-02-21 16:10:19,199 - log/train6.log - INFO - iteration:2 step:1300/10100, NER loss:75.860687
2019-02-21 16:10:21,401 - log/train6.log - INFO - iteration:2 step:1400/10100, NER loss:97.847214
2019-02-21 16:10:23,532 - log/train6.log - INFO - iteration:2 step:1500/10100, NER loss:90.329170
2019-02-21 16:10:25,716 - log/train6.log - INFO - iteration:2 step:1600/10100, NER loss:63.132202
2019-02-21 16:10:27,922 - log/train6.log - INFO - iteration:2 step:1700/10100, NER loss:140.375198
2019-02-21 16:10:30,221 - log/train6.log - INFO - iteration:2 step:1800/10100, NER loss:102.347267
2019-02-21 16:10:32,577 - log/train6.log - INFO - iteration:2 step:1900/10100, NER loss:115.067497
2019-02-21 16:10:34,856 - log/train6.log - INFO - iteration:2 step:2000/10100, NER loss:111.687004
2019-02-21 16:10:37,398 - log/train6.log - INFO - iteration:2 step:2100/10100, NER loss:114.680023
2019-02-21 16:10:42,082 - log/train6.log - INFO - iteration:2 step:2200/10100, NER loss:174.531326
2019-02-21 16:10:44,331 - log/train6.log - INFO - iteration:2 step:2300/10100, NER loss:134.469223
2019-02-21 16:10:46,398 - log/train6.log - INFO - iteration:2 step:2400/10100, NER loss:115.701813
2019-02-21 16:10:48,568 - log/train6.log - INFO - iteration:2 step:2500/10100, NER loss:83.620712
2019-02-21 16:10:50,600 - log/train6.log - INFO - iteration:2 step:2600/10100, NER loss:74.875252
2019-02-21 16:10:53,292 - log/train6.log - INFO - iteration:2 step:2700/10100, NER loss:146.458191
2019-02-21 16:10:57,451 - log/train6.log - INFO - iteration:2 step:2800/10100, NER loss:934.414124
2019-02-21 16:10:59,661 - log/train6.log - INFO - iteration:2 step:2900/10100, NER loss:103.448143
2019-02-21 16:11:01,908 - log/train6.log - INFO - iteration:2 step:3000/10100, NER loss:121.963806
2019-02-21 16:11:03,924 - log/train6.log - INFO - iteration:2 step:3100/10100, NER loss:89.883751
2019-02-21 16:11:06,395 - log/train6.log - INFO - iteration:2 step:3200/10100, NER loss:101.190521
2019-02-21 16:11:08,749 - log/train6.log - INFO - iteration:2 step:3300/10100, NER loss:96.394875
2019-02-21 16:11:11,231 - log/train6.log - INFO - iteration:2 step:3400/10100, NER loss:80.270676
2019-02-21 16:11:13,188 - log/train6.log - INFO - iteration:2 step:3500/10100, NER loss:92.961716
2019-02-21 16:11:15,497 - log/train6.log - INFO - iteration:2 step:3600/10100, NER loss:76.155876
2019-02-21 16:11:18,015 - log/train6.log - INFO - iteration:2 step:3700/10100, NER loss:137.688980
2019-02-21 16:11:20,441 - log/train6.log - INFO - iteration:2 step:3800/10100, NER loss:140.990005
2019-02-21 16:11:22,908 - log/train6.log - INFO - iteration:2 step:3900/10100, NER loss:100.667801
2019-02-21 16:11:25,284 - log/train6.log - INFO - iteration:2 step:4000/10100, NER loss:85.612999
2019-02-21 16:11:27,461 - log/train6.log - INFO - iteration:2 step:4100/10100, NER loss:90.296295
2019-02-21 16:11:29,708 - log/train6.log - INFO - iteration:2 step:4200/10100, NER loss:98.051727
2019-02-21 16:11:31,950 - log/train6.log - INFO - iteration:2 step:4300/10100, NER loss:116.076546
2019-02-21 16:11:34,303 - log/train6.log - INFO - iteration:2 step:4400/10100, NER loss:84.307953
2019-02-21 16:11:36,600 - log/train6.log - INFO - iteration:2 step:4500/10100, NER loss:120.855682
2019-02-21 16:11:38,744 - log/train6.log - INFO - iteration:2 step:4600/10100, NER loss:85.018166
2019-02-21 16:11:40,825 - log/train6.log - INFO - iteration:2 step:4700/10100, NER loss:61.821945
2019-02-21 16:11:42,997 - log/train6.log - INFO - iteration:2 step:4800/10100, NER loss:89.755333
2019-02-21 16:11:45,242 - log/train6.log - INFO - iteration:2 step:4900/10100, NER loss:104.852257
2019-02-21 16:11:47,349 - log/train6.log - INFO - iteration:2 step:5000/10100, NER loss:86.615692
2019-02-21 16:11:49,329 - log/train6.log - INFO - iteration:2 step:5100/10100, NER loss:71.140755
2019-02-21 16:11:51,528 - log/train6.log - INFO - iteration:2 step:5200/10100, NER loss:89.893867
2019-02-21 16:11:53,741 - log/train6.log - INFO - iteration:2 step:5300/10100, NER loss:107.198616
2019-02-21 16:11:55,799 - log/train6.log - INFO - iteration:2 step:5400/10100, NER loss:84.410950
2019-02-21 16:11:58,110 - log/train6.log - INFO - iteration:2 step:5500/10100, NER loss:107.925026
2019-02-21 16:12:00,583 - log/train6.log - INFO - iteration:2 step:5600/10100, NER loss:88.147530
2019-02-21 16:12:02,957 - log/train6.log - INFO - iteration:2 step:5700/10100, NER loss:111.258789
2019-02-21 16:12:05,133 - log/train6.log - INFO - iteration:2 step:5800/10100, NER loss:95.290657
2019-02-21 16:12:07,210 - log/train6.log - INFO - iteration:2 step:5900/10100, NER loss:91.558304
2019-02-21 16:12:09,578 - log/train6.log - INFO - iteration:2 step:6000/10100, NER loss:83.841789
2019-02-21 16:12:11,864 - log/train6.log - INFO - iteration:2 step:6100/10100, NER loss:99.123718
2019-02-21 16:12:14,240 - log/train6.log - INFO - iteration:2 step:6200/10100, NER loss:95.983505
2019-02-21 16:12:16,286 - log/train6.log - INFO - iteration:2 step:6300/10100, NER loss:106.307396
2019-02-21 16:12:18,452 - log/train6.log - INFO - iteration:2 step:6400/10100, NER loss:84.826866
2019-02-21 16:12:20,638 - log/train6.log - INFO - iteration:2 step:6500/10100, NER loss:85.528587
2019-02-21 16:12:22,864 - log/train6.log - INFO - iteration:2 step:6600/10100, NER loss:106.339539
2019-02-21 16:12:25,070 - log/train6.log - INFO - iteration:2 step:6700/10100, NER loss:82.727493
2019-02-21 16:12:27,178 - log/train6.log - INFO - iteration:2 step:6800/10100, NER loss:67.087013
2019-02-21 16:12:29,330 - log/train6.log - INFO - iteration:2 step:6900/10100, NER loss:89.636292
2019-02-21 16:12:31,471 - log/train6.log - INFO - iteration:2 step:7000/10100, NER loss:106.206764
2019-02-21 16:12:33,593 - log/train6.log - INFO - iteration:2 step:7100/10100, NER loss:82.493896
2019-02-21 16:12:35,648 - log/train6.log - INFO - iteration:2 step:7200/10100, NER loss:95.672897
2019-02-21 16:12:37,765 - log/train6.log - INFO - iteration:2 step:7300/10100, NER loss:99.484924
2019-02-21 16:12:40,038 - log/train6.log - INFO - iteration:2 step:7400/10100, NER loss:92.596825
2019-02-21 16:12:42,351 - log/train6.log - INFO - iteration:2 step:7500/10100, NER loss:122.245895
2019-02-21 16:12:46,420 - log/train6.log - INFO - iteration:2 step:7600/10100, NER loss:199.352234
2019-02-21 16:12:48,754 - log/train6.log - INFO - iteration:2 step:7700/10100, NER loss:72.936958
2019-02-21 16:12:50,828 - log/train6.log - INFO - iteration:2 step:7800/10100, NER loss:94.399811
2019-02-21 16:12:52,875 - log/train6.log - INFO - iteration:2 step:7900/10100, NER loss:55.303780
2019-02-21 16:12:55,179 - log/train6.log - INFO - iteration:2 step:8000/10100, NER loss:82.877380
2019-02-21 16:12:57,490 - log/train6.log - INFO - iteration:2 step:8100/10100, NER loss:115.026466
2019-02-21 16:12:59,693 - log/train6.log - INFO - iteration:2 step:8200/10100, NER loss:88.712753
2019-02-21 16:13:01,906 - log/train6.log - INFO - iteration:2 step:8300/10100, NER loss:109.593758
2019-02-21 16:13:04,180 - log/train6.log - INFO - iteration:2 step:8400/10100, NER loss:114.718651
2019-02-21 16:13:06,351 - log/train6.log - INFO - iteration:2 step:8500/10100, NER loss:72.789978
2019-02-21 16:13:08,586 - log/train6.log - INFO - iteration:2 step:8600/10100, NER loss:66.109100
2019-02-21 16:13:11,007 - log/train6.log - INFO - iteration:2 step:8700/10100, NER loss:98.072334
2019-02-21 16:13:13,181 - log/train6.log - INFO - iteration:2 step:8800/10100, NER loss:95.194870
2019-02-21 16:13:15,453 - log/train6.log - INFO - iteration:2 step:8900/10100, NER loss:99.601036
2019-02-21 16:13:17,850 - log/train6.log - INFO - iteration:2 step:9000/10100, NER loss:76.133743
2019-02-21 16:13:20,165 - log/train6.log - INFO - iteration:2 step:9100/10100, NER loss:116.711349
2019-02-21 16:13:22,271 - log/train6.log - INFO - iteration:2 step:9200/10100, NER loss:87.216751
2019-02-21 16:13:24,431 - log/train6.log - INFO - iteration:2 step:9300/10100, NER loss:91.782578
2019-02-21 16:13:26,729 - log/train6.log - INFO - iteration:2 step:9400/10100, NER loss:96.616943
2019-02-21 16:13:28,821 - log/train6.log - INFO - iteration:2 step:9500/10100, NER loss:76.842918
2019-02-21 16:13:30,909 - log/train6.log - INFO - iteration:2 step:9600/10100, NER loss:79.580887
2019-02-21 16:13:32,948 - log/train6.log - INFO - iteration:2 step:9700/10100, NER loss:78.429077
2019-02-21 16:13:35,278 - log/train6.log - INFO - iteration:2 step:9800/10100, NER loss:82.350563
2019-02-21 16:13:37,496 - log/train6.log - INFO - iteration:2 step:9900/10100, NER loss:122.102074
2019-02-21 16:13:39,922 - log/train6.log - INFO - iteration:2 step:10000/10100, NER loss:113.665970
2019-02-21 16:13:42,166 - log/train6.log - INFO - iteration:3 step:0/10100, NER loss:104.211090
2019-02-21 16:13:42,166 - log/train6.log - INFO - evaluate:dev
2019-02-21 16:13:48,695 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5625 phrases; correct: 3965.

2019-02-21 16:13:48,695 - log/train6.log - INFO - accuracy:  94.68%; precision:  70.49%; recall:  67.81%; FB1:  69.12

2019-02-21 16:13:48,696 - log/train6.log - INFO -                 C: precision:  87.38%; recall:  86.87%; FB1:  87.13  3369

2019-02-21 16:13:48,696 - log/train6.log - INFO -               IND: precision:  44.44%; recall:  33.33%; FB1:  38.10  306

2019-02-21 16:13:48,696 - log/train6.log - INFO -               INS: precision:  55.83%; recall:  72.03%; FB1:  62.90  489

2019-02-21 16:13:48,696 - log/train6.log - INFO -                 L: precision:   0.72%; recall:   0.66%; FB1:   0.69  556

2019-02-21 16:13:48,696 - log/train6.log - INFO -                 P: precision:  88.31%; recall:  90.42%; FB1:  89.35  556

2019-02-21 16:13:48,696 - log/train6.log - INFO -               PRO: precision:  33.52%; recall:  22.41%; FB1:  26.87  349

2019-02-21 16:13:48,700 - log/train6.log - INFO - evaluate:test
2019-02-21 16:13:50,174 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1631 phrases; correct: 1269.

2019-02-21 16:13:50,174 - log/train6.log - INFO - accuracy:  95.87%; precision:  77.81%; recall:  77.05%; FB1:  77.43

2019-02-21 16:13:50,174 - log/train6.log - INFO -                 C: precision:  88.76%; recall:  89.80%; FB1:  89.28  1041

2019-02-21 16:13:50,175 - log/train6.log - INFO -               IND: precision:  44.78%; recall:  63.83%; FB1:  52.63  67

2019-02-21 16:13:50,175 - log/train6.log - INFO -               INS: precision:  56.36%; recall:  65.26%; FB1:  60.49  110

2019-02-21 16:13:50,175 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  100

2019-02-21 16:13:50,175 - log/train6.log - INFO -                 P: precision:  88.79%; recall:  93.14%; FB1:  90.91  214

2019-02-21 16:13:50,175 - log/train6.log - INFO -               PRO: precision:  63.64%; recall:  37.28%; FB1:  47.01  99

2019-02-21 16:13:50,246 - log/train6.log - INFO - new best test f1 score:77.430
2019-02-21 16:13:52,387 - log/train6.log - INFO - iteration:3 step:100/10100, NER loss:118.480400
2019-02-21 16:13:54,388 - log/train6.log - INFO - iteration:3 step:200/10100, NER loss:102.982986
2019-02-21 16:13:56,427 - log/train6.log - INFO - iteration:3 step:300/10100, NER loss:85.259125
2019-02-21 16:13:58,423 - log/train6.log - INFO - iteration:3 step:400/10100, NER loss:104.906395
2019-02-21 16:14:00,620 - log/train6.log - INFO - iteration:3 step:500/10100, NER loss:95.341385
2019-02-21 16:14:02,743 - log/train6.log - INFO - iteration:3 step:600/10100, NER loss:88.913750
2019-02-21 16:14:04,788 - log/train6.log - INFO - iteration:3 step:700/10100, NER loss:84.104599
2019-02-21 16:14:07,221 - log/train6.log - INFO - iteration:3 step:800/10100, NER loss:111.534782
2019-02-21 16:14:09,534 - log/train6.log - INFO - iteration:3 step:900/10100, NER loss:101.332283
2019-02-21 16:14:11,754 - log/train6.log - INFO - iteration:3 step:1000/10100, NER loss:129.684753
2019-02-21 16:14:13,934 - log/train6.log - INFO - iteration:3 step:1100/10100, NER loss:68.179214
2019-02-21 16:14:16,137 - log/train6.log - INFO - iteration:3 step:1200/10100, NER loss:109.236511
2019-02-21 16:14:18,410 - log/train6.log - INFO - iteration:3 step:1300/10100, NER loss:80.435989
2019-02-21 16:14:20,484 - log/train6.log - INFO - iteration:3 step:1400/10100, NER loss:92.806816
2019-02-21 16:14:22,592 - log/train6.log - INFO - iteration:3 step:1500/10100, NER loss:69.167801
2019-02-21 16:14:24,700 - log/train6.log - INFO - iteration:3 step:1600/10100, NER loss:79.825027
2019-02-21 16:14:26,903 - log/train6.log - INFO - iteration:3 step:1700/10100, NER loss:102.800682
2019-02-21 16:14:29,223 - log/train6.log - INFO - iteration:3 step:1800/10100, NER loss:99.491524
2019-02-21 16:14:31,436 - log/train6.log - INFO - iteration:3 step:1900/10100, NER loss:81.576759
2019-02-21 16:14:33,506 - log/train6.log - INFO - iteration:3 step:2000/10100, NER loss:80.350838
2019-02-21 16:14:35,910 - log/train6.log - INFO - iteration:3 step:2100/10100, NER loss:81.836205
2019-02-21 16:14:38,036 - log/train6.log - INFO - iteration:3 step:2200/10100, NER loss:84.882393
2019-02-21 16:14:40,092 - log/train6.log - INFO - iteration:3 step:2300/10100, NER loss:93.268951
2019-02-21 16:14:42,321 - log/train6.log - INFO - iteration:3 step:2400/10100, NER loss:109.803474
2019-02-21 16:14:44,388 - log/train6.log - INFO - iteration:3 step:2500/10100, NER loss:87.285301
2019-02-21 16:14:46,581 - log/train6.log - INFO - iteration:3 step:2600/10100, NER loss:79.988457
2019-02-21 16:14:48,781 - log/train6.log - INFO - iteration:3 step:2700/10100, NER loss:74.447090
2019-02-21 16:14:50,941 - log/train6.log - INFO - iteration:3 step:2800/10100, NER loss:82.870491
2019-02-21 16:14:52,997 - log/train6.log - INFO - iteration:3 step:2900/10100, NER loss:59.407738
2019-02-21 16:14:55,144 - log/train6.log - INFO - iteration:3 step:3000/10100, NER loss:82.582375
2019-02-21 16:14:57,335 - log/train6.log - INFO - iteration:3 step:3100/10100, NER loss:99.092392
2019-02-21 16:14:59,588 - log/train6.log - INFO - iteration:3 step:3200/10100, NER loss:80.029274
2019-02-21 16:15:01,901 - log/train6.log - INFO - iteration:3 step:3300/10100, NER loss:108.263962
2019-02-21 16:15:03,970 - log/train6.log - INFO - iteration:3 step:3400/10100, NER loss:102.640160
2019-02-21 16:15:06,231 - log/train6.log - INFO - iteration:3 step:3500/10100, NER loss:60.910961
2019-02-21 16:15:08,479 - log/train6.log - INFO - iteration:3 step:3600/10100, NER loss:111.130470
2019-02-21 16:15:10,751 - log/train6.log - INFO - iteration:3 step:3700/10100, NER loss:91.777344
2019-02-21 16:15:14,833 - log/train6.log - INFO - iteration:3 step:3800/10100, NER loss:186.649765
2019-02-21 16:15:16,915 - log/train6.log - INFO - iteration:3 step:3900/10100, NER loss:79.093445
2019-02-21 16:15:19,009 - log/train6.log - INFO - iteration:3 step:4000/10100, NER loss:73.915627
2019-02-21 16:15:21,557 - log/train6.log - INFO - iteration:3 step:4100/10100, NER loss:84.716797
2019-02-21 16:15:23,769 - log/train6.log - INFO - iteration:3 step:4200/10100, NER loss:84.769402
2019-02-21 16:15:25,987 - log/train6.log - INFO - iteration:3 step:4300/10100, NER loss:131.210266
2019-02-21 16:15:28,204 - log/train6.log - INFO - iteration:3 step:4400/10100, NER loss:75.286644
2019-02-21 16:15:30,586 - log/train6.log - INFO - iteration:3 step:4500/10100, NER loss:107.543709
2019-02-21 16:15:33,065 - log/train6.log - INFO - iteration:3 step:4600/10100, NER loss:123.249306
2019-02-21 16:15:35,533 - log/train6.log - INFO - iteration:3 step:4700/10100, NER loss:69.075745
2019-02-21 16:15:37,790 - log/train6.log - INFO - iteration:3 step:4800/10100, NER loss:109.268059
2019-02-21 16:15:39,996 - log/train6.log - INFO - iteration:3 step:4900/10100, NER loss:86.318367
2019-02-21 16:15:42,050 - log/train6.log - INFO - iteration:3 step:5000/10100, NER loss:93.747864
2019-02-21 16:15:44,279 - log/train6.log - INFO - iteration:3 step:5100/10100, NER loss:85.899300
2019-02-21 16:15:46,643 - log/train6.log - INFO - iteration:3 step:5200/10100, NER loss:75.776848
2019-02-21 16:15:48,939 - log/train6.log - INFO - iteration:3 step:5300/10100, NER loss:76.104187
2019-02-21 16:15:50,916 - log/train6.log - INFO - iteration:3 step:5400/10100, NER loss:60.261322
2019-02-21 16:15:53,269 - log/train6.log - INFO - iteration:3 step:5500/10100, NER loss:92.614754
2019-02-21 16:15:55,385 - log/train6.log - INFO - iteration:3 step:5600/10100, NER loss:67.589409
2019-02-21 16:15:57,592 - log/train6.log - INFO - iteration:3 step:5700/10100, NER loss:103.803421
2019-02-21 16:15:59,668 - log/train6.log - INFO - iteration:3 step:5800/10100, NER loss:72.364449
2019-02-21 16:16:01,726 - log/train6.log - INFO - iteration:3 step:5900/10100, NER loss:85.756485
2019-02-21 16:16:04,179 - log/train6.log - INFO - iteration:3 step:6000/10100, NER loss:118.901466
2019-02-21 16:16:06,443 - log/train6.log - INFO - iteration:3 step:6100/10100, NER loss:78.281052
2019-02-21 16:16:08,792 - log/train6.log - INFO - iteration:3 step:6200/10100, NER loss:85.917900
2019-02-21 16:16:10,976 - log/train6.log - INFO - iteration:3 step:6300/10100, NER loss:117.402214
2019-02-21 16:16:13,180 - log/train6.log - INFO - iteration:3 step:6400/10100, NER loss:114.851540
2019-02-21 16:16:15,235 - log/train6.log - INFO - iteration:3 step:6500/10100, NER loss:74.685715
2019-02-21 16:16:19,258 - log/train6.log - INFO - iteration:3 step:6600/10100, NER loss:748.524475
2019-02-21 16:16:21,649 - log/train6.log - INFO - iteration:3 step:6700/10100, NER loss:78.360741
2019-02-21 16:16:23,905 - log/train6.log - INFO - iteration:3 step:6800/10100, NER loss:73.916946
2019-02-21 16:16:26,165 - log/train6.log - INFO - iteration:3 step:6900/10100, NER loss:63.588375
2019-02-21 16:16:28,645 - log/train6.log - INFO - iteration:3 step:7000/10100, NER loss:94.738281
2019-02-21 16:16:30,987 - log/train6.log - INFO - iteration:3 step:7100/10100, NER loss:116.511566
2019-02-21 16:16:33,031 - log/train6.log - INFO - iteration:3 step:7200/10100, NER loss:94.315094
2019-02-21 16:16:35,226 - log/train6.log - INFO - iteration:3 step:7300/10100, NER loss:86.149025
2019-02-21 16:16:37,387 - log/train6.log - INFO - iteration:3 step:7400/10100, NER loss:66.768997
2019-02-21 16:16:39,621 - log/train6.log - INFO - iteration:3 step:7500/10100, NER loss:80.243820
2019-02-21 16:16:41,969 - log/train6.log - INFO - iteration:3 step:7600/10100, NER loss:105.842728
2019-02-21 16:16:44,105 - log/train6.log - INFO - iteration:3 step:7700/10100, NER loss:67.810974
2019-02-21 16:16:46,069 - log/train6.log - INFO - iteration:3 step:7800/10100, NER loss:83.161736
2019-02-21 16:16:48,349 - log/train6.log - INFO - iteration:3 step:7900/10100, NER loss:95.797508
2019-02-21 16:16:50,732 - log/train6.log - INFO - iteration:3 step:8000/10100, NER loss:108.544395
2019-02-21 16:16:52,896 - log/train6.log - INFO - iteration:3 step:8100/10100, NER loss:58.427021
2019-02-21 16:16:55,053 - log/train6.log - INFO - iteration:3 step:8200/10100, NER loss:77.896027
2019-02-21 16:16:57,357 - log/train6.log - INFO - iteration:3 step:8300/10100, NER loss:78.605125
2019-02-21 16:16:59,547 - log/train6.log - INFO - iteration:3 step:8400/10100, NER loss:76.092751
2019-02-21 16:17:01,899 - log/train6.log - INFO - iteration:3 step:8500/10100, NER loss:83.288040
2019-02-21 16:17:04,028 - log/train6.log - INFO - iteration:3 step:8600/10100, NER loss:63.803974
2019-02-21 16:17:06,354 - log/train6.log - INFO - iteration:3 step:8700/10100, NER loss:74.549217
2019-02-21 16:17:08,506 - log/train6.log - INFO - iteration:3 step:8800/10100, NER loss:59.905521
2019-02-21 16:17:10,665 - log/train6.log - INFO - iteration:3 step:8900/10100, NER loss:89.717728
2019-02-21 16:17:13,017 - log/train6.log - INFO - iteration:3 step:9000/10100, NER loss:117.001686
2019-02-21 16:17:15,019 - log/train6.log - INFO - iteration:3 step:9100/10100, NER loss:58.898560
2019-02-21 16:17:17,250 - log/train6.log - INFO - iteration:3 step:9200/10100, NER loss:83.566139
2019-02-21 16:17:21,883 - log/train6.log - INFO - iteration:3 step:9300/10100, NER loss:189.235138
2019-02-21 16:17:24,345 - log/train6.log - INFO - iteration:3 step:9400/10100, NER loss:102.164719
2019-02-21 16:17:26,590 - log/train6.log - INFO - iteration:3 step:9500/10100, NER loss:87.890648
2019-02-21 16:17:28,703 - log/train6.log - INFO - iteration:3 step:9600/10100, NER loss:79.729271
2019-02-21 16:17:31,600 - log/train6.log - INFO - iteration:3 step:9700/10100, NER loss:130.185822
2019-02-21 16:17:34,014 - log/train6.log - INFO - iteration:3 step:9800/10100, NER loss:91.977448
2019-02-21 16:17:36,090 - log/train6.log - INFO - iteration:3 step:9900/10100, NER loss:88.792381
2019-02-21 16:17:38,081 - log/train6.log - INFO - iteration:3 step:10000/10100, NER loss:67.739006
2019-02-21 16:17:40,505 - log/train6.log - INFO - iteration:4 step:0/10100, NER loss:88.175880
2019-02-21 16:17:40,505 - log/train6.log - INFO - evaluate:dev
2019-02-21 16:17:47,009 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5566 phrases; correct: 4001.

2019-02-21 16:17:47,009 - log/train6.log - INFO - accuracy:  94.82%; precision:  71.88%; recall:  68.43%; FB1:  70.11

2019-02-21 16:17:47,010 - log/train6.log - INFO -                 C: precision:  85.06%; recall:  87.34%; FB1:  86.18  3480

2019-02-21 16:17:47,010 - log/train6.log - INFO -               IND: precision:  41.92%; recall:  34.31%; FB1:  37.74  334

2019-02-21 16:17:47,010 - log/train6.log - INFO -               INS: precision:  73.82%; recall:  69.92%; FB1:  71.82  359

2019-02-21 16:17:47,010 - log/train6.log - INFO -                 L: precision:   0.73%; recall:   0.50%; FB1:   0.59  411

2019-02-21 16:17:47,010 - log/train6.log - INFO -                 P: precision:  88.32%; recall:  91.90%; FB1:  90.07  565

2019-02-21 16:17:47,010 - log/train6.log - INFO -               PRO: precision:  32.13%; recall:  25.67%; FB1:  28.54  417

2019-02-21 16:17:47,090 - log/train6.log - INFO - new best dev f1 score:70.110
2019-02-21 16:17:47,381 - log/train6.log - INFO - model saved
2019-02-21 16:17:47,381 - log/train6.log - INFO - evaluate:test
2019-02-21 16:17:48,838 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1662 phrases; correct: 1317.

2019-02-21 16:17:48,838 - log/train6.log - INFO - accuracy:  96.63%; precision:  79.24%; recall:  79.96%; FB1:  79.60

2019-02-21 16:17:48,838 - log/train6.log - INFO -                 C: precision:  88.18%; recall:  91.35%; FB1:  89.74  1066

2019-02-21 16:17:48,838 - log/train6.log - INFO -               IND: precision:  45.33%; recall:  72.34%; FB1:  55.74  75

2019-02-21 16:17:48,838 - log/train6.log - INFO -               INS: precision:  75.61%; recall:  65.26%; FB1:  70.06  82

2019-02-21 16:17:48,838 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  91

2019-02-21 16:17:48,838 - log/train6.log - INFO -                 P: precision:  89.45%; recall:  95.59%; FB1:  92.42  218

2019-02-21 16:17:48,838 - log/train6.log - INFO -               PRO: precision:  66.15%; recall:  50.89%; FB1:  57.53  130

2019-02-21 16:17:48,912 - log/train6.log - INFO - new best test f1 score:79.600
2019-02-21 16:17:50,917 - log/train6.log - INFO - iteration:4 step:100/10100, NER loss:79.135315
2019-02-21 16:17:53,005 - log/train6.log - INFO - iteration:4 step:200/10100, NER loss:96.301117
2019-02-21 16:17:54,960 - log/train6.log - INFO - iteration:4 step:300/10100, NER loss:85.179901
2019-02-21 16:17:56,841 - log/train6.log - INFO - iteration:4 step:400/10100, NER loss:70.495613
2019-02-21 16:17:59,315 - log/train6.log - INFO - iteration:4 step:500/10100, NER loss:105.578606
2019-02-21 16:18:01,439 - log/train6.log - INFO - iteration:4 step:600/10100, NER loss:84.433899
2019-02-21 16:18:03,457 - log/train6.log - INFO - iteration:4 step:700/10100, NER loss:94.979958
2019-02-21 16:18:05,931 - log/train6.log - INFO - iteration:4 step:800/10100, NER loss:102.088905
2019-02-21 16:18:08,025 - log/train6.log - INFO - iteration:4 step:900/10100, NER loss:64.868889
2019-02-21 16:18:10,344 - log/train6.log - INFO - iteration:4 step:1000/10100, NER loss:98.290352
2019-02-21 16:18:12,529 - log/train6.log - INFO - iteration:4 step:1100/10100, NER loss:77.747353
2019-02-21 16:18:14,692 - log/train6.log - INFO - iteration:4 step:1200/10100, NER loss:65.678635
2019-02-21 16:18:16,902 - log/train6.log - INFO - iteration:4 step:1300/10100, NER loss:82.065109
2019-02-21 16:18:18,962 - log/train6.log - INFO - iteration:4 step:1400/10100, NER loss:62.842060
2019-02-21 16:18:21,586 - log/train6.log - INFO - iteration:4 step:1500/10100, NER loss:115.269997
2019-02-21 16:18:23,687 - log/train6.log - INFO - iteration:4 step:1600/10100, NER loss:71.626633
2019-02-21 16:18:25,995 - log/train6.log - INFO - iteration:4 step:1700/10100, NER loss:84.593994
2019-02-21 16:18:28,203 - log/train6.log - INFO - iteration:4 step:1800/10100, NER loss:78.492607
2019-02-21 16:18:30,343 - log/train6.log - INFO - iteration:4 step:1900/10100, NER loss:86.020752
2019-02-21 16:18:32,394 - log/train6.log - INFO - iteration:4 step:2000/10100, NER loss:56.077778
2019-02-21 16:18:34,587 - log/train6.log - INFO - iteration:4 step:2100/10100, NER loss:70.854240
2019-02-21 16:18:36,845 - log/train6.log - INFO - iteration:4 step:2200/10100, NER loss:78.207191
2019-02-21 16:18:38,943 - log/train6.log - INFO - iteration:4 step:2300/10100, NER loss:87.152390
2019-02-21 16:18:41,015 - log/train6.log - INFO - iteration:4 step:2400/10100, NER loss:71.015526
2019-02-21 16:18:43,347 - log/train6.log - INFO - iteration:4 step:2500/10100, NER loss:109.176193
2019-02-21 16:18:45,611 - log/train6.log - INFO - iteration:4 step:2600/10100, NER loss:129.757721
2019-02-21 16:18:47,811 - log/train6.log - INFO - iteration:4 step:2700/10100, NER loss:102.613846
2019-02-21 16:18:49,898 - log/train6.log - INFO - iteration:4 step:2800/10100, NER loss:90.817726
2019-02-21 16:18:52,045 - log/train6.log - INFO - iteration:4 step:2900/10100, NER loss:72.595184
2019-02-21 16:18:54,363 - log/train6.log - INFO - iteration:4 step:3000/10100, NER loss:77.674622
2019-02-21 16:18:56,542 - log/train6.log - INFO - iteration:4 step:3100/10100, NER loss:86.593063
2019-02-21 16:18:58,801 - log/train6.log - INFO - iteration:4 step:3200/10100, NER loss:91.124580
2019-02-21 16:19:01,324 - log/train6.log - INFO - iteration:4 step:3300/10100, NER loss:97.593658
2019-02-21 16:19:03,765 - log/train6.log - INFO - iteration:4 step:3400/10100, NER loss:91.842812
2019-02-21 16:19:05,968 - log/train6.log - INFO - iteration:4 step:3500/10100, NER loss:84.907028
2019-02-21 16:19:08,372 - log/train6.log - INFO - iteration:4 step:3600/10100, NER loss:83.108231
2019-02-21 16:19:10,745 - log/train6.log - INFO - iteration:4 step:3700/10100, NER loss:93.393486
2019-02-21 16:19:13,066 - log/train6.log - INFO - iteration:4 step:3800/10100, NER loss:73.873802
2019-02-21 16:19:15,324 - log/train6.log - INFO - iteration:4 step:3900/10100, NER loss:76.810081
2019-02-21 16:19:19,919 - log/train6.log - INFO - iteration:4 step:4000/10100, NER loss:162.227097
2019-02-21 16:19:22,078 - log/train6.log - INFO - iteration:4 step:4100/10100, NER loss:75.725891
2019-02-21 16:19:24,364 - log/train6.log - INFO - iteration:4 step:4200/10100, NER loss:91.495880
2019-02-21 16:19:26,807 - log/train6.log - INFO - iteration:4 step:4300/10100, NER loss:84.855759
2019-02-21 16:19:29,204 - log/train6.log - INFO - iteration:4 step:4400/10100, NER loss:78.139450
2019-02-21 16:19:31,258 - log/train6.log - INFO - iteration:4 step:4500/10100, NER loss:89.073799
2019-02-21 16:19:33,326 - log/train6.log - INFO - iteration:4 step:4600/10100, NER loss:64.650116
2019-02-21 16:19:37,437 - log/train6.log - INFO - iteration:4 step:4700/10100, NER loss:167.788010
2019-02-21 16:19:39,735 - log/train6.log - INFO - iteration:4 step:4800/10100, NER loss:80.321434
2019-02-21 16:19:41,816 - log/train6.log - INFO - iteration:4 step:4900/10100, NER loss:65.344086
2019-02-21 16:19:44,362 - log/train6.log - INFO - iteration:4 step:5000/10100, NER loss:92.988426
2019-02-21 16:19:46,692 - log/train6.log - INFO - iteration:4 step:5100/10100, NER loss:86.540184
2019-02-21 16:19:49,013 - log/train6.log - INFO - iteration:4 step:5200/10100, NER loss:81.205635
2019-02-21 16:19:51,168 - log/train6.log - INFO - iteration:4 step:5300/10100, NER loss:96.651688
2019-02-21 16:19:53,316 - log/train6.log - INFO - iteration:4 step:5400/10100, NER loss:93.971924
2019-02-21 16:19:55,459 - log/train6.log - INFO - iteration:4 step:5500/10100, NER loss:78.507584
2019-02-21 16:19:57,679 - log/train6.log - INFO - iteration:4 step:5600/10100, NER loss:59.741188
2019-02-21 16:19:59,930 - log/train6.log - INFO - iteration:4 step:5700/10100, NER loss:69.393654
2019-02-21 16:20:02,226 - log/train6.log - INFO - iteration:4 step:5800/10100, NER loss:72.013687
2019-02-21 16:20:04,744 - log/train6.log - INFO - iteration:4 step:5900/10100, NER loss:76.407875
2019-02-21 16:20:07,504 - log/train6.log - INFO - iteration:4 step:6000/10100, NER loss:113.316010
2019-02-21 16:20:10,249 - log/train6.log - INFO - iteration:4 step:6100/10100, NER loss:95.879303
2019-02-21 16:20:12,559 - log/train6.log - INFO - iteration:4 step:6200/10100, NER loss:75.516113
2019-02-21 16:20:14,756 - log/train6.log - INFO - iteration:4 step:6300/10100, NER loss:82.382492
2019-02-21 16:20:17,056 - log/train6.log - INFO - iteration:4 step:6400/10100, NER loss:93.525848
2019-02-21 16:20:19,580 - log/train6.log - INFO - iteration:4 step:6500/10100, NER loss:125.433800
2019-02-21 16:20:21,694 - log/train6.log - INFO - iteration:4 step:6600/10100, NER loss:59.151623
2019-02-21 16:20:24,088 - log/train6.log - INFO - iteration:4 step:6700/10100, NER loss:90.810501
2019-02-21 16:20:26,239 - log/train6.log - INFO - iteration:4 step:6800/10100, NER loss:82.006554
2019-02-21 16:20:28,450 - log/train6.log - INFO - iteration:4 step:6900/10100, NER loss:84.589661
2019-02-21 16:20:30,918 - log/train6.log - INFO - iteration:4 step:7000/10100, NER loss:85.996017
2019-02-21 16:20:32,933 - log/train6.log - INFO - iteration:4 step:7100/10100, NER loss:68.331345
2019-02-21 16:20:35,132 - log/train6.log - INFO - iteration:4 step:7200/10100, NER loss:59.268776
2019-02-21 16:20:37,170 - log/train6.log - INFO - iteration:4 step:7300/10100, NER loss:57.188324
2019-02-21 16:20:39,504 - log/train6.log - INFO - iteration:4 step:7400/10100, NER loss:69.191437
2019-02-21 16:20:43,735 - log/train6.log - INFO - iteration:4 step:7500/10100, NER loss:720.924072
2019-02-21 16:20:46,019 - log/train6.log - INFO - iteration:4 step:7600/10100, NER loss:64.430412
2019-02-21 16:20:48,230 - log/train6.log - INFO - iteration:4 step:7700/10100, NER loss:70.644226
2019-02-21 16:20:50,423 - log/train6.log - INFO - iteration:4 step:7800/10100, NER loss:70.036827
2019-02-21 16:20:52,871 - log/train6.log - INFO - iteration:4 step:7900/10100, NER loss:95.135292
2019-02-21 16:20:55,373 - log/train6.log - INFO - iteration:4 step:8000/10100, NER loss:81.877266
2019-02-21 16:20:57,617 - log/train6.log - INFO - iteration:4 step:8100/10100, NER loss:69.993729
2019-02-21 16:20:59,572 - log/train6.log - INFO - iteration:4 step:8200/10100, NER loss:52.723965
2019-02-21 16:21:01,717 - log/train6.log - INFO - iteration:4 step:8300/10100, NER loss:64.447884
2019-02-21 16:21:04,019 - log/train6.log - INFO - iteration:4 step:8400/10100, NER loss:73.151535
2019-02-21 16:21:06,202 - log/train6.log - INFO - iteration:4 step:8500/10100, NER loss:86.530052
2019-02-21 16:21:08,450 - log/train6.log - INFO - iteration:4 step:8600/10100, NER loss:65.069572
2019-02-21 16:21:10,441 - log/train6.log - INFO - iteration:4 step:8700/10100, NER loss:69.316902
2019-02-21 16:21:13,132 - log/train6.log - INFO - iteration:4 step:8800/10100, NER loss:139.650513
2019-02-21 16:21:15,222 - log/train6.log - INFO - iteration:4 step:8900/10100, NER loss:70.920166
2019-02-21 16:21:17,742 - log/train6.log - INFO - iteration:4 step:9000/10100, NER loss:67.441841
2019-02-21 16:21:20,462 - log/train6.log - INFO - iteration:4 step:9100/10100, NER loss:71.360359
2019-02-21 16:21:22,819 - log/train6.log - INFO - iteration:4 step:9200/10100, NER loss:70.063805
2019-02-21 16:21:25,326 - log/train6.log - INFO - iteration:4 step:9300/10100, NER loss:72.164024
2019-02-21 16:21:27,704 - log/train6.log - INFO - iteration:4 step:9400/10100, NER loss:75.696732
2019-02-21 16:21:30,131 - log/train6.log - INFO - iteration:4 step:9500/10100, NER loss:71.423141
2019-02-21 16:21:32,354 - log/train6.log - INFO - iteration:4 step:9600/10100, NER loss:67.248993
2019-02-21 16:21:34,746 - log/train6.log - INFO - iteration:4 step:9700/10100, NER loss:99.719269
2019-02-21 16:21:37,053 - log/train6.log - INFO - iteration:4 step:9800/10100, NER loss:59.545975
2019-02-21 16:21:39,397 - log/train6.log - INFO - iteration:4 step:9900/10100, NER loss:73.273209
2019-02-21 16:21:41,642 - log/train6.log - INFO - iteration:4 step:10000/10100, NER loss:60.947041
2019-02-21 16:21:43,808 - log/train6.log - INFO - iteration:5 step:0/10100, NER loss:52.559189
2019-02-21 16:21:43,809 - log/train6.log - INFO - evaluate:dev
2019-02-21 16:21:50,384 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5642 phrases; correct: 4050.

2019-02-21 16:21:50,384 - log/train6.log - INFO - accuracy:  94.90%; precision:  71.78%; recall:  69.27%; FB1:  70.50

2019-02-21 16:21:50,384 - log/train6.log - INFO -                 C: precision:  85.80%; recall:  88.93%; FB1:  87.34  3513

2019-02-21 16:21:50,385 - log/train6.log - INFO -               IND: precision:  49.48%; recall:  23.53%; FB1:  31.89  194

2019-02-21 16:21:50,385 - log/train6.log - INFO -               INS: precision:  69.15%; recall:  70.98%; FB1:  70.05  389

2019-02-21 16:21:50,385 - log/train6.log - INFO -                 L: precision:   1.03%; recall:   0.83%; FB1:   0.92  485

2019-02-21 16:21:50,385 - log/train6.log - INFO -                 P: precision:  81.74%; recall:  93.19%; FB1:  87.09  619

2019-02-21 16:21:50,385 - log/train6.log - INFO -               PRO: precision:  36.20%; recall:  30.65%; FB1:  33.20  442

2019-02-21 16:21:50,464 - log/train6.log - INFO - new best dev f1 score:70.500
2019-02-21 16:21:50,749 - log/train6.log - INFO - model saved
2019-02-21 16:21:50,750 - log/train6.log - INFO - evaluate:test
2019-02-21 16:21:52,201 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1654 phrases; correct: 1324.

2019-02-21 16:21:52,201 - log/train6.log - INFO - accuracy:  96.60%; precision:  80.05%; recall:  80.39%; FB1:  80.22

2019-02-21 16:21:52,201 - log/train6.log - INFO -                 C: precision:  87.88%; recall:  92.32%; FB1:  90.05  1081

2019-02-21 16:21:52,201 - log/train6.log - INFO -               IND: precision:  69.23%; recall:  57.45%; FB1:  62.79  39

2019-02-21 16:21:52,201 - log/train6.log - INFO -               INS: precision:  70.59%; recall:  63.16%; FB1:  66.67  85

2019-02-21 16:21:52,201 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  88

2019-02-21 16:21:52,201 - log/train6.log - INFO -                 P: precision:  86.61%; recall:  95.10%; FB1:  90.65  224

2019-02-21 16:21:52,201 - log/train6.log - INFO -               PRO: precision:  67.88%; recall:  55.03%; FB1:  60.78  137

2019-02-21 16:21:52,273 - log/train6.log - INFO - new best test f1 score:80.220
2019-02-21 16:21:54,316 - log/train6.log - INFO - iteration:5 step:100/10100, NER loss:66.704559
2019-02-21 16:21:56,527 - log/train6.log - INFO - iteration:5 step:200/10100, NER loss:64.158722
2019-02-21 16:21:58,709 - log/train6.log - INFO - iteration:5 step:300/10100, NER loss:75.560555
2019-02-21 16:22:00,760 - log/train6.log - INFO - iteration:5 step:400/10100, NER loss:76.384979
2019-02-21 16:22:02,775 - log/train6.log - INFO - iteration:5 step:500/10100, NER loss:59.609894
2019-02-21 16:22:05,130 - log/train6.log - INFO - iteration:5 step:600/10100, NER loss:75.501007
2019-02-21 16:22:07,429 - log/train6.log - INFO - iteration:5 step:700/10100, NER loss:105.648087
2019-02-21 16:22:09,594 - log/train6.log - INFO - iteration:5 step:800/10100, NER loss:42.833553
2019-02-21 16:22:11,925 - log/train6.log - INFO - iteration:5 step:900/10100, NER loss:110.137108
2019-02-21 16:22:14,137 - log/train6.log - INFO - iteration:5 step:1000/10100, NER loss:101.461731
2019-02-21 16:22:16,341 - log/train6.log - INFO - iteration:5 step:1100/10100, NER loss:63.131485
2019-02-21 16:22:18,680 - log/train6.log - INFO - iteration:5 step:1200/10100, NER loss:97.933731
2019-02-21 16:22:20,874 - log/train6.log - INFO - iteration:5 step:1300/10100, NER loss:72.477898
2019-02-21 16:22:23,288 - log/train6.log - INFO - iteration:5 step:1400/10100, NER loss:64.162758
2019-02-21 16:22:25,702 - log/train6.log - INFO - iteration:5 step:1500/10100, NER loss:72.172913
2019-02-21 16:22:27,812 - log/train6.log - INFO - iteration:5 step:1600/10100, NER loss:73.626999
2019-02-21 16:22:30,042 - log/train6.log - INFO - iteration:5 step:1700/10100, NER loss:71.672096
2019-02-21 16:22:32,017 - log/train6.log - INFO - iteration:5 step:1800/10100, NER loss:70.542282
2019-02-21 16:22:34,339 - log/train6.log - INFO - iteration:5 step:1900/10100, NER loss:102.007545
2019-02-21 16:22:36,506 - log/train6.log - INFO - iteration:5 step:2000/10100, NER loss:74.243713
2019-02-21 16:22:38,645 - log/train6.log - INFO - iteration:5 step:2100/10100, NER loss:89.730515
2019-02-21 16:22:40,885 - log/train6.log - INFO - iteration:5 step:2200/10100, NER loss:68.155769
2019-02-21 16:22:43,596 - log/train6.log - INFO - iteration:5 step:2300/10100, NER loss:84.946503
2019-02-21 16:22:45,815 - log/train6.log - INFO - iteration:5 step:2400/10100, NER loss:76.490524
2019-02-21 16:22:48,158 - log/train6.log - INFO - iteration:5 step:2500/10100, NER loss:80.102852
2019-02-21 16:22:50,354 - log/train6.log - INFO - iteration:5 step:2600/10100, NER loss:90.132263
2019-02-21 16:22:52,605 - log/train6.log - INFO - iteration:5 step:2700/10100, NER loss:78.771164
2019-02-21 16:22:54,676 - log/train6.log - INFO - iteration:5 step:2800/10100, NER loss:60.428486
2019-02-21 16:22:56,996 - log/train6.log - INFO - iteration:5 step:2900/10100, NER loss:102.424805
2019-02-21 16:22:59,233 - log/train6.log - INFO - iteration:5 step:3000/10100, NER loss:85.857315
2019-02-21 16:23:01,607 - log/train6.log - INFO - iteration:5 step:3100/10100, NER loss:87.519943
2019-02-21 16:23:03,518 - log/train6.log - INFO - iteration:5 step:3200/10100, NER loss:55.504215
2019-02-21 16:23:05,820 - log/train6.log - INFO - iteration:5 step:3300/10100, NER loss:61.635551
2019-02-21 16:23:07,916 - log/train6.log - INFO - iteration:5 step:3400/10100, NER loss:81.160240
2019-02-21 16:23:10,084 - log/train6.log - INFO - iteration:5 step:3500/10100, NER loss:80.080956
2019-02-21 16:23:12,315 - log/train6.log - INFO - iteration:5 step:3600/10100, NER loss:80.014832
2019-02-21 16:23:14,269 - log/train6.log - INFO - iteration:5 step:3700/10100, NER loss:58.305050
2019-02-21 16:23:16,498 - log/train6.log - INFO - iteration:5 step:3800/10100, NER loss:63.712215
2019-02-21 16:23:18,724 - log/train6.log - INFO - iteration:5 step:3900/10100, NER loss:84.592506
2019-02-21 16:23:20,913 - log/train6.log - INFO - iteration:5 step:4000/10100, NER loss:69.529968
2019-02-21 16:23:23,214 - log/train6.log - INFO - iteration:5 step:4100/10100, NER loss:105.051361
2019-02-21 16:23:25,351 - log/train6.log - INFO - iteration:5 step:4200/10100, NER loss:78.848183
2019-02-21 16:23:27,585 - log/train6.log - INFO - iteration:5 step:4300/10100, NER loss:65.146538
2019-02-21 16:23:29,755 - log/train6.log - INFO - iteration:5 step:4400/10100, NER loss:65.645905
2019-02-21 16:23:32,099 - log/train6.log - INFO - iteration:5 step:4500/10100, NER loss:108.859505
2019-02-21 16:23:34,526 - log/train6.log - INFO - iteration:5 step:4600/10100, NER loss:73.711487
2019-02-21 16:23:36,907 - log/train6.log - INFO - iteration:5 step:4700/10100, NER loss:88.592354
2019-02-21 16:23:39,087 - log/train6.log - INFO - iteration:5 step:4800/10100, NER loss:54.116077
2019-02-21 16:23:41,292 - log/train6.log - INFO - iteration:5 step:4900/10100, NER loss:76.158211
2019-02-21 16:23:43,512 - log/train6.log - INFO - iteration:5 step:5000/10100, NER loss:66.362083
2019-02-21 16:23:45,632 - log/train6.log - INFO - iteration:5 step:5100/10100, NER loss:65.787819
2019-02-21 16:23:47,794 - log/train6.log - INFO - iteration:5 step:5200/10100, NER loss:79.619171
2019-02-21 16:23:50,125 - log/train6.log - INFO - iteration:5 step:5300/10100, NER loss:75.360420
2019-02-21 16:23:52,284 - log/train6.log - INFO - iteration:5 step:5400/10100, NER loss:70.481514
2019-02-21 16:23:54,532 - log/train6.log - INFO - iteration:5 step:5500/10100, NER loss:51.484898
2019-02-21 16:23:56,734 - log/train6.log - INFO - iteration:5 step:5600/10100, NER loss:63.876720
2019-02-21 16:23:58,790 - log/train6.log - INFO - iteration:5 step:5700/10100, NER loss:58.790226
2019-02-21 16:24:05,399 - log/train6.log - INFO - iteration:5 step:5800/10100, NER loss:744.972717
2019-02-21 16:24:07,671 - log/train6.log - INFO - iteration:5 step:5900/10100, NER loss:66.108696
2019-02-21 16:24:09,767 - log/train6.log - INFO - iteration:5 step:6000/10100, NER loss:48.131214
2019-02-21 16:24:12,554 - log/train6.log - INFO - iteration:5 step:6100/10100, NER loss:64.329681
2019-02-21 16:24:15,461 - log/train6.log - INFO - iteration:5 step:6200/10100, NER loss:67.419563
2019-02-21 16:24:18,047 - log/train6.log - INFO - iteration:5 step:6300/10100, NER loss:72.396675
2019-02-21 16:24:20,498 - log/train6.log - INFO - iteration:5 step:6400/10100, NER loss:67.113693
2019-02-21 16:24:22,910 - log/train6.log - INFO - iteration:5 step:6500/10100, NER loss:65.886147
2019-02-21 16:24:25,023 - log/train6.log - INFO - iteration:5 step:6600/10100, NER loss:64.003433
2019-02-21 16:24:27,188 - log/train6.log - INFO - iteration:5 step:6700/10100, NER loss:65.472580
2019-02-21 16:24:29,426 - log/train6.log - INFO - iteration:5 step:6800/10100, NER loss:67.070091
2019-02-21 16:24:31,926 - log/train6.log - INFO - iteration:5 step:6900/10100, NER loss:100.233185
2019-02-21 16:24:34,453 - log/train6.log - INFO - iteration:5 step:7000/10100, NER loss:64.642685
2019-02-21 16:24:39,347 - log/train6.log - INFO - iteration:5 step:7100/10100, NER loss:153.662903
2019-02-21 16:24:41,632 - log/train6.log - INFO - iteration:5 step:7200/10100, NER loss:95.307549
2019-02-21 16:24:43,861 - log/train6.log - INFO - iteration:5 step:7300/10100, NER loss:68.767700
2019-02-21 16:24:45,939 - log/train6.log - INFO - iteration:5 step:7400/10100, NER loss:68.795280
2019-02-21 16:24:48,558 - log/train6.log - INFO - iteration:5 step:7500/10100, NER loss:61.399487
2019-02-21 16:24:50,952 - log/train6.log - INFO - iteration:5 step:7600/10100, NER loss:51.638710
2019-02-21 16:24:53,252 - log/train6.log - INFO - iteration:5 step:7700/10100, NER loss:53.213516
2019-02-21 16:24:55,464 - log/train6.log - INFO - iteration:5 step:7800/10100, NER loss:84.475945
2019-02-21 16:24:58,121 - log/train6.log - INFO - iteration:5 step:7900/10100, NER loss:103.547020
2019-02-21 16:25:00,604 - log/train6.log - INFO - iteration:5 step:8000/10100, NER loss:76.033478
2019-02-21 16:25:02,994 - log/train6.log - INFO - iteration:5 step:8100/10100, NER loss:61.102905
2019-02-21 16:25:05,313 - log/train6.log - INFO - iteration:5 step:8200/10100, NER loss:55.574322
2019-02-21 16:25:07,544 - log/train6.log - INFO - iteration:5 step:8300/10100, NER loss:55.809223
2019-02-21 16:25:09,967 - log/train6.log - INFO - iteration:5 step:8400/10100, NER loss:72.148720
2019-02-21 16:25:12,176 - log/train6.log - INFO - iteration:5 step:8500/10100, NER loss:61.046722
2019-02-21 16:25:14,571 - log/train6.log - INFO - iteration:5 step:8600/10100, NER loss:67.476410
2019-02-21 16:25:16,947 - log/train6.log - INFO - iteration:5 step:8700/10100, NER loss:55.676407
2019-02-21 16:25:19,177 - log/train6.log - INFO - iteration:5 step:8800/10100, NER loss:68.762093
2019-02-21 16:25:21,649 - log/train6.log - INFO - iteration:5 step:8900/10100, NER loss:85.143600
2019-02-21 16:25:23,926 - log/train6.log - INFO - iteration:5 step:9000/10100, NER loss:56.276299
2019-02-21 16:25:26,179 - log/train6.log - INFO - iteration:5 step:9100/10100, NER loss:73.726097
2019-02-21 16:25:28,916 - log/train6.log - INFO - iteration:5 step:9200/10100, NER loss:71.079391
2019-02-21 16:25:31,202 - log/train6.log - INFO - iteration:5 step:9300/10100, NER loss:65.942284
2019-02-21 16:25:33,982 - log/train6.log - INFO - iteration:5 step:9400/10100, NER loss:64.132454
2019-02-21 16:25:36,412 - log/train6.log - INFO - iteration:5 step:9500/10100, NER loss:107.314445
2019-02-21 16:25:38,944 - log/train6.log - INFO - iteration:5 step:9600/10100, NER loss:68.465836
2019-02-21 16:25:41,380 - log/train6.log - INFO - iteration:5 step:9700/10100, NER loss:64.032623
2019-02-21 16:25:43,921 - log/train6.log - INFO - iteration:5 step:9800/10100, NER loss:89.954300
2019-02-21 16:25:46,543 - log/train6.log - INFO - iteration:5 step:9900/10100, NER loss:71.788719
2019-02-21 16:25:49,208 - log/train6.log - INFO - iteration:5 step:10000/10100, NER loss:67.494720
2019-02-21 16:25:51,740 - log/train6.log - INFO - iteration:6 step:0/10100, NER loss:77.746086
2019-02-21 16:25:51,740 - log/train6.log - INFO - evaluate:dev
2019-02-21 16:25:58,561 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5946 phrases; correct: 4091.

2019-02-21 16:25:58,561 - log/train6.log - INFO - accuracy:  94.78%; precision:  68.80%; recall:  69.97%; FB1:  69.38

2019-02-21 16:25:58,561 - log/train6.log - INFO -                 C: precision:  83.89%; recall:  89.55%; FB1:  86.63  3618

2019-02-21 16:25:58,561 - log/train6.log - INFO -               IND: precision:  44.49%; recall:  29.66%; FB1:  35.59  272

2019-02-21 16:25:58,561 - log/train6.log - INFO -               INS: precision:  65.22%; recall:  71.24%; FB1:  68.10  414

2019-02-21 16:25:58,561 - log/train6.log - INFO -                 L: precision:   1.33%; recall:   1.16%; FB1:   1.24  526

2019-02-21 16:25:58,561 - log/train6.log - INFO -                 P: precision:  90.29%; recall:  92.45%; FB1:  91.36  556

2019-02-21 16:25:58,561 - log/train6.log - INFO -               PRO: precision:  27.86%; recall:  29.89%; FB1:  28.84  560

2019-02-21 16:25:58,565 - log/train6.log - INFO - evaluate:test
2019-02-21 16:26:00,082 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1711 phrases; correct: 1346.

2019-02-21 16:26:00,082 - log/train6.log - INFO - accuracy:  96.40%; precision:  78.67%; recall:  81.72%; FB1:  80.17

2019-02-21 16:26:00,082 - log/train6.log - INFO -                 C: precision:  87.10%; recall:  93.20%; FB1:  90.05  1101

2019-02-21 16:26:00,082 - log/train6.log - INFO -               IND: precision:  58.82%; recall:  63.83%; FB1:  61.22  51

2019-02-21 16:26:00,082 - log/train6.log - INFO -               INS: precision:  69.23%; recall:  66.32%; FB1:  67.74  91

2019-02-21 16:26:00,082 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  92

2019-02-21 16:26:00,082 - log/train6.log - INFO -                 P: precision:  89.30%; recall:  94.12%; FB1:  91.65  215

2019-02-21 16:26:00,082 - log/train6.log - INFO -               PRO: precision:  63.35%; recall:  60.36%; FB1:  61.82  161

2019-02-21 16:26:02,411 - log/train6.log - INFO - iteration:6 step:100/10100, NER loss:46.933041
2019-02-21 16:26:04,724 - log/train6.log - INFO - iteration:6 step:200/10100, NER loss:66.872108
2019-02-21 16:26:07,425 - log/train6.log - INFO - iteration:6 step:300/10100, NER loss:75.040001
2019-02-21 16:26:09,859 - log/train6.log - INFO - iteration:6 step:400/10100, NER loss:66.257767
2019-02-21 16:26:12,363 - log/train6.log - INFO - iteration:6 step:500/10100, NER loss:65.095207
2019-02-21 16:26:14,865 - log/train6.log - INFO - iteration:6 step:600/10100, NER loss:68.780571
2019-02-21 16:26:17,481 - log/train6.log - INFO - iteration:6 step:700/10100, NER loss:69.272926
2019-02-21 16:26:19,816 - log/train6.log - INFO - iteration:6 step:800/10100, NER loss:83.495758
2019-02-21 16:26:21,998 - log/train6.log - INFO - iteration:6 step:900/10100, NER loss:47.652531
2019-02-21 16:26:24,277 - log/train6.log - INFO - iteration:6 step:1000/10100, NER loss:61.892982
2019-02-21 16:26:26,453 - log/train6.log - INFO - iteration:6 step:1100/10100, NER loss:55.845478
2019-02-21 16:26:28,979 - log/train6.log - INFO - iteration:6 step:1200/10100, NER loss:68.132996
2019-02-21 16:26:31,656 - log/train6.log - INFO - iteration:6 step:1300/10100, NER loss:75.391853
2019-02-21 16:26:36,592 - log/train6.log - INFO - iteration:6 step:1400/10100, NER loss:172.721283
2019-02-21 16:26:38,934 - log/train6.log - INFO - iteration:6 step:1500/10100, NER loss:55.450550
2019-02-21 16:26:41,425 - log/train6.log - INFO - iteration:6 step:1600/10100, NER loss:97.612297
2019-02-21 16:26:44,022 - log/train6.log - INFO - iteration:6 step:1700/10100, NER loss:74.434395
2019-02-21 16:26:46,293 - log/train6.log - INFO - iteration:6 step:1800/10100, NER loss:52.192684
2019-02-21 16:26:48,576 - log/train6.log - INFO - iteration:6 step:1900/10100, NER loss:101.393288
2019-02-21 16:26:50,982 - log/train6.log - INFO - iteration:6 step:2000/10100, NER loss:87.498627
2019-02-21 16:26:53,415 - log/train6.log - INFO - iteration:6 step:2100/10100, NER loss:76.157516
2019-02-21 16:26:55,800 - log/train6.log - INFO - iteration:6 step:2200/10100, NER loss:56.615742
2019-02-21 16:26:57,970 - log/train6.log - INFO - iteration:6 step:2300/10100, NER loss:53.677086
2019-02-21 16:27:00,218 - log/train6.log - INFO - iteration:6 step:2400/10100, NER loss:65.715637
2019-02-21 16:27:02,527 - log/train6.log - INFO - iteration:6 step:2500/10100, NER loss:84.221375
2019-02-21 16:27:04,849 - log/train6.log - INFO - iteration:6 step:2600/10100, NER loss:64.016571
2019-02-21 16:27:07,249 - log/train6.log - INFO - iteration:6 step:2700/10100, NER loss:63.556530
2019-02-21 16:27:09,538 - log/train6.log - INFO - iteration:6 step:2800/10100, NER loss:68.274094
2019-02-21 16:27:11,795 - log/train6.log - INFO - iteration:6 step:2900/10100, NER loss:71.515182
2019-02-21 16:27:14,243 - log/train6.log - INFO - iteration:6 step:3000/10100, NER loss:78.516296
2019-02-21 16:27:16,387 - log/train6.log - INFO - iteration:6 step:3100/10100, NER loss:66.087830
2019-02-21 16:27:18,781 - log/train6.log - INFO - iteration:6 step:3200/10100, NER loss:70.566338
2019-02-21 16:27:21,095 - log/train6.log - INFO - iteration:6 step:3300/10100, NER loss:60.283035
2019-02-21 16:27:23,623 - log/train6.log - INFO - iteration:6 step:3400/10100, NER loss:77.832146
2019-02-21 16:27:25,785 - log/train6.log - INFO - iteration:6 step:3500/10100, NER loss:82.013466
2019-02-21 16:27:28,054 - log/train6.log - INFO - iteration:6 step:3600/10100, NER loss:82.734474
2019-02-21 16:27:30,438 - log/train6.log - INFO - iteration:6 step:3700/10100, NER loss:68.659027
2019-02-21 16:27:32,760 - log/train6.log - INFO - iteration:6 step:3800/10100, NER loss:52.529907
2019-02-21 16:27:35,282 - log/train6.log - INFO - iteration:6 step:3900/10100, NER loss:70.125778
2019-02-21 16:27:37,515 - log/train6.log - INFO - iteration:6 step:4000/10100, NER loss:83.760704
2019-02-21 16:27:39,578 - log/train6.log - INFO - iteration:6 step:4100/10100, NER loss:62.088970
2019-02-21 16:27:41,795 - log/train6.log - INFO - iteration:6 step:4200/10100, NER loss:70.939827
2019-02-21 16:27:44,237 - log/train6.log - INFO - iteration:6 step:4300/10100, NER loss:59.692902
2019-02-21 16:27:46,852 - log/train6.log - INFO - iteration:6 step:4400/10100, NER loss:69.431473
2019-02-21 16:27:49,373 - log/train6.log - INFO - iteration:6 step:4500/10100, NER loss:75.145363
2019-02-21 16:27:52,063 - log/train6.log - INFO - iteration:6 step:4600/10100, NER loss:98.825485
2019-02-21 16:27:54,387 - log/train6.log - INFO - iteration:6 step:4700/10100, NER loss:71.807289
2019-02-21 16:27:58,959 - log/train6.log - INFO - iteration:6 step:4800/10100, NER loss:590.553528
2019-02-21 16:28:01,216 - log/train6.log - INFO - iteration:6 step:4900/10100, NER loss:32.912735
2019-02-21 16:28:04,047 - log/train6.log - INFO - iteration:6 step:5000/10100, NER loss:83.110741
2019-02-21 16:28:06,407 - log/train6.log - INFO - iteration:6 step:5100/10100, NER loss:71.822639
2019-02-21 16:28:08,645 - log/train6.log - INFO - iteration:6 step:5200/10100, NER loss:75.385696
2019-02-21 16:28:10,940 - log/train6.log - INFO - iteration:6 step:5300/10100, NER loss:48.123558
2019-02-21 16:28:13,445 - log/train6.log - INFO - iteration:6 step:5400/10100, NER loss:64.298470
2019-02-21 16:28:15,895 - log/train6.log - INFO - iteration:6 step:5500/10100, NER loss:73.842987
2019-02-21 16:28:18,358 - log/train6.log - INFO - iteration:6 step:5600/10100, NER loss:52.089088
2019-02-21 16:28:20,884 - log/train6.log - INFO - iteration:6 step:5700/10100, NER loss:55.940868
2019-02-21 16:28:23,366 - log/train6.log - INFO - iteration:6 step:5800/10100, NER loss:75.676682
2019-02-21 16:28:25,938 - log/train6.log - INFO - iteration:6 step:5900/10100, NER loss:66.761780
2019-02-21 16:28:28,523 - log/train6.log - INFO - iteration:6 step:6000/10100, NER loss:76.602562
2019-02-21 16:28:30,975 - log/train6.log - INFO - iteration:6 step:6100/10100, NER loss:54.286320
2019-02-21 16:28:33,583 - log/train6.log - INFO - iteration:6 step:6200/10100, NER loss:71.493195
2019-02-21 16:28:35,726 - log/train6.log - INFO - iteration:6 step:6300/10100, NER loss:44.476288
2019-02-21 16:28:38,159 - log/train6.log - INFO - iteration:6 step:6400/10100, NER loss:57.797096
2019-02-21 16:28:40,402 - log/train6.log - INFO - iteration:6 step:6500/10100, NER loss:47.596561
2019-02-21 16:28:42,981 - log/train6.log - INFO - iteration:6 step:6600/10100, NER loss:68.821152
2019-02-21 16:28:45,615 - log/train6.log - INFO - iteration:6 step:6700/10100, NER loss:63.470699
2019-02-21 16:28:47,942 - log/train6.log - INFO - iteration:6 step:6800/10100, NER loss:72.253624
2019-02-21 16:28:52,508 - log/train6.log - INFO - iteration:6 step:6900/10100, NER loss:140.794052
2019-02-21 16:28:54,696 - log/train6.log - INFO - iteration:6 step:7000/10100, NER loss:60.317726
2019-02-21 16:28:57,176 - log/train6.log - INFO - iteration:6 step:7100/10100, NER loss:67.653503
2019-02-21 16:28:59,495 - log/train6.log - INFO - iteration:6 step:7200/10100, NER loss:56.858875
2019-02-21 16:29:01,716 - log/train6.log - INFO - iteration:6 step:7300/10100, NER loss:45.769352
2019-02-21 16:29:04,093 - log/train6.log - INFO - iteration:6 step:7400/10100, NER loss:61.189800
2019-02-21 16:29:06,378 - log/train6.log - INFO - iteration:6 step:7500/10100, NER loss:62.095913
2019-02-21 16:29:08,673 - log/train6.log - INFO - iteration:6 step:7600/10100, NER loss:78.053093
2019-02-21 16:29:11,454 - log/train6.log - INFO - iteration:6 step:7700/10100, NER loss:117.310860
2019-02-21 16:29:13,567 - log/train6.log - INFO - iteration:6 step:7800/10100, NER loss:44.485905
2019-02-21 16:29:15,830 - log/train6.log - INFO - iteration:6 step:7900/10100, NER loss:68.136101
2019-02-21 16:29:18,122 - log/train6.log - INFO - iteration:6 step:8000/10100, NER loss:67.350754
2019-02-21 16:29:20,572 - log/train6.log - INFO - iteration:6 step:8100/10100, NER loss:65.209290
2019-02-21 16:29:22,894 - log/train6.log - INFO - iteration:6 step:8200/10100, NER loss:51.695789
2019-02-21 16:29:25,710 - log/train6.log - INFO - iteration:6 step:8300/10100, NER loss:61.255917
2019-02-21 16:29:27,778 - log/train6.log - INFO - iteration:6 step:8400/10100, NER loss:39.252659
2019-02-21 16:29:30,303 - log/train6.log - INFO - iteration:6 step:8500/10100, NER loss:57.727886
2019-02-21 16:29:32,781 - log/train6.log - INFO - iteration:6 step:8600/10100, NER loss:51.666256
2019-02-21 16:29:34,961 - log/train6.log - INFO - iteration:6 step:8700/10100, NER loss:54.487930
2019-02-21 16:29:37,218 - log/train6.log - INFO - iteration:6 step:8800/10100, NER loss:61.012203
2019-02-21 16:29:39,498 - log/train6.log - INFO - iteration:6 step:8900/10100, NER loss:59.274918
2019-02-21 16:29:41,821 - log/train6.log - INFO - iteration:6 step:9000/10100, NER loss:63.162064
2019-02-21 16:29:44,016 - log/train6.log - INFO - iteration:6 step:9100/10100, NER loss:59.042965
2019-02-21 16:29:46,327 - log/train6.log - INFO - iteration:6 step:9200/10100, NER loss:51.673721
2019-02-21 16:29:48,736 - log/train6.log - INFO - iteration:6 step:9300/10100, NER loss:60.590626
2019-02-21 16:29:51,026 - log/train6.log - INFO - iteration:6 step:9400/10100, NER loss:53.588535
2019-02-21 16:29:53,445 - log/train6.log - INFO - iteration:6 step:9500/10100, NER loss:74.489883
2019-02-21 16:29:55,799 - log/train6.log - INFO - iteration:6 step:9600/10100, NER loss:58.188107
2019-02-21 16:29:58,158 - log/train6.log - INFO - iteration:6 step:9700/10100, NER loss:70.105652
2019-02-21 16:30:00,490 - log/train6.log - INFO - iteration:6 step:9800/10100, NER loss:52.695919
2019-02-21 16:30:02,761 - log/train6.log - INFO - iteration:6 step:9900/10100, NER loss:62.044468
2019-02-21 16:30:05,500 - log/train6.log - INFO - iteration:6 step:10000/10100, NER loss:61.027168
2019-02-21 16:30:08,054 - log/train6.log - INFO - iteration:7 step:0/10100, NER loss:65.949913
2019-02-21 16:30:08,054 - log/train6.log - INFO - evaluate:dev
2019-02-21 16:30:14,959 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5172 phrases; correct: 3974.

2019-02-21 16:30:14,959 - log/train6.log - INFO - accuracy:  95.16%; precision:  76.84%; recall:  67.97%; FB1:  72.13

2019-02-21 16:30:14,959 - log/train6.log - INFO -                 C: precision:  87.47%; recall:  88.58%; FB1:  88.02  3432

2019-02-21 16:30:14,959 - log/train6.log - INFO -               IND: precision:  58.78%; recall:  18.87%; FB1:  28.57  131

2019-02-21 16:30:14,959 - log/train6.log - INFO -               INS: precision:  64.78%; recall:  72.30%; FB1:  68.33  423

2019-02-21 16:30:14,960 - log/train6.log - INFO -                 L: precision:   0.63%; recall:   0.33%; FB1:   0.43  315

2019-02-21 16:30:14,960 - log/train6.log - INFO -                 P: precision:  88.87%; recall:  92.63%; FB1:  90.71  566

2019-02-21 16:30:14,960 - log/train6.log - INFO -               PRO: precision:  38.03%; recall:  22.22%; FB1:  28.05  305

2019-02-21 16:30:15,039 - log/train6.log - INFO - new best dev f1 score:72.130
2019-02-21 16:30:15,315 - log/train6.log - INFO - model saved
2019-02-21 16:30:15,315 - log/train6.log - INFO - evaluate:test
2019-02-21 16:30:16,796 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1565 phrases; correct: 1315.

2019-02-21 16:30:16,796 - log/train6.log - INFO - accuracy:  96.85%; precision:  84.03%; recall:  79.84%; FB1:  81.88

2019-02-21 16:30:16,796 - log/train6.log - INFO -                 C: precision:  89.96%; recall:  92.32%; FB1:  91.13  1056

2019-02-21 16:30:16,796 - log/train6.log - INFO -               IND: precision:  86.21%; recall:  53.19%; FB1:  65.79  29

2019-02-21 16:30:16,796 - log/train6.log - INFO -               INS: precision:  66.33%; recall:  68.42%; FB1:  67.36  98

2019-02-21 16:30:16,796 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  59

2019-02-21 16:30:16,796 - log/train6.log - INFO -                 P: precision:  91.16%; recall:  96.08%; FB1:  93.56  215

2019-02-21 16:30:16,796 - log/train6.log - INFO -               PRO: precision:  73.15%; recall:  46.75%; FB1:  57.04  108

2019-02-21 16:30:16,873 - log/train6.log - INFO - new best test f1 score:81.880
2019-02-21 16:30:19,153 - log/train6.log - INFO - iteration:7 step:100/10100, NER loss:74.056046
2019-02-21 16:30:23,026 - log/train6.log - INFO - iteration:7 step:200/10100, NER loss:547.806274
2019-02-21 16:30:25,404 - log/train6.log - INFO - iteration:7 step:300/10100, NER loss:59.450962
2019-02-21 16:30:27,637 - log/train6.log - INFO - iteration:7 step:400/10100, NER loss:79.570618
2019-02-21 16:30:29,878 - log/train6.log - INFO - iteration:7 step:500/10100, NER loss:53.531742
2019-02-21 16:30:32,168 - log/train6.log - INFO - iteration:7 step:600/10100, NER loss:61.305782
2019-02-21 16:30:34,494 - log/train6.log - INFO - iteration:7 step:700/10100, NER loss:48.896786
2019-02-21 16:30:36,955 - log/train6.log - INFO - iteration:7 step:800/10100, NER loss:57.418941
2019-02-21 16:30:39,314 - log/train6.log - INFO - iteration:7 step:900/10100, NER loss:57.632511
2019-02-21 16:30:41,616 - log/train6.log - INFO - iteration:7 step:1000/10100, NER loss:58.087372
2019-02-21 16:30:43,881 - log/train6.log - INFO - iteration:7 step:1100/10100, NER loss:62.562252
2019-02-21 16:30:46,205 - log/train6.log - INFO - iteration:7 step:1200/10100, NER loss:70.502838
2019-02-21 16:30:48,393 - log/train6.log - INFO - iteration:7 step:1300/10100, NER loss:56.928722
2019-02-21 16:30:50,571 - log/train6.log - INFO - iteration:7 step:1400/10100, NER loss:62.171707
2019-02-21 16:30:52,721 - log/train6.log - INFO - iteration:7 step:1500/10100, NER loss:46.727974
2019-02-21 16:30:55,015 - log/train6.log - INFO - iteration:7 step:1600/10100, NER loss:58.642879
2019-02-21 16:30:57,189 - log/train6.log - INFO - iteration:7 step:1700/10100, NER loss:63.036057
2019-02-21 16:30:59,225 - log/train6.log - INFO - iteration:7 step:1800/10100, NER loss:56.493404
2019-02-21 16:31:01,433 - log/train6.log - INFO - iteration:7 step:1900/10100, NER loss:68.885002
2019-02-21 16:31:03,656 - log/train6.log - INFO - iteration:7 step:2000/10100, NER loss:59.012066
2019-02-21 16:31:06,120 - log/train6.log - INFO - iteration:7 step:2100/10100, NER loss:61.958187
2019-02-21 16:31:08,453 - log/train6.log - INFO - iteration:7 step:2200/10100, NER loss:55.807705
2019-02-21 16:31:10,795 - log/train6.log - INFO - iteration:7 step:2300/10100, NER loss:77.061951
2019-02-21 16:31:13,213 - log/train6.log - INFO - iteration:7 step:2400/10100, NER loss:59.822681
2019-02-21 16:31:16,020 - log/train6.log - INFO - iteration:7 step:2500/10100, NER loss:101.400414
2019-02-21 16:31:18,197 - log/train6.log - INFO - iteration:7 step:2600/10100, NER loss:56.245907
2019-02-21 16:31:20,462 - log/train6.log - INFO - iteration:7 step:2700/10100, NER loss:59.808208
2019-02-21 16:31:22,749 - log/train6.log - INFO - iteration:7 step:2800/10100, NER loss:60.522831
2019-02-21 16:31:24,992 - log/train6.log - INFO - iteration:7 step:2900/10100, NER loss:44.311466
2019-02-21 16:31:27,333 - log/train6.log - INFO - iteration:7 step:3000/10100, NER loss:64.942169
2019-02-21 16:31:29,536 - log/train6.log - INFO - iteration:7 step:3100/10100, NER loss:59.192917
2019-02-21 16:31:31,864 - log/train6.log - INFO - iteration:7 step:3200/10100, NER loss:87.715332
2019-02-21 16:31:34,075 - log/train6.log - INFO - iteration:7 step:3300/10100, NER loss:64.464981
2019-02-21 16:31:36,298 - log/train6.log - INFO - iteration:7 step:3400/10100, NER loss:61.261719
2019-02-21 16:31:38,851 - log/train6.log - INFO - iteration:7 step:3500/10100, NER loss:90.508415
2019-02-21 16:31:43,607 - log/train6.log - INFO - iteration:7 step:3600/10100, NER loss:125.990990
2019-02-21 16:31:45,899 - log/train6.log - INFO - iteration:7 step:3700/10100, NER loss:54.344219
2019-02-21 16:31:48,097 - log/train6.log - INFO - iteration:7 step:3800/10100, NER loss:53.979424
2019-02-21 16:31:50,180 - log/train6.log - INFO - iteration:7 step:3900/10100, NER loss:64.274368
2019-02-21 16:31:52,432 - log/train6.log - INFO - iteration:7 step:4000/10100, NER loss:64.100388
2019-02-21 16:31:54,725 - log/train6.log - INFO - iteration:7 step:4100/10100, NER loss:67.820335
2019-02-21 16:31:57,080 - log/train6.log - INFO - iteration:7 step:4200/10100, NER loss:56.438332
2019-02-21 16:31:59,447 - log/train6.log - INFO - iteration:7 step:4300/10100, NER loss:74.969749
2019-02-21 16:32:01,507 - log/train6.log - INFO - iteration:7 step:4400/10100, NER loss:46.686665
2019-02-21 16:32:03,747 - log/train6.log - INFO - iteration:7 step:4500/10100, NER loss:65.178024
2019-02-21 16:32:05,999 - log/train6.log - INFO - iteration:7 step:4600/10100, NER loss:61.832748
2019-02-21 16:32:08,159 - log/train6.log - INFO - iteration:7 step:4700/10100, NER loss:49.463627
2019-02-21 16:32:10,221 - log/train6.log - INFO - iteration:7 step:4800/10100, NER loss:45.991554
2019-02-21 16:32:12,232 - log/train6.log - INFO - iteration:7 step:4900/10100, NER loss:57.773075
2019-02-21 16:32:14,466 - log/train6.log - INFO - iteration:7 step:5000/10100, NER loss:68.992867
2019-02-21 16:32:16,571 - log/train6.log - INFO - iteration:7 step:5100/10100, NER loss:52.914658
2019-02-21 16:32:18,813 - log/train6.log - INFO - iteration:7 step:5200/10100, NER loss:73.472237
2019-02-21 16:32:21,184 - log/train6.log - INFO - iteration:7 step:5300/10100, NER loss:60.056244
2019-02-21 16:32:23,477 - log/train6.log - INFO - iteration:7 step:5400/10100, NER loss:55.966339
2019-02-21 16:32:25,751 - log/train6.log - INFO - iteration:7 step:5500/10100, NER loss:54.455997
2019-02-21 16:32:28,155 - log/train6.log - INFO - iteration:7 step:5600/10100, NER loss:73.471779
2019-02-21 16:32:30,699 - log/train6.log - INFO - iteration:7 step:5700/10100, NER loss:72.640816
2019-02-21 16:32:32,762 - log/train6.log - INFO - iteration:7 step:5800/10100, NER loss:48.844795
2019-02-21 16:32:35,289 - log/train6.log - INFO - iteration:7 step:5900/10100, NER loss:67.778778
2019-02-21 16:32:37,595 - log/train6.log - INFO - iteration:7 step:6000/10100, NER loss:48.508141
2019-02-21 16:32:39,720 - log/train6.log - INFO - iteration:7 step:6100/10100, NER loss:60.590565
2019-02-21 16:32:41,840 - log/train6.log - INFO - iteration:7 step:6200/10100, NER loss:58.630295
2019-02-21 16:32:43,909 - log/train6.log - INFO - iteration:7 step:6300/10100, NER loss:49.754395
2019-02-21 16:32:46,017 - log/train6.log - INFO - iteration:7 step:6400/10100, NER loss:54.735161
2019-02-21 16:32:48,323 - log/train6.log - INFO - iteration:7 step:6500/10100, NER loss:49.197426
2019-02-21 16:32:50,578 - log/train6.log - INFO - iteration:7 step:6600/10100, NER loss:61.547890
2019-02-21 16:32:52,670 - log/train6.log - INFO - iteration:7 step:6700/10100, NER loss:45.181053
2019-02-21 16:32:54,787 - log/train6.log - INFO - iteration:7 step:6800/10100, NER loss:58.270142
2019-02-21 16:32:57,179 - log/train6.log - INFO - iteration:7 step:6900/10100, NER loss:60.550663
2019-02-21 16:32:59,345 - log/train6.log - INFO - iteration:7 step:7000/10100, NER loss:81.304253
2019-02-21 16:33:01,494 - log/train6.log - INFO - iteration:7 step:7100/10100, NER loss:64.282166
2019-02-21 16:33:03,763 - log/train6.log - INFO - iteration:7 step:7200/10100, NER loss:53.814342
2019-02-21 16:33:06,057 - log/train6.log - INFO - iteration:7 step:7300/10100, NER loss:64.796989
2019-02-21 16:33:08,309 - log/train6.log - INFO - iteration:7 step:7400/10100, NER loss:57.436535
2019-02-21 16:33:10,438 - log/train6.log - INFO - iteration:7 step:7500/10100, NER loss:53.542381
2019-02-21 16:33:12,536 - log/train6.log - INFO - iteration:7 step:7600/10100, NER loss:40.794861
2019-02-21 16:33:14,878 - log/train6.log - INFO - iteration:7 step:7700/10100, NER loss:53.581711
2019-02-21 16:33:17,397 - log/train6.log - INFO - iteration:7 step:7800/10100, NER loss:58.640976
2019-02-21 16:33:19,572 - log/train6.log - INFO - iteration:7 step:7900/10100, NER loss:47.506783
2019-02-21 16:33:21,677 - log/train6.log - INFO - iteration:7 step:8000/10100, NER loss:47.160946
2019-02-21 16:33:23,792 - log/train6.log - INFO - iteration:7 step:8100/10100, NER loss:65.420364
2019-02-21 16:33:25,964 - log/train6.log - INFO - iteration:7 step:8200/10100, NER loss:60.189335
2019-02-21 16:33:30,230 - log/train6.log - INFO - iteration:7 step:8300/10100, NER loss:140.688263
2019-02-21 16:33:32,415 - log/train6.log - INFO - iteration:7 step:8400/10100, NER loss:47.769886
2019-02-21 16:33:34,732 - log/train6.log - INFO - iteration:7 step:8500/10100, NER loss:44.859009
2019-02-21 16:33:37,218 - log/train6.log - INFO - iteration:7 step:8600/10100, NER loss:69.892815
2019-02-21 16:33:39,621 - log/train6.log - INFO - iteration:7 step:8700/10100, NER loss:47.221344
2019-02-21 16:33:41,862 - log/train6.log - INFO - iteration:7 step:8800/10100, NER loss:43.232574
2019-02-21 16:33:44,183 - log/train6.log - INFO - iteration:7 step:8900/10100, NER loss:52.775635
2019-02-21 16:33:46,514 - log/train6.log - INFO - iteration:7 step:9000/10100, NER loss:67.727356
2019-02-21 16:33:48,567 - log/train6.log - INFO - iteration:7 step:9100/10100, NER loss:46.151264
2019-02-21 16:33:50,872 - log/train6.log - INFO - iteration:7 step:9200/10100, NER loss:44.991558
2019-02-21 16:33:52,991 - log/train6.log - INFO - iteration:7 step:9300/10100, NER loss:41.207809
2019-02-21 16:33:55,068 - log/train6.log - INFO - iteration:7 step:9400/10100, NER loss:52.159218
2019-02-21 16:33:57,261 - log/train6.log - INFO - iteration:7 step:9500/10100, NER loss:35.552326
2019-02-21 16:33:59,499 - log/train6.log - INFO - iteration:7 step:9600/10100, NER loss:47.428104
2019-02-21 16:34:01,632 - log/train6.log - INFO - iteration:7 step:9700/10100, NER loss:55.561047
2019-02-21 16:34:03,931 - log/train6.log - INFO - iteration:7 step:9800/10100, NER loss:38.481220
2019-02-21 16:34:06,180 - log/train6.log - INFO - iteration:7 step:9900/10100, NER loss:49.836647
2019-02-21 16:34:08,246 - log/train6.log - INFO - iteration:7 step:10000/10100, NER loss:51.927769
2019-02-21 16:34:10,447 - log/train6.log - INFO - iteration:8 step:0/10100, NER loss:47.124840
2019-02-21 16:34:10,447 - log/train6.log - INFO - evaluate:dev
2019-02-21 16:34:16,941 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5328 phrases; correct: 3925.

2019-02-21 16:34:16,942 - log/train6.log - INFO - accuracy:  94.92%; precision:  73.67%; recall:  67.13%; FB1:  70.25

2019-02-21 16:34:16,942 - log/train6.log - INFO -                 C: precision:  85.70%; recall:  88.08%; FB1:  86.87  3483

2019-02-21 16:34:16,942 - log/train6.log - INFO -               IND: precision:  44.74%; recall:  25.00%; FB1:  32.08  228

2019-02-21 16:34:16,942 - log/train6.log - INFO -               INS: precision:  68.83%; recall:  69.92%; FB1:  69.37  385

2019-02-21 16:34:16,943 - log/train6.log - INFO -                 L: precision:   0.67%; recall:   0.50%; FB1:   0.57  447

2019-02-21 16:34:16,943 - log/train6.log - INFO -                 P: precision:  81.63%; recall:  92.45%; FB1:  86.70  615

2019-02-21 16:34:16,943 - log/train6.log - INFO -               PRO: precision:  40.00%; recall:  13.03%; FB1:  19.65  170

2019-02-21 16:34:16,948 - log/train6.log - INFO - evaluate:test
2019-02-21 16:34:18,407 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1572 phrases; correct: 1293.

2019-02-21 16:34:18,407 - log/train6.log - INFO - accuracy:  96.65%; precision:  82.25%; recall:  78.51%; FB1:  80.34

2019-02-21 16:34:18,407 - log/train6.log - INFO -                 C: precision:  89.31%; recall:  92.52%; FB1:  90.88  1066

2019-02-21 16:34:18,407 - log/train6.log - INFO -               IND: precision:  72.09%; recall:  65.96%; FB1:  68.89  43

2019-02-21 16:34:18,407 - log/train6.log - INFO -               INS: precision:  69.77%; recall:  63.16%; FB1:  66.30  86

2019-02-21 16:34:18,407 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  86

2019-02-21 16:34:18,407 - log/train6.log - INFO -                 P: precision:  88.89%; recall:  94.12%; FB1:  91.43  216

2019-02-21 16:34:18,407 - log/train6.log - INFO -               PRO: precision:  77.33%; recall:  34.32%; FB1:  47.54  75

2019-02-21 16:34:20,663 - log/train6.log - INFO - iteration:8 step:100/10100, NER loss:59.261318
2019-02-21 16:34:22,858 - log/train6.log - INFO - iteration:8 step:200/10100, NER loss:71.273224
2019-02-21 16:34:25,273 - log/train6.log - INFO - iteration:8 step:300/10100, NER loss:48.552345
2019-02-21 16:34:27,660 - log/train6.log - INFO - iteration:8 step:400/10100, NER loss:38.684147
2019-02-21 16:34:30,028 - log/train6.log - INFO - iteration:8 step:500/10100, NER loss:60.727516
2019-02-21 16:34:32,318 - log/train6.log - INFO - iteration:8 step:600/10100, NER loss:54.770496
2019-02-21 16:34:34,502 - log/train6.log - INFO - iteration:8 step:700/10100, NER loss:55.855412
2019-02-21 16:34:36,688 - log/train6.log - INFO - iteration:8 step:800/10100, NER loss:54.381290
2019-02-21 16:34:38,954 - log/train6.log - INFO - iteration:8 step:900/10100, NER loss:53.219242
2019-02-21 16:34:43,782 - log/train6.log - INFO - iteration:8 step:1000/10100, NER loss:115.562874
2019-02-21 16:34:45,851 - log/train6.log - INFO - iteration:8 step:1100/10100, NER loss:51.304844
2019-02-21 16:34:48,182 - log/train6.log - INFO - iteration:8 step:1200/10100, NER loss:64.832939
2019-02-21 16:34:50,330 - log/train6.log - INFO - iteration:8 step:1300/10100, NER loss:63.435707
2019-02-21 16:34:52,397 - log/train6.log - INFO - iteration:8 step:1400/10100, NER loss:48.077114
2019-02-21 16:34:54,758 - log/train6.log - INFO - iteration:8 step:1500/10100, NER loss:83.203400
2019-02-21 16:34:56,892 - log/train6.log - INFO - iteration:8 step:1600/10100, NER loss:52.303879
2019-02-21 16:34:58,967 - log/train6.log - INFO - iteration:8 step:1700/10100, NER loss:38.043488
2019-02-21 16:35:01,179 - log/train6.log - INFO - iteration:8 step:1800/10100, NER loss:52.205711
2019-02-21 16:35:03,385 - log/train6.log - INFO - iteration:8 step:1900/10100, NER loss:53.264111
2019-02-21 16:35:05,814 - log/train6.log - INFO - iteration:8 step:2000/10100, NER loss:54.945122
2019-02-21 16:35:07,997 - log/train6.log - INFO - iteration:8 step:2100/10100, NER loss:47.522636
2019-02-21 16:35:09,981 - log/train6.log - INFO - iteration:8 step:2200/10100, NER loss:38.058121
2019-02-21 16:35:12,224 - log/train6.log - INFO - iteration:8 step:2300/10100, NER loss:52.175491
2019-02-21 16:35:14,440 - log/train6.log - INFO - iteration:8 step:2400/10100, NER loss:50.594200
2019-02-21 16:35:16,645 - log/train6.log - INFO - iteration:8 step:2500/10100, NER loss:44.134533
2019-02-21 16:35:19,426 - log/train6.log - INFO - iteration:8 step:2600/10100, NER loss:77.274078
2019-02-21 16:35:21,767 - log/train6.log - INFO - iteration:8 step:2700/10100, NER loss:64.924637
2019-02-21 16:35:24,100 - log/train6.log - INFO - iteration:8 step:2800/10100, NER loss:45.951969
2019-02-21 16:35:26,189 - log/train6.log - INFO - iteration:8 step:2900/10100, NER loss:50.442207
2019-02-21 16:35:28,525 - log/train6.log - INFO - iteration:8 step:3000/10100, NER loss:48.950287
2019-02-21 16:35:30,839 - log/train6.log - INFO - iteration:8 step:3100/10100, NER loss:58.277260
2019-02-21 16:35:33,106 - log/train6.log - INFO - iteration:8 step:3200/10100, NER loss:48.668442
2019-02-21 16:35:35,462 - log/train6.log - INFO - iteration:8 step:3300/10100, NER loss:55.585815
2019-02-21 16:35:37,551 - log/train6.log - INFO - iteration:8 step:3400/10100, NER loss:55.033394
2019-02-21 16:35:39,929 - log/train6.log - INFO - iteration:8 step:3500/10100, NER loss:44.840118
2019-02-21 16:35:42,083 - log/train6.log - INFO - iteration:8 step:3600/10100, NER loss:43.164619
2019-02-21 16:35:44,264 - log/train6.log - INFO - iteration:8 step:3700/10100, NER loss:61.310421
2019-02-21 16:35:46,513 - log/train6.log - INFO - iteration:8 step:3800/10100, NER loss:58.750107
2019-02-21 16:35:49,150 - log/train6.log - INFO - iteration:8 step:3900/10100, NER loss:71.160950
2019-02-21 16:35:51,240 - log/train6.log - INFO - iteration:8 step:4000/10100, NER loss:43.378178
2019-02-21 16:35:53,637 - log/train6.log - INFO - iteration:8 step:4100/10100, NER loss:47.518345
2019-02-21 16:35:56,007 - log/train6.log - INFO - iteration:8 step:4200/10100, NER loss:62.872108
2019-02-21 16:35:58,120 - log/train6.log - INFO - iteration:8 step:4300/10100, NER loss:42.790001
2019-02-21 16:36:00,564 - log/train6.log - INFO - iteration:8 step:4400/10100, NER loss:76.294846
2019-02-21 16:36:02,850 - log/train6.log - INFO - iteration:8 step:4500/10100, NER loss:52.554008
2019-02-21 16:36:05,053 - log/train6.log - INFO - iteration:8 step:4600/10100, NER loss:55.348000
2019-02-21 16:36:07,320 - log/train6.log - INFO - iteration:8 step:4700/10100, NER loss:38.483631
2019-02-21 16:36:11,504 - log/train6.log - INFO - iteration:8 step:4800/10100, NER loss:109.769798
2019-02-21 16:36:13,609 - log/train6.log - INFO - iteration:8 step:4900/10100, NER loss:47.321579
2019-02-21 16:36:15,853 - log/train6.log - INFO - iteration:8 step:5000/10100, NER loss:53.769375
2019-02-21 16:36:18,239 - log/train6.log - INFO - iteration:8 step:5100/10100, NER loss:43.275143
2019-02-21 16:36:20,325 - log/train6.log - INFO - iteration:8 step:5200/10100, NER loss:63.420841
2019-02-21 16:36:22,604 - log/train6.log - INFO - iteration:8 step:5300/10100, NER loss:62.677471
2019-02-21 16:36:24,852 - log/train6.log - INFO - iteration:8 step:5400/10100, NER loss:49.959682
2019-02-21 16:36:26,997 - log/train6.log - INFO - iteration:8 step:5500/10100, NER loss:48.420998
2019-02-21 16:36:29,284 - log/train6.log - INFO - iteration:8 step:5600/10100, NER loss:62.704834
2019-02-21 16:36:31,287 - log/train6.log - INFO - iteration:8 step:5700/10100, NER loss:38.804016
2019-02-21 16:36:33,425 - log/train6.log - INFO - iteration:8 step:5800/10100, NER loss:38.109180
2019-02-21 16:36:35,575 - log/train6.log - INFO - iteration:8 step:5900/10100, NER loss:41.624584
2019-02-21 16:36:37,757 - log/train6.log - INFO - iteration:8 step:6000/10100, NER loss:55.032768
2019-02-21 16:36:40,049 - log/train6.log - INFO - iteration:8 step:6100/10100, NER loss:52.117382
2019-02-21 16:36:42,243 - log/train6.log - INFO - iteration:8 step:6200/10100, NER loss:41.658325
2019-02-21 16:36:44,820 - log/train6.log - INFO - iteration:8 step:6300/10100, NER loss:52.567852
2019-02-21 16:36:47,151 - log/train6.log - INFO - iteration:8 step:6400/10100, NER loss:49.285423
2019-02-21 16:36:49,250 - log/train6.log - INFO - iteration:8 step:6500/10100, NER loss:56.390678
2019-02-21 16:36:51,120 - log/train6.log - INFO - iteration:8 step:6600/10100, NER loss:36.860306
2019-02-21 16:36:53,230 - log/train6.log - INFO - iteration:8 step:6700/10100, NER loss:62.822506
2019-02-21 16:36:55,425 - log/train6.log - INFO - iteration:8 step:6800/10100, NER loss:43.732231
2019-02-21 16:36:57,863 - log/train6.log - INFO - iteration:8 step:6900/10100, NER loss:51.961315
2019-02-21 16:36:59,986 - log/train6.log - INFO - iteration:8 step:7000/10100, NER loss:46.329891
2019-02-21 16:37:02,486 - log/train6.log - INFO - iteration:8 step:7100/10100, NER loss:61.556602
2019-02-21 16:37:04,572 - log/train6.log - INFO - iteration:8 step:7200/10100, NER loss:37.315380
2019-02-21 16:37:06,579 - log/train6.log - INFO - iteration:8 step:7300/10100, NER loss:52.129360
2019-02-21 16:37:08,704 - log/train6.log - INFO - iteration:8 step:7400/10100, NER loss:51.670570
2019-02-21 16:37:10,841 - log/train6.log - INFO - iteration:8 step:7500/10100, NER loss:50.473663
2019-02-21 16:37:13,042 - log/train6.log - INFO - iteration:8 step:7600/10100, NER loss:56.297928
2019-02-21 16:37:15,169 - log/train6.log - INFO - iteration:8 step:7700/10100, NER loss:44.248241
2019-02-21 16:37:17,531 - log/train6.log - INFO - iteration:8 step:7800/10100, NER loss:45.986515
2019-02-21 16:37:19,725 - log/train6.log - INFO - iteration:8 step:7900/10100, NER loss:40.600441
2019-02-21 16:37:22,230 - log/train6.log - INFO - iteration:8 step:8000/10100, NER loss:55.123714
2019-02-21 16:37:24,468 - log/train6.log - INFO - iteration:8 step:8100/10100, NER loss:53.830353
2019-02-21 16:37:26,691 - log/train6.log - INFO - iteration:8 step:8200/10100, NER loss:48.686543
2019-02-21 16:37:28,815 - log/train6.log - INFO - iteration:8 step:8300/10100, NER loss:34.977360
2019-02-21 16:37:31,183 - log/train6.log - INFO - iteration:8 step:8400/10100, NER loss:48.458351
2019-02-21 16:37:33,647 - log/train6.log - INFO - iteration:8 step:8500/10100, NER loss:57.533672
2019-02-21 16:37:36,179 - log/train6.log - INFO - iteration:8 step:8600/10100, NER loss:56.021378
2019-02-21 16:37:38,380 - log/train6.log - INFO - iteration:8 step:8700/10100, NER loss:49.584850
2019-02-21 16:37:40,504 - log/train6.log - INFO - iteration:8 step:8800/10100, NER loss:37.882572
2019-02-21 16:37:42,665 - log/train6.log - INFO - iteration:8 step:8900/10100, NER loss:40.372440
2019-02-21 16:37:44,747 - log/train6.log - INFO - iteration:8 step:9000/10100, NER loss:34.931179
2019-02-21 16:37:46,996 - log/train6.log - INFO - iteration:8 step:9100/10100, NER loss:52.299076
2019-02-21 16:37:51,124 - log/train6.log - INFO - iteration:8 step:9200/10100, NER loss:445.896332
2019-02-21 16:37:53,141 - log/train6.log - INFO - iteration:8 step:9300/10100, NER loss:54.244827
2019-02-21 16:37:55,451 - log/train6.log - INFO - iteration:8 step:9400/10100, NER loss:36.650368
2019-02-21 16:37:57,644 - log/train6.log - INFO - iteration:8 step:9500/10100, NER loss:49.017265
2019-02-21 16:37:59,898 - log/train6.log - INFO - iteration:8 step:9600/10100, NER loss:56.619652
2019-02-21 16:38:02,008 - log/train6.log - INFO - iteration:8 step:9700/10100, NER loss:34.013630
2019-02-21 16:38:04,304 - log/train6.log - INFO - iteration:8 step:9800/10100, NER loss:63.145340
2019-02-21 16:38:06,394 - log/train6.log - INFO - iteration:8 step:9900/10100, NER loss:42.514095
2019-02-21 16:38:08,601 - log/train6.log - INFO - iteration:8 step:10000/10100, NER loss:35.385391
2019-02-21 16:38:10,508 - log/train6.log - INFO - iteration:9 step:0/10100, NER loss:34.591644
2019-02-21 16:38:10,508 - log/train6.log - INFO - evaluate:dev
2019-02-21 16:38:17,027 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5649 phrases; correct: 3963.

2019-02-21 16:38:17,028 - log/train6.log - INFO - accuracy:  94.96%; precision:  70.15%; recall:  67.78%; FB1:  68.95

2019-02-21 16:38:17,028 - log/train6.log - INFO -                 C: precision:  82.04%; recall:  88.58%; FB1:  85.19  3659

2019-02-21 16:38:17,028 - log/train6.log - INFO -               IND: precision:  46.22%; recall:  26.96%; FB1:  34.06  238

2019-02-21 16:38:17,028 - log/train6.log - INFO -               INS: precision:  60.13%; recall:  72.03%; FB1:  65.55  454

2019-02-21 16:38:17,029 - log/train6.log - INFO -                 L: precision:   0.55%; recall:   0.50%; FB1:   0.52  541

2019-02-21 16:38:17,029 - log/train6.log - INFO -                 P: precision:  90.86%; recall:  91.53%; FB1:  91.19  547

2019-02-21 16:38:17,029 - log/train6.log - INFO -               PRO: precision:  37.14%; recall:  14.94%; FB1:  21.31  210

2019-02-21 16:38:17,032 - log/train6.log - INFO - evaluate:test
2019-02-21 16:38:18,481 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1618 phrases; correct: 1319.

2019-02-21 16:38:18,481 - log/train6.log - INFO - accuracy:  96.96%; precision:  81.52%; recall:  80.09%; FB1:  80.80

2019-02-21 16:38:18,481 - log/train6.log - INFO -                 C: precision:  88.80%; recall:  93.20%; FB1:  90.94  1080

2019-02-21 16:38:18,481 - log/train6.log - INFO -               IND: precision:  63.04%; recall:  61.70%; FB1:  62.37  46

2019-02-21 16:38:18,481 - log/train6.log - INFO -               INS: precision:  68.69%; recall:  71.58%; FB1:  70.10  99

2019-02-21 16:38:18,481 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  98

2019-02-21 16:38:18,481 - log/train6.log - INFO -                 P: precision:  92.79%; recall:  94.61%; FB1:  93.69  208

2019-02-21 16:38:18,481 - log/train6.log - INFO -               PRO: precision:  80.46%; recall:  41.42%; FB1:  54.69  87

2019-02-21 16:38:20,421 - log/train6.log - INFO - iteration:9 step:100/10100, NER loss:40.611618
2019-02-21 16:38:22,415 - log/train6.log - INFO - iteration:9 step:200/10100, NER loss:30.559265
2019-02-21 16:38:24,892 - log/train6.log - INFO - iteration:9 step:300/10100, NER loss:45.272263
2019-02-21 16:38:27,034 - log/train6.log - INFO - iteration:9 step:400/10100, NER loss:38.828617
2019-02-21 16:38:29,479 - log/train6.log - INFO - iteration:9 step:500/10100, NER loss:53.189491
2019-02-21 16:38:31,783 - log/train6.log - INFO - iteration:9 step:600/10100, NER loss:52.273880
2019-02-21 16:38:33,964 - log/train6.log - INFO - iteration:9 step:700/10100, NER loss:40.187965
2019-02-21 16:38:35,995 - log/train6.log - INFO - iteration:9 step:800/10100, NER loss:42.997089
2019-02-21 16:38:38,129 - log/train6.log - INFO - iteration:9 step:900/10100, NER loss:44.666519
2019-02-21 16:38:40,239 - log/train6.log - INFO - iteration:9 step:1000/10100, NER loss:34.032078
2019-02-21 16:38:42,512 - log/train6.log - INFO - iteration:9 step:1100/10100, NER loss:48.822121
2019-02-21 16:38:47,070 - log/train6.log - INFO - iteration:9 step:1200/10100, NER loss:127.930214
2019-02-21 16:38:49,015 - log/train6.log - INFO - iteration:9 step:1300/10100, NER loss:33.416733
2019-02-21 16:38:51,348 - log/train6.log - INFO - iteration:9 step:1400/10100, NER loss:34.452343
2019-02-21 16:38:53,466 - log/train6.log - INFO - iteration:9 step:1500/10100, NER loss:42.989044
2019-02-21 16:38:55,820 - log/train6.log - INFO - iteration:9 step:1600/10100, NER loss:58.062721
2019-02-21 16:38:58,001 - log/train6.log - INFO - iteration:9 step:1700/10100, NER loss:46.601288
2019-02-21 16:39:00,283 - log/train6.log - INFO - iteration:9 step:1800/10100, NER loss:41.772682
2019-02-21 16:39:02,296 - log/train6.log - INFO - iteration:9 step:1900/10100, NER loss:44.585171
2019-02-21 16:39:04,314 - log/train6.log - INFO - iteration:9 step:2000/10100, NER loss:38.473145
2019-02-21 16:39:06,833 - log/train6.log - INFO - iteration:9 step:2100/10100, NER loss:41.577671
2019-02-21 16:39:09,176 - log/train6.log - INFO - iteration:9 step:2200/10100, NER loss:59.795204
2019-02-21 16:39:11,265 - log/train6.log - INFO - iteration:9 step:2300/10100, NER loss:51.935368
2019-02-21 16:39:13,615 - log/train6.log - INFO - iteration:9 step:2400/10100, NER loss:41.783882
2019-02-21 16:39:15,786 - log/train6.log - INFO - iteration:9 step:2500/10100, NER loss:31.735247
2019-02-21 16:39:18,242 - log/train6.log - INFO - iteration:9 step:2600/10100, NER loss:48.985996
2019-02-21 16:39:20,714 - log/train6.log - INFO - iteration:9 step:2700/10100, NER loss:63.133411
2019-02-21 16:39:22,893 - log/train6.log - INFO - iteration:9 step:2800/10100, NER loss:28.823538
2019-02-21 16:39:25,064 - log/train6.log - INFO - iteration:9 step:2900/10100, NER loss:43.794056
2019-02-21 16:39:26,920 - log/train6.log - INFO - iteration:9 step:3000/10100, NER loss:32.441479
2019-02-21 16:39:29,100 - log/train6.log - INFO - iteration:9 step:3100/10100, NER loss:38.445717
2019-02-21 16:39:31,146 - log/train6.log - INFO - iteration:9 step:3200/10100, NER loss:43.256744
2019-02-21 16:39:33,370 - log/train6.log - INFO - iteration:9 step:3300/10100, NER loss:32.474987
2019-02-21 16:39:35,540 - log/train6.log - INFO - iteration:9 step:3400/10100, NER loss:43.095127
2019-02-21 16:39:37,640 - log/train6.log - INFO - iteration:9 step:3500/10100, NER loss:53.142635
2019-02-21 16:39:40,292 - log/train6.log - INFO - iteration:9 step:3600/10100, NER loss:69.081970
2019-02-21 16:39:42,646 - log/train6.log - INFO - iteration:9 step:3700/10100, NER loss:50.851528
2019-02-21 16:39:44,908 - log/train6.log - INFO - iteration:9 step:3800/10100, NER loss:44.139694
2019-02-21 16:39:47,196 - log/train6.log - INFO - iteration:9 step:3900/10100, NER loss:55.624950
2019-02-21 16:39:49,501 - log/train6.log - INFO - iteration:9 step:4000/10100, NER loss:42.865612
2019-02-21 16:39:51,688 - log/train6.log - INFO - iteration:9 step:4100/10100, NER loss:50.052700
2019-02-21 16:39:53,724 - log/train6.log - INFO - iteration:9 step:4200/10100, NER loss:48.468651
2019-02-21 16:39:56,113 - log/train6.log - INFO - iteration:9 step:4300/10100, NER loss:63.492252
2019-02-21 16:39:58,368 - log/train6.log - INFO - iteration:9 step:4400/10100, NER loss:43.025997
2019-02-21 16:40:00,609 - log/train6.log - INFO - iteration:9 step:4500/10100, NER loss:53.358032
2019-02-21 16:40:02,902 - log/train6.log - INFO - iteration:9 step:4600/10100, NER loss:45.514229
2019-02-21 16:40:05,075 - log/train6.log - INFO - iteration:9 step:4700/10100, NER loss:47.593910
2019-02-21 16:40:07,122 - log/train6.log - INFO - iteration:9 step:4800/10100, NER loss:43.399849
2019-02-21 16:40:09,288 - log/train6.log - INFO - iteration:9 step:4900/10100, NER loss:45.034122
2019-02-21 16:40:11,602 - log/train6.log - INFO - iteration:9 step:5000/10100, NER loss:41.070580
2019-02-21 16:40:13,632 - log/train6.log - INFO - iteration:9 step:5100/10100, NER loss:33.386391
2019-02-21 16:40:15,642 - log/train6.log - INFO - iteration:9 step:5200/10100, NER loss:37.792297
2019-02-21 16:40:17,827 - log/train6.log - INFO - iteration:9 step:5300/10100, NER loss:34.617714
2019-02-21 16:40:20,081 - log/train6.log - INFO - iteration:9 step:5400/10100, NER loss:43.128922
2019-02-21 16:40:22,117 - log/train6.log - INFO - iteration:9 step:5500/10100, NER loss:43.626877
2019-02-21 16:40:24,281 - log/train6.log - INFO - iteration:9 step:5600/10100, NER loss:35.792519
2019-02-21 16:40:26,492 - log/train6.log - INFO - iteration:9 step:5700/10100, NER loss:46.617775
2019-02-21 16:40:28,823 - log/train6.log - INFO - iteration:9 step:5800/10100, NER loss:38.809547
2019-02-21 16:40:31,078 - log/train6.log - INFO - iteration:9 step:5900/10100, NER loss:36.005077
2019-02-21 16:40:33,376 - log/train6.log - INFO - iteration:9 step:6000/10100, NER loss:39.766605
2019-02-21 16:40:35,487 - log/train6.log - INFO - iteration:9 step:6100/10100, NER loss:28.865147
2019-02-21 16:40:37,714 - log/train6.log - INFO - iteration:9 step:6200/10100, NER loss:41.623138
2019-02-21 16:40:39,991 - log/train6.log - INFO - iteration:9 step:6300/10100, NER loss:36.698418
2019-02-21 16:40:42,306 - log/train6.log - INFO - iteration:9 step:6400/10100, NER loss:38.404076
2019-02-21 16:40:44,733 - log/train6.log - INFO - iteration:9 step:6500/10100, NER loss:52.483345
2019-02-21 16:40:46,782 - log/train6.log - INFO - iteration:9 step:6600/10100, NER loss:38.831490
2019-02-21 16:40:48,964 - log/train6.log - INFO - iteration:9 step:6700/10100, NER loss:58.550743
2019-02-21 16:40:51,131 - log/train6.log - INFO - iteration:9 step:6800/10100, NER loss:31.535547
2019-02-21 16:40:53,252 - log/train6.log - INFO - iteration:9 step:6900/10100, NER loss:38.866219
2019-02-21 16:40:55,685 - log/train6.log - INFO - iteration:9 step:7000/10100, NER loss:53.669167
2019-02-21 16:40:58,144 - log/train6.log - INFO - iteration:9 step:7100/10100, NER loss:57.431572
2019-02-21 16:41:00,399 - log/train6.log - INFO - iteration:9 step:7200/10100, NER loss:44.770210
2019-02-21 16:41:02,735 - log/train6.log - INFO - iteration:9 step:7300/10100, NER loss:48.656094
2019-02-21 16:41:05,127 - log/train6.log - INFO - iteration:9 step:7400/10100, NER loss:55.806469
2019-02-21 16:41:07,123 - log/train6.log - INFO - iteration:9 step:7500/10100, NER loss:30.690630
2019-02-21 16:41:09,270 - log/train6.log - INFO - iteration:9 step:7600/10100, NER loss:30.870308
2019-02-21 16:41:13,498 - log/train6.log - INFO - iteration:9 step:7700/10100, NER loss:390.420898
2019-02-21 16:41:15,705 - log/train6.log - INFO - iteration:9 step:7800/10100, NER loss:56.455368
2019-02-21 16:41:17,954 - log/train6.log - INFO - iteration:9 step:7900/10100, NER loss:50.459522
2019-02-21 16:41:20,260 - log/train6.log - INFO - iteration:9 step:8000/10100, NER loss:38.354553
2019-02-21 16:41:22,476 - log/train6.log - INFO - iteration:9 step:8100/10100, NER loss:42.771572
2019-02-21 16:41:24,529 - log/train6.log - INFO - iteration:9 step:8200/10100, NER loss:39.203922
2019-02-21 16:41:26,761 - log/train6.log - INFO - iteration:9 step:8300/10100, NER loss:39.505424
2019-02-21 16:41:28,825 - log/train6.log - INFO - iteration:9 step:8400/10100, NER loss:27.802349
2019-02-21 16:41:31,058 - log/train6.log - INFO - iteration:9 step:8500/10100, NER loss:45.881546
2019-02-21 16:41:33,585 - log/train6.log - INFO - iteration:9 step:8600/10100, NER loss:39.100983
2019-02-21 16:41:35,826 - log/train6.log - INFO - iteration:9 step:8700/10100, NER loss:45.397995
2019-02-21 16:41:37,768 - log/train6.log - INFO - iteration:9 step:8800/10100, NER loss:22.865540
2019-02-21 16:41:40,150 - log/train6.log - INFO - iteration:9 step:8900/10100, NER loss:44.218849
2019-02-21 16:41:45,016 - log/train6.log - INFO - iteration:9 step:9000/10100, NER loss:97.788261
2019-02-21 16:41:47,435 - log/train6.log - INFO - iteration:9 step:9100/10100, NER loss:39.198334
2019-02-21 16:41:49,662 - log/train6.log - INFO - iteration:9 step:9200/10100, NER loss:29.871719
2019-02-21 16:41:51,935 - log/train6.log - INFO - iteration:9 step:9300/10100, NER loss:44.929672
2019-02-21 16:41:54,425 - log/train6.log - INFO - iteration:9 step:9400/10100, NER loss:55.346451
2019-02-21 16:41:56,867 - log/train6.log - INFO - iteration:9 step:9500/10100, NER loss:49.794022
2019-02-21 16:41:59,206 - log/train6.log - INFO - iteration:9 step:9600/10100, NER loss:39.360741
2019-02-21 16:42:01,367 - log/train6.log - INFO - iteration:9 step:9700/10100, NER loss:41.300762
2019-02-21 16:42:03,527 - log/train6.log - INFO - iteration:9 step:9800/10100, NER loss:39.782616
2019-02-21 16:42:05,879 - log/train6.log - INFO - iteration:9 step:9900/10100, NER loss:41.229015
2019-02-21 16:42:07,984 - log/train6.log - INFO - iteration:9 step:10000/10100, NER loss:22.551874
2019-02-21 16:42:10,309 - log/train6.log - INFO - iteration:10 step:0/10100, NER loss:40.750168
2019-02-21 16:42:10,309 - log/train6.log - INFO - evaluate:dev
2019-02-21 16:42:16,867 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5420 phrases; correct: 3920.

2019-02-21 16:42:16,867 - log/train6.log - INFO - accuracy:  94.70%; precision:  72.32%; recall:  67.04%; FB1:  69.58

2019-02-21 16:42:16,868 - log/train6.log - INFO -                 C: precision:  82.97%; recall:  87.81%; FB1:  85.32  3587

2019-02-21 16:42:16,868 - log/train6.log - INFO -               IND: precision:  43.12%; recall:  23.04%; FB1:  30.03  218

2019-02-21 16:42:16,868 - log/train6.log - INFO -               INS: precision:  68.93%; recall:  69.66%; FB1:  69.29  383

2019-02-21 16:42:16,868 - log/train6.log - INFO -                 L: precision:   0.52%; recall:   0.33%; FB1:   0.40  387

2019-02-21 16:42:16,868 - log/train6.log - INFO -                 P: precision:  89.73%; recall:  91.71%; FB1:  90.71  555

2019-02-21 16:42:16,868 - log/train6.log - INFO -               PRO: precision:  29.66%; recall:  16.48%; FB1:  21.18  290

2019-02-21 16:42:16,871 - log/train6.log - INFO - evaluate:test
2019-02-21 16:42:18,329 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1613 phrases; correct: 1301.

2019-02-21 16:42:18,329 - log/train6.log - INFO - accuracy:  96.86%; precision:  80.66%; recall:  78.99%; FB1:  79.82

2019-02-21 16:42:18,329 - log/train6.log - INFO -                 C: precision:  87.51%; recall:  92.61%; FB1:  89.99  1089

2019-02-21 16:42:18,329 - log/train6.log - INFO -               IND: precision:  65.91%; recall:  61.70%; FB1:  63.74  44

2019-02-21 16:42:18,329 - log/train6.log - INFO -               INS: precision:  71.91%; recall:  67.37%; FB1:  69.57  89

2019-02-21 16:42:18,330 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  81

2019-02-21 16:42:18,330 - log/train6.log - INFO -                 P: precision:  91.08%; recall:  95.10%; FB1:  93.05  213

2019-02-21 16:42:18,330 - log/train6.log - INFO -               PRO: precision:  62.89%; recall:  36.09%; FB1:  45.86  97

2019-02-21 16:42:20,427 - log/train6.log - INFO - iteration:10 step:100/10100, NER loss:42.051712
2019-02-21 16:42:22,409 - log/train6.log - INFO - iteration:10 step:200/10100, NER loss:31.906876
2019-02-21 16:42:24,585 - log/train6.log - INFO - iteration:10 step:300/10100, NER loss:42.665684
2019-02-21 16:42:26,865 - log/train6.log - INFO - iteration:10 step:400/10100, NER loss:42.669674
2019-02-21 16:42:28,999 - log/train6.log - INFO - iteration:10 step:500/10100, NER loss:32.162296
2019-02-21 16:42:31,095 - log/train6.log - INFO - iteration:10 step:600/10100, NER loss:36.317894
2019-02-21 16:42:33,332 - log/train6.log - INFO - iteration:10 step:700/10100, NER loss:42.493423
2019-02-21 16:42:35,723 - log/train6.log - INFO - iteration:10 step:800/10100, NER loss:46.678257
2019-02-21 16:42:37,884 - log/train6.log - INFO - iteration:10 step:900/10100, NER loss:38.302578
2019-02-21 16:42:40,023 - log/train6.log - INFO - iteration:10 step:1000/10100, NER loss:33.604687
2019-02-21 16:42:42,309 - log/train6.log - INFO - iteration:10 step:1100/10100, NER loss:38.656445
2019-02-21 16:42:44,579 - log/train6.log - INFO - iteration:10 step:1200/10100, NER loss:41.027843
2019-02-21 16:42:46,560 - log/train6.log - INFO - iteration:10 step:1300/10100, NER loss:28.608061
2019-02-21 16:42:48,812 - log/train6.log - INFO - iteration:10 step:1400/10100, NER loss:36.521801
2019-02-21 16:42:51,058 - log/train6.log - INFO - iteration:10 step:1500/10100, NER loss:31.626398
2019-02-21 16:42:53,218 - log/train6.log - INFO - iteration:10 step:1600/10100, NER loss:40.496933
2019-02-21 16:42:55,366 - log/train6.log - INFO - iteration:10 step:1700/10100, NER loss:38.910851
2019-02-21 16:42:57,612 - log/train6.log - INFO - iteration:10 step:1800/10100, NER loss:38.497120
2019-02-21 16:42:59,813 - log/train6.log - INFO - iteration:10 step:1900/10100, NER loss:30.045069
2019-02-21 16:43:02,027 - log/train6.log - INFO - iteration:10 step:2000/10100, NER loss:39.172352
2019-02-21 16:43:03,934 - log/train6.log - INFO - iteration:10 step:2100/10100, NER loss:31.246367
2019-02-21 16:43:06,074 - log/train6.log - INFO - iteration:10 step:2200/10100, NER loss:32.175854
2019-02-21 16:43:08,355 - log/train6.log - INFO - iteration:10 step:2300/10100, NER loss:31.800230
2019-02-21 16:43:10,359 - log/train6.log - INFO - iteration:10 step:2400/10100, NER loss:28.622158
2019-02-21 16:43:12,422 - log/train6.log - INFO - iteration:10 step:2500/10100, NER loss:33.985397
2019-02-21 16:43:14,941 - log/train6.log - INFO - iteration:10 step:2600/10100, NER loss:51.486053
2019-02-21 16:43:16,902 - log/train6.log - INFO - iteration:10 step:2700/10100, NER loss:45.162754
2019-02-21 16:43:19,412 - log/train6.log - INFO - iteration:10 step:2800/10100, NER loss:39.478859
2019-02-21 16:43:22,075 - log/train6.log - INFO - iteration:10 step:2900/10100, NER loss:32.407036
2019-02-21 16:43:24,783 - log/train6.log - INFO - iteration:10 step:3000/10100, NER loss:43.685635
2019-02-21 16:43:27,408 - log/train6.log - INFO - iteration:10 step:3100/10100, NER loss:30.160460
2019-02-21 16:43:29,908 - log/train6.log - INFO - iteration:10 step:3200/10100, NER loss:42.087189
2019-02-21 16:43:32,176 - log/train6.log - INFO - iteration:10 step:3300/10100, NER loss:30.094299
2019-02-21 16:43:34,653 - log/train6.log - INFO - iteration:10 step:3400/10100, NER loss:33.046043
2019-02-21 16:43:37,104 - log/train6.log - INFO - iteration:10 step:3500/10100, NER loss:41.944618
2019-02-21 16:43:39,352 - log/train6.log - INFO - iteration:10 step:3600/10100, NER loss:40.637142
2019-02-21 16:43:42,026 - log/train6.log - INFO - iteration:10 step:3700/10100, NER loss:50.793381
2019-02-21 16:43:44,517 - log/train6.log - INFO - iteration:10 step:3800/10100, NER loss:41.327606
2019-02-21 16:43:46,883 - log/train6.log - INFO - iteration:10 step:3900/10100, NER loss:31.441355
2019-02-21 16:43:49,150 - log/train6.log - INFO - iteration:10 step:4000/10100, NER loss:44.650002
2019-02-21 16:43:51,609 - log/train6.log - INFO - iteration:10 step:4100/10100, NER loss:38.840000
2019-02-21 16:43:56,065 - log/train6.log - INFO - iteration:10 step:4200/10100, NER loss:351.024414
2019-02-21 16:43:58,286 - log/train6.log - INFO - iteration:10 step:4300/10100, NER loss:44.038101
2019-02-21 16:44:00,758 - log/train6.log - INFO - iteration:10 step:4400/10100, NER loss:43.678123
2019-02-21 16:44:03,120 - log/train6.log - INFO - iteration:10 step:4500/10100, NER loss:31.554323
2019-02-21 16:44:07,780 - log/train6.log - INFO - iteration:10 step:4600/10100, NER loss:91.023102
2019-02-21 16:44:10,120 - log/train6.log - INFO - iteration:10 step:4700/10100, NER loss:27.039131
2019-02-21 16:44:12,465 - log/train6.log - INFO - iteration:10 step:4800/10100, NER loss:28.835266
2019-02-21 16:44:14,832 - log/train6.log - INFO - iteration:10 step:4900/10100, NER loss:30.985420
2019-02-21 16:44:17,187 - log/train6.log - INFO - iteration:10 step:5000/10100, NER loss:25.665159
2019-02-21 16:44:19,501 - log/train6.log - INFO - iteration:10 step:5100/10100, NER loss:31.982264
2019-02-21 16:44:22,001 - log/train6.log - INFO - iteration:10 step:5200/10100, NER loss:44.036339
2019-02-21 16:44:24,454 - log/train6.log - INFO - iteration:10 step:5300/10100, NER loss:35.269657
2019-02-21 16:44:26,727 - log/train6.log - INFO - iteration:10 step:5400/10100, NER loss:31.048002
2019-02-21 16:44:28,972 - log/train6.log - INFO - iteration:10 step:5500/10100, NER loss:42.531792
2019-02-21 16:44:31,164 - log/train6.log - INFO - iteration:10 step:5600/10100, NER loss:32.845715
2019-02-21 16:44:33,309 - log/train6.log - INFO - iteration:10 step:5700/10100, NER loss:38.601227
2019-02-21 16:44:35,766 - log/train6.log - INFO - iteration:10 step:5800/10100, NER loss:29.478775
2019-02-21 16:44:38,122 - log/train6.log - INFO - iteration:10 step:5900/10100, NER loss:29.661949
2019-02-21 16:44:40,334 - log/train6.log - INFO - iteration:10 step:6000/10100, NER loss:33.194313
2019-02-21 16:44:42,537 - log/train6.log - INFO - iteration:10 step:6100/10100, NER loss:39.238781
2019-02-21 16:44:44,925 - log/train6.log - INFO - iteration:10 step:6200/10100, NER loss:31.861794
2019-02-21 16:44:47,159 - log/train6.log - INFO - iteration:10 step:6300/10100, NER loss:36.004372
2019-02-21 16:44:49,153 - log/train6.log - INFO - iteration:10 step:6400/10100, NER loss:28.921162
2019-02-21 16:44:51,373 - log/train6.log - INFO - iteration:10 step:6500/10100, NER loss:38.097328
2019-02-21 16:44:53,474 - log/train6.log - INFO - iteration:10 step:6600/10100, NER loss:26.843243
2019-02-21 16:44:55,765 - log/train6.log - INFO - iteration:10 step:6700/10100, NER loss:53.674664
2019-02-21 16:44:58,472 - log/train6.log - INFO - iteration:10 step:6800/10100, NER loss:44.913536
2019-02-21 16:45:00,679 - log/train6.log - INFO - iteration:10 step:6900/10100, NER loss:30.163721
2019-02-21 16:45:02,876 - log/train6.log - INFO - iteration:10 step:7000/10100, NER loss:30.706738
2019-02-21 16:45:05,413 - log/train6.log - INFO - iteration:10 step:7100/10100, NER loss:38.711414
2019-02-21 16:45:07,550 - log/train6.log - INFO - iteration:10 step:7200/10100, NER loss:31.959219
2019-02-21 16:45:09,723 - log/train6.log - INFO - iteration:10 step:7300/10100, NER loss:40.657845
2019-02-21 16:45:11,928 - log/train6.log - INFO - iteration:10 step:7400/10100, NER loss:25.002661
2019-02-21 16:45:14,198 - log/train6.log - INFO - iteration:10 step:7500/10100, NER loss:38.338951
2019-02-21 16:45:16,449 - log/train6.log - INFO - iteration:10 step:7600/10100, NER loss:37.049881
2019-02-21 16:45:18,529 - log/train6.log - INFO - iteration:10 step:7700/10100, NER loss:32.972099
2019-02-21 16:45:20,743 - log/train6.log - INFO - iteration:10 step:7800/10100, NER loss:28.080244
2019-02-21 16:45:22,853 - log/train6.log - INFO - iteration:10 step:7900/10100, NER loss:31.475893
2019-02-21 16:45:25,094 - log/train6.log - INFO - iteration:10 step:8000/10100, NER loss:45.793720
2019-02-21 16:45:27,318 - log/train6.log - INFO - iteration:10 step:8100/10100, NER loss:37.976093
2019-02-21 16:45:31,663 - log/train6.log - INFO - iteration:10 step:8200/10100, NER loss:55.220970
2019-02-21 16:45:34,036 - log/train6.log - INFO - iteration:10 step:8300/10100, NER loss:39.218624
2019-02-21 16:45:36,532 - log/train6.log - INFO - iteration:10 step:8400/10100, NER loss:31.438503
2019-02-21 16:45:38,924 - log/train6.log - INFO - iteration:10 step:8500/10100, NER loss:37.657387
2019-02-21 16:45:41,601 - log/train6.log - INFO - iteration:10 step:8600/10100, NER loss:37.465977
2019-02-21 16:45:43,981 - log/train6.log - INFO - iteration:10 step:8700/10100, NER loss:32.808105
2019-02-21 16:45:46,238 - log/train6.log - INFO - iteration:10 step:8800/10100, NER loss:30.565073
2019-02-21 16:45:48,943 - log/train6.log - INFO - iteration:10 step:8900/10100, NER loss:33.516811
2019-02-21 16:45:51,521 - log/train6.log - INFO - iteration:10 step:9000/10100, NER loss:34.652046
2019-02-21 16:45:53,891 - log/train6.log - INFO - iteration:10 step:9100/10100, NER loss:48.458424
2019-02-21 16:45:56,196 - log/train6.log - INFO - iteration:10 step:9200/10100, NER loss:31.884504
2019-02-21 16:45:58,740 - log/train6.log - INFO - iteration:10 step:9300/10100, NER loss:29.419670
2019-02-21 16:46:01,197 - log/train6.log - INFO - iteration:10 step:9400/10100, NER loss:29.756531
2019-02-21 16:46:03,701 - log/train6.log - INFO - iteration:10 step:9500/10100, NER loss:34.313156
2019-02-21 16:46:06,350 - log/train6.log - INFO - iteration:10 step:9600/10100, NER loss:36.148384
2019-02-21 16:46:08,832 - log/train6.log - INFO - iteration:10 step:9700/10100, NER loss:23.559587
2019-02-21 16:46:11,285 - log/train6.log - INFO - iteration:10 step:9800/10100, NER loss:36.287338
2019-02-21 16:46:13,483 - log/train6.log - INFO - iteration:10 step:9900/10100, NER loss:30.209898
2019-02-21 16:46:15,824 - log/train6.log - INFO - iteration:10 step:10000/10100, NER loss:34.823048
2019-02-21 16:46:18,105 - log/train6.log - INFO - iteration:11 step:0/10100, NER loss:41.292004
2019-02-21 16:46:18,105 - log/train6.log - INFO - evaluate:dev
2019-02-21 16:46:24,897 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 4815 phrases; correct: 3704.

2019-02-21 16:46:24,897 - log/train6.log - INFO - accuracy:  94.49%; precision:  76.93%; recall:  63.35%; FB1:  69.48

2019-02-21 16:46:24,897 - log/train6.log - INFO -                 C: precision:  89.46%; recall:  83.89%; FB1:  86.58  3178

2019-02-21 16:46:24,898 - log/train6.log - INFO -               IND: precision:  50.98%; recall:  25.49%; FB1:  33.99  204

2019-02-21 16:46:24,898 - log/train6.log - INFO -               INS: precision:  77.47%; recall:  51.72%; FB1:  62.03  253

2019-02-21 16:46:24,898 - log/train6.log - INFO -                 L: precision:   0.81%; recall:   0.50%; FB1:   0.61  371

2019-02-21 16:46:24,898 - log/train6.log - INFO -                 P: precision:  76.47%; recall:  90.98%; FB1:  83.10  646

2019-02-21 16:46:24,898 - log/train6.log - INFO -               PRO: precision:  39.26%; recall:  12.26%; FB1:  18.69  163

2019-02-21 16:46:24,901 - log/train6.log - INFO - evaluate:test
2019-02-21 16:46:26,410 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1495 phrases; correct: 1260.

2019-02-21 16:46:26,411 - log/train6.log - INFO - accuracy:  96.50%; precision:  84.28%; recall:  76.50%; FB1:  80.20

2019-02-21 16:46:26,411 - log/train6.log - INFO -                 C: precision:  92.61%; recall:  90.18%; FB1:  91.38  1002

2019-02-21 16:46:26,411 - log/train6.log - INFO -               IND: precision:  70.00%; recall:  59.57%; FB1:  64.37  40

2019-02-21 16:46:26,411 - log/train6.log - INFO -               INS: precision:  76.67%; recall:  48.42%; FB1:  59.35  60

2019-02-21 16:46:26,411 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  89

2019-02-21 16:46:26,411 - log/train6.log - INFO -                 P: precision:  84.72%; recall:  95.10%; FB1:  89.61  229

2019-02-21 16:46:26,411 - log/train6.log - INFO -               PRO: precision:  85.33%; recall:  37.87%; FB1:  52.46  75

2019-02-21 16:46:28,635 - log/train6.log - INFO - iteration:11 step:100/10100, NER loss:37.865433
2019-02-21 16:46:30,980 - log/train6.log - INFO - iteration:11 step:200/10100, NER loss:37.161587
2019-02-21 16:46:33,211 - log/train6.log - INFO - iteration:11 step:300/10100, NER loss:28.383080
2019-02-21 16:46:35,471 - log/train6.log - INFO - iteration:11 step:400/10100, NER loss:37.222111
2019-02-21 16:46:37,790 - log/train6.log - INFO - iteration:11 step:500/10100, NER loss:22.648945
2019-02-21 16:46:40,100 - log/train6.log - INFO - iteration:11 step:600/10100, NER loss:32.390652
2019-02-21 16:46:42,346 - log/train6.log - INFO - iteration:11 step:700/10100, NER loss:29.967213
2019-02-21 16:46:44,750 - log/train6.log - INFO - iteration:11 step:800/10100, NER loss:35.161156
2019-02-21 16:46:49,955 - log/train6.log - INFO - iteration:11 step:900/10100, NER loss:65.323181
2019-02-21 16:46:52,117 - log/train6.log - INFO - iteration:11 step:1000/10100, NER loss:27.548199
2019-02-21 16:46:54,532 - log/train6.log - INFO - iteration:11 step:1100/10100, NER loss:29.225685
2019-02-21 16:46:56,902 - log/train6.log - INFO - iteration:11 step:1200/10100, NER loss:24.963140
2019-02-21 16:46:59,094 - log/train6.log - INFO - iteration:11 step:1300/10100, NER loss:31.158230
2019-02-21 16:47:01,604 - log/train6.log - INFO - iteration:11 step:1400/10100, NER loss:51.306587
2019-02-21 16:47:03,865 - log/train6.log - INFO - iteration:11 step:1500/10100, NER loss:31.123266
2019-02-21 16:47:06,105 - log/train6.log - INFO - iteration:11 step:1600/10100, NER loss:25.619114
2019-02-21 16:47:08,303 - log/train6.log - INFO - iteration:11 step:1700/10100, NER loss:32.170826
2019-02-21 16:47:10,660 - log/train6.log - INFO - iteration:11 step:1800/10100, NER loss:34.481510
2019-02-21 16:47:13,048 - log/train6.log - INFO - iteration:11 step:1900/10100, NER loss:28.141657
2019-02-21 16:47:15,352 - log/train6.log - INFO - iteration:11 step:2000/10100, NER loss:39.801674
2019-02-21 16:47:17,590 - log/train6.log - INFO - iteration:11 step:2100/10100, NER loss:52.346661
2019-02-21 16:47:19,977 - log/train6.log - INFO - iteration:11 step:2200/10100, NER loss:31.655693
2019-02-21 16:47:22,268 - log/train6.log - INFO - iteration:11 step:2300/10100, NER loss:24.527840
2019-02-21 16:47:24,565 - log/train6.log - INFO - iteration:11 step:2400/10100, NER loss:25.794701
2019-02-21 16:47:27,104 - log/train6.log - INFO - iteration:11 step:2500/10100, NER loss:27.560390
2019-02-21 16:47:29,528 - log/train6.log - INFO - iteration:11 step:2600/10100, NER loss:29.943476
2019-02-21 16:47:31,697 - log/train6.log - INFO - iteration:11 step:2700/10100, NER loss:21.997166
2019-02-21 16:47:34,197 - log/train6.log - INFO - iteration:11 step:2800/10100, NER loss:34.654179
2019-02-21 16:47:36,766 - log/train6.log - INFO - iteration:11 step:2900/10100, NER loss:22.061296
2019-02-21 16:47:39,456 - log/train6.log - INFO - iteration:11 step:3000/10100, NER loss:41.481621
2019-02-21 16:47:41,672 - log/train6.log - INFO - iteration:11 step:3100/10100, NER loss:25.374723
2019-02-21 16:47:43,896 - log/train6.log - INFO - iteration:11 step:3200/10100, NER loss:22.922171
2019-02-21 16:47:46,569 - log/train6.log - INFO - iteration:11 step:3300/10100, NER loss:41.428226
2019-02-21 16:47:48,955 - log/train6.log - INFO - iteration:11 step:3400/10100, NER loss:37.432617
2019-02-21 16:47:51,268 - log/train6.log - INFO - iteration:11 step:3500/10100, NER loss:31.806293
2019-02-21 16:47:53,755 - log/train6.log - INFO - iteration:11 step:3600/10100, NER loss:29.047850
2019-02-21 16:47:58,293 - log/train6.log - INFO - iteration:11 step:3700/10100, NER loss:70.456741
2019-02-21 16:48:00,505 - log/train6.log - INFO - iteration:11 step:3800/10100, NER loss:25.905092
2019-02-21 16:48:02,872 - log/train6.log - INFO - iteration:11 step:3900/10100, NER loss:24.820545
2019-02-21 16:48:05,345 - log/train6.log - INFO - iteration:11 step:4000/10100, NER loss:29.942556
2019-02-21 16:48:07,981 - log/train6.log - INFO - iteration:11 step:4100/10100, NER loss:30.295246
2019-02-21 16:48:10,249 - log/train6.log - INFO - iteration:11 step:4200/10100, NER loss:30.376406
2019-02-21 16:48:12,497 - log/train6.log - INFO - iteration:11 step:4300/10100, NER loss:30.032255
2019-02-21 16:48:14,890 - log/train6.log - INFO - iteration:11 step:4400/10100, NER loss:19.742876
2019-02-21 16:48:17,427 - log/train6.log - INFO - iteration:11 step:4500/10100, NER loss:26.734840
2019-02-21 16:48:20,036 - log/train6.log - INFO - iteration:11 step:4600/10100, NER loss:32.875320
2019-02-21 16:48:22,569 - log/train6.log - INFO - iteration:11 step:4700/10100, NER loss:22.135496
2019-02-21 16:48:25,590 - log/train6.log - INFO - iteration:11 step:4800/10100, NER loss:49.948185
2019-02-21 16:48:27,942 - log/train6.log - INFO - iteration:11 step:4900/10100, NER loss:22.909845
2019-02-21 16:48:30,368 - log/train6.log - INFO - iteration:11 step:5000/10100, NER loss:22.020445
2019-02-21 16:48:32,720 - log/train6.log - INFO - iteration:11 step:5100/10100, NER loss:31.260839
2019-02-21 16:48:35,186 - log/train6.log - INFO - iteration:11 step:5200/10100, NER loss:32.215206
2019-02-21 16:48:37,474 - log/train6.log - INFO - iteration:11 step:5300/10100, NER loss:18.974665
2019-02-21 16:48:39,714 - log/train6.log - INFO - iteration:11 step:5400/10100, NER loss:28.823950
2019-02-21 16:48:41,975 - log/train6.log - INFO - iteration:11 step:5500/10100, NER loss:17.654076
2019-02-21 16:48:44,349 - log/train6.log - INFO - iteration:11 step:5600/10100, NER loss:24.107124
2019-02-21 16:48:46,570 - log/train6.log - INFO - iteration:11 step:5700/10100, NER loss:23.873041
2019-02-21 16:48:48,810 - log/train6.log - INFO - iteration:11 step:5800/10100, NER loss:18.950951
2019-02-21 16:48:51,385 - log/train6.log - INFO - iteration:11 step:5900/10100, NER loss:35.686153
2019-02-21 16:48:53,690 - log/train6.log - INFO - iteration:11 step:6000/10100, NER loss:17.519407
2019-02-21 16:48:55,868 - log/train6.log - INFO - iteration:11 step:6100/10100, NER loss:19.811281
2019-02-21 16:48:58,215 - log/train6.log - INFO - iteration:11 step:6200/10100, NER loss:21.734581
2019-02-21 16:49:00,596 - log/train6.log - INFO - iteration:11 step:6300/10100, NER loss:30.777027
2019-02-21 16:49:03,227 - log/train6.log - INFO - iteration:11 step:6400/10100, NER loss:30.227859
2019-02-21 16:49:05,461 - log/train6.log - INFO - iteration:11 step:6500/10100, NER loss:31.088608
2019-02-21 16:49:07,822 - log/train6.log - INFO - iteration:11 step:6600/10100, NER loss:24.314251
2019-02-21 16:49:12,368 - log/train6.log - INFO - iteration:11 step:6700/10100, NER loss:277.281616
2019-02-21 16:49:14,796 - log/train6.log - INFO - iteration:11 step:6800/10100, NER loss:36.574196
2019-02-21 16:49:16,949 - log/train6.log - INFO - iteration:11 step:6900/10100, NER loss:26.533728
2019-02-21 16:49:19,386 - log/train6.log - INFO - iteration:11 step:7000/10100, NER loss:27.426748
2019-02-21 16:49:22,025 - log/train6.log - INFO - iteration:11 step:7100/10100, NER loss:34.459618
2019-02-21 16:49:24,399 - log/train6.log - INFO - iteration:11 step:7200/10100, NER loss:25.253019
2019-02-21 16:49:26,736 - log/train6.log - INFO - iteration:11 step:7300/10100, NER loss:18.036261
2019-02-21 16:49:29,140 - log/train6.log - INFO - iteration:11 step:7400/10100, NER loss:24.072155
2019-02-21 16:49:31,559 - log/train6.log - INFO - iteration:11 step:7500/10100, NER loss:22.554436
2019-02-21 16:49:33,862 - log/train6.log - INFO - iteration:11 step:7600/10100, NER loss:31.367727
2019-02-21 16:49:36,208 - log/train6.log - INFO - iteration:11 step:7700/10100, NER loss:27.915001
2019-02-21 16:49:38,612 - log/train6.log - INFO - iteration:11 step:7800/10100, NER loss:30.637478
2019-02-21 16:49:40,940 - log/train6.log - INFO - iteration:11 step:7900/10100, NER loss:30.241192
2019-02-21 16:49:43,326 - log/train6.log - INFO - iteration:11 step:8000/10100, NER loss:27.077471
2019-02-21 16:49:45,832 - log/train6.log - INFO - iteration:11 step:8100/10100, NER loss:30.900764
2019-02-21 16:49:48,256 - log/train6.log - INFO - iteration:11 step:8200/10100, NER loss:31.755688
2019-02-21 16:49:50,371 - log/train6.log - INFO - iteration:11 step:8300/10100, NER loss:19.640863
2019-02-21 16:49:52,878 - log/train6.log - INFO - iteration:11 step:8400/10100, NER loss:30.420038
2019-02-21 16:49:55,388 - log/train6.log - INFO - iteration:11 step:8500/10100, NER loss:27.700829
2019-02-21 16:49:57,505 - log/train6.log - INFO - iteration:11 step:8600/10100, NER loss:16.599298
2019-02-21 16:49:59,602 - log/train6.log - INFO - iteration:11 step:8700/10100, NER loss:21.122671
2019-02-21 16:50:01,863 - log/train6.log - INFO - iteration:11 step:8800/10100, NER loss:23.969114
2019-02-21 16:50:04,380 - log/train6.log - INFO - iteration:11 step:8900/10100, NER loss:26.682287
2019-02-21 16:50:07,163 - log/train6.log - INFO - iteration:11 step:9000/10100, NER loss:28.135681
2019-02-21 16:50:09,511 - log/train6.log - INFO - iteration:11 step:9100/10100, NER loss:25.493528
2019-02-21 16:50:12,069 - log/train6.log - INFO - iteration:11 step:9200/10100, NER loss:20.334038
2019-02-21 16:50:14,447 - log/train6.log - INFO - iteration:11 step:9300/10100, NER loss:35.180523
2019-02-21 16:50:16,955 - log/train6.log - INFO - iteration:11 step:9400/10100, NER loss:27.012529
2019-02-21 16:50:19,377 - log/train6.log - INFO - iteration:11 step:9500/10100, NER loss:21.370821
2019-02-21 16:50:21,604 - log/train6.log - INFO - iteration:11 step:9600/10100, NER loss:25.240772
2019-02-21 16:50:24,382 - log/train6.log - INFO - iteration:11 step:9700/10100, NER loss:20.681015
2019-02-21 16:50:26,825 - log/train6.log - INFO - iteration:11 step:9800/10100, NER loss:33.776459
2019-02-21 16:50:28,945 - log/train6.log - INFO - iteration:11 step:9900/10100, NER loss:19.311575
2019-02-21 16:50:31,059 - log/train6.log - INFO - iteration:11 step:10000/10100, NER loss:21.591490
2019-02-21 16:50:33,237 - log/train6.log - INFO - iteration:12 step:0/10100, NER loss:26.195433
2019-02-21 16:50:33,237 - log/train6.log - INFO - evaluate:dev
2019-02-21 16:50:40,117 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 6379 phrases; correct: 4015.

2019-02-21 16:50:40,118 - log/train6.log - INFO - accuracy:  93.72%; precision:  62.94%; recall:  68.67%; FB1:  65.68

2019-02-21 16:50:40,118 - log/train6.log - INFO -                 C: precision:  75.34%; recall:  87.87%; FB1:  81.12  3953

2019-02-21 16:50:40,118 - log/train6.log - INFO -               IND: precision:  32.89%; recall:  36.27%; FB1:  34.50  450

2019-02-21 16:50:40,118 - log/train6.log - INFO -               INS: precision:  63.15%; recall:  70.98%; FB1:  66.83  426

2019-02-21 16:50:40,119 - log/train6.log - INFO -                 L: precision:   0.83%; recall:   0.83%; FB1:   0.83  599

2019-02-21 16:50:40,119 - log/train6.log - INFO -                 P: precision:  91.22%; recall:  91.90%; FB1:  91.56  547

2019-02-21 16:50:40,119 - log/train6.log - INFO -               PRO: precision:  28.71%; recall:  22.22%; FB1:  25.05  404

2019-02-21 16:50:40,123 - log/train6.log - INFO - evaluate:test
2019-02-21 16:50:41,710 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1792 phrases; correct: 1339.

2019-02-21 16:50:41,710 - log/train6.log - INFO - accuracy:  95.89%; precision:  74.72%; recall:  81.30%; FB1:  77.87

2019-02-21 16:50:41,710 - log/train6.log - INFO -                 C: precision:  83.98%; recall:  93.20%; FB1:  88.35  1142

2019-02-21 16:50:41,710 - log/train6.log - INFO -               IND: precision:  38.82%; recall:  70.21%; FB1:  50.00  85

2019-02-21 16:50:41,710 - log/train6.log - INFO -               INS: precision:  64.65%; recall:  67.37%; FB1:  65.98  99

2019-02-21 16:50:41,710 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  109

2019-02-21 16:50:41,710 - log/train6.log - INFO -                 P: precision:  91.08%; recall:  95.10%; FB1:  93.05  213

2019-02-21 16:50:41,710 - log/train6.log - INFO -               PRO: precision:  61.81%; recall:  52.66%; FB1:  56.87  144

2019-02-21 16:50:44,161 - log/train6.log - INFO - iteration:12 step:100/10100, NER loss:17.756512
2019-02-21 16:50:46,260 - log/train6.log - INFO - iteration:12 step:200/10100, NER loss:16.648720
2019-02-21 16:50:48,493 - log/train6.log - INFO - iteration:12 step:300/10100, NER loss:35.232254
2019-02-21 16:50:53,164 - log/train6.log - INFO - iteration:12 step:400/10100, NER loss:65.313019
2019-02-21 16:50:55,470 - log/train6.log - INFO - iteration:12 step:500/10100, NER loss:18.129459
2019-02-21 16:50:58,109 - log/train6.log - INFO - iteration:12 step:600/10100, NER loss:24.527639
2019-02-21 16:51:00,641 - log/train6.log - INFO - iteration:12 step:700/10100, NER loss:22.112873
2019-02-21 16:51:05,444 - log/train6.log - INFO - iteration:12 step:800/10100, NER loss:44.054668
2019-02-21 16:51:07,816 - log/train6.log - INFO - iteration:12 step:900/10100, NER loss:23.087042
2019-02-21 16:51:10,321 - log/train6.log - INFO - iteration:12 step:1000/10100, NER loss:24.973488
2019-02-21 16:51:12,477 - log/train6.log - INFO - iteration:12 step:1100/10100, NER loss:29.151495
2019-02-21 16:51:14,880 - log/train6.log - INFO - iteration:12 step:1200/10100, NER loss:21.385723
2019-02-21 16:51:17,056 - log/train6.log - INFO - iteration:12 step:1300/10100, NER loss:18.331244
2019-02-21 16:51:19,462 - log/train6.log - INFO - iteration:12 step:1400/10100, NER loss:23.319927
2019-02-21 16:51:21,689 - log/train6.log - INFO - iteration:12 step:1500/10100, NER loss:39.964676
2019-02-21 16:51:23,825 - log/train6.log - INFO - iteration:12 step:1600/10100, NER loss:16.495722
2019-02-21 16:51:26,090 - log/train6.log - INFO - iteration:12 step:1700/10100, NER loss:29.697641
2019-02-21 16:51:28,547 - log/train6.log - INFO - iteration:12 step:1800/10100, NER loss:18.037817
2019-02-21 16:51:31,224 - log/train6.log - INFO - iteration:12 step:1900/10100, NER loss:24.328608
2019-02-21 16:51:33,333 - log/train6.log - INFO - iteration:12 step:2000/10100, NER loss:31.064297
2019-02-21 16:51:35,520 - log/train6.log - INFO - iteration:12 step:2100/10100, NER loss:21.006987
2019-02-21 16:51:38,109 - log/train6.log - INFO - iteration:12 step:2200/10100, NER loss:32.336067
2019-02-21 16:51:40,652 - log/train6.log - INFO - iteration:12 step:2300/10100, NER loss:25.399712
2019-02-21 16:51:42,965 - log/train6.log - INFO - iteration:12 step:2400/10100, NER loss:18.650627
2019-02-21 16:51:45,571 - log/train6.log - INFO - iteration:12 step:2500/10100, NER loss:21.229204
2019-02-21 16:51:47,943 - log/train6.log - INFO - iteration:12 step:2600/10100, NER loss:23.408123
2019-02-21 16:51:50,200 - log/train6.log - INFO - iteration:12 step:2700/10100, NER loss:21.124783
2019-02-21 16:51:52,443 - log/train6.log - INFO - iteration:12 step:2800/10100, NER loss:19.274872
2019-02-21 16:51:54,814 - log/train6.log - INFO - iteration:12 step:2900/10100, NER loss:24.775896
2019-02-21 16:51:57,168 - log/train6.log - INFO - iteration:12 step:3000/10100, NER loss:24.238619
2019-02-21 16:51:59,390 - log/train6.log - INFO - iteration:12 step:3100/10100, NER loss:21.231417
2019-02-21 16:52:01,640 - log/train6.log - INFO - iteration:12 step:3200/10100, NER loss:18.854271
2019-02-21 16:52:04,242 - log/train6.log - INFO - iteration:12 step:3300/10100, NER loss:33.097534
2019-02-21 16:52:06,385 - log/train6.log - INFO - iteration:12 step:3400/10100, NER loss:23.373890
2019-02-21 16:52:08,621 - log/train6.log - INFO - iteration:12 step:3500/10100, NER loss:18.898022
2019-02-21 16:52:10,890 - log/train6.log - INFO - iteration:12 step:3600/10100, NER loss:14.507988
2019-02-21 16:52:13,049 - log/train6.log - INFO - iteration:12 step:3700/10100, NER loss:26.335529
2019-02-21 16:52:15,467 - log/train6.log - INFO - iteration:12 step:3800/10100, NER loss:20.656321
2019-02-21 16:52:17,624 - log/train6.log - INFO - iteration:12 step:3900/10100, NER loss:17.300653
2019-02-21 16:52:19,933 - log/train6.log - INFO - iteration:12 step:4000/10100, NER loss:23.253105
2019-02-21 16:52:22,493 - log/train6.log - INFO - iteration:12 step:4100/10100, NER loss:20.848127
2019-02-21 16:52:25,031 - log/train6.log - INFO - iteration:12 step:4200/10100, NER loss:24.605955
2019-02-21 16:52:27,095 - log/train6.log - INFO - iteration:12 step:4300/10100, NER loss:19.064514
2019-02-21 16:52:29,677 - log/train6.log - INFO - iteration:12 step:4400/10100, NER loss:16.227341
2019-02-21 16:52:32,022 - log/train6.log - INFO - iteration:12 step:4500/10100, NER loss:22.818504
2019-02-21 16:52:34,283 - log/train6.log - INFO - iteration:12 step:4600/10100, NER loss:16.739731
2019-02-21 16:52:36,531 - log/train6.log - INFO - iteration:12 step:4700/10100, NER loss:22.463430
2019-02-21 16:52:38,743 - log/train6.log - INFO - iteration:12 step:4800/10100, NER loss:24.440235
2019-02-21 16:52:41,038 - log/train6.log - INFO - iteration:12 step:4900/10100, NER loss:15.010075
2019-02-21 16:52:43,624 - log/train6.log - INFO - iteration:12 step:5000/10100, NER loss:22.604300
2019-02-21 16:52:45,871 - log/train6.log - INFO - iteration:12 step:5100/10100, NER loss:15.960027
2019-02-21 16:52:48,222 - log/train6.log - INFO - iteration:12 step:5200/10100, NER loss:24.665041
2019-02-21 16:52:50,734 - log/train6.log - INFO - iteration:12 step:5300/10100, NER loss:25.101818
2019-02-21 16:52:53,168 - log/train6.log - INFO - iteration:12 step:5400/10100, NER loss:29.319798
2019-02-21 16:52:55,476 - log/train6.log - INFO - iteration:12 step:5500/10100, NER loss:14.843019
2019-02-21 16:52:57,543 - log/train6.log - INFO - iteration:12 step:5600/10100, NER loss:16.428791
2019-02-21 16:53:00,078 - log/train6.log - INFO - iteration:12 step:5700/10100, NER loss:20.443983
2019-02-21 16:53:02,432 - log/train6.log - INFO - iteration:12 step:5800/10100, NER loss:20.388952
2019-02-21 16:53:04,837 - log/train6.log - INFO - iteration:12 step:5900/10100, NER loss:18.710363
2019-02-21 16:53:07,198 - log/train6.log - INFO - iteration:12 step:6000/10100, NER loss:18.111231
2019-02-21 16:53:09,578 - log/train6.log - INFO - iteration:12 step:6100/10100, NER loss:19.920311
2019-02-21 16:53:11,918 - log/train6.log - INFO - iteration:12 step:6200/10100, NER loss:17.022058
2019-02-21 16:53:14,330 - log/train6.log - INFO - iteration:12 step:6300/10100, NER loss:18.461403
2019-02-21 16:53:16,833 - log/train6.log - INFO - iteration:12 step:6400/10100, NER loss:20.041019
2019-02-21 16:53:19,126 - log/train6.log - INFO - iteration:12 step:6500/10100, NER loss:18.009272
2019-02-21 16:53:21,553 - log/train6.log - INFO - iteration:12 step:6600/10100, NER loss:18.275711
2019-02-21 16:53:24,080 - log/train6.log - INFO - iteration:12 step:6700/10100, NER loss:24.799227
2019-02-21 16:53:26,199 - log/train6.log - INFO - iteration:12 step:6800/10100, NER loss:18.212044
2019-02-21 16:53:28,175 - log/train6.log - INFO - iteration:12 step:6900/10100, NER loss:17.078793
2019-02-21 16:53:30,764 - log/train6.log - INFO - iteration:12 step:7000/10100, NER loss:25.865356
2019-02-21 16:53:33,074 - log/train6.log - INFO - iteration:12 step:7100/10100, NER loss:26.580767
2019-02-21 16:53:35,384 - log/train6.log - INFO - iteration:12 step:7200/10100, NER loss:19.802498
2019-02-21 16:53:37,636 - log/train6.log - INFO - iteration:12 step:7300/10100, NER loss:19.208990
2019-02-21 16:53:39,947 - log/train6.log - INFO - iteration:12 step:7400/10100, NER loss:19.652794
2019-02-21 16:53:42,720 - log/train6.log - INFO - iteration:12 step:7500/10100, NER loss:29.280315
2019-02-21 16:53:45,200 - log/train6.log - INFO - iteration:12 step:7600/10100, NER loss:19.021450
2019-02-21 16:53:47,672 - log/train6.log - INFO - iteration:12 step:7700/10100, NER loss:15.016658
2019-02-21 16:53:50,137 - log/train6.log - INFO - iteration:12 step:7800/10100, NER loss:18.497292
2019-02-21 16:53:52,464 - log/train6.log - INFO - iteration:12 step:7900/10100, NER loss:16.764053
2019-02-21 16:53:54,875 - log/train6.log - INFO - iteration:12 step:8000/10100, NER loss:19.019571
2019-02-21 16:53:57,538 - log/train6.log - INFO - iteration:12 step:8100/10100, NER loss:18.884497
2019-02-21 16:53:59,681 - log/train6.log - INFO - iteration:12 step:8200/10100, NER loss:11.332698
2019-02-21 16:54:01,802 - log/train6.log - INFO - iteration:12 step:8300/10100, NER loss:15.437542
2019-02-21 16:54:04,165 - log/train6.log - INFO - iteration:12 step:8400/10100, NER loss:10.976240
2019-02-21 16:54:06,515 - log/train6.log - INFO - iteration:12 step:8500/10100, NER loss:16.278250
2019-02-21 16:54:09,088 - log/train6.log - INFO - iteration:12 step:8600/10100, NER loss:29.259632
2019-02-21 16:54:11,693 - log/train6.log - INFO - iteration:12 step:8700/10100, NER loss:19.648718
2019-02-21 16:54:13,785 - log/train6.log - INFO - iteration:12 step:8800/10100, NER loss:19.060835
2019-02-21 16:54:16,070 - log/train6.log - INFO - iteration:12 step:8900/10100, NER loss:19.077986
2019-02-21 16:54:18,456 - log/train6.log - INFO - iteration:12 step:9000/10100, NER loss:16.445946
2019-02-21 16:54:20,788 - log/train6.log - INFO - iteration:12 step:9100/10100, NER loss:19.211178
2019-02-21 16:54:22,994 - log/train6.log - INFO - iteration:12 step:9200/10100, NER loss:12.949730
2019-02-21 16:54:27,262 - log/train6.log - INFO - iteration:12 step:9300/10100, NER loss:195.940170
2019-02-21 16:54:29,649 - log/train6.log - INFO - iteration:12 step:9400/10100, NER loss:24.121731
2019-02-21 16:54:31,967 - log/train6.log - INFO - iteration:12 step:9500/10100, NER loss:16.570044
2019-02-21 16:54:34,088 - log/train6.log - INFO - iteration:12 step:9600/10100, NER loss:15.118904
2019-02-21 16:54:36,660 - log/train6.log - INFO - iteration:12 step:9700/10100, NER loss:16.506052
2019-02-21 16:54:39,008 - log/train6.log - INFO - iteration:12 step:9800/10100, NER loss:13.558527
2019-02-21 16:54:41,171 - log/train6.log - INFO - iteration:12 step:9900/10100, NER loss:18.180717
2019-02-21 16:54:43,383 - log/train6.log - INFO - iteration:12 step:10000/10100, NER loss:18.191460
2019-02-21 16:54:45,633 - log/train6.log - INFO - iteration:13 step:0/10100, NER loss:19.461510
2019-02-21 16:54:45,633 - log/train6.log - INFO - evaluate:dev
2019-02-21 16:54:52,466 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5656 phrases; correct: 3985.

2019-02-21 16:54:52,467 - log/train6.log - INFO - accuracy:  94.98%; precision:  70.46%; recall:  68.15%; FB1:  69.29

2019-02-21 16:54:52,467 - log/train6.log - INFO -                 C: precision:  82.90%; recall:  88.96%; FB1:  85.82  3637

2019-02-21 16:54:52,467 - log/train6.log - INFO -               IND: precision:  36.89%; recall:  31.37%; FB1:  33.91  347

2019-02-21 16:54:52,467 - log/train6.log - INFO -               INS: precision:  69.84%; recall:  69.66%; FB1:  69.75  378

2019-02-21 16:54:52,467 - log/train6.log - INFO -                 L: precision:   0.36%; recall:   0.33%; FB1:   0.35  551

2019-02-21 16:54:52,467 - log/train6.log - INFO -                 P: precision:  90.42%; recall:  92.08%; FB1:  91.24  553

2019-02-21 16:54:52,468 - log/train6.log - INFO -               PRO: precision:  40.00%; recall:  14.56%; FB1:  21.35  190

2019-02-21 16:54:52,471 - log/train6.log - INFO - evaluate:test
2019-02-21 16:54:53,960 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1610 phrases; correct: 1309.

2019-02-21 16:54:53,960 - log/train6.log - INFO - accuracy:  96.74%; precision:  81.30%; recall:  79.48%; FB1:  80.38

2019-02-21 16:54:53,960 - log/train6.log - INFO -                 C: precision:  89.51%; recall:  92.91%; FB1:  91.18  1068

2019-02-21 16:54:53,961 - log/train6.log - INFO -               IND: precision:  54.10%; recall:  70.21%; FB1:  61.11  61

2019-02-21 16:54:53,961 - log/train6.log - INFO -               INS: precision:  70.59%; recall:  63.16%; FB1:  66.67  85

2019-02-21 16:54:53,961 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  101

2019-02-21 16:54:53,961 - log/train6.log - INFO -                 P: precision:  92.86%; recall:  95.59%; FB1:  94.20  210

2019-02-21 16:54:53,961 - log/train6.log - INFO -               PRO: precision:  76.47%; recall:  38.46%; FB1:  51.18  85

2019-02-21 16:54:56,033 - log/train6.log - INFO - iteration:13 step:100/10100, NER loss:17.004997
2019-02-21 16:54:57,987 - log/train6.log - INFO - iteration:13 step:200/10100, NER loss:11.884298
2019-02-21 16:55:00,376 - log/train6.log - INFO - iteration:13 step:300/10100, NER loss:14.322379
2019-02-21 16:55:02,859 - log/train6.log - INFO - iteration:13 step:400/10100, NER loss:18.617805
2019-02-21 16:55:05,311 - log/train6.log - INFO - iteration:13 step:500/10100, NER loss:19.384769
2019-02-21 16:55:07,475 - log/train6.log - INFO - iteration:13 step:600/10100, NER loss:13.316229
2019-02-21 16:55:09,718 - log/train6.log - INFO - iteration:13 step:700/10100, NER loss:27.969168
2019-02-21 16:55:12,156 - log/train6.log - INFO - iteration:13 step:800/10100, NER loss:20.756651
2019-02-21 16:55:14,274 - log/train6.log - INFO - iteration:13 step:900/10100, NER loss:12.973948
2019-02-21 16:55:16,403 - log/train6.log - INFO - iteration:13 step:1000/10100, NER loss:14.331925
2019-02-21 16:55:18,441 - log/train6.log - INFO - iteration:13 step:1100/10100, NER loss:17.625582
2019-02-21 16:55:20,884 - log/train6.log - INFO - iteration:13 step:1200/10100, NER loss:17.870569
2019-02-21 16:55:23,849 - log/train6.log - INFO - iteration:13 step:1300/10100, NER loss:17.408131
2019-02-21 16:55:25,964 - log/train6.log - INFO - iteration:13 step:1400/10100, NER loss:10.358090
2019-02-21 16:55:28,499 - log/train6.log - INFO - iteration:13 step:1500/10100, NER loss:13.081768
2019-02-21 16:55:30,892 - log/train6.log - INFO - iteration:13 step:1600/10100, NER loss:12.026329
2019-02-21 16:55:33,361 - log/train6.log - INFO - iteration:13 step:1700/10100, NER loss:13.871727
2019-02-21 16:55:35,925 - log/train6.log - INFO - iteration:13 step:1800/10100, NER loss:17.634920
2019-02-21 16:55:38,077 - log/train6.log - INFO - iteration:13 step:1900/10100, NER loss:11.731606
2019-02-21 16:55:40,241 - log/train6.log - INFO - iteration:13 step:2000/10100, NER loss:13.795396
2019-02-21 16:55:42,492 - log/train6.log - INFO - iteration:13 step:2100/10100, NER loss:13.244015
2019-02-21 16:55:44,598 - log/train6.log - INFO - iteration:13 step:2200/10100, NER loss:10.779309
2019-02-21 16:55:46,928 - log/train6.log - INFO - iteration:13 step:2300/10100, NER loss:16.705368
2019-02-21 16:55:49,256 - log/train6.log - INFO - iteration:13 step:2400/10100, NER loss:19.791937
2019-02-21 16:55:51,576 - log/train6.log - INFO - iteration:13 step:2500/10100, NER loss:17.061779
2019-02-21 16:55:53,543 - log/train6.log - INFO - iteration:13 step:2600/10100, NER loss:12.790143
2019-02-21 16:55:55,628 - log/train6.log - INFO - iteration:13 step:2700/10100, NER loss:10.616028
2019-02-21 16:55:57,874 - log/train6.log - INFO - iteration:13 step:2800/10100, NER loss:16.706656
2019-02-21 16:56:00,079 - log/train6.log - INFO - iteration:13 step:2900/10100, NER loss:19.196453
2019-02-21 16:56:02,428 - log/train6.log - INFO - iteration:13 step:3000/10100, NER loss:18.635893
2019-02-21 16:56:04,664 - log/train6.log - INFO - iteration:13 step:3100/10100, NER loss:16.982162
2019-02-21 16:56:06,930 - log/train6.log - INFO - iteration:13 step:3200/10100, NER loss:18.531067
2019-02-21 16:56:09,100 - log/train6.log - INFO - iteration:13 step:3300/10100, NER loss:10.404231
2019-02-21 16:56:11,468 - log/train6.log - INFO - iteration:13 step:3400/10100, NER loss:14.019096
2019-02-21 16:56:13,828 - log/train6.log - INFO - iteration:13 step:3500/10100, NER loss:18.379219
2019-02-21 16:56:16,247 - log/train6.log - INFO - iteration:13 step:3600/10100, NER loss:15.060505
2019-02-21 16:56:18,308 - log/train6.log - INFO - iteration:13 step:3700/10100, NER loss:12.261023
2019-02-21 16:56:20,533 - log/train6.log - INFO - iteration:13 step:3800/10100, NER loss:11.823806
2019-02-21 16:56:22,814 - log/train6.log - INFO - iteration:13 step:3900/10100, NER loss:15.479633
2019-02-21 16:56:25,084 - log/train6.log - INFO - iteration:13 step:4000/10100, NER loss:12.648987
2019-02-21 16:56:27,174 - log/train6.log - INFO - iteration:13 step:4100/10100, NER loss:12.631660
2019-02-21 16:56:29,362 - log/train6.log - INFO - iteration:13 step:4200/10100, NER loss: 9.466390
2019-02-21 16:56:31,758 - log/train6.log - INFO - iteration:13 step:4300/10100, NER loss:19.555176
2019-02-21 16:56:34,620 - log/train6.log - INFO - iteration:13 step:4400/10100, NER loss:24.296099
2019-02-21 16:56:36,947 - log/train6.log - INFO - iteration:13 step:4500/10100, NER loss:13.711722
2019-02-21 16:56:39,692 - log/train6.log - INFO - iteration:13 step:4600/10100, NER loss:14.759089
2019-02-21 16:56:42,336 - log/train6.log - INFO - iteration:13 step:4700/10100, NER loss:16.288544
2019-02-21 16:56:44,645 - log/train6.log - INFO - iteration:13 step:4800/10100, NER loss:15.631538
2019-02-21 16:56:46,844 - log/train6.log - INFO - iteration:13 step:4900/10100, NER loss: 6.008922
2019-02-21 16:56:49,030 - log/train6.log - INFO - iteration:13 step:5000/10100, NER loss:13.748399
2019-02-21 16:56:51,435 - log/train6.log - INFO - iteration:13 step:5100/10100, NER loss:20.667923
2019-02-21 16:56:53,657 - log/train6.log - INFO - iteration:13 step:5200/10100, NER loss:15.828087
2019-02-21 16:56:55,888 - log/train6.log - INFO - iteration:13 step:5300/10100, NER loss:12.598438
2019-02-21 16:56:58,319 - log/train6.log - INFO - iteration:13 step:5400/10100, NER loss:13.345835
2019-02-21 16:57:00,823 - log/train6.log - INFO - iteration:13 step:5500/10100, NER loss:11.117711
2019-02-21 16:57:03,390 - log/train6.log - INFO - iteration:13 step:5600/10100, NER loss:12.949250
2019-02-21 16:57:05,819 - log/train6.log - INFO - iteration:13 step:5700/10100, NER loss:10.227841
2019-02-21 16:57:08,277 - log/train6.log - INFO - iteration:13 step:5800/10100, NER loss:14.176465
2019-02-21 16:57:10,716 - log/train6.log - INFO - iteration:13 step:5900/10100, NER loss:13.670222
2019-02-21 16:57:13,203 - log/train6.log - INFO - iteration:13 step:6000/10100, NER loss:15.630855
2019-02-21 16:57:15,516 - log/train6.log - INFO - iteration:13 step:6100/10100, NER loss:15.102359
2019-02-21 16:57:17,798 - log/train6.log - INFO - iteration:13 step:6200/10100, NER loss:10.047853
2019-02-21 16:57:20,045 - log/train6.log - INFO - iteration:13 step:6300/10100, NER loss: 9.719673
2019-02-21 16:57:22,250 - log/train6.log - INFO - iteration:13 step:6400/10100, NER loss: 9.759910
2019-02-21 16:57:24,245 - log/train6.log - INFO - iteration:13 step:6500/10100, NER loss: 6.165944
2019-02-21 16:57:26,526 - log/train6.log - INFO - iteration:13 step:6600/10100, NER loss:12.122714
2019-02-21 16:57:28,728 - log/train6.log - INFO - iteration:13 step:6700/10100, NER loss:17.019665
2019-02-21 16:57:31,006 - log/train6.log - INFO - iteration:13 step:6800/10100, NER loss:10.626139
2019-02-21 16:57:33,329 - log/train6.log - INFO - iteration:13 step:6900/10100, NER loss:11.059811
2019-02-21 16:57:35,505 - log/train6.log - INFO - iteration:13 step:7000/10100, NER loss:11.535266
2019-02-21 16:57:37,729 - log/train6.log - INFO - iteration:13 step:7100/10100, NER loss:10.388355
2019-02-21 16:57:40,151 - log/train6.log - INFO - iteration:13 step:7200/10100, NER loss:11.611492
2019-02-21 16:57:42,315 - log/train6.log - INFO - iteration:13 step:7300/10100, NER loss:14.901462
2019-02-21 16:57:44,738 - log/train6.log - INFO - iteration:13 step:7400/10100, NER loss:10.090255
2019-02-21 16:57:47,188 - log/train6.log - INFO - iteration:13 step:7500/10100, NER loss:10.933993
2019-02-21 16:57:53,659 - log/train6.log - INFO - iteration:13 step:7600/10100, NER loss:156.615997
2019-02-21 16:57:55,846 - log/train6.log - INFO - iteration:13 step:7700/10100, NER loss: 9.769087
2019-02-21 16:57:57,999 - log/train6.log - INFO - iteration:13 step:7800/10100, NER loss: 7.826196
2019-02-21 16:58:00,150 - log/train6.log - INFO - iteration:13 step:7900/10100, NER loss: 5.821333
2019-02-21 16:58:02,444 - log/train6.log - INFO - iteration:13 step:8000/10100, NER loss: 8.175920
2019-02-21 16:58:04,524 - log/train6.log - INFO - iteration:13 step:8100/10100, NER loss: 6.740607
2019-02-21 16:58:06,987 - log/train6.log - INFO - iteration:13 step:8200/10100, NER loss:10.200912
2019-02-21 16:58:09,332 - log/train6.log - INFO - iteration:13 step:8300/10100, NER loss:11.198994
2019-02-21 16:58:11,529 - log/train6.log - INFO - iteration:13 step:8400/10100, NER loss: 5.970232
2019-02-21 16:58:13,746 - log/train6.log - INFO - iteration:13 step:8500/10100, NER loss:10.828602
2019-02-21 16:58:16,077 - log/train6.log - INFO - iteration:13 step:8600/10100, NER loss: 9.798154
2019-02-21 16:58:18,506 - log/train6.log - INFO - iteration:13 step:8700/10100, NER loss:12.578440
2019-02-21 16:58:20,739 - log/train6.log - INFO - iteration:13 step:8800/10100, NER loss: 9.776410
2019-02-21 16:58:23,140 - log/train6.log - INFO - iteration:13 step:8900/10100, NER loss:13.179055
2019-02-21 16:58:25,559 - log/train6.log - INFO - iteration:13 step:9000/10100, NER loss:10.130316
2019-02-21 16:58:27,807 - log/train6.log - INFO - iteration:13 step:9100/10100, NER loss: 9.995609
2019-02-21 16:58:30,367 - log/train6.log - INFO - iteration:13 step:9200/10100, NER loss:19.048534
2019-02-21 16:58:32,772 - log/train6.log - INFO - iteration:13 step:9300/10100, NER loss:10.239685
2019-02-21 16:58:35,121 - log/train6.log - INFO - iteration:13 step:9400/10100, NER loss: 5.716385
2019-02-21 16:58:37,570 - log/train6.log - INFO - iteration:13 step:9500/10100, NER loss: 7.268228
2019-02-21 16:58:42,359 - log/train6.log - INFO - iteration:13 step:9600/10100, NER loss:16.242655
2019-02-21 16:58:44,752 - log/train6.log - INFO - iteration:13 step:9700/10100, NER loss:16.558439
2019-02-21 16:58:47,065 - log/train6.log - INFO - iteration:13 step:9800/10100, NER loss: 8.900607
2019-02-21 16:58:49,361 - log/train6.log - INFO - iteration:13 step:9900/10100, NER loss: 9.581757
2019-02-21 16:58:51,667 - log/train6.log - INFO - iteration:13 step:10000/10100, NER loss:11.366053
2019-02-21 16:58:54,019 - log/train6.log - INFO - iteration:14 step:0/10100, NER loss:13.091993
2019-02-21 16:58:54,019 - log/train6.log - INFO - evaluate:dev
2019-02-21 16:59:00,725 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5839 phrases; correct: 3912.

2019-02-21 16:59:00,725 - log/train6.log - INFO - accuracy:  94.61%; precision:  67.00%; recall:  66.91%; FB1:  66.95

2019-02-21 16:59:00,725 - log/train6.log - INFO -                 C: precision:  80.88%; recall:  84.74%; FB1:  82.77  3551

2019-02-21 16:59:00,725 - log/train6.log - INFO -               IND: precision:  50.48%; recall:  25.74%; FB1:  34.09  208

2019-02-21 16:59:00,726 - log/train6.log - INFO -               INS: precision:  66.50%; recall:  69.13%; FB1:  67.79  394

2019-02-21 16:59:00,726 - log/train6.log - INFO -                 L: precision:   0.44%; recall:   0.33%; FB1:   0.38  453

2019-02-21 16:59:00,726 - log/train6.log - INFO -                 P: precision:  89.27%; recall:  91.90%; FB1:  90.56  559

2019-02-21 16:59:00,726 - log/train6.log - INFO -               PRO: precision:  25.52%; recall:  32.95%; FB1:  28.76  674

2019-02-21 16:59:00,729 - log/train6.log - INFO - evaluate:test
2019-02-21 16:59:02,241 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1744 phrases; correct: 1356.

2019-02-21 16:59:02,241 - log/train6.log - INFO - accuracy:  96.42%; precision:  77.75%; recall:  82.33%; FB1:  79.98

2019-02-21 16:59:02,241 - log/train6.log - INFO -                 C: precision:  88.26%; recall:  93.49%; FB1:  90.80  1090

2019-02-21 16:59:02,241 - log/train6.log - INFO -               IND: precision:  67.50%; recall:  57.45%; FB1:  62.07  40

2019-02-21 16:59:02,241 - log/train6.log - INFO -               INS: precision:  70.45%; recall:  65.26%; FB1:  67.76  88

2019-02-21 16:59:02,241 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  101

2019-02-21 16:59:02,241 - log/train6.log - INFO -                 P: precision:  89.40%; recall:  95.10%; FB1:  92.16  217

2019-02-21 16:59:02,241 - log/train6.log - INFO -               PRO: precision:  53.37%; recall:  65.68%; FB1:  58.89  208

2019-02-21 16:59:04,382 - log/train6.log - INFO - iteration:14 step:100/10100, NER loss: 9.376407
2019-02-21 16:59:06,716 - log/train6.log - INFO - iteration:14 step:200/10100, NER loss: 8.295457
2019-02-21 16:59:08,842 - log/train6.log - INFO - iteration:14 step:300/10100, NER loss: 7.505669
2019-02-21 16:59:11,192 - log/train6.log - INFO - iteration:14 step:400/10100, NER loss: 5.978453
2019-02-21 16:59:13,509 - log/train6.log - INFO - iteration:14 step:500/10100, NER loss:13.154749
2019-02-21 16:59:15,743 - log/train6.log - INFO - iteration:14 step:600/10100, NER loss: 5.787921
2019-02-21 16:59:19,810 - log/train6.log - INFO - iteration:14 step:700/10100, NER loss:119.412804
2019-02-21 16:59:22,260 - log/train6.log - INFO - iteration:14 step:800/10100, NER loss: 5.413811
2019-02-21 16:59:24,864 - log/train6.log - INFO - iteration:14 step:900/10100, NER loss: 9.054178
2019-02-21 16:59:27,135 - log/train6.log - INFO - iteration:14 step:1000/10100, NER loss:11.379878
2019-02-21 16:59:29,277 - log/train6.log - INFO - iteration:14 step:1100/10100, NER loss: 5.156756
2019-02-21 16:59:31,633 - log/train6.log - INFO - iteration:14 step:1200/10100, NER loss:11.585947
2019-02-21 16:59:33,974 - log/train6.log - INFO - iteration:14 step:1300/10100, NER loss: 6.655354
2019-02-21 16:59:36,176 - log/train6.log - INFO - iteration:14 step:1400/10100, NER loss: 9.830858
2019-02-21 16:59:38,292 - log/train6.log - INFO - iteration:14 step:1500/10100, NER loss: 5.217054
2019-02-21 16:59:40,450 - log/train6.log - INFO - iteration:14 step:1600/10100, NER loss: 7.153197
2019-02-21 16:59:42,970 - log/train6.log - INFO - iteration:14 step:1700/10100, NER loss: 7.500269
2019-02-21 16:59:45,374 - log/train6.log - INFO - iteration:14 step:1800/10100, NER loss: 8.261914
2019-02-21 16:59:47,721 - log/train6.log - INFO - iteration:14 step:1900/10100, NER loss: 7.686776
2019-02-21 16:59:50,328 - log/train6.log - INFO - iteration:14 step:2000/10100, NER loss: 6.370056
2019-02-21 16:59:52,523 - log/train6.log - INFO - iteration:14 step:2100/10100, NER loss: 7.519098
2019-02-21 16:59:54,913 - log/train6.log - INFO - iteration:14 step:2200/10100, NER loss: 7.811940
2019-02-21 16:59:57,782 - log/train6.log - INFO - iteration:14 step:2300/10100, NER loss: 9.930620
2019-02-21 17:00:00,617 - log/train6.log - INFO - iteration:14 step:2400/10100, NER loss:11.285977
2019-02-21 17:00:02,771 - log/train6.log - INFO - iteration:14 step:2500/10100, NER loss:10.272185
2019-02-21 17:00:05,050 - log/train6.log - INFO - iteration:14 step:2600/10100, NER loss: 7.268191
2019-02-21 17:00:07,522 - log/train6.log - INFO - iteration:14 step:2700/10100, NER loss: 7.382154
2019-02-21 17:00:09,606 - log/train6.log - INFO - iteration:14 step:2800/10100, NER loss: 7.246610
2019-02-21 17:00:12,009 - log/train6.log - INFO - iteration:14 step:2900/10100, NER loss: 6.905570
2019-02-21 17:00:14,381 - log/train6.log - INFO - iteration:14 step:3000/10100, NER loss: 9.881647
2019-02-21 17:00:16,948 - log/train6.log - INFO - iteration:14 step:3100/10100, NER loss: 8.531010
2019-02-21 17:00:19,840 - log/train6.log - INFO - iteration:14 step:3200/10100, NER loss:11.033910
2019-02-21 17:00:22,315 - log/train6.log - INFO - iteration:14 step:3300/10100, NER loss: 8.559542
2019-02-21 17:00:24,650 - log/train6.log - INFO - iteration:14 step:3400/10100, NER loss: 6.645117
2019-02-21 17:00:27,262 - log/train6.log - INFO - iteration:14 step:3500/10100, NER loss: 8.310251
2019-02-21 17:00:29,509 - log/train6.log - INFO - iteration:14 step:3600/10100, NER loss: 6.621617
2019-02-21 17:00:31,954 - log/train6.log - INFO - iteration:14 step:3700/10100, NER loss: 6.623853
2019-02-21 17:00:34,577 - log/train6.log - INFO - iteration:14 step:3800/10100, NER loss: 8.887458
2019-02-21 17:00:36,963 - log/train6.log - INFO - iteration:14 step:3900/10100, NER loss: 6.603621
2019-02-21 17:00:39,380 - log/train6.log - INFO - iteration:14 step:4000/10100, NER loss: 8.432355
2019-02-21 17:00:41,493 - log/train6.log - INFO - iteration:14 step:4100/10100, NER loss: 4.274859
2019-02-21 17:00:43,831 - log/train6.log - INFO - iteration:14 step:4200/10100, NER loss: 8.211574
2019-02-21 17:00:46,214 - log/train6.log - INFO - iteration:14 step:4300/10100, NER loss: 6.422911
2019-02-21 17:00:48,598 - log/train6.log - INFO - iteration:14 step:4400/10100, NER loss: 8.563922
2019-02-21 17:00:50,797 - log/train6.log - INFO - iteration:14 step:4500/10100, NER loss: 4.676773
2019-02-21 17:00:53,190 - log/train6.log - INFO - iteration:14 step:4600/10100, NER loss: 6.777822
2019-02-21 17:00:55,801 - log/train6.log - INFO - iteration:14 step:4700/10100, NER loss: 5.974310
2019-02-21 17:00:58,155 - log/train6.log - INFO - iteration:14 step:4800/10100, NER loss: 5.398978
2019-02-21 17:01:00,439 - log/train6.log - INFO - iteration:14 step:4900/10100, NER loss: 6.800136
2019-02-21 17:01:02,814 - log/train6.log - INFO - iteration:14 step:5000/10100, NER loss: 7.888340
2019-02-21 17:01:05,322 - log/train6.log - INFO - iteration:14 step:5100/10100, NER loss: 8.445259
2019-02-21 17:01:07,839 - log/train6.log - INFO - iteration:14 step:5200/10100, NER loss: 7.289030
2019-02-21 17:01:10,649 - log/train6.log - INFO - iteration:14 step:5300/10100, NER loss: 7.387532
2019-02-21 17:01:14,961 - log/train6.log - INFO - iteration:14 step:5400/10100, NER loss:20.201141
2019-02-21 17:01:17,227 - log/train6.log - INFO - iteration:14 step:5500/10100, NER loss: 4.135721
2019-02-21 17:01:19,680 - log/train6.log - INFO - iteration:14 step:5600/10100, NER loss:11.635214
2019-02-21 17:01:21,769 - log/train6.log - INFO - iteration:14 step:5700/10100, NER loss: 5.972647
2019-02-21 17:01:23,914 - log/train6.log - INFO - iteration:14 step:5800/10100, NER loss: 5.072269
2019-02-21 17:01:25,989 - log/train6.log - INFO - iteration:14 step:5900/10100, NER loss: 7.951448
2019-02-21 17:01:28,443 - log/train6.log - INFO - iteration:14 step:6000/10100, NER loss: 5.523227
2019-02-21 17:01:30,620 - log/train6.log - INFO - iteration:14 step:6100/10100, NER loss: 4.074790
2019-02-21 17:01:32,591 - log/train6.log - INFO - iteration:14 step:6200/10100, NER loss: 5.935372
2019-02-21 17:01:34,918 - log/train6.log - INFO - iteration:14 step:6300/10100, NER loss:11.351901
2019-02-21 17:01:36,985 - log/train6.log - INFO - iteration:14 step:6400/10100, NER loss: 4.283630
2019-02-21 17:01:39,116 - log/train6.log - INFO - iteration:14 step:6500/10100, NER loss: 7.031556
2019-02-21 17:01:41,291 - log/train6.log - INFO - iteration:14 step:6600/10100, NER loss: 4.978263
2019-02-21 17:01:43,586 - log/train6.log - INFO - iteration:14 step:6700/10100, NER loss: 9.830675
2019-02-21 17:01:45,804 - log/train6.log - INFO - iteration:14 step:6800/10100, NER loss: 6.729918
2019-02-21 17:01:48,326 - log/train6.log - INFO - iteration:14 step:6900/10100, NER loss:11.446240
2019-02-21 17:01:50,418 - log/train6.log - INFO - iteration:14 step:7000/10100, NER loss: 5.835249
2019-02-21 17:01:52,563 - log/train6.log - INFO - iteration:14 step:7100/10100, NER loss: 4.083565
2019-02-21 17:01:54,950 - log/train6.log - INFO - iteration:14 step:7200/10100, NER loss: 7.045424
2019-02-21 17:01:57,037 - log/train6.log - INFO - iteration:14 step:7300/10100, NER loss: 5.735895
2019-02-21 17:01:59,287 - log/train6.log - INFO - iteration:14 step:7400/10100, NER loss: 4.040610
2019-02-21 17:02:01,534 - log/train6.log - INFO - iteration:14 step:7500/10100, NER loss: 4.082416
2019-02-21 17:02:03,937 - log/train6.log - INFO - iteration:14 step:7600/10100, NER loss: 5.659116
2019-02-21 17:02:06,254 - log/train6.log - INFO - iteration:14 step:7700/10100, NER loss: 4.431046
2019-02-21 17:02:08,380 - log/train6.log - INFO - iteration:14 step:7800/10100, NER loss: 6.653183
2019-02-21 17:02:10,553 - log/train6.log - INFO - iteration:14 step:7900/10100, NER loss: 6.536349
2019-02-21 17:02:12,792 - log/train6.log - INFO - iteration:14 step:8000/10100, NER loss: 8.459599
2019-02-21 17:02:14,823 - log/train6.log - INFO - iteration:14 step:8100/10100, NER loss: 5.134709
2019-02-21 17:02:17,057 - log/train6.log - INFO - iteration:14 step:8200/10100, NER loss: 7.100661
2019-02-21 17:02:19,321 - log/train6.log - INFO - iteration:14 step:8300/10100, NER loss: 9.723376
2019-02-21 17:02:21,453 - log/train6.log - INFO - iteration:14 step:8400/10100, NER loss: 5.086935
2019-02-21 17:02:23,802 - log/train6.log - INFO - iteration:14 step:8500/10100, NER loss: 4.804238
2019-02-21 17:02:26,009 - log/train6.log - INFO - iteration:14 step:8600/10100, NER loss: 6.981990
2019-02-21 17:02:28,011 - log/train6.log - INFO - iteration:14 step:8700/10100, NER loss: 4.041476
2019-02-21 17:02:30,222 - log/train6.log - INFO - iteration:14 step:8800/10100, NER loss: 6.342701
2019-02-21 17:02:32,473 - log/train6.log - INFO - iteration:14 step:8900/10100, NER loss: 5.171183
2019-02-21 17:02:34,698 - log/train6.log - INFO - iteration:14 step:9000/10100, NER loss: 7.186033
2019-02-21 17:02:39,219 - log/train6.log - INFO - iteration:14 step:9100/10100, NER loss:10.795764
2019-02-21 17:02:41,354 - log/train6.log - INFO - iteration:14 step:9200/10100, NER loss: 4.337033
2019-02-21 17:02:43,422 - log/train6.log - INFO - iteration:14 step:9300/10100, NER loss: 5.555655
2019-02-21 17:02:45,587 - log/train6.log - INFO - iteration:14 step:9400/10100, NER loss: 5.161978
2019-02-21 17:02:47,732 - log/train6.log - INFO - iteration:14 step:9500/10100, NER loss: 5.228402
2019-02-21 17:02:49,903 - log/train6.log - INFO - iteration:14 step:9600/10100, NER loss: 5.907350
2019-02-21 17:02:52,359 - log/train6.log - INFO - iteration:14 step:9700/10100, NER loss:12.006970
2019-02-21 17:02:54,616 - log/train6.log - INFO - iteration:14 step:9800/10100, NER loss: 4.278278
2019-02-21 17:02:56,998 - log/train6.log - INFO - iteration:14 step:9900/10100, NER loss: 7.005693
2019-02-21 17:02:59,381 - log/train6.log - INFO - iteration:14 step:10000/10100, NER loss: 6.215286
2019-02-21 17:03:01,769 - log/train6.log - INFO - iteration:15 step:0/10100, NER loss: 8.235837
2019-02-21 17:03:01,769 - log/train6.log - INFO - evaluate:dev
2019-02-21 17:03:08,321 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5893 phrases; correct: 4177.

2019-02-21 17:03:08,321 - log/train6.log - INFO - accuracy:  94.46%; precision:  70.88%; recall:  71.44%; FB1:  71.16

2019-02-21 17:03:08,321 - log/train6.log - INFO -                 C: precision:  83.86%; recall:  86.90%; FB1:  85.35  3512

2019-02-21 17:03:08,321 - log/train6.log - INFO -               IND: precision:  42.29%; recall:  28.92%; FB1:  34.35  279

2019-02-21 17:03:08,321 - log/train6.log - INFO -               INS: precision:  60.18%; recall:  72.56%; FB1:  65.79  457

2019-02-21 17:03:08,321 - log/train6.log - INFO -                 L: precision:  31.68%; recall:  28.38%; FB1:  29.94  543

2019-02-21 17:03:08,321 - log/train6.log - INFO -                 P: precision:  89.21%; recall:  89.87%; FB1:  89.54  547

2019-02-21 17:03:08,321 - log/train6.log - INFO -               PRO: precision:  32.25%; recall:  34.29%; FB1:  33.24  555

2019-02-21 17:03:08,324 - log/train6.log - INFO - evaluate:test
2019-02-21 17:03:09,791 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1746 phrases; correct: 1393.

2019-02-21 17:03:09,791 - log/train6.log - INFO - accuracy:  96.39%; precision:  79.78%; recall:  84.58%; FB1:  82.11

2019-02-21 17:03:09,791 - log/train6.log - INFO -                 C: precision:  87.92%; recall:  92.61%; FB1:  90.20  1084

2019-02-21 17:03:09,792 - log/train6.log - INFO -               IND: precision:  60.38%; recall:  68.09%; FB1:  64.00  53

2019-02-21 17:03:09,792 - log/train6.log - INFO -               INS: precision:  56.64%; recall:  67.37%; FB1:  61.54  113

2019-02-21 17:03:09,792 - log/train6.log - INFO -                 L: precision:  36.44%; recall:  41.75%; FB1:  38.91  118

2019-02-21 17:03:09,792 - log/train6.log - INFO -                 P: precision:  92.27%; recall:  93.63%; FB1:  92.94  207

2019-02-21 17:03:09,792 - log/train6.log - INFO -               PRO: precision:  64.33%; recall:  65.09%; FB1:  64.71  171

2019-02-21 17:03:09,866 - log/train6.log - INFO - new best test f1 score:82.110
2019-02-21 17:03:12,000 - log/train6.log - INFO - iteration:15 step:100/10100, NER loss: 8.489719
2019-02-21 17:03:13,996 - log/train6.log - INFO - iteration:15 step:200/10100, NER loss: 7.313991
2019-02-21 17:03:16,090 - log/train6.log - INFO - iteration:15 step:300/10100, NER loss: 6.018642
2019-02-21 17:03:18,329 - log/train6.log - INFO - iteration:15 step:400/10100, NER loss: 6.584993
2019-02-21 17:03:20,801 - log/train6.log - INFO - iteration:15 step:500/10100, NER loss: 7.338748
2019-02-21 17:03:23,194 - log/train6.log - INFO - iteration:15 step:600/10100, NER loss: 6.757132
2019-02-21 17:03:25,256 - log/train6.log - INFO - iteration:15 step:700/10100, NER loss: 6.398610
2019-02-21 17:03:27,432 - log/train6.log - INFO - iteration:15 step:800/10100, NER loss:12.298135
2019-02-21 17:03:29,641 - log/train6.log - INFO - iteration:15 step:900/10100, NER loss: 7.374817
2019-02-21 17:03:31,974 - log/train6.log - INFO - iteration:15 step:1000/10100, NER loss: 7.176642
2019-02-21 17:03:34,233 - log/train6.log - INFO - iteration:15 step:1100/10100, NER loss: 7.608470
2019-02-21 17:03:36,322 - log/train6.log - INFO - iteration:15 step:1200/10100, NER loss: 6.228357
2019-02-21 17:03:38,520 - log/train6.log - INFO - iteration:15 step:1300/10100, NER loss: 3.781238
2019-02-21 17:03:40,735 - log/train6.log - INFO - iteration:15 step:1400/10100, NER loss: 5.653713
2019-02-21 17:03:43,037 - log/train6.log - INFO - iteration:15 step:1500/10100, NER loss: 6.788280
2019-02-21 17:03:45,329 - log/train6.log - INFO - iteration:15 step:1600/10100, NER loss: 5.254618
2019-02-21 17:03:47,452 - log/train6.log - INFO - iteration:15 step:1700/10100, NER loss: 4.414068
2019-02-21 17:03:49,567 - log/train6.log - INFO - iteration:15 step:1800/10100, NER loss: 4.525391
2019-02-21 17:03:51,946 - log/train6.log - INFO - iteration:15 step:1900/10100, NER loss: 8.094419
2019-02-21 17:03:54,319 - log/train6.log - INFO - iteration:15 step:2000/10100, NER loss: 7.104495
2019-02-21 17:03:56,756 - log/train6.log - INFO - iteration:15 step:2100/10100, NER loss: 4.440851
2019-02-21 17:03:59,182 - log/train6.log - INFO - iteration:15 step:2200/10100, NER loss: 8.621975
2019-02-21 17:04:01,474 - log/train6.log - INFO - iteration:15 step:2300/10100, NER loss: 4.895334
2019-02-21 17:04:03,684 - log/train6.log - INFO - iteration:15 step:2400/10100, NER loss: 4.545088
2019-02-21 17:04:06,545 - log/train6.log - INFO - iteration:15 step:2500/10100, NER loss:11.628439
2019-02-21 17:04:08,949 - log/train6.log - INFO - iteration:15 step:2600/10100, NER loss: 7.264217
2019-02-21 17:04:11,180 - log/train6.log - INFO - iteration:15 step:2700/10100, NER loss: 8.059765
2019-02-21 17:04:13,284 - log/train6.log - INFO - iteration:15 step:2800/10100, NER loss: 5.079242
2019-02-21 17:04:15,607 - log/train6.log - INFO - iteration:15 step:2900/10100, NER loss: 5.958967
2019-02-21 17:04:17,567 - log/train6.log - INFO - iteration:15 step:3000/10100, NER loss: 5.611589
2019-02-21 17:04:19,661 - log/train6.log - INFO - iteration:15 step:3100/10100, NER loss: 5.784086
2019-02-21 17:04:22,364 - log/train6.log - INFO - iteration:15 step:3200/10100, NER loss: 6.686075
2019-02-21 17:04:24,508 - log/train6.log - INFO - iteration:15 step:3300/10100, NER loss: 3.734421
2019-02-21 17:04:26,873 - log/train6.log - INFO - iteration:15 step:3400/10100, NER loss: 6.709354
2019-02-21 17:04:28,942 - log/train6.log - INFO - iteration:15 step:3500/10100, NER loss: 4.927292
2019-02-21 17:04:31,048 - log/train6.log - INFO - iteration:15 step:3600/10100, NER loss: 5.205786
2019-02-21 17:04:33,122 - log/train6.log - INFO - iteration:15 step:3700/10100, NER loss: 3.729367
2019-02-21 17:04:35,244 - log/train6.log - INFO - iteration:15 step:3800/10100, NER loss: 7.432711
2019-02-21 17:04:37,611 - log/train6.log - INFO - iteration:15 step:3900/10100, NER loss: 5.839991
2019-02-21 17:04:39,912 - log/train6.log - INFO - iteration:15 step:4000/10100, NER loss: 5.364269
2019-02-21 17:04:42,259 - log/train6.log - INFO - iteration:15 step:4100/10100, NER loss: 3.771090
2019-02-21 17:04:44,270 - log/train6.log - INFO - iteration:15 step:4200/10100, NER loss: 5.252378
2019-02-21 17:04:46,390 - log/train6.log - INFO - iteration:15 step:4300/10100, NER loss: 2.544364
2019-02-21 17:04:48,996 - log/train6.log - INFO - iteration:15 step:4400/10100, NER loss: 5.076586
2019-02-21 17:04:51,092 - log/train6.log - INFO - iteration:15 step:4500/10100, NER loss: 6.436972
2019-02-21 17:04:53,244 - log/train6.log - INFO - iteration:15 step:4600/10100, NER loss: 4.889197
2019-02-21 17:04:55,367 - log/train6.log - INFO - iteration:15 step:4700/10100, NER loss: 4.655963
2019-02-21 17:04:57,509 - log/train6.log - INFO - iteration:15 step:4800/10100, NER loss: 9.123502
2019-02-21 17:04:59,550 - log/train6.log - INFO - iteration:15 step:4900/10100, NER loss: 3.263829
2019-02-21 17:05:01,840 - log/train6.log - INFO - iteration:15 step:5000/10100, NER loss: 4.109220
2019-02-21 17:05:04,203 - log/train6.log - INFO - iteration:15 step:5100/10100, NER loss: 5.646314
2019-02-21 17:05:06,510 - log/train6.log - INFO - iteration:15 step:5200/10100, NER loss: 6.372170
2019-02-21 17:05:08,896 - log/train6.log - INFO - iteration:15 step:5300/10100, NER loss: 8.493407
2019-02-21 17:05:11,172 - log/train6.log - INFO - iteration:15 step:5400/10100, NER loss: 4.973852
2019-02-21 17:05:13,498 - log/train6.log - INFO - iteration:15 step:5500/10100, NER loss: 6.723536
2019-02-21 17:05:15,342 - log/train6.log - INFO - iteration:15 step:5600/10100, NER loss: 3.955153
2019-02-21 17:05:21,508 - log/train6.log - INFO - iteration:15 step:5700/10100, NER loss:88.953896
2019-02-21 17:05:23,680 - log/train6.log - INFO - iteration:15 step:5800/10100, NER loss: 6.574979
2019-02-21 17:05:25,668 - log/train6.log - INFO - iteration:15 step:5900/10100, NER loss: 5.730278
2019-02-21 17:05:27,945 - log/train6.log - INFO - iteration:15 step:6000/10100, NER loss: 4.553687
2019-02-21 17:05:30,187 - log/train6.log - INFO - iteration:15 step:6100/10100, NER loss: 4.320425
2019-02-21 17:05:32,316 - log/train6.log - INFO - iteration:15 step:6200/10100, NER loss: 5.667361
2019-02-21 17:05:34,500 - log/train6.log - INFO - iteration:15 step:6300/10100, NER loss: 4.353128
2019-02-21 17:05:36,692 - log/train6.log - INFO - iteration:15 step:6400/10100, NER loss: 6.250064
2019-02-21 17:05:38,797 - log/train6.log - INFO - iteration:15 step:6500/10100, NER loss: 3.537394
2019-02-21 17:05:41,037 - log/train6.log - INFO - iteration:15 step:6600/10100, NER loss: 4.599781
2019-02-21 17:05:43,328 - log/train6.log - INFO - iteration:15 step:6700/10100, NER loss: 5.076967
2019-02-21 17:05:45,555 - log/train6.log - INFO - iteration:15 step:6800/10100, NER loss: 4.600337
2019-02-21 17:05:47,792 - log/train6.log - INFO - iteration:15 step:6900/10100, NER loss: 6.486034
2019-02-21 17:05:50,074 - log/train6.log - INFO - iteration:15 step:7000/10100, NER loss: 5.532587
2019-02-21 17:05:52,195 - log/train6.log - INFO - iteration:15 step:7100/10100, NER loss: 4.710394
2019-02-21 17:05:54,369 - log/train6.log - INFO - iteration:15 step:7200/10100, NER loss: 6.169731
2019-02-21 17:05:56,443 - log/train6.log - INFO - iteration:15 step:7300/10100, NER loss: 6.949382
2019-02-21 17:05:58,867 - log/train6.log - INFO - iteration:15 step:7400/10100, NER loss: 6.538505
2019-02-21 17:06:01,104 - log/train6.log - INFO - iteration:15 step:7500/10100, NER loss: 4.001181
2019-02-21 17:06:03,256 - log/train6.log - INFO - iteration:15 step:7600/10100, NER loss: 4.224854
2019-02-21 17:06:05,467 - log/train6.log - INFO - iteration:15 step:7700/10100, NER loss: 4.798812
2019-02-21 17:06:07,537 - log/train6.log - INFO - iteration:15 step:7800/10100, NER loss: 2.975050
2019-02-21 17:06:09,897 - log/train6.log - INFO - iteration:15 step:7900/10100, NER loss: 6.276116
2019-02-21 17:06:12,116 - log/train6.log - INFO - iteration:15 step:8000/10100, NER loss: 3.349143
2019-02-21 17:06:14,348 - log/train6.log - INFO - iteration:15 step:8100/10100, NER loss: 8.484267
2019-02-21 17:06:16,653 - log/train6.log - INFO - iteration:15 step:8200/10100, NER loss: 6.219683
2019-02-21 17:06:18,937 - log/train6.log - INFO - iteration:15 step:8300/10100, NER loss: 5.752758
2019-02-21 17:06:21,276 - log/train6.log - INFO - iteration:15 step:8400/10100, NER loss: 5.091431
2019-02-21 17:06:23,663 - log/train6.log - INFO - iteration:15 step:8500/10100, NER loss: 5.128942
2019-02-21 17:06:26,130 - log/train6.log - INFO - iteration:15 step:8600/10100, NER loss: 7.569119
2019-02-21 17:06:28,351 - log/train6.log - INFO - iteration:15 step:8700/10100, NER loss: 6.790902
2019-02-21 17:06:30,453 - log/train6.log - INFO - iteration:15 step:8800/10100, NER loss: 3.408355
2019-02-21 17:06:34,842 - log/train6.log - INFO - iteration:15 step:8900/10100, NER loss: 8.916089
2019-02-21 17:06:36,960 - log/train6.log - INFO - iteration:15 step:9000/10100, NER loss: 3.214791
2019-02-21 17:06:39,149 - log/train6.log - INFO - iteration:15 step:9100/10100, NER loss: 4.616233
2019-02-21 17:06:41,348 - log/train6.log - INFO - iteration:15 step:9200/10100, NER loss: 5.038505
2019-02-21 17:06:43,513 - log/train6.log - INFO - iteration:15 step:9300/10100, NER loss: 6.285621
2019-02-21 17:06:45,671 - log/train6.log - INFO - iteration:15 step:9400/10100, NER loss: 5.047428
2019-02-21 17:06:47,886 - log/train6.log - INFO - iteration:15 step:9500/10100, NER loss: 3.748948
2019-02-21 17:06:50,076 - log/train6.log - INFO - iteration:15 step:9600/10100, NER loss: 7.662807
2019-02-21 17:06:52,147 - log/train6.log - INFO - iteration:15 step:9700/10100, NER loss: 4.933229
2019-02-21 17:06:54,298 - log/train6.log - INFO - iteration:15 step:9800/10100, NER loss: 3.592936
2019-02-21 17:06:56,831 - log/train6.log - INFO - iteration:15 step:9900/10100, NER loss: 6.273381
2019-02-21 17:06:59,085 - log/train6.log - INFO - iteration:15 step:10000/10100, NER loss: 4.298688
2019-02-21 17:07:01,593 - log/train6.log - INFO - iteration:16 step:0/10100, NER loss: 5.723182
2019-02-21 17:07:01,593 - log/train6.log - INFO - evaluate:dev
2019-02-21 17:07:08,449 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5750 phrases; correct: 4241.

2019-02-21 17:07:08,449 - log/train6.log - INFO - accuracy:  94.87%; precision:  73.76%; recall:  72.53%; FB1:  73.14

2019-02-21 17:07:08,449 - log/train6.log - INFO -                 C: precision:  87.54%; recall:  88.29%; FB1:  87.91  3418

2019-02-21 17:07:08,449 - log/train6.log - INFO -               IND: precision:  37.01%; recall:  37.01%; FB1:  37.01  408

2019-02-21 17:07:08,449 - log/train6.log - INFO -               INS: precision:  67.62%; recall:  74.93%; FB1:  71.09  420

2019-02-21 17:07:08,449 - log/train6.log - INFO -                 L: precision:  33.93%; recall:  28.22%; FB1:  30.81  504

2019-02-21 17:07:08,449 - log/train6.log - INFO -                 P: precision:  88.55%; recall:  91.16%; FB1:  89.84  559

2019-02-21 17:07:08,449 - log/train6.log - INFO -               PRO: precision:  33.56%; recall:  28.35%; FB1:  30.74  441

2019-02-21 17:07:08,536 - log/train6.log - INFO - new best dev f1 score:73.140
2019-02-21 17:07:08,813 - log/train6.log - INFO - model saved
2019-02-21 17:07:08,813 - log/train6.log - INFO - evaluate:test
2019-02-21 17:07:10,279 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1714 phrases; correct: 1384.

2019-02-21 17:07:10,279 - log/train6.log - INFO - accuracy:  96.74%; precision:  80.75%; recall:  84.03%; FB1:  82.36

2019-02-21 17:07:10,279 - log/train6.log - INFO -                 C: precision:  88.72%; recall:  92.52%; FB1:  90.58  1073

2019-02-21 17:07:10,280 - log/train6.log - INFO -               IND: precision:  43.04%; recall:  72.34%; FB1:  53.97  79

2019-02-21 17:07:10,280 - log/train6.log - INFO -               INS: precision:  68.13%; recall:  65.26%; FB1:  66.67  91

2019-02-21 17:07:10,280 - log/train6.log - INFO -                 L: precision:  36.44%; recall:  41.75%; FB1:  38.91  118

2019-02-21 17:07:10,280 - log/train6.log - INFO -                 P: precision:  91.90%; recall:  94.61%; FB1:  93.24  210

2019-02-21 17:07:10,280 - log/train6.log - INFO -               PRO: precision:  69.93%; recall:  59.17%; FB1:  64.10  143

2019-02-21 17:07:10,350 - log/train6.log - INFO - new best test f1 score:82.360
2019-02-21 17:07:12,493 - log/train6.log - INFO - iteration:16 step:100/10100, NER loss: 5.489878
2019-02-21 17:07:14,514 - log/train6.log - INFO - iteration:16 step:200/10100, NER loss: 5.510433
2019-02-21 17:07:16,511 - log/train6.log - INFO - iteration:16 step:300/10100, NER loss: 6.072791
2019-02-21 17:07:18,575 - log/train6.log - INFO - iteration:16 step:400/10100, NER loss: 4.452719
2019-02-21 17:07:20,719 - log/train6.log - INFO - iteration:16 step:500/10100, NER loss: 4.019888
2019-02-21 17:07:23,010 - log/train6.log - INFO - iteration:16 step:600/10100, NER loss: 7.572637
2019-02-21 17:07:25,245 - log/train6.log - INFO - iteration:16 step:700/10100, NER loss: 4.560517
2019-02-21 17:07:27,669 - log/train6.log - INFO - iteration:16 step:800/10100, NER loss: 5.835099
2019-02-21 17:07:29,873 - log/train6.log - INFO - iteration:16 step:900/10100, NER loss: 5.067124
2019-02-21 17:07:32,210 - log/train6.log - INFO - iteration:16 step:1000/10100, NER loss: 6.471794
2019-02-21 17:07:34,479 - log/train6.log - INFO - iteration:16 step:1100/10100, NER loss: 6.383323
2019-02-21 17:07:36,995 - log/train6.log - INFO - iteration:16 step:1200/10100, NER loss: 4.359978
2019-02-21 17:07:39,406 - log/train6.log - INFO - iteration:16 step:1300/10100, NER loss: 5.975151
2019-02-21 17:07:41,738 - log/train6.log - INFO - iteration:16 step:1400/10100, NER loss: 3.995765
2019-02-21 17:07:44,093 - log/train6.log - INFO - iteration:16 step:1500/10100, NER loss: 4.704111
2019-02-21 17:07:46,523 - log/train6.log - INFO - iteration:16 step:1600/10100, NER loss: 9.856453
2019-02-21 17:07:48,579 - log/train6.log - INFO - iteration:16 step:1700/10100, NER loss: 4.318887
2019-02-21 17:07:50,730 - log/train6.log - INFO - iteration:16 step:1800/10100, NER loss: 5.169449
2019-02-21 17:07:53,052 - log/train6.log - INFO - iteration:16 step:1900/10100, NER loss: 3.912109
2019-02-21 17:07:55,375 - log/train6.log - INFO - iteration:16 step:2000/10100, NER loss: 3.126247
2019-02-21 17:07:57,562 - log/train6.log - INFO - iteration:16 step:2100/10100, NER loss: 4.548086
2019-02-21 17:07:59,532 - log/train6.log - INFO - iteration:16 step:2200/10100, NER loss: 3.145322
2019-02-21 17:08:01,614 - log/train6.log - INFO - iteration:16 step:2300/10100, NER loss: 4.530867
2019-02-21 17:08:03,746 - log/train6.log - INFO - iteration:16 step:2400/10100, NER loss: 4.866930
2019-02-21 17:08:05,761 - log/train6.log - INFO - iteration:16 step:2500/10100, NER loss: 3.876703
2019-02-21 17:08:07,804 - log/train6.log - INFO - iteration:16 step:2600/10100, NER loss: 3.309493
2019-02-21 17:08:10,065 - log/train6.log - INFO - iteration:16 step:2700/10100, NER loss: 4.465637
2019-02-21 17:08:12,361 - log/train6.log - INFO - iteration:16 step:2800/10100, NER loss: 5.472521
2019-02-21 17:08:14,652 - log/train6.log - INFO - iteration:16 step:2900/10100, NER loss: 6.991431
2019-02-21 17:08:16,760 - log/train6.log - INFO - iteration:16 step:3000/10100, NER loss: 3.964159
2019-02-21 17:08:18,939 - log/train6.log - INFO - iteration:16 step:3100/10100, NER loss: 4.354573
2019-02-21 17:08:21,099 - log/train6.log - INFO - iteration:16 step:3200/10100, NER loss: 3.601965
2019-02-21 17:08:23,287 - log/train6.log - INFO - iteration:16 step:3300/10100, NER loss: 2.824444
2019-02-21 17:08:25,434 - log/train6.log - INFO - iteration:16 step:3400/10100, NER loss: 6.765363
2019-02-21 17:08:27,788 - log/train6.log - INFO - iteration:16 step:3500/10100, NER loss: 4.989440
2019-02-21 17:08:30,055 - log/train6.log - INFO - iteration:16 step:3600/10100, NER loss: 3.624251
2019-02-21 17:08:32,360 - log/train6.log - INFO - iteration:16 step:3700/10100, NER loss: 3.892008
2019-02-21 17:08:34,705 - log/train6.log - INFO - iteration:16 step:3800/10100, NER loss: 6.666413
2019-02-21 17:08:36,939 - log/train6.log - INFO - iteration:16 step:3900/10100, NER loss: 5.780618
2019-02-21 17:08:39,219 - log/train6.log - INFO - iteration:16 step:4000/10100, NER loss: 6.021875
2019-02-21 17:08:41,407 - log/train6.log - INFO - iteration:16 step:4100/10100, NER loss: 4.599723
2019-02-21 17:08:43,823 - log/train6.log - INFO - iteration:16 step:4200/10100, NER loss: 5.495340
2019-02-21 17:08:46,040 - log/train6.log - INFO - iteration:16 step:4300/10100, NER loss: 3.499624
2019-02-21 17:08:48,267 - log/train6.log - INFO - iteration:16 step:4400/10100, NER loss: 6.542191
2019-02-21 17:08:50,701 - log/train6.log - INFO - iteration:16 step:4500/10100, NER loss: 6.901163
2019-02-21 17:08:53,095 - log/train6.log - INFO - iteration:16 step:4600/10100, NER loss: 3.694073
2019-02-21 17:08:55,665 - log/train6.log - INFO - iteration:16 step:4700/10100, NER loss: 9.395967
2019-02-21 17:08:57,863 - log/train6.log - INFO - iteration:16 step:4800/10100, NER loss: 4.003893
2019-02-21 17:09:00,024 - log/train6.log - INFO - iteration:16 step:4900/10100, NER loss: 4.238209
2019-02-21 17:09:02,235 - log/train6.log - INFO - iteration:16 step:5000/10100, NER loss: 6.228215
2019-02-21 17:09:04,475 - log/train6.log - INFO - iteration:16 step:5100/10100, NER loss: 6.675467
2019-02-21 17:09:06,732 - log/train6.log - INFO - iteration:16 step:5200/10100, NER loss: 4.429722
2019-02-21 17:09:08,995 - log/train6.log - INFO - iteration:16 step:5300/10100, NER loss: 4.690509
2019-02-21 17:09:11,194 - log/train6.log - INFO - iteration:16 step:5400/10100, NER loss: 4.988812
2019-02-21 17:09:13,565 - log/train6.log - INFO - iteration:16 step:5500/10100, NER loss: 4.317343
2019-02-21 17:09:16,091 - log/train6.log - INFO - iteration:16 step:5600/10100, NER loss: 4.896851
2019-02-21 17:09:20,224 - log/train6.log - INFO - iteration:16 step:5700/10100, NER loss:64.506371
2019-02-21 17:09:22,586 - log/train6.log - INFO - iteration:16 step:5800/10100, NER loss: 3.091966
2019-02-21 17:09:24,647 - log/train6.log - INFO - iteration:16 step:5900/10100, NER loss: 4.597988
2019-02-21 17:09:26,981 - log/train6.log - INFO - iteration:16 step:6000/10100, NER loss: 5.420634
2019-02-21 17:09:31,134 - log/train6.log - INFO - iteration:16 step:6100/10100, NER loss: 9.122315
2019-02-21 17:09:33,293 - log/train6.log - INFO - iteration:16 step:6200/10100, NER loss: 3.892270
2019-02-21 17:09:35,538 - log/train6.log - INFO - iteration:16 step:6300/10100, NER loss: 5.125202
2019-02-21 17:09:37,993 - log/train6.log - INFO - iteration:16 step:6400/10100, NER loss: 9.333303
2019-02-21 17:09:40,305 - log/train6.log - INFO - iteration:16 step:6500/10100, NER loss: 4.708194
2019-02-21 17:09:42,841 - log/train6.log - INFO - iteration:16 step:6600/10100, NER loss: 4.576385
2019-02-21 17:09:45,201 - log/train6.log - INFO - iteration:16 step:6700/10100, NER loss: 4.191677
2019-02-21 17:09:47,343 - log/train6.log - INFO - iteration:16 step:6800/10100, NER loss: 4.450561
2019-02-21 17:09:49,497 - log/train6.log - INFO - iteration:16 step:6900/10100, NER loss: 4.723368
2019-02-21 17:09:51,624 - log/train6.log - INFO - iteration:16 step:7000/10100, NER loss: 6.337986
2019-02-21 17:09:53,877 - log/train6.log - INFO - iteration:16 step:7100/10100, NER loss: 3.484302
2019-02-21 17:09:55,934 - log/train6.log - INFO - iteration:16 step:7200/10100, NER loss: 4.423416
2019-02-21 17:09:58,292 - log/train6.log - INFO - iteration:16 step:7300/10100, NER loss: 4.658151
2019-02-21 17:10:00,618 - log/train6.log - INFO - iteration:16 step:7400/10100, NER loss: 5.363400
2019-02-21 17:10:02,744 - log/train6.log - INFO - iteration:16 step:7500/10100, NER loss: 3.349014
2019-02-21 17:10:05,104 - log/train6.log - INFO - iteration:16 step:7600/10100, NER loss: 5.224843
2019-02-21 17:10:07,339 - log/train6.log - INFO - iteration:16 step:7700/10100, NER loss: 3.397537
2019-02-21 17:10:09,487 - log/train6.log - INFO - iteration:16 step:7800/10100, NER loss: 4.105466
2019-02-21 17:10:11,779 - log/train6.log - INFO - iteration:16 step:7900/10100, NER loss: 3.709966
2019-02-21 17:10:14,038 - log/train6.log - INFO - iteration:16 step:8000/10100, NER loss: 5.352449
2019-02-21 17:10:16,184 - log/train6.log - INFO - iteration:16 step:8100/10100, NER loss: 3.213578
2019-02-21 17:10:18,410 - log/train6.log - INFO - iteration:16 step:8200/10100, NER loss: 4.962082
2019-02-21 17:10:20,521 - log/train6.log - INFO - iteration:16 step:8300/10100, NER loss: 2.976870
2019-02-21 17:10:22,654 - log/train6.log - INFO - iteration:16 step:8400/10100, NER loss: 2.645046
2019-02-21 17:10:24,808 - log/train6.log - INFO - iteration:16 step:8500/10100, NER loss: 4.139995
2019-02-21 17:10:27,159 - log/train6.log - INFO - iteration:16 step:8600/10100, NER loss: 3.176371
2019-02-21 17:10:29,305 - log/train6.log - INFO - iteration:16 step:8700/10100, NER loss: 3.499722
2019-02-21 17:10:31,408 - log/train6.log - INFO - iteration:16 step:8800/10100, NER loss: 5.116823
2019-02-21 17:10:33,658 - log/train6.log - INFO - iteration:16 step:8900/10100, NER loss: 4.261217
2019-02-21 17:10:35,873 - log/train6.log - INFO - iteration:16 step:9000/10100, NER loss: 3.055570
2019-02-21 17:10:37,983 - log/train6.log - INFO - iteration:16 step:9100/10100, NER loss: 4.792319
2019-02-21 17:10:40,038 - log/train6.log - INFO - iteration:16 step:9200/10100, NER loss: 3.664351
2019-02-21 17:10:42,195 - log/train6.log - INFO - iteration:16 step:9300/10100, NER loss: 3.203758
2019-02-21 17:10:46,330 - log/train6.log - INFO - iteration:16 step:9400/10100, NER loss:10.767378
2019-02-21 17:10:48,487 - log/train6.log - INFO - iteration:16 step:9500/10100, NER loss: 5.154792
2019-02-21 17:10:50,862 - log/train6.log - INFO - iteration:16 step:9600/10100, NER loss: 3.425686
2019-02-21 17:10:52,986 - log/train6.log - INFO - iteration:16 step:9700/10100, NER loss: 2.865642
2019-02-21 17:10:55,419 - log/train6.log - INFO - iteration:16 step:9800/10100, NER loss: 6.842207
2019-02-21 17:10:57,800 - log/train6.log - INFO - iteration:16 step:9900/10100, NER loss: 5.984350
2019-02-21 17:11:00,162 - log/train6.log - INFO - iteration:16 step:10000/10100, NER loss: 4.015506
2019-02-21 17:11:02,327 - log/train6.log - INFO - iteration:17 step:0/10100, NER loss: 4.324049
2019-02-21 17:11:02,327 - log/train6.log - INFO - evaluate:dev
2019-02-21 17:11:08,835 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5995 phrases; correct: 4203.

2019-02-21 17:11:08,835 - log/train6.log - INFO - accuracy:  94.67%; precision:  70.11%; recall:  71.88%; FB1:  70.98

2019-02-21 17:11:08,836 - log/train6.log - INFO -                 C: precision:  88.60%; recall:  87.37%; FB1:  87.98  3342

2019-02-21 17:11:08,836 - log/train6.log - INFO -               IND: precision:  33.78%; recall:  37.01%; FB1:  35.32  447

2019-02-21 17:11:08,836 - log/train6.log - INFO -               INS: precision:  57.11%; recall:  73.09%; FB1:  64.12  485

2019-02-21 17:11:08,836 - log/train6.log - INFO -                 L: precision:  26.74%; recall:  30.36%; FB1:  28.44  688

2019-02-21 17:11:08,836 - log/train6.log - INFO -                 P: precision:  89.71%; recall:  89.87%; FB1:  89.79  544

2019-02-21 17:11:08,836 - log/train6.log - INFO -               PRO: precision:  29.04%; recall:  27.20%; FB1:  28.09  489

2019-02-21 17:11:08,839 - log/train6.log - INFO - evaluate:test
2019-02-21 17:11:10,293 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1732 phrases; correct: 1390.

2019-02-21 17:11:10,294 - log/train6.log - INFO - accuracy:  96.35%; precision:  80.25%; recall:  84.40%; FB1:  82.27

2019-02-21 17:11:10,294 - log/train6.log - INFO -                 C: precision:  90.88%; recall:  92.03%; FB1:  91.45  1042

2019-02-21 17:11:10,294 - log/train6.log - INFO -               IND: precision:  43.75%; recall:  74.47%; FB1:  55.12  80

2019-02-21 17:11:10,294 - log/train6.log - INFO -               INS: precision:  60.00%; recall:  66.32%; FB1:  63.00  105

2019-02-21 17:11:10,294 - log/train6.log - INFO -                 L: precision:  40.50%; recall:  47.57%; FB1:  43.75  121

2019-02-21 17:11:10,294 - log/train6.log - INFO -                 P: precision:  90.95%; recall:  93.63%; FB1:  92.27  210

2019-02-21 17:11:10,294 - log/train6.log - INFO -               PRO: precision:  60.34%; recall:  62.13%; FB1:  61.22  174

2019-02-21 17:11:12,098 - log/train6.log - INFO - iteration:17 step:100/10100, NER loss: 2.615304
2019-02-21 17:11:14,004 - log/train6.log - INFO - iteration:17 step:200/10100, NER loss: 3.640894
2019-02-21 17:11:15,888 - log/train6.log - INFO - iteration:17 step:300/10100, NER loss: 4.654056
2019-02-21 17:11:18,034 - log/train6.log - INFO - iteration:17 step:400/10100, NER loss: 4.657259
2019-02-21 17:11:20,358 - log/train6.log - INFO - iteration:17 step:500/10100, NER loss: 3.473257
2019-02-21 17:11:24,468 - log/train6.log - INFO - iteration:17 step:600/10100, NER loss:57.031124
2019-02-21 17:11:26,432 - log/train6.log - INFO - iteration:17 step:700/10100, NER loss: 2.767764
2019-02-21 17:11:28,710 - log/train6.log - INFO - iteration:17 step:800/10100, NER loss: 3.688814
2019-02-21 17:11:30,801 - log/train6.log - INFO - iteration:17 step:900/10100, NER loss: 3.437504
2019-02-21 17:11:32,908 - log/train6.log - INFO - iteration:17 step:1000/10100, NER loss: 3.619144
2019-02-21 17:11:34,987 - log/train6.log - INFO - iteration:17 step:1100/10100, NER loss: 3.092989
2019-02-21 17:11:37,240 - log/train6.log - INFO - iteration:17 step:1200/10100, NER loss: 4.521959
2019-02-21 17:11:39,346 - log/train6.log - INFO - iteration:17 step:1300/10100, NER loss: 3.520481
2019-02-21 17:11:41,509 - log/train6.log - INFO - iteration:17 step:1400/10100, NER loss: 3.846984
2019-02-21 17:11:43,953 - log/train6.log - INFO - iteration:17 step:1500/10100, NER loss: 5.310239
2019-02-21 17:11:46,469 - log/train6.log - INFO - iteration:17 step:1600/10100, NER loss: 4.707886
2019-02-21 17:11:48,273 - log/train6.log - INFO - iteration:17 step:1700/10100, NER loss: 2.224545
2019-02-21 17:11:50,602 - log/train6.log - INFO - iteration:17 step:1800/10100, NER loss: 5.107729
2019-02-21 17:11:52,809 - log/train6.log - INFO - iteration:17 step:1900/10100, NER loss: 3.730433
2019-02-21 17:11:54,822 - log/train6.log - INFO - iteration:17 step:2000/10100, NER loss: 3.664761
2019-02-21 17:11:56,950 - log/train6.log - INFO - iteration:17 step:2100/10100, NER loss: 3.524731
2019-02-21 17:11:59,214 - log/train6.log - INFO - iteration:17 step:2200/10100, NER loss: 3.760740
2019-02-21 17:12:01,878 - log/train6.log - INFO - iteration:17 step:2300/10100, NER loss: 4.644690
2019-02-21 17:12:04,254 - log/train6.log - INFO - iteration:17 step:2400/10100, NER loss: 2.681410
2019-02-21 17:12:06,477 - log/train6.log - INFO - iteration:17 step:2500/10100, NER loss: 4.360878
2019-02-21 17:12:08,932 - log/train6.log - INFO - iteration:17 step:2600/10100, NER loss: 5.480173
2019-02-21 17:12:11,321 - log/train6.log - INFO - iteration:17 step:2700/10100, NER loss: 3.633077
2019-02-21 17:12:13,717 - log/train6.log - INFO - iteration:17 step:2800/10100, NER loss: 3.946394
2019-02-21 17:12:15,770 - log/train6.log - INFO - iteration:17 step:2900/10100, NER loss: 2.869352
2019-02-21 17:12:18,186 - log/train6.log - INFO - iteration:17 step:3000/10100, NER loss: 3.879976
2019-02-21 17:12:20,521 - log/train6.log - INFO - iteration:17 step:3100/10100, NER loss: 4.384482
2019-02-21 17:12:25,163 - log/train6.log - INFO - iteration:17 step:3200/10100, NER loss: 7.912847
2019-02-21 17:12:27,578 - log/train6.log - INFO - iteration:17 step:3300/10100, NER loss: 4.048378
2019-02-21 17:12:30,247 - log/train6.log - INFO - iteration:17 step:3400/10100, NER loss: 3.911381
2019-02-21 17:12:32,490 - log/train6.log - INFO - iteration:17 step:3500/10100, NER loss: 3.229307
2019-02-21 17:12:34,832 - log/train6.log - INFO - iteration:17 step:3600/10100, NER loss: 3.745741
2019-02-21 17:12:37,265 - log/train6.log - INFO - iteration:17 step:3700/10100, NER loss: 4.520262
2019-02-21 17:12:39,375 - log/train6.log - INFO - iteration:17 step:3800/10100, NER loss: 3.319804
2019-02-21 17:12:41,617 - log/train6.log - INFO - iteration:17 step:3900/10100, NER loss: 3.827180
2019-02-21 17:12:43,793 - log/train6.log - INFO - iteration:17 step:4000/10100, NER loss: 4.101802
2019-02-21 17:12:46,099 - log/train6.log - INFO - iteration:17 step:4100/10100, NER loss: 5.437439
2019-02-21 17:12:48,565 - log/train6.log - INFO - iteration:17 step:4200/10100, NER loss: 4.112737
2019-02-21 17:12:51,142 - log/train6.log - INFO - iteration:17 step:4300/10100, NER loss: 4.654612
2019-02-21 17:12:53,104 - log/train6.log - INFO - iteration:17 step:4400/10100, NER loss: 3.042281
2019-02-21 17:12:55,507 - log/train6.log - INFO - iteration:17 step:4500/10100, NER loss: 4.749481
2019-02-21 17:12:57,814 - log/train6.log - INFO - iteration:17 step:4600/10100, NER loss: 6.517080
2019-02-21 17:12:59,773 - log/train6.log - INFO - iteration:17 step:4700/10100, NER loss: 3.496857
2019-02-21 17:13:02,150 - log/train6.log - INFO - iteration:17 step:4800/10100, NER loss: 2.535414
2019-02-21 17:13:04,466 - log/train6.log - INFO - iteration:17 step:4900/10100, NER loss: 2.987846
2019-02-21 17:13:06,685 - log/train6.log - INFO - iteration:17 step:5000/10100, NER loss: 3.684592
2019-02-21 17:13:09,746 - log/train6.log - INFO - iteration:17 step:5100/10100, NER loss: 6.163576
2019-02-21 17:13:12,224 - log/train6.log - INFO - iteration:17 step:5200/10100, NER loss: 4.791280
2019-02-21 17:13:14,986 - log/train6.log - INFO - iteration:17 step:5300/10100, NER loss: 4.039513
2019-02-21 17:13:17,439 - log/train6.log - INFO - iteration:17 step:5400/10100, NER loss: 4.171356
2019-02-21 17:13:19,781 - log/train6.log - INFO - iteration:17 step:5500/10100, NER loss: 4.249537
2019-02-21 17:13:22,183 - log/train6.log - INFO - iteration:17 step:5600/10100, NER loss: 3.782647
2019-02-21 17:13:24,310 - log/train6.log - INFO - iteration:17 step:5700/10100, NER loss: 3.371354
2019-02-21 17:13:26,465 - log/train6.log - INFO - iteration:17 step:5800/10100, NER loss: 4.475631
2019-02-21 17:13:28,727 - log/train6.log - INFO - iteration:17 step:5900/10100, NER loss: 4.328801
2019-02-21 17:13:30,774 - log/train6.log - INFO - iteration:17 step:6000/10100, NER loss: 2.973914
2019-02-21 17:13:33,048 - log/train6.log - INFO - iteration:17 step:6100/10100, NER loss: 3.352318
2019-02-21 17:13:35,541 - log/train6.log - INFO - iteration:17 step:6200/10100, NER loss: 2.812546
2019-02-21 17:13:37,792 - log/train6.log - INFO - iteration:17 step:6300/10100, NER loss: 4.968774
2019-02-21 17:13:40,055 - log/train6.log - INFO - iteration:17 step:6400/10100, NER loss: 5.570609
2019-02-21 17:13:42,342 - log/train6.log - INFO - iteration:17 step:6500/10100, NER loss: 3.620447
2019-02-21 17:13:44,484 - log/train6.log - INFO - iteration:17 step:6600/10100, NER loss: 2.214701
2019-02-21 17:13:46,793 - log/train6.log - INFO - iteration:17 step:6700/10100, NER loss: 5.243132
2019-02-21 17:13:49,149 - log/train6.log - INFO - iteration:17 step:6800/10100, NER loss: 4.052652
2019-02-21 17:13:51,466 - log/train6.log - INFO - iteration:17 step:6900/10100, NER loss: 4.827071
2019-02-21 17:13:53,903 - log/train6.log - INFO - iteration:17 step:7000/10100, NER loss: 2.638003
2019-02-21 17:13:55,999 - log/train6.log - INFO - iteration:17 step:7100/10100, NER loss: 2.085780
2019-02-21 17:13:58,231 - log/train6.log - INFO - iteration:17 step:7200/10100, NER loss: 2.389942
2019-02-21 17:14:00,630 - log/train6.log - INFO - iteration:17 step:7300/10100, NER loss: 5.585207
2019-02-21 17:14:02,820 - log/train6.log - INFO - iteration:17 step:7400/10100, NER loss: 2.737366
2019-02-21 17:14:05,117 - log/train6.log - INFO - iteration:17 step:7500/10100, NER loss: 3.757641
2019-02-21 17:14:07,490 - log/train6.log - INFO - iteration:17 step:7600/10100, NER loss: 2.857149
2019-02-21 17:14:10,175 - log/train6.log - INFO - iteration:17 step:7700/10100, NER loss: 4.669686
2019-02-21 17:14:12,576 - log/train6.log - INFO - iteration:17 step:7800/10100, NER loss: 3.937515
2019-02-21 17:14:15,013 - log/train6.log - INFO - iteration:17 step:7900/10100, NER loss: 4.090492
2019-02-21 17:14:17,308 - log/train6.log - INFO - iteration:17 step:8000/10100, NER loss: 2.458078
2019-02-21 17:14:19,408 - log/train6.log - INFO - iteration:17 step:8100/10100, NER loss: 3.413238
2019-02-21 17:14:21,512 - log/train6.log - INFO - iteration:17 step:8200/10100, NER loss: 4.151171
2019-02-21 17:14:23,758 - log/train6.log - INFO - iteration:17 step:8300/10100, NER loss: 2.486222
2019-02-21 17:14:26,206 - log/train6.log - INFO - iteration:17 step:8400/10100, NER loss: 3.711774
2019-02-21 17:14:28,646 - log/train6.log - INFO - iteration:17 step:8500/10100, NER loss: 5.227842
2019-02-21 17:14:31,268 - log/train6.log - INFO - iteration:17 step:8600/10100, NER loss: 4.474647
2019-02-21 17:14:33,694 - log/train6.log - INFO - iteration:17 step:8700/10100, NER loss: 4.107596
2019-02-21 17:14:36,045 - log/train6.log - INFO - iteration:17 step:8800/10100, NER loss: 3.984496
2019-02-21 17:14:40,291 - log/train6.log - INFO - iteration:17 step:8900/10100, NER loss: 8.123103
2019-02-21 17:14:42,533 - log/train6.log - INFO - iteration:17 step:9000/10100, NER loss: 4.608394
2019-02-21 17:14:45,193 - log/train6.log - INFO - iteration:17 step:9100/10100, NER loss: 3.801025
2019-02-21 17:14:47,708 - log/train6.log - INFO - iteration:17 step:9200/10100, NER loss: 4.645769
2019-02-21 17:14:50,258 - log/train6.log - INFO - iteration:17 step:9300/10100, NER loss: 2.697431
2019-02-21 17:14:52,753 - log/train6.log - INFO - iteration:17 step:9400/10100, NER loss: 6.346171
2019-02-21 17:14:55,617 - log/train6.log - INFO - iteration:17 step:9500/10100, NER loss: 4.299676
2019-02-21 17:14:57,973 - log/train6.log - INFO - iteration:17 step:9600/10100, NER loss: 4.298499
2019-02-21 17:15:00,537 - log/train6.log - INFO - iteration:17 step:9700/10100, NER loss: 3.486788
2019-02-21 17:15:02,794 - log/train6.log - INFO - iteration:17 step:9800/10100, NER loss: 3.120110
2019-02-21 17:15:05,165 - log/train6.log - INFO - iteration:17 step:9900/10100, NER loss: 2.617933
2019-02-21 17:15:07,454 - log/train6.log - INFO - iteration:17 step:10000/10100, NER loss: 2.661271
2019-02-21 17:15:09,564 - log/train6.log - INFO - iteration:18 step:0/10100, NER loss: 3.398213
2019-02-21 17:15:09,564 - log/train6.log - INFO - evaluate:dev
2019-02-21 17:15:16,477 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5672 phrases; correct: 4145.

2019-02-21 17:15:16,477 - log/train6.log - INFO - accuracy:  94.94%; precision:  73.08%; recall:  70.89%; FB1:  71.97

2019-02-21 17:15:16,477 - log/train6.log - INFO -                 C: precision:  86.77%; recall:  88.46%; FB1:  87.61  3455

2019-02-21 17:15:16,477 - log/train6.log - INFO -               IND: precision:  37.58%; recall:  30.39%; FB1:  33.60  330

2019-02-21 17:15:16,478 - log/train6.log - INFO -               INS: precision:  67.00%; recall:  71.24%; FB1:  69.05  403

2019-02-21 17:15:16,478 - log/train6.log - INFO -                 L: precision:  28.09%; recall:  28.88%; FB1:  28.48  623

2019-02-21 17:15:16,478 - log/train6.log - INFO -                 P: precision:  89.32%; recall:  89.32%; FB1:  89.32  543

2019-02-21 17:15:16,478 - log/train6.log - INFO -               PRO: precision:  29.25%; recall:  17.82%; FB1:  22.14  318

2019-02-21 17:15:16,481 - log/train6.log - INFO - evaluate:test
2019-02-21 17:15:18,236 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1654 phrases; correct: 1375.

2019-02-21 17:15:18,236 - log/train6.log - INFO - accuracy:  96.97%; precision:  83.13%; recall:  83.49%; FB1:  83.31

2019-02-21 17:15:18,236 - log/train6.log - INFO -                 C: precision:  89.63%; recall:  92.42%; FB1:  91.00  1061

2019-02-21 17:15:18,236 - log/train6.log - INFO -               IND: precision:  61.82%; recall:  72.34%; FB1:  66.67  55

2019-02-21 17:15:18,236 - log/train6.log - INFO -               INS: precision:  66.67%; recall:  67.37%; FB1:  67.02  96

2019-02-21 17:15:18,236 - log/train6.log - INFO -                 L: precision:  40.78%; recall:  40.78%; FB1:  40.78  103

2019-02-21 17:15:18,236 - log/train6.log - INFO -                 P: precision:  93.72%; recall:  95.10%; FB1:  94.40  207

2019-02-21 17:15:18,236 - log/train6.log - INFO -               PRO: precision:  68.18%; recall:  53.25%; FB1:  59.80  132

2019-02-21 17:15:18,313 - log/train6.log - INFO - new best test f1 score:83.310
2019-02-21 17:15:20,359 - log/train6.log - INFO - iteration:18 step:100/10100, NER loss: 1.930212
2019-02-21 17:15:22,550 - log/train6.log - INFO - iteration:18 step:200/10100, NER loss: 2.381440
2019-02-21 17:15:24,522 - log/train6.log - INFO - iteration:18 step:300/10100, NER loss: 2.999170
2019-02-21 17:15:26,799 - log/train6.log - INFO - iteration:18 step:400/10100, NER loss: 3.938800
2019-02-21 17:15:29,102 - log/train6.log - INFO - iteration:18 step:500/10100, NER loss: 3.530862
2019-02-21 17:15:31,346 - log/train6.log - INFO - iteration:18 step:600/10100, NER loss: 2.000100
2019-02-21 17:15:33,834 - log/train6.log - INFO - iteration:18 step:700/10100, NER loss: 3.136032
2019-02-21 17:15:36,420 - log/train6.log - INFO - iteration:18 step:800/10100, NER loss: 3.133750
2019-02-21 17:15:38,760 - log/train6.log - INFO - iteration:18 step:900/10100, NER loss: 2.862287
2019-02-21 17:15:41,243 - log/train6.log - INFO - iteration:18 step:1000/10100, NER loss: 3.335007
2019-02-21 17:15:43,721 - log/train6.log - INFO - iteration:18 step:1100/10100, NER loss: 3.176951
2019-02-21 17:15:46,118 - log/train6.log - INFO - iteration:18 step:1200/10100, NER loss: 3.516966
2019-02-21 17:15:48,675 - log/train6.log - INFO - iteration:18 step:1300/10100, NER loss: 3.177033
2019-02-21 17:15:51,216 - log/train6.log - INFO - iteration:18 step:1400/10100, NER loss: 3.540573
2019-02-21 17:15:53,650 - log/train6.log - INFO - iteration:18 step:1500/10100, NER loss: 3.255890
2019-02-21 17:15:56,081 - log/train6.log - INFO - iteration:18 step:1600/10100, NER loss: 3.847232
2019-02-21 17:15:58,463 - log/train6.log - INFO - iteration:18 step:1700/10100, NER loss: 2.813538
2019-02-21 17:16:00,993 - log/train6.log - INFO - iteration:18 step:1800/10100, NER loss: 3.153132
2019-02-21 17:16:03,203 - log/train6.log - INFO - iteration:18 step:1900/10100, NER loss: 2.576563
2019-02-21 17:16:05,843 - log/train6.log - INFO - iteration:18 step:2000/10100, NER loss: 4.173078
2019-02-21 17:16:08,319 - log/train6.log - INFO - iteration:18 step:2100/10100, NER loss: 3.074617
2019-02-21 17:16:10,645 - log/train6.log - INFO - iteration:18 step:2200/10100, NER loss: 3.843080
2019-02-21 17:16:13,439 - log/train6.log - INFO - iteration:18 step:2300/10100, NER loss: 4.612234
2019-02-21 17:16:15,604 - log/train6.log - INFO - iteration:18 step:2400/10100, NER loss: 2.191592
2019-02-21 17:16:17,642 - log/train6.log - INFO - iteration:18 step:2500/10100, NER loss: 2.427629
2019-02-21 17:16:19,742 - log/train6.log - INFO - iteration:18 step:2600/10100, NER loss: 2.437849
2019-02-21 17:16:22,297 - log/train6.log - INFO - iteration:18 step:2700/10100, NER loss: 3.760823
2019-02-21 17:16:24,561 - log/train6.log - INFO - iteration:18 step:2800/10100, NER loss: 2.536907
2019-02-21 17:16:27,234 - log/train6.log - INFO - iteration:18 step:2900/10100, NER loss: 2.654696
2019-02-21 17:16:29,678 - log/train6.log - INFO - iteration:18 step:3000/10100, NER loss: 2.282043
2019-02-21 17:16:32,225 - log/train6.log - INFO - iteration:18 step:3100/10100, NER loss: 2.765216
2019-02-21 17:16:34,262 - log/train6.log - INFO - iteration:18 step:3200/10100, NER loss: 3.698169
2019-02-21 17:16:36,577 - log/train6.log - INFO - iteration:18 step:3300/10100, NER loss: 4.165223
2019-02-21 17:16:39,194 - log/train6.log - INFO - iteration:18 step:3400/10100, NER loss: 4.735762
2019-02-21 17:16:41,680 - log/train6.log - INFO - iteration:18 step:3500/10100, NER loss: 4.981383
2019-02-21 17:16:46,241 - log/train6.log - INFO - iteration:18 step:3600/10100, NER loss:38.127533
2019-02-21 17:16:48,528 - log/train6.log - INFO - iteration:18 step:3700/10100, NER loss: 3.832751
2019-02-21 17:16:50,724 - log/train6.log - INFO - iteration:18 step:3800/10100, NER loss: 1.805023
2019-02-21 17:16:53,149 - log/train6.log - INFO - iteration:18 step:3900/10100, NER loss: 3.608577
2019-02-21 17:16:55,675 - log/train6.log - INFO - iteration:18 step:4000/10100, NER loss: 2.907683
2019-02-21 17:16:58,075 - log/train6.log - INFO - iteration:18 step:4100/10100, NER loss: 2.749041
2019-02-21 17:17:00,206 - log/train6.log - INFO - iteration:18 step:4200/10100, NER loss: 3.373336
2019-02-21 17:17:02,336 - log/train6.log - INFO - iteration:18 step:4300/10100, NER loss: 2.353264
2019-02-21 17:17:04,500 - log/train6.log - INFO - iteration:18 step:4400/10100, NER loss: 2.252077
2019-02-21 17:17:06,811 - log/train6.log - INFO - iteration:18 step:4500/10100, NER loss: 2.703525
2019-02-21 17:17:09,045 - log/train6.log - INFO - iteration:18 step:4600/10100, NER loss: 2.064092
2019-02-21 17:17:11,369 - log/train6.log - INFO - iteration:18 step:4700/10100, NER loss: 3.290933
2019-02-21 17:17:14,049 - log/train6.log - INFO - iteration:18 step:4800/10100, NER loss: 3.795341
2019-02-21 17:17:16,496 - log/train6.log - INFO - iteration:18 step:4900/10100, NER loss: 3.425669
2019-02-21 17:17:18,947 - log/train6.log - INFO - iteration:18 step:5000/10100, NER loss: 3.106506
2019-02-21 17:17:21,395 - log/train6.log - INFO - iteration:18 step:5100/10100, NER loss: 4.158184
2019-02-21 17:17:23,893 - log/train6.log - INFO - iteration:18 step:5200/10100, NER loss: 3.158293
2019-02-21 17:17:26,347 - log/train6.log - INFO - iteration:18 step:5300/10100, NER loss: 2.510060
2019-02-21 17:17:28,655 - log/train6.log - INFO - iteration:18 step:5400/10100, NER loss: 3.371985
2019-02-21 17:17:30,891 - log/train6.log - INFO - iteration:18 step:5500/10100, NER loss: 2.400601
2019-02-21 17:17:33,139 - log/train6.log - INFO - iteration:18 step:5600/10100, NER loss: 3.453025
2019-02-21 17:17:35,303 - log/train6.log - INFO - iteration:18 step:5700/10100, NER loss: 3.439305
2019-02-21 17:17:37,593 - log/train6.log - INFO - iteration:18 step:5800/10100, NER loss: 3.462557
2019-02-21 17:17:39,929 - log/train6.log - INFO - iteration:18 step:5900/10100, NER loss: 2.560227
2019-02-21 17:17:42,168 - log/train6.log - INFO - iteration:18 step:6000/10100, NER loss: 2.656060
2019-02-21 17:17:44,494 - log/train6.log - INFO - iteration:18 step:6100/10100, NER loss: 2.601411
2019-02-21 17:17:46,895 - log/train6.log - INFO - iteration:18 step:6200/10100, NER loss: 2.836407
2019-02-21 17:17:49,121 - log/train6.log - INFO - iteration:18 step:6300/10100, NER loss: 2.494429
2019-02-21 17:17:51,135 - log/train6.log - INFO - iteration:18 step:6400/10100, NER loss: 2.315185
2019-02-21 17:17:53,475 - log/train6.log - INFO - iteration:18 step:6500/10100, NER loss: 4.405716
2019-02-21 17:17:55,711 - log/train6.log - INFO - iteration:18 step:6600/10100, NER loss: 3.224584
2019-02-21 17:17:57,923 - log/train6.log - INFO - iteration:18 step:6700/10100, NER loss: 3.095787
2019-02-21 17:18:00,263 - log/train6.log - INFO - iteration:18 step:6800/10100, NER loss: 3.061971
2019-02-21 17:18:02,454 - log/train6.log - INFO - iteration:18 step:6900/10100, NER loss: 2.898591
2019-02-21 17:18:04,801 - log/train6.log - INFO - iteration:18 step:7000/10100, NER loss: 3.224511
2019-02-21 17:18:06,781 - log/train6.log - INFO - iteration:18 step:7100/10100, NER loss: 1.922991
2019-02-21 17:18:09,094 - log/train6.log - INFO - iteration:18 step:7200/10100, NER loss: 2.280164
2019-02-21 17:18:11,189 - log/train6.log - INFO - iteration:18 step:7300/10100, NER loss: 2.236964
2019-02-21 17:18:13,558 - log/train6.log - INFO - iteration:18 step:7400/10100, NER loss: 2.675127
2019-02-21 17:18:15,843 - log/train6.log - INFO - iteration:18 step:7500/10100, NER loss: 3.297977
2019-02-21 17:18:18,225 - log/train6.log - INFO - iteration:18 step:7600/10100, NER loss: 2.672569
2019-02-21 17:18:20,720 - log/train6.log - INFO - iteration:18 step:7700/10100, NER loss: 4.775238
2019-02-21 17:18:22,905 - log/train6.log - INFO - iteration:18 step:7800/10100, NER loss: 2.379863
2019-02-21 17:18:27,412 - log/train6.log - INFO - iteration:18 step:7900/10100, NER loss: 6.729021
2019-02-21 17:18:29,613 - log/train6.log - INFO - iteration:18 step:8000/10100, NER loss: 2.190825
2019-02-21 17:18:32,065 - log/train6.log - INFO - iteration:18 step:8100/10100, NER loss: 2.591304
2019-02-21 17:18:34,476 - log/train6.log - INFO - iteration:18 step:8200/10100, NER loss: 3.205536
2019-02-21 17:18:36,585 - log/train6.log - INFO - iteration:18 step:8300/10100, NER loss: 2.754154
2019-02-21 17:18:38,810 - log/train6.log - INFO - iteration:18 step:8400/10100, NER loss: 2.591086
2019-02-21 17:18:41,105 - log/train6.log - INFO - iteration:18 step:8500/10100, NER loss: 2.804849
2019-02-21 17:18:43,185 - log/train6.log - INFO - iteration:18 step:8600/10100, NER loss: 2.564813
2019-02-21 17:18:45,431 - log/train6.log - INFO - iteration:18 step:8700/10100, NER loss: 1.648709
2019-02-21 17:18:49,946 - log/train6.log - INFO - iteration:18 step:8800/10100, NER loss: 4.649137
2019-02-21 17:18:52,305 - log/train6.log - INFO - iteration:18 step:8900/10100, NER loss: 4.482451
2019-02-21 17:18:54,491 - log/train6.log - INFO - iteration:18 step:9000/10100, NER loss: 2.456226
2019-02-21 17:18:56,870 - log/train6.log - INFO - iteration:18 step:9100/10100, NER loss: 3.927827
2019-02-21 17:18:59,130 - log/train6.log - INFO - iteration:18 step:9200/10100, NER loss: 2.040308
2019-02-21 17:19:01,633 - log/train6.log - INFO - iteration:18 step:9300/10100, NER loss: 2.361004
2019-02-21 17:19:03,945 - log/train6.log - INFO - iteration:18 step:9400/10100, NER loss: 2.044528
2019-02-21 17:19:06,341 - log/train6.log - INFO - iteration:18 step:9500/10100, NER loss: 2.658623
2019-02-21 17:19:08,852 - log/train6.log - INFO - iteration:18 step:9600/10100, NER loss: 2.733530
2019-02-21 17:19:11,398 - log/train6.log - INFO - iteration:18 step:9700/10100, NER loss: 1.954689
2019-02-21 17:19:13,755 - log/train6.log - INFO - iteration:18 step:9800/10100, NER loss: 2.632185
2019-02-21 17:19:15,965 - log/train6.log - INFO - iteration:18 step:9900/10100, NER loss: 1.817492
2019-02-21 17:19:18,336 - log/train6.log - INFO - iteration:18 step:10000/10100, NER loss: 3.703314
2019-02-21 17:19:20,559 - log/train6.log - INFO - iteration:19 step:0/10100, NER loss: 2.033362
2019-02-21 17:19:20,559 - log/train6.log - INFO - evaluate:dev
2019-02-21 17:19:27,069 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5491 phrases; correct: 4121.

2019-02-21 17:19:27,069 - log/train6.log - INFO - accuracy:  94.68%; precision:  75.05%; recall:  70.48%; FB1:  72.69

2019-02-21 17:19:27,069 - log/train6.log - INFO -                 C: precision:  88.19%; recall:  88.14%; FB1:  88.16  3387

2019-02-21 17:19:27,069 - log/train6.log - INFO -               IND: precision:  43.61%; recall:  28.43%; FB1:  34.42  266

2019-02-21 17:19:27,070 - log/train6.log - INFO -               INS: precision:  54.01%; recall:  72.82%; FB1:  62.02  511

2019-02-21 17:19:27,070 - log/train6.log - INFO -                 L: precision:  33.71%; recall:  29.37%; FB1:  31.39  528

2019-02-21 17:19:27,070 - log/train6.log - INFO -                 P: precision:  85.49%; recall:  91.16%; FB1:  88.24  579

2019-02-21 17:19:27,070 - log/train6.log - INFO -               PRO: precision:  31.36%; recall:  13.22%; FB1:  18.60  220

2019-02-21 17:19:27,073 - log/train6.log - INFO - evaluate:test
2019-02-21 17:19:28,530 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1664 phrases; correct: 1357.

2019-02-21 17:19:28,530 - log/train6.log - INFO - accuracy:  96.63%; precision:  81.55%; recall:  82.39%; FB1:  81.97

2019-02-21 17:19:28,530 - log/train6.log - INFO -                 C: precision:  88.84%; recall:  92.03%; FB1:  90.41  1066

2019-02-21 17:19:28,530 - log/train6.log - INFO -               IND: precision:  67.39%; recall:  65.96%; FB1:  66.67  46

2019-02-21 17:19:28,530 - log/train6.log - INFO -               INS: precision:  57.14%; recall:  71.58%; FB1:  63.55  119

2019-02-21 17:19:28,530 - log/train6.log - INFO -                 L: precision:  36.67%; recall:  42.72%; FB1:  39.46  120

2019-02-21 17:19:28,530 - log/train6.log - INFO -                 P: precision:  90.23%; recall:  95.10%; FB1:  92.60  215

2019-02-21 17:19:28,530 - log/train6.log - INFO -               PRO: precision:  74.49%; recall:  43.20%; FB1:  54.68  98

2019-02-21 17:19:30,545 - log/train6.log - INFO - iteration:19 step:100/10100, NER loss: 2.088832
2019-02-21 17:19:32,366 - log/train6.log - INFO - iteration:19 step:200/10100, NER loss: 2.095318
2019-02-21 17:19:34,520 - log/train6.log - INFO - iteration:19 step:300/10100, NER loss: 2.551824
2019-02-21 17:19:36,609 - log/train6.log - INFO - iteration:19 step:400/10100, NER loss: 1.885053
2019-02-21 17:19:40,775 - log/train6.log - INFO - iteration:19 step:500/10100, NER loss:26.197149
2019-02-21 17:19:42,839 - log/train6.log - INFO - iteration:19 step:600/10100, NER loss: 2.323706
2019-02-21 17:19:45,055 - log/train6.log - INFO - iteration:19 step:700/10100, NER loss: 2.594045
2019-02-21 17:19:47,221 - log/train6.log - INFO - iteration:19 step:800/10100, NER loss: 1.577208
2019-02-21 17:19:49,600 - log/train6.log - INFO - iteration:19 step:900/10100, NER loss: 2.861174
2019-02-21 17:19:51,726 - log/train6.log - INFO - iteration:19 step:1000/10100, NER loss: 2.402152
2019-02-21 17:19:53,831 - log/train6.log - INFO - iteration:19 step:1100/10100, NER loss: 3.092191
2019-02-21 17:19:56,109 - log/train6.log - INFO - iteration:19 step:1200/10100, NER loss: 2.288208
2019-02-21 17:19:58,483 - log/train6.log - INFO - iteration:19 step:1300/10100, NER loss: 3.627306
2019-02-21 17:20:00,966 - log/train6.log - INFO - iteration:19 step:1400/10100, NER loss: 2.436965
2019-02-21 17:20:03,223 - log/train6.log - INFO - iteration:19 step:1500/10100, NER loss: 2.885206
2019-02-21 17:20:05,295 - log/train6.log - INFO - iteration:19 step:1600/10100, NER loss: 1.851063
2019-02-21 17:20:08,207 - log/train6.log - INFO - iteration:19 step:1700/10100, NER loss: 4.101964
2019-02-21 17:20:10,582 - log/train6.log - INFO - iteration:19 step:1800/10100, NER loss: 1.523237
2019-02-21 17:20:12,774 - log/train6.log - INFO - iteration:19 step:1900/10100, NER loss: 2.892454
2019-02-21 17:20:15,048 - log/train6.log - INFO - iteration:19 step:2000/10100, NER loss: 1.965806
2019-02-21 17:20:17,449 - log/train6.log - INFO - iteration:19 step:2100/10100, NER loss: 1.949832
2019-02-21 17:20:19,974 - log/train6.log - INFO - iteration:19 step:2200/10100, NER loss: 1.969450
2019-02-21 17:20:22,483 - log/train6.log - INFO - iteration:19 step:2300/10100, NER loss: 2.700788
2019-02-21 17:20:24,754 - log/train6.log - INFO - iteration:19 step:2400/10100, NER loss: 2.051552
2019-02-21 17:20:27,415 - log/train6.log - INFO - iteration:19 step:2500/10100, NER loss: 1.786016
2019-02-21 17:20:29,885 - log/train6.log - INFO - iteration:19 step:2600/10100, NER loss: 2.251256
2019-02-21 17:20:32,640 - log/train6.log - INFO - iteration:19 step:2700/10100, NER loss: 3.580570
2019-02-21 17:20:34,919 - log/train6.log - INFO - iteration:19 step:2800/10100, NER loss: 2.291317
2019-02-21 17:20:37,113 - log/train6.log - INFO - iteration:19 step:2900/10100, NER loss: 2.130941
2019-02-21 17:20:39,475 - log/train6.log - INFO - iteration:19 step:3000/10100, NER loss: 2.497307
2019-02-21 17:20:42,144 - log/train6.log - INFO - iteration:19 step:3100/10100, NER loss: 2.777806
2019-02-21 17:20:44,867 - log/train6.log - INFO - iteration:19 step:3200/10100, NER loss: 2.196044
2019-02-21 17:20:47,605 - log/train6.log - INFO - iteration:19 step:3300/10100, NER loss: 3.463036
2019-02-21 17:20:50,000 - log/train6.log - INFO - iteration:19 step:3400/10100, NER loss: 2.352132
2019-02-21 17:20:52,392 - log/train6.log - INFO - iteration:19 step:3500/10100, NER loss: 2.263814
2019-02-21 17:20:54,644 - log/train6.log - INFO - iteration:19 step:3600/10100, NER loss: 1.789501
2019-02-21 17:20:56,885 - log/train6.log - INFO - iteration:19 step:3700/10100, NER loss: 2.530764
2019-02-21 17:20:59,176 - log/train6.log - INFO - iteration:19 step:3800/10100, NER loss: 2.105687
2019-02-21 17:21:01,726 - log/train6.log - INFO - iteration:19 step:3900/10100, NER loss: 1.959336
2019-02-21 17:21:04,165 - log/train6.log - INFO - iteration:19 step:4000/10100, NER loss: 2.493174
2019-02-21 17:21:06,388 - log/train6.log - INFO - iteration:19 step:4100/10100, NER loss: 1.269295
2019-02-21 17:21:08,546 - log/train6.log - INFO - iteration:19 step:4200/10100, NER loss: 1.711392
2019-02-21 17:21:10,890 - log/train6.log - INFO - iteration:19 step:4300/10100, NER loss: 2.334045
2019-02-21 17:21:14,941 - log/train6.log - INFO - iteration:19 step:4400/10100, NER loss: 4.557537
2019-02-21 17:21:17,136 - log/train6.log - INFO - iteration:19 step:4500/10100, NER loss: 2.305299
2019-02-21 17:21:19,375 - log/train6.log - INFO - iteration:19 step:4600/10100, NER loss: 2.587461
2019-02-21 17:21:21,724 - log/train6.log - INFO - iteration:19 step:4700/10100, NER loss: 3.352274
2019-02-21 17:21:23,784 - log/train6.log - INFO - iteration:19 step:4800/10100, NER loss: 1.486844
2019-02-21 17:21:26,111 - log/train6.log - INFO - iteration:19 step:4900/10100, NER loss: 2.308641
2019-02-21 17:21:28,363 - log/train6.log - INFO - iteration:19 step:5000/10100, NER loss: 2.160116
2019-02-21 17:21:30,511 - log/train6.log - INFO - iteration:19 step:5100/10100, NER loss: 2.164002
2019-02-21 17:21:32,864 - log/train6.log - INFO - iteration:19 step:5200/10100, NER loss: 1.869563
2019-02-21 17:21:35,090 - log/train6.log - INFO - iteration:19 step:5300/10100, NER loss: 1.476870
2019-02-21 17:21:37,754 - log/train6.log - INFO - iteration:19 step:5400/10100, NER loss: 1.865197
2019-02-21 17:21:39,974 - log/train6.log - INFO - iteration:19 step:5500/10100, NER loss: 2.376319
2019-02-21 17:21:42,313 - log/train6.log - INFO - iteration:19 step:5600/10100, NER loss: 2.327229
2019-02-21 17:21:44,610 - log/train6.log - INFO - iteration:19 step:5700/10100, NER loss: 1.640277
2019-02-21 17:21:47,086 - log/train6.log - INFO - iteration:19 step:5800/10100, NER loss: 1.977765
2019-02-21 17:21:49,504 - log/train6.log - INFO - iteration:19 step:5900/10100, NER loss: 2.269162
2019-02-21 17:21:52,200 - log/train6.log - INFO - iteration:19 step:6000/10100, NER loss: 2.340684
2019-02-21 17:21:54,393 - log/train6.log - INFO - iteration:19 step:6100/10100, NER loss: 1.681935
2019-02-21 17:21:56,465 - log/train6.log - INFO - iteration:19 step:6200/10100, NER loss: 1.950175
2019-02-21 17:21:58,448 - log/train6.log - INFO - iteration:19 step:6300/10100, NER loss: 1.585617
2019-02-21 17:22:00,641 - log/train6.log - INFO - iteration:19 step:6400/10100, NER loss: 1.657077
2019-02-21 17:22:02,964 - log/train6.log - INFO - iteration:19 step:6500/10100, NER loss: 2.070730
2019-02-21 17:22:05,218 - log/train6.log - INFO - iteration:19 step:6600/10100, NER loss: 1.697855
2019-02-21 17:22:07,570 - log/train6.log - INFO - iteration:19 step:6700/10100, NER loss: 1.904030
2019-02-21 17:22:09,887 - log/train6.log - INFO - iteration:19 step:6800/10100, NER loss: 2.334128
2019-02-21 17:22:12,177 - log/train6.log - INFO - iteration:19 step:6900/10100, NER loss: 2.491518
2019-02-21 17:22:14,870 - log/train6.log - INFO - iteration:19 step:7000/10100, NER loss: 2.560122
2019-02-21 17:22:17,559 - log/train6.log - INFO - iteration:19 step:7100/10100, NER loss: 2.199230
2019-02-21 17:22:20,111 - log/train6.log - INFO - iteration:19 step:7200/10100, NER loss: 1.436071
2019-02-21 17:22:22,205 - log/train6.log - INFO - iteration:19 step:7300/10100, NER loss: 2.205567
2019-02-21 17:22:24,702 - log/train6.log - INFO - iteration:19 step:7400/10100, NER loss: 2.030702
2019-02-21 17:22:27,330 - log/train6.log - INFO - iteration:19 step:7500/10100, NER loss: 1.779386
2019-02-21 17:22:29,832 - log/train6.log - INFO - iteration:19 step:7600/10100, NER loss: 1.481486
2019-02-21 17:22:32,397 - log/train6.log - INFO - iteration:19 step:7700/10100, NER loss: 1.996909
2019-02-21 17:22:35,044 - log/train6.log - INFO - iteration:19 step:7800/10100, NER loss: 2.435971
2019-02-21 17:22:37,499 - log/train6.log - INFO - iteration:19 step:7900/10100, NER loss: 2.115687
2019-02-21 17:22:42,363 - log/train6.log - INFO - iteration:19 step:8000/10100, NER loss: 2.756414
2019-02-21 17:22:44,725 - log/train6.log - INFO - iteration:19 step:8100/10100, NER loss: 1.728128
2019-02-21 17:22:46,869 - log/train6.log - INFO - iteration:19 step:8200/10100, NER loss: 1.605385
2019-02-21 17:22:49,027 - log/train6.log - INFO - iteration:19 step:8300/10100, NER loss: 2.750154
2019-02-21 17:22:50,971 - log/train6.log - INFO - iteration:19 step:8400/10100, NER loss: 1.063637
2019-02-21 17:22:53,319 - log/train6.log - INFO - iteration:19 step:8500/10100, NER loss: 1.931776
2019-02-21 17:22:55,576 - log/train6.log - INFO - iteration:19 step:8600/10100, NER loss: 2.708722
2019-02-21 17:22:58,111 - log/train6.log - INFO - iteration:19 step:8700/10100, NER loss: 2.302363
2019-02-21 17:23:00,348 - log/train6.log - INFO - iteration:19 step:8800/10100, NER loss: 2.035876
2019-02-21 17:23:02,680 - log/train6.log - INFO - iteration:19 step:8900/10100, NER loss: 1.971471
2019-02-21 17:23:04,686 - log/train6.log - INFO - iteration:19 step:9000/10100, NER loss: 1.230605
2019-02-21 17:23:07,009 - log/train6.log - INFO - iteration:19 step:9100/10100, NER loss: 1.812644
2019-02-21 17:23:09,181 - log/train6.log - INFO - iteration:19 step:9200/10100, NER loss: 2.139870
2019-02-21 17:23:11,339 - log/train6.log - INFO - iteration:19 step:9300/10100, NER loss: 1.830069
2019-02-21 17:23:13,736 - log/train6.log - INFO - iteration:19 step:9400/10100, NER loss: 1.979574
2019-02-21 17:23:16,056 - log/train6.log - INFO - iteration:19 step:9500/10100, NER loss: 1.768532
2019-02-21 17:23:18,213 - log/train6.log - INFO - iteration:19 step:9600/10100, NER loss: 1.780077
2019-02-21 17:23:20,602 - log/train6.log - INFO - iteration:19 step:9700/10100, NER loss: 1.923818
2019-02-21 17:23:23,081 - log/train6.log - INFO - iteration:19 step:9800/10100, NER loss: 1.509408
2019-02-21 17:23:25,674 - log/train6.log - INFO - iteration:19 step:9900/10100, NER loss: 1.383599
2019-02-21 17:23:28,043 - log/train6.log - INFO - iteration:19 step:10000/10100, NER loss: 1.704258
2019-02-21 17:23:30,191 - log/train6.log - INFO - iteration:20 step:0/10100, NER loss: 1.329501
2019-02-21 17:23:30,191 - log/train6.log - INFO - evaluate:dev
2019-02-21 17:23:36,874 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5625 phrases; correct: 4188.

2019-02-21 17:23:36,875 - log/train6.log - INFO - accuracy:  94.72%; precision:  74.45%; recall:  71.63%; FB1:  73.01

2019-02-21 17:23:36,875 - log/train6.log - INFO -                 C: precision:  85.07%; recall:  89.64%; FB1:  87.30  3571

2019-02-21 17:23:36,875 - log/train6.log - INFO -               IND: precision:  54.68%; recall:  18.63%; FB1:  27.79  139

2019-02-21 17:23:36,875 - log/train6.log - INFO -               INS: precision:  60.00%; recall:  73.61%; FB1:  66.11  465

2019-02-21 17:23:36,875 - log/train6.log - INFO -                 L: precision:  37.09%; recall:  28.22%; FB1:  32.05  461

2019-02-21 17:23:36,875 - log/train6.log - INFO -                 P: precision:  87.57%; recall:  90.79%; FB1:  89.15  563

2019-02-21 17:23:36,875 - log/train6.log - INFO -               PRO: precision:  30.75%; recall:  25.10%; FB1:  27.64  426

2019-02-21 17:23:36,879 - log/train6.log - INFO - evaluate:test
2019-02-21 17:23:38,459 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1680 phrases; correct: 1370.

2019-02-21 17:23:38,459 - log/train6.log - INFO - accuracy:  96.60%; precision:  81.55%; recall:  83.18%; FB1:  82.36

2019-02-21 17:23:38,459 - log/train6.log - INFO -                 C: precision:  87.29%; recall:  92.81%; FB1:  89.97  1094

2019-02-21 17:23:38,459 - log/train6.log - INFO -               IND: precision:  81.48%; recall:  46.81%; FB1:  59.46  27

2019-02-21 17:23:38,459 - log/train6.log - INFO -               INS: precision:  59.82%; recall:  70.53%; FB1:  64.73  112

2019-02-21 17:23:38,459 - log/train6.log - INFO -                 L: precision:  45.65%; recall:  40.78%; FB1:  43.08  92

2019-02-21 17:23:38,460 - log/train6.log - INFO -                 P: precision:  89.72%; recall:  94.12%; FB1:  91.87  214

2019-02-21 17:23:38,460 - log/train6.log - INFO -               PRO: precision:  65.25%; recall:  54.44%; FB1:  59.35  141

2019-02-21 17:23:40,931 - log/train6.log - INFO - iteration:20 step:100/10100, NER loss: 1.610407
2019-02-21 17:23:43,030 - log/train6.log - INFO - iteration:20 step:200/10100, NER loss: 1.780905
2019-02-21 17:23:47,752 - log/train6.log - INFO - iteration:20 step:300/10100, NER loss: 3.547656
2019-02-21 17:23:50,147 - log/train6.log - INFO - iteration:20 step:400/10100, NER loss: 1.672264
2019-02-21 17:23:52,424 - log/train6.log - INFO - iteration:20 step:500/10100, NER loss: 1.686447
2019-02-21 17:23:54,914 - log/train6.log - INFO - iteration:20 step:600/10100, NER loss: 1.741996
2019-02-21 17:23:57,975 - log/train6.log - INFO - iteration:20 step:700/10100, NER loss: 2.452718
2019-02-21 17:24:00,552 - log/train6.log - INFO - iteration:20 step:800/10100, NER loss: 1.537192
2019-02-21 17:24:02,985 - log/train6.log - INFO - iteration:20 step:900/10100, NER loss: 2.101230
2019-02-21 17:24:05,645 - log/train6.log - INFO - iteration:20 step:1000/10100, NER loss: 2.120405
2019-02-21 17:24:07,801 - log/train6.log - INFO - iteration:20 step:1100/10100, NER loss: 1.694288
2019-02-21 17:24:10,331 - log/train6.log - INFO - iteration:20 step:1200/10100, NER loss: 1.697951
2019-02-21 17:24:12,535 - log/train6.log - INFO - iteration:20 step:1300/10100, NER loss: 1.241372
2019-02-21 17:24:14,918 - log/train6.log - INFO - iteration:20 step:1400/10100, NER loss: 1.703520
2019-02-21 17:24:17,259 - log/train6.log - INFO - iteration:20 step:1500/10100, NER loss: 1.623625
2019-02-21 17:24:19,595 - log/train6.log - INFO - iteration:20 step:1600/10100, NER loss: 2.015798
2019-02-21 17:24:23,767 - log/train6.log - INFO - iteration:20 step:1700/10100, NER loss: 8.508698
2019-02-21 17:24:25,891 - log/train6.log - INFO - iteration:20 step:1800/10100, NER loss: 1.465612
2019-02-21 17:24:27,995 - log/train6.log - INFO - iteration:20 step:1900/10100, NER loss: 1.356376
2019-02-21 17:24:30,378 - log/train6.log - INFO - iteration:20 step:2000/10100, NER loss: 1.690941
2019-02-21 17:24:32,584 - log/train6.log - INFO - iteration:20 step:2100/10100, NER loss: 1.285031
2019-02-21 17:24:34,711 - log/train6.log - INFO - iteration:20 step:2200/10100, NER loss: 1.609621
2019-02-21 17:24:36,810 - log/train6.log - INFO - iteration:20 step:2300/10100, NER loss: 0.894416
2019-02-21 17:24:38,939 - log/train6.log - INFO - iteration:20 step:2400/10100, NER loss: 1.136883
2019-02-21 17:24:41,417 - log/train6.log - INFO - iteration:20 step:2500/10100, NER loss: 1.513133
2019-02-21 17:24:43,770 - log/train6.log - INFO - iteration:20 step:2600/10100, NER loss: 1.549407
2019-02-21 17:24:46,157 - log/train6.log - INFO - iteration:20 step:2700/10100, NER loss: 1.784863
2019-02-21 17:24:48,627 - log/train6.log - INFO - iteration:20 step:2800/10100, NER loss: 1.808140
2019-02-21 17:24:50,995 - log/train6.log - INFO - iteration:20 step:2900/10100, NER loss: 1.434180
2019-02-21 17:24:53,277 - log/train6.log - INFO - iteration:20 step:3000/10100, NER loss: 1.582965
2019-02-21 17:24:55,451 - log/train6.log - INFO - iteration:20 step:3100/10100, NER loss: 1.112889
2019-02-21 17:24:57,772 - log/train6.log - INFO - iteration:20 step:3200/10100, NER loss: 1.489246
2019-02-21 17:25:00,071 - log/train6.log - INFO - iteration:20 step:3300/10100, NER loss: 1.344480
2019-02-21 17:25:02,368 - log/train6.log - INFO - iteration:20 step:3400/10100, NER loss: 1.563730
2019-02-21 17:25:04,441 - log/train6.log - INFO - iteration:20 step:3500/10100, NER loss: 1.283844
2019-02-21 17:25:06,587 - log/train6.log - INFO - iteration:20 step:3600/10100, NER loss: 1.162316
2019-02-21 17:25:08,673 - log/train6.log - INFO - iteration:20 step:3700/10100, NER loss: 0.999960
2019-02-21 17:25:10,989 - log/train6.log - INFO - iteration:20 step:3800/10100, NER loss: 1.195762
2019-02-21 17:25:13,083 - log/train6.log - INFO - iteration:20 step:3900/10100, NER loss: 1.080233
2019-02-21 17:25:15,181 - log/train6.log - INFO - iteration:20 step:4000/10100, NER loss: 1.136617
2019-02-21 17:25:17,573 - log/train6.log - INFO - iteration:20 step:4100/10100, NER loss: 1.362956
2019-02-21 17:25:19,785 - log/train6.log - INFO - iteration:20 step:4200/10100, NER loss: 1.325074
2019-02-21 17:25:22,036 - log/train6.log - INFO - iteration:20 step:4300/10100, NER loss: 0.997120
2019-02-21 17:25:24,201 - log/train6.log - INFO - iteration:20 step:4400/10100, NER loss: 1.330338
2019-02-21 17:25:26,392 - log/train6.log - INFO - iteration:20 step:4500/10100, NER loss: 1.477384
2019-02-21 17:25:28,668 - log/train6.log - INFO - iteration:20 step:4600/10100, NER loss: 1.480595
2019-02-21 17:25:30,993 - log/train6.log - INFO - iteration:20 step:4700/10100, NER loss: 1.270376
2019-02-21 17:25:33,288 - log/train6.log - INFO - iteration:20 step:4800/10100, NER loss: 1.294971
2019-02-21 17:25:35,733 - log/train6.log - INFO - iteration:20 step:4900/10100, NER loss: 1.243852
2019-02-21 17:25:37,905 - log/train6.log - INFO - iteration:20 step:5000/10100, NER loss: 1.149695
2019-02-21 17:25:40,237 - log/train6.log - INFO - iteration:20 step:5100/10100, NER loss: 2.112962
2019-02-21 17:25:42,532 - log/train6.log - INFO - iteration:20 step:5200/10100, NER loss: 1.385976
2019-02-21 17:25:44,707 - log/train6.log - INFO - iteration:20 step:5300/10100, NER loss: 1.398807
2019-02-21 17:25:46,927 - log/train6.log - INFO - iteration:20 step:5400/10100, NER loss: 1.173768
2019-02-21 17:25:49,133 - log/train6.log - INFO - iteration:20 step:5500/10100, NER loss: 1.231332
2019-02-21 17:25:51,344 - log/train6.log - INFO - iteration:20 step:5600/10100, NER loss: 1.419410
2019-02-21 17:25:53,514 - log/train6.log - INFO - iteration:20 step:5700/10100, NER loss: 1.631886
2019-02-21 17:25:55,622 - log/train6.log - INFO - iteration:20 step:5800/10100, NER loss: 1.161659
2019-02-21 17:25:57,764 - log/train6.log - INFO - iteration:20 step:5900/10100, NER loss: 1.183693
2019-02-21 17:26:00,035 - log/train6.log - INFO - iteration:20 step:6000/10100, NER loss: 1.574746
2019-02-21 17:26:02,268 - log/train6.log - INFO - iteration:20 step:6100/10100, NER loss: 1.436962
2019-02-21 17:26:04,569 - log/train6.log - INFO - iteration:20 step:6200/10100, NER loss: 1.564659
2019-02-21 17:26:06,707 - log/train6.log - INFO - iteration:20 step:6300/10100, NER loss: 1.045560
2019-02-21 17:26:08,958 - log/train6.log - INFO - iteration:20 step:6400/10100, NER loss: 1.388454
2019-02-21 17:26:11,166 - log/train6.log - INFO - iteration:20 step:6500/10100, NER loss: 1.214644
2019-02-21 17:26:13,472 - log/train6.log - INFO - iteration:20 step:6600/10100, NER loss: 1.232090
2019-02-21 17:26:15,661 - log/train6.log - INFO - iteration:20 step:6700/10100, NER loss: 1.233003
2019-02-21 17:26:17,999 - log/train6.log - INFO - iteration:20 step:6800/10100, NER loss: 1.223539
2019-02-21 17:26:20,410 - log/train6.log - INFO - iteration:20 step:6900/10100, NER loss: 1.259814
2019-02-21 17:26:22,553 - log/train6.log - INFO - iteration:20 step:7000/10100, NER loss: 1.280431
2019-02-21 17:26:24,720 - log/train6.log - INFO - iteration:20 step:7100/10100, NER loss: 1.071778
2019-02-21 17:26:29,320 - log/train6.log - INFO - iteration:20 step:7200/10100, NER loss: 2.411464
2019-02-21 17:26:31,494 - log/train6.log - INFO - iteration:20 step:7300/10100, NER loss: 0.870988
2019-02-21 17:26:33,823 - log/train6.log - INFO - iteration:20 step:7400/10100, NER loss: 1.378252
2019-02-21 17:26:35,895 - log/train6.log - INFO - iteration:20 step:7500/10100, NER loss: 1.266443
2019-02-21 17:26:38,136 - log/train6.log - INFO - iteration:20 step:7600/10100, NER loss: 0.793703
2019-02-21 17:26:40,450 - log/train6.log - INFO - iteration:20 step:7700/10100, NER loss: 1.475251
2019-02-21 17:26:42,517 - log/train6.log - INFO - iteration:20 step:7800/10100, NER loss: 0.976218
2019-02-21 17:26:44,676 - log/train6.log - INFO - iteration:20 step:7900/10100, NER loss: 1.050196
2019-02-21 17:26:47,069 - log/train6.log - INFO - iteration:20 step:8000/10100, NER loss: 1.815199
2019-02-21 17:26:49,684 - log/train6.log - INFO - iteration:20 step:8100/10100, NER loss: 1.511028
2019-02-21 17:26:52,052 - log/train6.log - INFO - iteration:20 step:8200/10100, NER loss: 1.117797
2019-02-21 17:26:54,461 - log/train6.log - INFO - iteration:20 step:8300/10100, NER loss: 1.145988
2019-02-21 17:26:56,636 - log/train6.log - INFO - iteration:20 step:8400/10100, NER loss: 0.793052
2019-02-21 17:26:58,734 - log/train6.log - INFO - iteration:20 step:8500/10100, NER loss: 0.926233
2019-02-21 17:27:00,797 - log/train6.log - INFO - iteration:20 step:8600/10100, NER loss: 1.002308
2019-02-21 17:27:02,903 - log/train6.log - INFO - iteration:20 step:8700/10100, NER loss: 0.979946
2019-02-21 17:27:05,273 - log/train6.log - INFO - iteration:20 step:8800/10100, NER loss: 1.557621
2019-02-21 17:27:07,532 - log/train6.log - INFO - iteration:20 step:8900/10100, NER loss: 1.330549
2019-02-21 17:27:09,764 - log/train6.log - INFO - iteration:20 step:9000/10100, NER loss: 1.248124
2019-02-21 17:27:11,936 - log/train6.log - INFO - iteration:20 step:9100/10100, NER loss: 1.101841
2019-02-21 17:27:14,162 - log/train6.log - INFO - iteration:20 step:9200/10100, NER loss: 1.359225
2019-02-21 17:27:16,423 - log/train6.log - INFO - iteration:20 step:9300/10100, NER loss: 1.246187
2019-02-21 17:27:18,470 - log/train6.log - INFO - iteration:20 step:9400/10100, NER loss: 1.144428
2019-02-21 17:27:20,533 - log/train6.log - INFO - iteration:20 step:9500/10100, NER loss: 1.083461
2019-02-21 17:27:22,735 - log/train6.log - INFO - iteration:20 step:9600/10100, NER loss: 1.064279
2019-02-21 17:27:24,977 - log/train6.log - INFO - iteration:20 step:9700/10100, NER loss: 1.174909
2019-02-21 17:27:27,399 - log/train6.log - INFO - iteration:20 step:9800/10100, NER loss: 1.504158
2019-02-21 17:27:29,669 - log/train6.log - INFO - iteration:20 step:9900/10100, NER loss: 1.241148
2019-02-21 17:27:31,903 - log/train6.log - INFO - iteration:20 step:10000/10100, NER loss: 1.257437
2019-02-21 17:27:34,177 - log/train6.log - INFO - iteration:21 step:0/10100, NER loss: 1.124632
2019-02-21 17:27:34,177 - log/train6.log - INFO - evaluate:dev
2019-02-21 17:27:40,762 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5659 phrases; correct: 4366.

2019-02-21 17:27:40,762 - log/train6.log - INFO - accuracy:  95.46%; precision:  77.15%; recall:  74.67%; FB1:  75.89

2019-02-21 17:27:40,762 - log/train6.log - INFO -                 C: precision:  87.23%; recall:  89.11%; FB1:  88.16  3462

2019-02-21 17:27:40,762 - log/train6.log - INFO -               IND: precision:  46.06%; recall:  27.21%; FB1:  34.21  241

2019-02-21 17:27:40,762 - log/train6.log - INFO -               INS: precision:  58.99%; recall:  73.61%; FB1:  65.49  473

2019-02-21 17:27:40,762 - log/train6.log - INFO -                 L: precision:  54.02%; recall:  63.20%; FB1:  58.25  709

2019-02-21 17:27:40,762 - log/train6.log - INFO -                 P: precision:  89.47%; recall:  90.79%; FB1:  90.13  551

2019-02-21 17:27:40,763 - log/train6.log - INFO -               PRO: precision:  35.87%; recall:  15.33%; FB1:  21.48  223

2019-02-21 17:27:40,839 - log/train6.log - INFO - new best dev f1 score:75.890
2019-02-21 17:27:41,122 - log/train6.log - INFO - model saved
2019-02-21 17:27:41,122 - log/train6.log - INFO - evaluate:test
2019-02-21 17:27:42,581 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1632 phrases; correct: 1375.

2019-02-21 17:27:42,581 - log/train6.log - INFO - accuracy:  96.76%; precision:  84.25%; recall:  83.49%; FB1:  83.87

2019-02-21 17:27:42,581 - log/train6.log - INFO -                 C: precision:  88.31%; recall:  92.52%; FB1:  90.37  1078

2019-02-21 17:27:42,581 - log/train6.log - INFO -               IND: precision:  68.18%; recall:  63.83%; FB1:  65.93  44

2019-02-21 17:27:42,581 - log/train6.log - INFO -               INS: precision:  66.67%; recall:  69.47%; FB1:  68.04  99

2019-02-21 17:27:42,581 - log/train6.log - INFO -                 L: precision:  57.89%; recall:  64.08%; FB1:  60.83  114

2019-02-21 17:27:42,581 - log/train6.log - INFO -                 P: precision:  91.43%; recall:  94.12%; FB1:  92.75  210

2019-02-21 17:27:42,581 - log/train6.log - INFO -               PRO: precision:  79.31%; recall:  40.83%; FB1:  53.91  87

2019-02-21 17:27:42,654 - log/train6.log - INFO - new best test f1 score:83.870
2019-02-21 17:27:44,790 - log/train6.log - INFO - iteration:21 step:100/10100, NER loss: 1.118333
2019-02-21 17:27:46,927 - log/train6.log - INFO - iteration:21 step:200/10100, NER loss: 1.229218
2019-02-21 17:27:49,204 - log/train6.log - INFO - iteration:21 step:300/10100, NER loss: 1.129552
2019-02-21 17:27:51,675 - log/train6.log - INFO - iteration:21 step:400/10100, NER loss: 1.348436
2019-02-21 17:27:53,765 - log/train6.log - INFO - iteration:21 step:500/10100, NER loss: 0.875853
2019-02-21 17:27:55,879 - log/train6.log - INFO - iteration:21 step:600/10100, NER loss: 1.142705
2019-02-21 17:27:58,146 - log/train6.log - INFO - iteration:21 step:700/10100, NER loss: 1.000521
2019-02-21 17:28:00,446 - log/train6.log - INFO - iteration:21 step:800/10100, NER loss: 1.012733
2019-02-21 17:28:02,696 - log/train6.log - INFO - iteration:21 step:900/10100, NER loss: 1.039945
2019-02-21 17:28:04,880 - log/train6.log - INFO - iteration:21 step:1000/10100, NER loss: 1.362560
2019-02-21 17:28:07,080 - log/train6.log - INFO - iteration:21 step:1100/10100, NER loss: 1.261244
2019-02-21 17:28:09,312 - log/train6.log - INFO - iteration:21 step:1200/10100, NER loss: 1.213369
2019-02-21 17:28:11,265 - log/train6.log - INFO - iteration:21 step:1300/10100, NER loss: 1.030267
2019-02-21 17:28:13,326 - log/train6.log - INFO - iteration:21 step:1400/10100, NER loss: 1.133343
2019-02-21 17:28:15,764 - log/train6.log - INFO - iteration:21 step:1500/10100, NER loss: 1.997940
2019-02-21 17:28:18,233 - log/train6.log - INFO - iteration:21 step:1600/10100, NER loss: 1.447916
2019-02-21 17:28:22,758 - log/train6.log - INFO - iteration:21 step:1700/10100, NER loss: 2.075406
2019-02-21 17:28:24,962 - log/train6.log - INFO - iteration:21 step:1800/10100, NER loss: 1.134586
2019-02-21 17:28:27,453 - log/train6.log - INFO - iteration:21 step:1900/10100, NER loss: 1.045063
2019-02-21 17:28:32,011 - log/train6.log - INFO - iteration:21 step:2000/10100, NER loss: 2.873387
2019-02-21 17:28:34,255 - log/train6.log - INFO - iteration:21 step:2100/10100, NER loss: 0.985880
2019-02-21 17:28:36,454 - log/train6.log - INFO - iteration:21 step:2200/10100, NER loss: 1.342759
2019-02-21 17:28:38,988 - log/train6.log - INFO - iteration:21 step:2300/10100, NER loss: 1.259759
2019-02-21 17:28:41,157 - log/train6.log - INFO - iteration:21 step:2400/10100, NER loss: 0.802056
2019-02-21 17:28:43,306 - log/train6.log - INFO - iteration:21 step:2500/10100, NER loss: 0.872273
2019-02-21 17:28:45,552 - log/train6.log - INFO - iteration:21 step:2600/10100, NER loss: 1.610132
2019-02-21 17:28:47,885 - log/train6.log - INFO - iteration:21 step:2700/10100, NER loss: 1.092218
2019-02-21 17:28:50,051 - log/train6.log - INFO - iteration:21 step:2800/10100, NER loss: 1.010010
2019-02-21 17:28:52,061 - log/train6.log - INFO - iteration:21 step:2900/10100, NER loss: 1.110760
2019-02-21 17:28:54,429 - log/train6.log - INFO - iteration:21 step:3000/10100, NER loss: 1.375475
2019-02-21 17:28:56,937 - log/train6.log - INFO - iteration:21 step:3100/10100, NER loss: 1.353809
2019-02-21 17:28:59,212 - log/train6.log - INFO - iteration:21 step:3200/10100, NER loss: 1.082399
2019-02-21 17:29:03,568 - log/train6.log - INFO - iteration:21 step:3300/10100, NER loss: 1.468922
2019-02-21 17:29:05,851 - log/train6.log - INFO - iteration:21 step:3400/10100, NER loss: 1.298433
2019-02-21 17:29:08,080 - log/train6.log - INFO - iteration:21 step:3500/10100, NER loss: 1.251729
2019-02-21 17:29:10,342 - log/train6.log - INFO - iteration:21 step:3600/10100, NER loss: 0.881043
2019-02-21 17:29:12,573 - log/train6.log - INFO - iteration:21 step:3700/10100, NER loss: 1.160008
2019-02-21 17:29:14,759 - log/train6.log - INFO - iteration:21 step:3800/10100, NER loss: 1.180413
2019-02-21 17:29:17,192 - log/train6.log - INFO - iteration:21 step:3900/10100, NER loss: 1.688772
2019-02-21 17:29:19,316 - log/train6.log - INFO - iteration:21 step:4000/10100, NER loss: 1.001274
2019-02-21 17:29:21,664 - log/train6.log - INFO - iteration:21 step:4100/10100, NER loss: 1.076981
2019-02-21 17:29:24,274 - log/train6.log - INFO - iteration:21 step:4200/10100, NER loss: 1.138629
2019-02-21 17:29:26,402 - log/train6.log - INFO - iteration:21 step:4300/10100, NER loss: 0.911604
2019-02-21 17:29:28,875 - log/train6.log - INFO - iteration:21 step:4400/10100, NER loss: 1.118575
2019-02-21 17:29:31,128 - log/train6.log - INFO - iteration:21 step:4500/10100, NER loss: 1.177439
2019-02-21 17:29:33,325 - log/train6.log - INFO - iteration:21 step:4600/10100, NER loss: 0.744440
2019-02-21 17:29:35,548 - log/train6.log - INFO - iteration:21 step:4700/10100, NER loss: 0.855600
2019-02-21 17:29:37,607 - log/train6.log - INFO - iteration:21 step:4800/10100, NER loss: 1.040427
2019-02-21 17:29:39,926 - log/train6.log - INFO - iteration:21 step:4900/10100, NER loss: 0.995208
2019-02-21 17:29:42,284 - log/train6.log - INFO - iteration:21 step:5000/10100, NER loss: 1.084926
2019-02-21 17:29:44,613 - log/train6.log - INFO - iteration:21 step:5100/10100, NER loss: 1.168358
2019-02-21 17:29:46,975 - log/train6.log - INFO - iteration:21 step:5200/10100, NER loss: 1.365270
2019-02-21 17:29:49,195 - log/train6.log - INFO - iteration:21 step:5300/10100, NER loss: 1.001941
2019-02-21 17:29:51,545 - log/train6.log - INFO - iteration:21 step:5400/10100, NER loss: 1.113850
2019-02-21 17:29:53,969 - log/train6.log - INFO - iteration:21 step:5500/10100, NER loss: 1.179865
2019-02-21 17:29:56,339 - log/train6.log - INFO - iteration:21 step:5600/10100, NER loss: 1.857437
2019-02-21 17:29:58,342 - log/train6.log - INFO - iteration:21 step:5700/10100, NER loss: 0.802475
2019-02-21 17:30:00,677 - log/train6.log - INFO - iteration:21 step:5800/10100, NER loss: 1.222665
2019-02-21 17:30:02,860 - log/train6.log - INFO - iteration:21 step:5900/10100, NER loss: 0.995813
2019-02-21 17:30:05,274 - log/train6.log - INFO - iteration:21 step:6000/10100, NER loss: 1.438029
2019-02-21 17:30:07,716 - log/train6.log - INFO - iteration:21 step:6100/10100, NER loss: 1.455436
2019-02-21 17:30:09,845 - log/train6.log - INFO - iteration:21 step:6200/10100, NER loss: 0.992274
2019-02-21 17:30:11,938 - log/train6.log - INFO - iteration:21 step:6300/10100, NER loss: 0.922466
2019-02-21 17:30:14,169 - log/train6.log - INFO - iteration:21 step:6400/10100, NER loss: 1.015259
2019-02-21 17:30:16,492 - log/train6.log - INFO - iteration:21 step:6500/10100, NER loss: 1.089898
2019-02-21 17:30:19,039 - log/train6.log - INFO - iteration:21 step:6600/10100, NER loss: 1.464579
2019-02-21 17:30:21,166 - log/train6.log - INFO - iteration:21 step:6700/10100, NER loss: 0.847566
2019-02-21 17:30:23,698 - log/train6.log - INFO - iteration:21 step:6800/10100, NER loss: 1.224637
2019-02-21 17:30:25,918 - log/train6.log - INFO - iteration:21 step:6900/10100, NER loss: 1.267735
2019-02-21 17:30:28,337 - log/train6.log - INFO - iteration:21 step:7000/10100, NER loss: 0.977723
2019-02-21 17:30:30,368 - log/train6.log - INFO - iteration:21 step:7100/10100, NER loss: 1.279644
2019-02-21 17:30:32,706 - log/train6.log - INFO - iteration:21 step:7200/10100, NER loss: 1.290444
2019-02-21 17:30:35,031 - log/train6.log - INFO - iteration:21 step:7300/10100, NER loss: 1.292266
2019-02-21 17:30:37,494 - log/train6.log - INFO - iteration:21 step:7400/10100, NER loss: 1.196129
2019-02-21 17:30:39,624 - log/train6.log - INFO - iteration:21 step:7500/10100, NER loss: 1.266166
2019-02-21 17:30:41,738 - log/train6.log - INFO - iteration:21 step:7600/10100, NER loss: 0.891160
2019-02-21 17:30:43,805 - log/train6.log - INFO - iteration:21 step:7700/10100, NER loss: 0.864362
2019-02-21 17:30:46,134 - log/train6.log - INFO - iteration:21 step:7800/10100, NER loss: 1.191855
2019-02-21 17:30:48,820 - log/train6.log - INFO - iteration:21 step:7900/10100, NER loss: 1.184670
2019-02-21 17:30:51,068 - log/train6.log - INFO - iteration:21 step:8000/10100, NER loss: 1.296327
2019-02-21 17:30:53,211 - log/train6.log - INFO - iteration:21 step:8100/10100, NER loss: 0.939473
2019-02-21 17:30:55,474 - log/train6.log - INFO - iteration:21 step:8200/10100, NER loss: 1.171152
2019-02-21 17:30:57,461 - log/train6.log - INFO - iteration:21 step:8300/10100, NER loss: 0.998017
2019-02-21 17:30:59,686 - log/train6.log - INFO - iteration:21 step:8400/10100, NER loss: 1.131691
2019-02-21 17:31:01,745 - log/train6.log - INFO - iteration:21 step:8500/10100, NER loss: 1.015057
2019-02-21 17:31:03,816 - log/train6.log - INFO - iteration:21 step:8600/10100, NER loss: 0.797935
2019-02-21 17:31:06,019 - log/train6.log - INFO - iteration:21 step:8700/10100, NER loss: 1.374503
2019-02-21 17:31:08,187 - log/train6.log - INFO - iteration:21 step:8800/10100, NER loss: 1.131437
2019-02-21 17:31:10,572 - log/train6.log - INFO - iteration:21 step:8900/10100, NER loss: 1.194966
2019-02-21 17:31:12,760 - log/train6.log - INFO - iteration:21 step:9000/10100, NER loss: 1.103039
2019-02-21 17:31:14,826 - log/train6.log - INFO - iteration:21 step:9100/10100, NER loss: 1.211270
2019-02-21 17:31:16,941 - log/train6.log - INFO - iteration:21 step:9200/10100, NER loss: 1.229930
2019-02-21 17:31:18,980 - log/train6.log - INFO - iteration:21 step:9300/10100, NER loss: 0.885603
2019-02-21 17:31:21,192 - log/train6.log - INFO - iteration:21 step:9400/10100, NER loss: 1.046996
2019-02-21 17:31:23,445 - log/train6.log - INFO - iteration:21 step:9500/10100, NER loss: 0.990213
2019-02-21 17:31:25,687 - log/train6.log - INFO - iteration:21 step:9600/10100, NER loss: 1.172959
2019-02-21 17:31:28,148 - log/train6.log - INFO - iteration:21 step:9700/10100, NER loss: 1.015184
2019-02-21 17:31:30,578 - log/train6.log - INFO - iteration:21 step:9800/10100, NER loss: 1.316070
2019-02-21 17:31:33,363 - log/train6.log - INFO - iteration:21 step:9900/10100, NER loss: 1.465058
2019-02-21 17:31:35,428 - log/train6.log - INFO - iteration:21 step:10000/10100, NER loss: 0.893260
2019-02-21 17:31:37,726 - log/train6.log - INFO - iteration:22 step:0/10100, NER loss: 1.125103
2019-02-21 17:31:37,727 - log/train6.log - INFO - evaluate:dev
2019-02-21 17:31:44,294 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5512 phrases; correct: 4337.

2019-02-21 17:31:44,295 - log/train6.log - INFO - accuracy:  95.35%; precision:  78.68%; recall:  74.17%; FB1:  76.36

2019-02-21 17:31:44,295 - log/train6.log - INFO -                 C: precision:  83.97%; recall:  89.47%; FB1:  86.63  3611

2019-02-21 17:31:44,295 - log/train6.log - INFO -               IND: precision:  53.70%; recall:  21.32%; FB1:  30.53  162

2019-02-21 17:31:44,295 - log/train6.log - INFO -               INS: precision:  78.29%; recall:  62.80%; FB1:  69.69  304

2019-02-21 17:31:44,295 - log/train6.log - INFO -                 L: precision:  60.88%; recall:  63.70%; FB1:  62.26  634

2019-02-21 17:31:44,296 - log/train6.log - INFO -                 P: precision:  88.95%; recall:  91.90%; FB1:  90.40  561

2019-02-21 17:31:44,296 - log/train6.log - INFO -               PRO: precision:  39.58%; recall:  18.20%; FB1:  24.93  240

2019-02-21 17:31:44,378 - log/train6.log - INFO - new best dev f1 score:76.360
2019-02-21 17:31:44,644 - log/train6.log - INFO - model saved
2019-02-21 17:31:44,645 - log/train6.log - INFO - evaluate:test
2019-02-21 17:31:46,099 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1623 phrases; correct: 1384.

2019-02-21 17:31:46,099 - log/train6.log - INFO - accuracy:  97.08%; precision:  85.27%; recall:  84.03%; FB1:  84.65

2019-02-21 17:31:46,099 - log/train6.log - INFO -                 C: precision:  86.84%; recall:  92.32%; FB1:  89.50  1094

2019-02-21 17:31:46,099 - log/train6.log - INFO -               IND: precision:  81.25%; recall:  55.32%; FB1:  65.82  32

2019-02-21 17:31:46,099 - log/train6.log - INFO -               INS: precision:  79.41%; recall:  56.84%; FB1:  66.26  68

2019-02-21 17:31:46,099 - log/train6.log - INFO -                 L: precision:  62.89%; recall:  59.22%; FB1:  61.00  97

2019-02-21 17:31:46,100 - log/train6.log - INFO -                 P: precision:  91.98%; recall:  95.59%; FB1:  93.75  212

2019-02-21 17:31:46,100 - log/train6.log - INFO -               PRO: precision:  81.67%; recall:  57.99%; FB1:  67.82  120

2019-02-21 17:31:46,171 - log/train6.log - INFO - new best test f1 score:84.650
2019-02-21 17:31:48,227 - log/train6.log - INFO - iteration:22 step:100/10100, NER loss: 1.332727
2019-02-21 17:31:50,280 - log/train6.log - INFO - iteration:22 step:200/10100, NER loss: 0.780162
2019-02-21 17:31:52,338 - log/train6.log - INFO - iteration:22 step:300/10100, NER loss: 0.904850
2019-02-21 17:31:54,513 - log/train6.log - INFO - iteration:22 step:400/10100, NER loss: 0.794332
2019-02-21 17:31:56,815 - log/train6.log - INFO - iteration:22 step:500/10100, NER loss: 1.073407
2019-02-21 17:31:58,868 - log/train6.log - INFO - iteration:22 step:600/10100, NER loss: 1.205195
2019-02-21 17:32:01,123 - log/train6.log - INFO - iteration:22 step:700/10100, NER loss: 1.278533
2019-02-21 17:32:03,376 - log/train6.log - INFO - iteration:22 step:800/10100, NER loss: 0.981382
2019-02-21 17:32:05,476 - log/train6.log - INFO - iteration:22 step:900/10100, NER loss: 1.000133
2019-02-21 17:32:07,646 - log/train6.log - INFO - iteration:22 step:1000/10100, NER loss: 1.320117
2019-02-21 17:32:09,868 - log/train6.log - INFO - iteration:22 step:1100/10100, NER loss: 0.865058
2019-02-21 17:32:13,983 - log/train6.log - INFO - iteration:22 step:1200/10100, NER loss: 1.564670
2019-02-21 17:32:16,242 - log/train6.log - INFO - iteration:22 step:1300/10100, NER loss: 0.940403
2019-02-21 17:32:18,511 - log/train6.log - INFO - iteration:22 step:1400/10100, NER loss: 1.105242
2019-02-21 17:32:20,563 - log/train6.log - INFO - iteration:22 step:1500/10100, NER loss: 0.948764
2019-02-21 17:32:23,047 - log/train6.log - INFO - iteration:22 step:1600/10100, NER loss: 0.933165
2019-02-21 17:32:25,299 - log/train6.log - INFO - iteration:22 step:1700/10100, NER loss: 0.919227
2019-02-21 17:32:27,489 - log/train6.log - INFO - iteration:22 step:1800/10100, NER loss: 1.086505
2019-02-21 17:32:29,578 - log/train6.log - INFO - iteration:22 step:1900/10100, NER loss: 0.945102
2019-02-21 17:32:31,892 - log/train6.log - INFO - iteration:22 step:2000/10100, NER loss: 0.821413
2019-02-21 17:32:34,251 - log/train6.log - INFO - iteration:22 step:2100/10100, NER loss: 1.101839
2019-02-21 17:32:36,699 - log/train6.log - INFO - iteration:22 step:2200/10100, NER loss: 1.157008
2019-02-21 17:32:38,988 - log/train6.log - INFO - iteration:22 step:2300/10100, NER loss: 1.125218
2019-02-21 17:32:41,351 - log/train6.log - INFO - iteration:22 step:2400/10100, NER loss: 1.265544
2019-02-21 17:32:43,658 - log/train6.log - INFO - iteration:22 step:2500/10100, NER loss: 1.396963
2019-02-21 17:32:46,044 - log/train6.log - INFO - iteration:22 step:2600/10100, NER loss: 1.133445
2019-02-21 17:32:48,536 - log/train6.log - INFO - iteration:22 step:2700/10100, NER loss: 1.221669
2019-02-21 17:32:50,670 - log/train6.log - INFO - iteration:22 step:2800/10100, NER loss: 0.925053
2019-02-21 17:32:52,668 - log/train6.log - INFO - iteration:22 step:2900/10100, NER loss: 0.807800
2019-02-21 17:32:55,086 - log/train6.log - INFO - iteration:22 step:3000/10100, NER loss: 1.270988
2019-02-21 17:32:57,194 - log/train6.log - INFO - iteration:22 step:3100/10100, NER loss: 0.910911
2019-02-21 17:32:59,790 - log/train6.log - INFO - iteration:22 step:3200/10100, NER loss: 1.002367
2019-02-21 17:33:02,053 - log/train6.log - INFO - iteration:22 step:3300/10100, NER loss: 1.188448
2019-02-21 17:33:04,232 - log/train6.log - INFO - iteration:22 step:3400/10100, NER loss: 1.146389
2019-02-21 17:33:06,462 - log/train6.log - INFO - iteration:22 step:3500/10100, NER loss: 1.029087
2019-02-21 17:33:08,813 - log/train6.log - INFO - iteration:22 step:3600/10100, NER loss: 1.376586
2019-02-21 17:33:11,188 - log/train6.log - INFO - iteration:22 step:3700/10100, NER loss: 1.487109
2019-02-21 17:33:13,298 - log/train6.log - INFO - iteration:22 step:3800/10100, NER loss: 1.184149
2019-02-21 17:33:15,440 - log/train6.log - INFO - iteration:22 step:3900/10100, NER loss: 1.211213
2019-02-21 17:33:17,590 - log/train6.log - INFO - iteration:22 step:4000/10100, NER loss: 0.915991
2019-02-21 17:33:19,769 - log/train6.log - INFO - iteration:22 step:4100/10100, NER loss: 0.947956
2019-02-21 17:33:21,977 - log/train6.log - INFO - iteration:22 step:4200/10100, NER loss: 1.072365
2019-02-21 17:33:24,022 - log/train6.log - INFO - iteration:22 step:4300/10100, NER loss: 0.864884
2019-02-21 17:33:26,095 - log/train6.log - INFO - iteration:22 step:4400/10100, NER loss: 0.750267
2019-02-21 17:33:28,621 - log/train6.log - INFO - iteration:22 step:4500/10100, NER loss: 1.122717
2019-02-21 17:33:31,213 - log/train6.log - INFO - iteration:22 step:4600/10100, NER loss: 1.540640
2019-02-21 17:33:33,800 - log/train6.log - INFO - iteration:22 step:4700/10100, NER loss: 1.205086
2019-02-21 17:33:35,767 - log/train6.log - INFO - iteration:22 step:4800/10100, NER loss: 0.806540
2019-02-21 17:33:38,714 - log/train6.log - INFO - iteration:22 step:4900/10100, NER loss: 1.302008
2019-02-21 17:33:41,334 - log/train6.log - INFO - iteration:22 step:5000/10100, NER loss: 0.862895
2019-02-21 17:33:43,528 - log/train6.log - INFO - iteration:22 step:5100/10100, NER loss: 0.847043
2019-02-21 17:33:45,867 - log/train6.log - INFO - iteration:22 step:5200/10100, NER loss: 1.086531
2019-02-21 17:33:48,825 - log/train6.log - INFO - iteration:22 step:5300/10100, NER loss: 1.416302
2019-02-21 17:33:51,157 - log/train6.log - INFO - iteration:22 step:5400/10100, NER loss: 1.394742
2019-02-21 17:33:53,523 - log/train6.log - INFO - iteration:22 step:5500/10100, NER loss: 1.097885
2019-02-21 17:33:55,885 - log/train6.log - INFO - iteration:22 step:5600/10100, NER loss: 1.037323
2019-02-21 17:33:57,917 - log/train6.log - INFO - iteration:22 step:5700/10100, NER loss: 1.236222
2019-02-21 17:34:00,193 - log/train6.log - INFO - iteration:22 step:5800/10100, NER loss: 1.188261
2019-02-21 17:34:02,760 - log/train6.log - INFO - iteration:22 step:5900/10100, NER loss: 1.630849
2019-02-21 17:34:04,899 - log/train6.log - INFO - iteration:22 step:6000/10100, NER loss: 1.096591
2019-02-21 17:34:07,039 - log/train6.log - INFO - iteration:22 step:6100/10100, NER loss: 1.040690
2019-02-21 17:34:09,246 - log/train6.log - INFO - iteration:22 step:6200/10100, NER loss: 1.117048
2019-02-21 17:34:11,541 - log/train6.log - INFO - iteration:22 step:6300/10100, NER loss: 1.292284
2019-02-21 17:34:13,817 - log/train6.log - INFO - iteration:22 step:6400/10100, NER loss: 1.042975
2019-02-21 17:34:16,002 - log/train6.log - INFO - iteration:22 step:6500/10100, NER loss: 1.273858
2019-02-21 17:34:18,258 - log/train6.log - INFO - iteration:22 step:6600/10100, NER loss: 1.046334
2019-02-21 17:34:20,662 - log/train6.log - INFO - iteration:22 step:6700/10100, NER loss: 1.283204
2019-02-21 17:34:23,132 - log/train6.log - INFO - iteration:22 step:6800/10100, NER loss: 1.164734
2019-02-21 17:34:25,591 - log/train6.log - INFO - iteration:22 step:6900/10100, NER loss: 1.265958
2019-02-21 17:34:28,091 - log/train6.log - INFO - iteration:22 step:7000/10100, NER loss: 1.064335
2019-02-21 17:34:30,565 - log/train6.log - INFO - iteration:22 step:7100/10100, NER loss: 1.347652
2019-02-21 17:34:32,791 - log/train6.log - INFO - iteration:22 step:7200/10100, NER loss: 1.288782
2019-02-21 17:34:35,226 - log/train6.log - INFO - iteration:22 step:7300/10100, NER loss: 1.085687
2019-02-21 17:34:37,379 - log/train6.log - INFO - iteration:22 step:7400/10100, NER loss: 1.377561
2019-02-21 17:34:39,719 - log/train6.log - INFO - iteration:22 step:7500/10100, NER loss: 1.150019
2019-02-21 17:34:42,046 - log/train6.log - INFO - iteration:22 step:7600/10100, NER loss: 1.222037
2019-02-21 17:34:44,122 - log/train6.log - INFO - iteration:22 step:7700/10100, NER loss: 1.188665
2019-02-21 17:34:50,989 - log/train6.log - INFO - iteration:22 step:7800/10100, NER loss: 2.817242
2019-02-21 17:34:53,431 - log/train6.log - INFO - iteration:22 step:7900/10100, NER loss: 1.273344
2019-02-21 17:34:56,190 - log/train6.log - INFO - iteration:22 step:8000/10100, NER loss: 1.467450
2019-02-21 17:34:58,726 - log/train6.log - INFO - iteration:22 step:8100/10100, NER loss: 1.192047
2019-02-21 17:35:01,050 - log/train6.log - INFO - iteration:22 step:8200/10100, NER loss: 1.011116
2019-02-21 17:35:03,547 - log/train6.log - INFO - iteration:22 step:8300/10100, NER loss: 1.268289
2019-02-21 17:35:06,100 - log/train6.log - INFO - iteration:22 step:8400/10100, NER loss: 1.145466
2019-02-21 17:35:08,417 - log/train6.log - INFO - iteration:22 step:8500/10100, NER loss: 0.879775
2019-02-21 17:35:10,996 - log/train6.log - INFO - iteration:22 step:8600/10100, NER loss: 1.257479
2019-02-21 17:35:13,337 - log/train6.log - INFO - iteration:22 step:8700/10100, NER loss: 0.930583
2019-02-21 17:35:15,685 - log/train6.log - INFO - iteration:22 step:8800/10100, NER loss: 1.186811
2019-02-21 17:35:17,994 - log/train6.log - INFO - iteration:22 step:8900/10100, NER loss: 0.725969
2019-02-21 17:35:20,365 - log/train6.log - INFO - iteration:22 step:9000/10100, NER loss: 1.030983
2019-02-21 17:35:22,666 - log/train6.log - INFO - iteration:22 step:9100/10100, NER loss: 0.950145
2019-02-21 17:35:25,153 - log/train6.log - INFO - iteration:22 step:9200/10100, NER loss: 0.897464
2019-02-21 17:35:27,477 - log/train6.log - INFO - iteration:22 step:9300/10100, NER loss: 1.175318
2019-02-21 17:35:29,695 - log/train6.log - INFO - iteration:22 step:9400/10100, NER loss: 0.831197
2019-02-21 17:35:31,844 - log/train6.log - INFO - iteration:22 step:9500/10100, NER loss: 1.093114
2019-02-21 17:35:33,988 - log/train6.log - INFO - iteration:22 step:9600/10100, NER loss: 0.969532
2019-02-21 17:35:36,275 - log/train6.log - INFO - iteration:22 step:9700/10100, NER loss: 1.085180
2019-02-21 17:35:38,618 - log/train6.log - INFO - iteration:22 step:9800/10100, NER loss: 1.173009
2019-02-21 17:35:40,996 - log/train6.log - INFO - iteration:22 step:9900/10100, NER loss: 1.100768
2019-02-21 17:35:43,825 - log/train6.log - INFO - iteration:22 step:10000/10100, NER loss: 1.202265
2019-02-21 17:35:45,958 - log/train6.log - INFO - iteration:23 step:0/10100, NER loss: 0.879554
2019-02-21 17:35:45,958 - log/train6.log - INFO - evaluate:dev
2019-02-21 17:35:52,786 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5562 phrases; correct: 4320.

2019-02-21 17:35:52,786 - log/train6.log - INFO - accuracy:  95.34%; precision:  77.67%; recall:  73.88%; FB1:  75.73

2019-02-21 17:35:52,786 - log/train6.log - INFO -                 C: precision:  87.69%; recall:  88.11%; FB1:  87.90  3405

2019-02-21 17:35:52,786 - log/train6.log - INFO -               IND: precision:  39.88%; recall:  31.86%; FB1:  35.42  326

2019-02-21 17:35:52,786 - log/train6.log - INFO -               INS: precision:  63.12%; recall:  70.45%; FB1:  66.58  423

2019-02-21 17:35:52,786 - log/train6.log - INFO -                 L: precision:  59.90%; recall:  58.42%; FB1:  59.15  591

2019-02-21 17:35:52,786 - log/train6.log - INFO -                 P: precision:  90.49%; recall:  89.32%; FB1:  89.90  536

2019-02-21 17:35:52,786 - log/train6.log - INFO -               PRO: precision:  34.88%; recall:  18.77%; FB1:  24.41  281

2019-02-21 17:35:52,791 - log/train6.log - INFO - evaluate:test
2019-02-21 17:35:54,282 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1632 phrases; correct: 1389.

2019-02-21 17:35:54,282 - log/train6.log - INFO - accuracy:  97.05%; precision:  85.11%; recall:  84.34%; FB1:  84.72

2019-02-21 17:35:54,283 - log/train6.log - INFO -                 C: precision:  89.50%; recall:  91.93%; FB1:  90.70  1057

2019-02-21 17:35:54,283 - log/train6.log - INFO -               IND: precision:  59.26%; recall:  68.09%; FB1:  63.37  54

2019-02-21 17:35:54,283 - log/train6.log - INFO -               INS: precision:  64.42%; recall:  70.53%; FB1:  67.34  104

2019-02-21 17:35:54,283 - log/train6.log - INFO -                 L: precision:  64.52%; recall:  58.25%; FB1:  61.22  93

2019-02-21 17:35:54,283 - log/train6.log - INFO -                 P: precision:  93.20%; recall:  94.12%; FB1:  93.66  206

2019-02-21 17:35:54,283 - log/train6.log - INFO -               PRO: precision:  77.97%; recall:  54.44%; FB1:  64.11  118

2019-02-21 17:35:54,357 - log/train6.log - INFO - new best test f1 score:84.720
2019-02-21 17:35:56,240 - log/train6.log - INFO - iteration:23 step:100/10100, NER loss: 1.210127
2019-02-21 17:36:00,238 - log/train6.log - INFO - iteration:23 step:200/10100, NER loss: 1.299301
2019-02-21 17:36:02,687 - log/train6.log - INFO - iteration:23 step:300/10100, NER loss: 1.222416
2019-02-21 17:36:05,100 - log/train6.log - INFO - iteration:23 step:400/10100, NER loss: 1.102883
2019-02-21 17:36:07,441 - log/train6.log - INFO - iteration:23 step:500/10100, NER loss: 1.134051
2019-02-21 17:36:09,791 - log/train6.log - INFO - iteration:23 step:600/10100, NER loss: 1.357919
2019-02-21 17:36:12,685 - log/train6.log - INFO - iteration:23 step:700/10100, NER loss: 1.491888
2019-02-21 17:36:14,724 - log/train6.log - INFO - iteration:23 step:800/10100, NER loss: 0.865967
2019-02-21 17:36:16,777 - log/train6.log - INFO - iteration:23 step:900/10100, NER loss: 0.893966
2019-02-21 17:36:18,902 - log/train6.log - INFO - iteration:23 step:1000/10100, NER loss: 1.157626
2019-02-21 17:36:21,034 - log/train6.log - INFO - iteration:23 step:1100/10100, NER loss: 1.104889
2019-02-21 17:36:23,363 - log/train6.log - INFO - iteration:23 step:1200/10100, NER loss: 1.180989
2019-02-21 17:36:25,659 - log/train6.log - INFO - iteration:23 step:1300/10100, NER loss: 1.014894
2019-02-21 17:36:27,953 - log/train6.log - INFO - iteration:23 step:1400/10100, NER loss: 1.336358
2019-02-21 17:36:29,898 - log/train6.log - INFO - iteration:23 step:1500/10100, NER loss: 0.798930
2019-02-21 17:36:31,998 - log/train6.log - INFO - iteration:23 step:1600/10100, NER loss: 0.927495
2019-02-21 17:36:34,144 - log/train6.log - INFO - iteration:23 step:1700/10100, NER loss: 1.038422
2019-02-21 17:36:36,205 - log/train6.log - INFO - iteration:23 step:1800/10100, NER loss: 0.736328
2019-02-21 17:36:38,284 - log/train6.log - INFO - iteration:23 step:1900/10100, NER loss: 1.084370
2019-02-21 17:36:40,489 - log/train6.log - INFO - iteration:23 step:2000/10100, NER loss: 1.088659
2019-02-21 17:36:42,455 - log/train6.log - INFO - iteration:23 step:2100/10100, NER loss: 0.766869
2019-02-21 17:36:44,470 - log/train6.log - INFO - iteration:23 step:2200/10100, NER loss: 0.915152
2019-02-21 17:36:46,549 - log/train6.log - INFO - iteration:23 step:2300/10100, NER loss: 1.094572
2019-02-21 17:36:48,781 - log/train6.log - INFO - iteration:23 step:2400/10100, NER loss: 1.071581
2019-02-21 17:36:51,180 - log/train6.log - INFO - iteration:23 step:2500/10100, NER loss: 0.969272
2019-02-21 17:36:53,314 - log/train6.log - INFO - iteration:23 step:2600/10100, NER loss: 1.059132
2019-02-21 17:36:55,555 - log/train6.log - INFO - iteration:23 step:2700/10100, NER loss: 0.957387
2019-02-21 17:36:57,744 - log/train6.log - INFO - iteration:23 step:2800/10100, NER loss: 1.127724
2019-02-21 17:36:59,958 - log/train6.log - INFO - iteration:23 step:2900/10100, NER loss: 1.100450
2019-02-21 17:37:02,561 - log/train6.log - INFO - iteration:23 step:3000/10100, NER loss: 1.407012
2019-02-21 17:37:04,665 - log/train6.log - INFO - iteration:23 step:3100/10100, NER loss: 1.031268
2019-02-21 17:37:06,773 - log/train6.log - INFO - iteration:23 step:3200/10100, NER loss: 1.026270
2019-02-21 17:37:08,968 - log/train6.log - INFO - iteration:23 step:3300/10100, NER loss: 1.103707
2019-02-21 17:37:11,308 - log/train6.log - INFO - iteration:23 step:3400/10100, NER loss: 1.164793
2019-02-21 17:37:13,413 - log/train6.log - INFO - iteration:23 step:3500/10100, NER loss: 1.210407
2019-02-21 17:37:15,709 - log/train6.log - INFO - iteration:23 step:3600/10100, NER loss: 1.065472
2019-02-21 17:37:17,905 - log/train6.log - INFO - iteration:23 step:3700/10100, NER loss: 0.850601
2019-02-21 17:37:20,286 - log/train6.log - INFO - iteration:23 step:3800/10100, NER loss: 1.361722
2019-02-21 17:37:22,473 - log/train6.log - INFO - iteration:23 step:3900/10100, NER loss: 0.911834
2019-02-21 17:37:24,762 - log/train6.log - INFO - iteration:23 step:4000/10100, NER loss: 1.263549
2019-02-21 17:37:27,072 - log/train6.log - INFO - iteration:23 step:4100/10100, NER loss: 1.241829
2019-02-21 17:37:29,277 - log/train6.log - INFO - iteration:23 step:4200/10100, NER loss: 1.063302
2019-02-21 17:37:31,533 - log/train6.log - INFO - iteration:23 step:4300/10100, NER loss: 1.059160
2019-02-21 17:37:33,853 - log/train6.log - INFO - iteration:23 step:4400/10100, NER loss: 1.455188
2019-02-21 17:37:36,038 - log/train6.log - INFO - iteration:23 step:4500/10100, NER loss: 1.008991
2019-02-21 17:37:38,128 - log/train6.log - INFO - iteration:23 step:4600/10100, NER loss: 1.035509
2019-02-21 17:37:40,110 - log/train6.log - INFO - iteration:23 step:4700/10100, NER loss: 0.872963
2019-02-21 17:37:42,350 - log/train6.log - INFO - iteration:23 step:4800/10100, NER loss: 0.876568
2019-02-21 17:37:44,683 - log/train6.log - INFO - iteration:23 step:4900/10100, NER loss: 0.937560
2019-02-21 17:37:46,885 - log/train6.log - INFO - iteration:23 step:5000/10100, NER loss: 1.263790
2019-02-21 17:37:48,962 - log/train6.log - INFO - iteration:23 step:5100/10100, NER loss: 0.974848
2019-02-21 17:37:51,216 - log/train6.log - INFO - iteration:23 step:5200/10100, NER loss: 0.908682
2019-02-21 17:37:53,533 - log/train6.log - INFO - iteration:23 step:5300/10100, NER loss: 1.271264
2019-02-21 17:37:55,752 - log/train6.log - INFO - iteration:23 step:5400/10100, NER loss: 0.930731
2019-02-21 17:37:57,908 - log/train6.log - INFO - iteration:23 step:5500/10100, NER loss: 1.084479
2019-02-21 17:38:00,017 - log/train6.log - INFO - iteration:23 step:5600/10100, NER loss: 0.855068
2019-02-21 17:38:02,483 - log/train6.log - INFO - iteration:23 step:5700/10100, NER loss: 1.634568
2019-02-21 17:38:04,560 - log/train6.log - INFO - iteration:23 step:5800/10100, NER loss: 1.036965
2019-02-21 17:38:06,931 - log/train6.log - INFO - iteration:23 step:5900/10100, NER loss: 1.361524
2019-02-21 17:38:09,278 - log/train6.log - INFO - iteration:23 step:6000/10100, NER loss: 1.123483
2019-02-21 17:38:11,642 - log/train6.log - INFO - iteration:23 step:6100/10100, NER loss: 0.975287
2019-02-21 17:38:13,997 - log/train6.log - INFO - iteration:23 step:6200/10100, NER loss: 1.159009
2019-02-21 17:38:16,449 - log/train6.log - INFO - iteration:23 step:6300/10100, NER loss: 1.106123
2019-02-21 17:38:18,542 - log/train6.log - INFO - iteration:23 step:6400/10100, NER loss: 0.869080
2019-02-21 17:38:21,253 - log/train6.log - INFO - iteration:23 step:6500/10100, NER loss: 1.472142
2019-02-21 17:38:23,386 - log/train6.log - INFO - iteration:23 step:6600/10100, NER loss: 0.941588
2019-02-21 17:38:25,411 - log/train6.log - INFO - iteration:23 step:6700/10100, NER loss: 0.772009
2019-02-21 17:38:27,449 - log/train6.log - INFO - iteration:23 step:6800/10100, NER loss: 0.886655
2019-02-21 17:38:29,606 - log/train6.log - INFO - iteration:23 step:6900/10100, NER loss: 1.003123
2019-02-21 17:38:31,868 - log/train6.log - INFO - iteration:23 step:7000/10100, NER loss: 1.319964
2019-02-21 17:38:34,142 - log/train6.log - INFO - iteration:23 step:7100/10100, NER loss: 1.008572
2019-02-21 17:38:36,479 - log/train6.log - INFO - iteration:23 step:7200/10100, NER loss: 1.185233
2019-02-21 17:38:38,737 - log/train6.log - INFO - iteration:23 step:7300/10100, NER loss: 0.994254
2019-02-21 17:38:40,994 - log/train6.log - INFO - iteration:23 step:7400/10100, NER loss: 1.023767
2019-02-21 17:38:43,251 - log/train6.log - INFO - iteration:23 step:7500/10100, NER loss: 1.026648
2019-02-21 17:38:47,818 - log/train6.log - INFO - iteration:23 step:7600/10100, NER loss: 2.466231
2019-02-21 17:38:50,312 - log/train6.log - INFO - iteration:23 step:7700/10100, NER loss: 1.535710
2019-02-21 17:38:52,681 - log/train6.log - INFO - iteration:23 step:7800/10100, NER loss: 1.116446
2019-02-21 17:38:55,207 - log/train6.log - INFO - iteration:23 step:7900/10100, NER loss: 1.292346
2019-02-21 17:38:57,567 - log/train6.log - INFO - iteration:23 step:8000/10100, NER loss: 1.160981
2019-02-21 17:38:59,687 - log/train6.log - INFO - iteration:23 step:8100/10100, NER loss: 1.012395
2019-02-21 17:39:01,970 - log/train6.log - INFO - iteration:23 step:8200/10100, NER loss: 1.370906
2019-02-21 17:39:04,074 - log/train6.log - INFO - iteration:23 step:8300/10100, NER loss: 0.840108
2019-02-21 17:39:06,475 - log/train6.log - INFO - iteration:23 step:8400/10100, NER loss: 1.393724
2019-02-21 17:39:08,629 - log/train6.log - INFO - iteration:23 step:8500/10100, NER loss: 1.159232
2019-02-21 17:39:10,786 - log/train6.log - INFO - iteration:23 step:8600/10100, NER loss: 0.941363
2019-02-21 17:39:13,032 - log/train6.log - INFO - iteration:23 step:8700/10100, NER loss: 0.905262
2019-02-21 17:39:17,073 - log/train6.log - INFO - iteration:23 step:8800/10100, NER loss: 1.473361
2019-02-21 17:39:19,101 - log/train6.log - INFO - iteration:23 step:8900/10100, NER loss: 0.872051
2019-02-21 17:39:21,220 - log/train6.log - INFO - iteration:23 step:9000/10100, NER loss: 1.072633
2019-02-21 17:39:23,554 - log/train6.log - INFO - iteration:23 step:9100/10100, NER loss: 0.990139
2019-02-21 17:39:25,791 - log/train6.log - INFO - iteration:23 step:9200/10100, NER loss: 1.349214
2019-02-21 17:39:27,980 - log/train6.log - INFO - iteration:23 step:9300/10100, NER loss: 1.212344
2019-02-21 17:39:30,249 - log/train6.log - INFO - iteration:23 step:9400/10100, NER loss: 1.211243
2019-02-21 17:39:32,326 - log/train6.log - INFO - iteration:23 step:9500/10100, NER loss: 0.965761
2019-02-21 17:39:34,568 - log/train6.log - INFO - iteration:23 step:9600/10100, NER loss: 0.960200
2019-02-21 17:39:36,691 - log/train6.log - INFO - iteration:23 step:9700/10100, NER loss: 1.028358
2019-02-21 17:39:39,098 - log/train6.log - INFO - iteration:23 step:9800/10100, NER loss: 1.103345
2019-02-21 17:39:41,252 - log/train6.log - INFO - iteration:23 step:9900/10100, NER loss: 1.000392
2019-02-21 17:39:43,450 - log/train6.log - INFO - iteration:23 step:10000/10100, NER loss: 0.892808
2019-02-21 17:39:45,763 - log/train6.log - INFO - iteration:24 step:0/10100, NER loss: 0.857769
2019-02-21 17:39:45,763 - log/train6.log - INFO - evaluate:dev
2019-02-21 17:39:52,253 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5582 phrases; correct: 4318.

2019-02-21 17:39:52,254 - log/train6.log - INFO - accuracy:  95.37%; precision:  77.36%; recall:  73.85%; FB1:  75.56

2019-02-21 17:39:52,255 - log/train6.log - INFO -                 C: precision:  88.47%; recall:  86.90%; FB1:  87.67  3329

2019-02-21 17:39:52,255 - log/train6.log - INFO -               IND: precision:  38.20%; recall:  35.29%; FB1:  36.69  377

2019-02-21 17:39:52,255 - log/train6.log - INFO -               INS: precision:  58.14%; recall:  74.41%; FB1:  65.28  485

2019-02-21 17:39:52,255 - log/train6.log - INFO -                 L: precision:  59.69%; recall:  56.44%; FB1:  58.02  573

2019-02-21 17:39:52,255 - log/train6.log - INFO -                 P: precision:  88.12%; recall:  91.53%; FB1:  89.79  564

2019-02-21 17:39:52,255 - log/train6.log - INFO -               PRO: precision:  42.52%; recall:  20.69%; FB1:  27.84  254

2019-02-21 17:39:52,260 - log/train6.log - INFO - evaluate:test
2019-02-21 17:39:53,721 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1642 phrases; correct: 1391.

2019-02-21 17:39:53,721 - log/train6.log - INFO - accuracy:  96.96%; precision:  84.71%; recall:  84.46%; FB1:  84.58

2019-02-21 17:39:53,721 - log/train6.log - INFO -                 C: precision:  90.60%; recall:  91.74%; FB1:  91.16  1042

2019-02-21 17:39:53,722 - log/train6.log - INFO -               IND: precision:  47.30%; recall:  74.47%; FB1:  57.85  74

2019-02-21 17:39:53,722 - log/train6.log - INFO -               INS: precision:  61.40%; recall:  73.68%; FB1:  66.99  114

2019-02-21 17:39:53,722 - log/train6.log - INFO -                 L: precision:  67.37%; recall:  62.14%; FB1:  64.65  95

2019-02-21 17:39:53,722 - log/train6.log - INFO -                 P: precision:  90.19%; recall:  94.61%; FB1:  92.34  214

2019-02-21 17:39:53,722 - log/train6.log - INFO -               PRO: precision:  82.52%; recall:  50.30%; FB1:  62.50  103

2019-02-21 17:39:55,913 - log/train6.log - INFO - iteration:24 step:100/10100, NER loss: 1.224785
2019-02-21 17:39:57,884 - log/train6.log - INFO - iteration:24 step:200/10100, NER loss: 0.836837
2019-02-21 17:39:59,747 - log/train6.log - INFO - iteration:24 step:300/10100, NER loss: 0.976025
2019-02-21 17:40:02,064 - log/train6.log - INFO - iteration:24 step:400/10100, NER loss: 1.184258
2019-02-21 17:40:04,285 - log/train6.log - INFO - iteration:24 step:500/10100, NER loss: 1.299727
2019-02-21 17:40:06,519 - log/train6.log - INFO - iteration:24 step:600/10100, NER loss: 0.969332
2019-02-21 17:40:08,925 - log/train6.log - INFO - iteration:24 step:700/10100, NER loss: 0.888968
2019-02-21 17:40:11,019 - log/train6.log - INFO - iteration:24 step:800/10100, NER loss: 1.143065
2019-02-21 17:40:13,349 - log/train6.log - INFO - iteration:24 step:900/10100, NER loss: 1.055193
2019-02-21 17:40:15,406 - log/train6.log - INFO - iteration:24 step:1000/10100, NER loss: 0.941152
2019-02-21 17:40:17,858 - log/train6.log - INFO - iteration:24 step:1100/10100, NER loss: 1.201220
2019-02-21 17:40:19,867 - log/train6.log - INFO - iteration:24 step:1200/10100, NER loss: 0.915484
2019-02-21 17:40:22,164 - log/train6.log - INFO - iteration:24 step:1300/10100, NER loss: 1.144207
2019-02-21 17:40:24,330 - log/train6.log - INFO - iteration:24 step:1400/10100, NER loss: 1.259456
2019-02-21 17:40:26,506 - log/train6.log - INFO - iteration:24 step:1500/10100, NER loss: 0.975670
2019-02-21 17:40:28,607 - log/train6.log - INFO - iteration:24 step:1600/10100, NER loss: 1.166564
2019-02-21 17:40:30,763 - log/train6.log - INFO - iteration:24 step:1700/10100, NER loss: 0.971282
2019-02-21 17:40:33,045 - log/train6.log - INFO - iteration:24 step:1800/10100, NER loss: 1.120723
2019-02-21 17:40:35,379 - log/train6.log - INFO - iteration:24 step:1900/10100, NER loss: 1.067129
2019-02-21 17:40:37,704 - log/train6.log - INFO - iteration:24 step:2000/10100, NER loss: 1.136413
2019-02-21 17:40:40,130 - log/train6.log - INFO - iteration:24 step:2100/10100, NER loss: 1.516023
2019-02-21 17:40:42,439 - log/train6.log - INFO - iteration:24 step:2200/10100, NER loss: 1.101416
2019-02-21 17:40:44,606 - log/train6.log - INFO - iteration:24 step:2300/10100, NER loss: 0.940052
2019-02-21 17:40:47,123 - log/train6.log - INFO - iteration:24 step:2400/10100, NER loss: 1.374821
2019-02-21 17:40:49,398 - log/train6.log - INFO - iteration:24 step:2500/10100, NER loss: 0.946581
2019-02-21 17:40:51,605 - log/train6.log - INFO - iteration:24 step:2600/10100, NER loss: 0.782733
2019-02-21 17:40:53,752 - log/train6.log - INFO - iteration:24 step:2700/10100, NER loss: 0.826973
2019-02-21 17:40:55,985 - log/train6.log - INFO - iteration:24 step:2800/10100, NER loss: 1.062567
2019-02-21 17:40:58,233 - log/train6.log - INFO - iteration:24 step:2900/10100, NER loss: 1.082732
2019-02-21 17:41:00,214 - log/train6.log - INFO - iteration:24 step:3000/10100, NER loss: 0.870324
2019-02-21 17:41:02,562 - log/train6.log - INFO - iteration:24 step:3100/10100, NER loss: 1.274097
2019-02-21 17:41:05,179 - log/train6.log - INFO - iteration:24 step:3200/10100, NER loss: 1.273686
2019-02-21 17:41:07,289 - log/train6.log - INFO - iteration:24 step:3300/10100, NER loss: 0.887711
2019-02-21 17:41:09,676 - log/train6.log - INFO - iteration:24 step:3400/10100, NER loss: 1.031999
2019-02-21 17:41:11,958 - log/train6.log - INFO - iteration:24 step:3500/10100, NER loss: 1.224976
2019-02-21 17:41:14,248 - log/train6.log - INFO - iteration:24 step:3600/10100, NER loss: 1.261559
2019-02-21 17:41:16,400 - log/train6.log - INFO - iteration:24 step:3700/10100, NER loss: 0.984557
2019-02-21 17:41:18,453 - log/train6.log - INFO - iteration:24 step:3800/10100, NER loss: 0.959205
2019-02-21 17:41:20,898 - log/train6.log - INFO - iteration:24 step:3900/10100, NER loss: 1.209535
2019-02-21 17:41:22,933 - log/train6.log - INFO - iteration:24 step:4000/10100, NER loss: 0.840089
2019-02-21 17:41:27,136 - log/train6.log - INFO - iteration:24 step:4100/10100, NER loss: 1.456147
2019-02-21 17:41:29,618 - log/train6.log - INFO - iteration:24 step:4200/10100, NER loss: 1.549210
2019-02-21 17:41:31,818 - log/train6.log - INFO - iteration:24 step:4300/10100, NER loss: 1.248155
2019-02-21 17:41:34,042 - log/train6.log - INFO - iteration:24 step:4400/10100, NER loss: 1.128334
2019-02-21 17:41:36,332 - log/train6.log - INFO - iteration:24 step:4500/10100, NER loss: 1.047136
2019-02-21 17:41:38,337 - log/train6.log - INFO - iteration:24 step:4600/10100, NER loss: 0.761433
2019-02-21 17:41:40,545 - log/train6.log - INFO - iteration:24 step:4700/10100, NER loss: 1.241289
2019-02-21 17:41:42,650 - log/train6.log - INFO - iteration:24 step:4800/10100, NER loss: 0.973716
2019-02-21 17:41:44,731 - log/train6.log - INFO - iteration:24 step:4900/10100, NER loss: 0.890810
2019-02-21 17:41:46,870 - log/train6.log - INFO - iteration:24 step:5000/10100, NER loss: 0.795462
2019-02-21 17:41:51,108 - log/train6.log - INFO - iteration:24 step:5100/10100, NER loss: 1.867123
2019-02-21 17:41:53,361 - log/train6.log - INFO - iteration:24 step:5200/10100, NER loss: 0.959588
2019-02-21 17:41:55,564 - log/train6.log - INFO - iteration:24 step:5300/10100, NER loss: 1.339115
2019-02-21 17:41:58,029 - log/train6.log - INFO - iteration:24 step:5400/10100, NER loss: 1.324413
2019-02-21 17:42:00,445 - log/train6.log - INFO - iteration:24 step:5500/10100, NER loss: 1.340649
2019-02-21 17:42:02,419 - log/train6.log - INFO - iteration:24 step:5600/10100, NER loss: 0.987695
2019-02-21 17:42:04,619 - log/train6.log - INFO - iteration:24 step:5700/10100, NER loss: 1.049072
2019-02-21 17:42:06,767 - log/train6.log - INFO - iteration:24 step:5800/10100, NER loss: 1.076831
2019-02-21 17:42:09,047 - log/train6.log - INFO - iteration:24 step:5900/10100, NER loss: 1.014726
2019-02-21 17:42:11,369 - log/train6.log - INFO - iteration:24 step:6000/10100, NER loss: 0.888639
2019-02-21 17:42:13,645 - log/train6.log - INFO - iteration:24 step:6100/10100, NER loss: 1.674182
2019-02-21 17:42:15,979 - log/train6.log - INFO - iteration:24 step:6200/10100, NER loss: 1.288943
2019-02-21 17:42:17,963 - log/train6.log - INFO - iteration:24 step:6300/10100, NER loss: 0.713240
2019-02-21 17:42:20,182 - log/train6.log - INFO - iteration:24 step:6400/10100, NER loss: 1.147238
2019-02-21 17:42:22,370 - log/train6.log - INFO - iteration:24 step:6500/10100, NER loss: 0.991404
2019-02-21 17:42:24,567 - log/train6.log - INFO - iteration:24 step:6600/10100, NER loss: 1.084112
2019-02-21 17:42:26,829 - log/train6.log - INFO - iteration:24 step:6700/10100, NER loss: 0.805719
2019-02-21 17:42:29,105 - log/train6.log - INFO - iteration:24 step:6800/10100, NER loss: 1.232069
2019-02-21 17:42:31,482 - log/train6.log - INFO - iteration:24 step:6900/10100, NER loss: 1.185364
2019-02-21 17:42:33,611 - log/train6.log - INFO - iteration:24 step:7000/10100, NER loss: 1.366449
2019-02-21 17:42:35,869 - log/train6.log - INFO - iteration:24 step:7100/10100, NER loss: 1.066804
2019-02-21 17:42:37,937 - log/train6.log - INFO - iteration:24 step:7200/10100, NER loss: 1.028283
2019-02-21 17:42:40,157 - log/train6.log - INFO - iteration:24 step:7300/10100, NER loss: 0.756654
2019-02-21 17:42:42,616 - log/train6.log - INFO - iteration:24 step:7400/10100, NER loss: 1.170995
2019-02-21 17:42:44,792 - log/train6.log - INFO - iteration:24 step:7500/10100, NER loss: 0.802452
2019-02-21 17:42:46,977 - log/train6.log - INFO - iteration:24 step:7600/10100, NER loss: 0.839872
2019-02-21 17:42:49,350 - log/train6.log - INFO - iteration:24 step:7700/10100, NER loss: 1.059409
2019-02-21 17:42:51,660 - log/train6.log - INFO - iteration:24 step:7800/10100, NER loss: 1.009894
2019-02-21 17:42:53,736 - log/train6.log - INFO - iteration:24 step:7900/10100, NER loss: 0.881861
2019-02-21 17:42:55,861 - log/train6.log - INFO - iteration:24 step:8000/10100, NER loss: 1.086046
2019-02-21 17:42:58,146 - log/train6.log - INFO - iteration:24 step:8100/10100, NER loss: 1.253750
2019-02-21 17:43:00,154 - log/train6.log - INFO - iteration:24 step:8200/10100, NER loss: 0.917553
2019-02-21 17:43:02,269 - log/train6.log - INFO - iteration:24 step:8300/10100, NER loss: 0.812436
2019-02-21 17:43:04,573 - log/train6.log - INFO - iteration:24 step:8400/10100, NER loss: 1.142404
2019-02-21 17:43:07,009 - log/train6.log - INFO - iteration:24 step:8500/10100, NER loss: 0.980141
2019-02-21 17:43:09,179 - log/train6.log - INFO - iteration:24 step:8600/10100, NER loss: 1.191349
2019-02-21 17:43:11,547 - log/train6.log - INFO - iteration:24 step:8700/10100, NER loss: 1.030648
2019-02-21 17:43:14,150 - log/train6.log - INFO - iteration:24 step:8800/10100, NER loss: 1.083206
2019-02-21 17:43:16,600 - log/train6.log - INFO - iteration:24 step:8900/10100, NER loss: 0.922925
2019-02-21 17:43:19,183 - log/train6.log - INFO - iteration:24 step:9000/10100, NER loss: 1.243541
2019-02-21 17:43:23,718 - log/train6.log - INFO - iteration:24 step:9100/10100, NER loss: 2.122580
2019-02-21 17:43:25,819 - log/train6.log - INFO - iteration:24 step:9200/10100, NER loss: 1.058618
2019-02-21 17:43:28,181 - log/train6.log - INFO - iteration:24 step:9300/10100, NER loss: 1.106507
2019-02-21 17:43:30,490 - log/train6.log - INFO - iteration:24 step:9400/10100, NER loss: 1.096399
2019-02-21 17:43:32,739 - log/train6.log - INFO - iteration:24 step:9500/10100, NER loss: 0.894960
2019-02-21 17:43:35,017 - log/train6.log - INFO - iteration:24 step:9600/10100, NER loss: 0.998019
2019-02-21 17:43:37,236 - log/train6.log - INFO - iteration:24 step:9700/10100, NER loss: 1.030083
2019-02-21 17:43:39,297 - log/train6.log - INFO - iteration:24 step:9800/10100, NER loss: 0.966092
2019-02-21 17:43:41,521 - log/train6.log - INFO - iteration:24 step:9900/10100, NER loss: 0.933336
2019-02-21 17:43:43,738 - log/train6.log - INFO - iteration:24 step:10000/10100, NER loss: 1.051933
2019-02-21 17:43:45,967 - log/train6.log - INFO - iteration:25 step:0/10100, NER loss: 1.007069
2019-02-21 17:43:45,967 - log/train6.log - INFO - evaluate:dev
2019-02-21 17:43:52,503 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5735 phrases; correct: 4413.

2019-02-21 17:43:52,503 - log/train6.log - INFO - accuracy:  95.43%; precision:  76.95%; recall:  75.47%; FB1:  76.20

2019-02-21 17:43:52,503 - log/train6.log - INFO -                 C: precision:  85.63%; recall:  89.88%; FB1:  87.71  3557

2019-02-21 17:43:52,503 - log/train6.log - INFO -               IND: precision:  43.17%; recall:  28.68%; FB1:  34.46  271

2019-02-21 17:43:52,503 - log/train6.log - INFO -               INS: precision:  63.17%; recall:  71.50%; FB1:  67.08  429

2019-02-21 17:43:52,503 - log/train6.log - INFO -                 L: precision:  60.27%; recall:  58.09%; FB1:  59.16  584

2019-02-21 17:43:52,503 - log/train6.log - INFO -                 P: precision:  88.48%; recall:  91.90%; FB1:  90.15  564

2019-02-21 17:43:52,503 - log/train6.log - INFO -               PRO: precision:  38.79%; recall:  24.52%; FB1:  30.05  330

2019-02-21 17:43:52,506 - log/train6.log - INFO - evaluate:test
2019-02-21 17:43:53,960 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1660 phrases; correct: 1407.

2019-02-21 17:43:53,961 - log/train6.log - INFO - accuracy:  97.09%; precision:  84.76%; recall:  85.43%; FB1:  85.09

2019-02-21 17:43:53,961 - log/train6.log - INFO -                 C: precision:  88.40%; recall:  93.29%; FB1:  90.78  1086

2019-02-21 17:43:53,961 - log/train6.log - INFO -               IND: precision:  65.22%; recall:  63.83%; FB1:  64.52  46

2019-02-21 17:43:53,961 - log/train6.log - INFO -               INS: precision:  69.07%; recall:  70.53%; FB1:  69.79  97

2019-02-21 17:43:53,961 - log/train6.log - INFO -                 L: precision:  65.00%; recall:  63.11%; FB1:  64.04  100

2019-02-21 17:43:53,961 - log/train6.log - INFO -                 P: precision:  91.04%; recall:  94.61%; FB1:  92.79  212

2019-02-21 17:43:53,961 - log/train6.log - INFO -               PRO: precision:  77.31%; recall:  54.44%; FB1:  63.89  119

2019-02-21 17:43:54,033 - log/train6.log - INFO - new best test f1 score:85.090
2019-02-21 17:43:56,195 - log/train6.log - INFO - iteration:25 step:100/10100, NER loss: 1.417840
2019-02-21 17:43:58,191 - log/train6.log - INFO - iteration:25 step:200/10100, NER loss: 0.811082
2019-02-21 17:44:00,438 - log/train6.log - INFO - iteration:25 step:300/10100, NER loss: 0.981109
2019-02-21 17:44:02,555 - log/train6.log - INFO - iteration:25 step:400/10100, NER loss: 0.999107
2019-02-21 17:44:04,892 - log/train6.log - INFO - iteration:25 step:500/10100, NER loss: 1.102234
2019-02-21 17:44:07,182 - log/train6.log - INFO - iteration:25 step:600/10100, NER loss: 1.039266
2019-02-21 17:44:09,336 - log/train6.log - INFO - iteration:25 step:700/10100, NER loss: 0.792682
2019-02-21 17:44:11,481 - log/train6.log - INFO - iteration:25 step:800/10100, NER loss: 0.995522
2019-02-21 17:44:13,574 - log/train6.log - INFO - iteration:25 step:900/10100, NER loss: 0.839145
2019-02-21 17:44:15,702 - log/train6.log - INFO - iteration:25 step:1000/10100, NER loss: 1.187036
2019-02-21 17:44:17,881 - log/train6.log - INFO - iteration:25 step:1100/10100, NER loss: 1.200481
2019-02-21 17:44:20,067 - log/train6.log - INFO - iteration:25 step:1200/10100, NER loss: 1.021579
2019-02-21 17:44:22,232 - log/train6.log - INFO - iteration:25 step:1300/10100, NER loss: 0.862445
2019-02-21 17:44:24,472 - log/train6.log - INFO - iteration:25 step:1400/10100, NER loss: 1.110981
2019-02-21 17:44:27,227 - log/train6.log - INFO - iteration:25 step:1500/10100, NER loss: 1.476365
2019-02-21 17:44:29,399 - log/train6.log - INFO - iteration:25 step:1600/10100, NER loss: 0.889693
2019-02-21 17:44:31,620 - log/train6.log - INFO - iteration:25 step:1700/10100, NER loss: 1.100218
2019-02-21 17:44:33,925 - log/train6.log - INFO - iteration:25 step:1800/10100, NER loss: 1.073614
2019-02-21 17:44:35,905 - log/train6.log - INFO - iteration:25 step:1900/10100, NER loss: 0.818085
2019-02-21 17:44:38,398 - log/train6.log - INFO - iteration:25 step:2000/10100, NER loss: 1.222298
2019-02-21 17:44:40,859 - log/train6.log - INFO - iteration:25 step:2100/10100, NER loss: 1.415425
2019-02-21 17:44:43,211 - log/train6.log - INFO - iteration:25 step:2200/10100, NER loss: 1.272370
2019-02-21 17:44:47,679 - log/train6.log - INFO - iteration:25 step:2300/10100, NER loss: 1.694125
2019-02-21 17:44:50,036 - log/train6.log - INFO - iteration:25 step:2400/10100, NER loss: 1.284175
2019-02-21 17:44:52,383 - log/train6.log - INFO - iteration:25 step:2500/10100, NER loss: 1.348018
2019-02-21 17:44:54,607 - log/train6.log - INFO - iteration:25 step:2600/10100, NER loss: 1.057001
2019-02-21 17:44:56,846 - log/train6.log - INFO - iteration:25 step:2700/10100, NER loss: 0.938446
2019-02-21 17:44:59,216 - log/train6.log - INFO - iteration:25 step:2800/10100, NER loss: 1.113777
2019-02-21 17:45:01,630 - log/train6.log - INFO - iteration:25 step:2900/10100, NER loss: 1.112150
2019-02-21 17:45:03,759 - log/train6.log - INFO - iteration:25 step:3000/10100, NER loss: 0.721117
2019-02-21 17:45:05,805 - log/train6.log - INFO - iteration:25 step:3100/10100, NER loss: 0.812596
2019-02-21 17:45:08,032 - log/train6.log - INFO - iteration:25 step:3200/10100, NER loss: 1.259447
2019-02-21 17:45:10,428 - log/train6.log - INFO - iteration:25 step:3300/10100, NER loss: 1.252968
2019-02-21 17:45:12,564 - log/train6.log - INFO - iteration:25 step:3400/10100, NER loss: 0.850129
2019-02-21 17:45:14,864 - log/train6.log - INFO - iteration:25 step:3500/10100, NER loss: 1.202521
2019-02-21 17:45:17,068 - log/train6.log - INFO - iteration:25 step:3600/10100, NER loss: 1.089737
2019-02-21 17:45:19,414 - log/train6.log - INFO - iteration:25 step:3700/10100, NER loss: 0.964268
2019-02-21 17:45:21,535 - log/train6.log - INFO - iteration:25 step:3800/10100, NER loss: 0.813238
2019-02-21 17:45:23,873 - log/train6.log - INFO - iteration:25 step:3900/10100, NER loss: 1.330072
2019-02-21 17:45:26,273 - log/train6.log - INFO - iteration:25 step:4000/10100, NER loss: 1.310969
2019-02-21 17:45:28,499 - log/train6.log - INFO - iteration:25 step:4100/10100, NER loss: 1.018488
2019-02-21 17:45:30,748 - log/train6.log - INFO - iteration:25 step:4200/10100, NER loss: 0.902603
2019-02-21 17:45:33,103 - log/train6.log - INFO - iteration:25 step:4300/10100, NER loss: 1.172263
2019-02-21 17:45:35,429 - log/train6.log - INFO - iteration:25 step:4400/10100, NER loss: 1.244161
2019-02-21 17:45:37,769 - log/train6.log - INFO - iteration:25 step:4500/10100, NER loss: 1.038572
2019-02-21 17:45:39,904 - log/train6.log - INFO - iteration:25 step:4600/10100, NER loss: 0.765671
2019-02-21 17:45:42,010 - log/train6.log - INFO - iteration:25 step:4700/10100, NER loss: 0.937575
2019-02-21 17:45:44,141 - log/train6.log - INFO - iteration:25 step:4800/10100, NER loss: 0.989789
2019-02-21 17:45:46,311 - log/train6.log - INFO - iteration:25 step:4900/10100, NER loss: 0.947217
2019-02-21 17:45:48,610 - log/train6.log - INFO - iteration:25 step:5000/10100, NER loss: 1.053410
2019-02-21 17:45:51,163 - log/train6.log - INFO - iteration:25 step:5100/10100, NER loss: 1.022815
2019-02-21 17:45:53,435 - log/train6.log - INFO - iteration:25 step:5200/10100, NER loss: 1.004971
2019-02-21 17:45:55,458 - log/train6.log - INFO - iteration:25 step:5300/10100, NER loss: 0.791766
2019-02-21 17:45:57,816 - log/train6.log - INFO - iteration:25 step:5400/10100, NER loss: 0.895410
2019-02-21 17:46:00,062 - log/train6.log - INFO - iteration:25 step:5500/10100, NER loss: 1.005436
2019-02-21 17:46:02,294 - log/train6.log - INFO - iteration:25 step:5600/10100, NER loss: 0.981485
2019-02-21 17:46:04,355 - log/train6.log - INFO - iteration:25 step:5700/10100, NER loss: 0.957649
2019-02-21 17:46:06,564 - log/train6.log - INFO - iteration:25 step:5800/10100, NER loss: 0.875904
2019-02-21 17:46:08,834 - log/train6.log - INFO - iteration:25 step:5900/10100, NER loss: 1.075791
2019-02-21 17:46:10,836 - log/train6.log - INFO - iteration:25 step:6000/10100, NER loss: 1.043737
2019-02-21 17:46:13,030 - log/train6.log - INFO - iteration:25 step:6100/10100, NER loss: 0.839883
2019-02-21 17:46:15,253 - log/train6.log - INFO - iteration:25 step:6200/10100, NER loss: 0.861647
2019-02-21 17:46:17,555 - log/train6.log - INFO - iteration:25 step:6300/10100, NER loss: 1.258052
2019-02-21 17:46:21,621 - log/train6.log - INFO - iteration:25 step:6400/10100, NER loss: 1.515809
2019-02-21 17:46:25,871 - log/train6.log - INFO - iteration:25 step:6500/10100, NER loss: 1.899979
2019-02-21 17:46:27,977 - log/train6.log - INFO - iteration:25 step:6600/10100, NER loss: 0.790034
2019-02-21 17:46:30,152 - log/train6.log - INFO - iteration:25 step:6700/10100, NER loss: 1.032342
2019-02-21 17:46:32,404 - log/train6.log - INFO - iteration:25 step:6800/10100, NER loss: 1.022495
2019-02-21 17:46:34,607 - log/train6.log - INFO - iteration:25 step:6900/10100, NER loss: 1.068517
2019-02-21 17:46:36,825 - log/train6.log - INFO - iteration:25 step:7000/10100, NER loss: 0.932395
2019-02-21 17:46:39,066 - log/train6.log - INFO - iteration:25 step:7100/10100, NER loss: 1.198003
2019-02-21 17:46:41,404 - log/train6.log - INFO - iteration:25 step:7200/10100, NER loss: 1.262381
2019-02-21 17:46:43,643 - log/train6.log - INFO - iteration:25 step:7300/10100, NER loss: 1.095623
2019-02-21 17:46:45,910 - log/train6.log - INFO - iteration:25 step:7400/10100, NER loss: 1.378485
2019-02-21 17:46:48,323 - log/train6.log - INFO - iteration:25 step:7500/10100, NER loss: 1.229601
2019-02-21 17:46:50,378 - log/train6.log - INFO - iteration:25 step:7600/10100, NER loss: 0.864608
2019-02-21 17:46:52,616 - log/train6.log - INFO - iteration:25 step:7700/10100, NER loss: 1.021827
2019-02-21 17:46:54,610 - log/train6.log - INFO - iteration:25 step:7800/10100, NER loss: 0.981148
2019-02-21 17:46:56,728 - log/train6.log - INFO - iteration:25 step:7900/10100, NER loss: 0.921729
2019-02-21 17:46:58,956 - log/train6.log - INFO - iteration:25 step:8000/10100, NER loss: 1.140404
2019-02-21 17:47:01,159 - log/train6.log - INFO - iteration:25 step:8100/10100, NER loss: 0.860144
2019-02-21 17:47:03,508 - log/train6.log - INFO - iteration:25 step:8200/10100, NER loss: 1.226272
2019-02-21 17:47:05,883 - log/train6.log - INFO - iteration:25 step:8300/10100, NER loss: 1.217782
2019-02-21 17:47:08,101 - log/train6.log - INFO - iteration:25 step:8400/10100, NER loss: 1.005582
2019-02-21 17:47:10,440 - log/train6.log - INFO - iteration:25 step:8500/10100, NER loss: 1.154167
2019-02-21 17:47:12,685 - log/train6.log - INFO - iteration:25 step:8600/10100, NER loss: 0.891629
2019-02-21 17:47:14,987 - log/train6.log - INFO - iteration:25 step:8700/10100, NER loss: 0.964971
2019-02-21 17:47:17,161 - log/train6.log - INFO - iteration:25 step:8800/10100, NER loss: 1.026392
2019-02-21 17:47:19,311 - log/train6.log - INFO - iteration:25 step:8900/10100, NER loss: 1.058740
2019-02-21 17:47:21,413 - log/train6.log - INFO - iteration:25 step:9000/10100, NER loss: 0.818654
2019-02-21 17:47:23,763 - log/train6.log - INFO - iteration:25 step:9100/10100, NER loss: 1.095163
2019-02-21 17:47:25,817 - log/train6.log - INFO - iteration:25 step:9200/10100, NER loss: 1.066661
2019-02-21 17:47:28,161 - log/train6.log - INFO - iteration:25 step:9300/10100, NER loss: 1.006349
2019-02-21 17:47:30,464 - log/train6.log - INFO - iteration:25 step:9400/10100, NER loss: 0.854794
2019-02-21 17:47:32,683 - log/train6.log - INFO - iteration:25 step:9500/10100, NER loss: 1.288980
2019-02-21 17:47:34,651 - log/train6.log - INFO - iteration:25 step:9600/10100, NER loss: 0.895428
2019-02-21 17:47:36,791 - log/train6.log - INFO - iteration:25 step:9700/10100, NER loss: 0.824363
2019-02-21 17:47:39,025 - log/train6.log - INFO - iteration:25 step:9800/10100, NER loss: 1.286271
2019-02-21 17:47:41,247 - log/train6.log - INFO - iteration:25 step:9900/10100, NER loss: 1.062025
2019-02-21 17:47:43,349 - log/train6.log - INFO - iteration:25 step:10000/10100, NER loss: 0.940798
2019-02-21 17:47:45,306 - log/train6.log - INFO - iteration:26 step:0/10100, NER loss: 0.970704
2019-02-21 17:47:45,306 - log/train6.log - INFO - evaluate:dev
2019-02-21 17:47:51,870 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5450 phrases; correct: 4324.

2019-02-21 17:47:51,870 - log/train6.log - INFO - accuracy:  95.60%; precision:  79.34%; recall:  73.95%; FB1:  76.55

2019-02-21 17:47:51,871 - log/train6.log - INFO -                 C: precision:  88.24%; recall:  87.19%; FB1:  87.71  3349

2019-02-21 17:47:51,871 - log/train6.log - INFO -               IND: precision:  48.29%; recall:  24.26%; FB1:  32.30  205

2019-02-21 17:47:51,871 - log/train6.log - INFO -               INS: precision:  68.03%; recall:  70.18%; FB1:  69.09  391

2019-02-21 17:47:51,871 - log/train6.log - INFO -                 L: precision:  62.67%; recall:  61.22%; FB1:  61.94  592

2019-02-21 17:47:51,871 - log/train6.log - INFO -                 P: precision:  89.07%; recall:  91.53%; FB1:  90.28  558

2019-02-21 17:47:51,871 - log/train6.log - INFO -               PRO: precision:  38.31%; recall:  26.05%; FB1:  31.01  355

2019-02-21 17:47:51,951 - log/train6.log - INFO - new best dev f1 score:76.550
2019-02-21 17:47:52,223 - log/train6.log - INFO - model saved
2019-02-21 17:47:52,223 - log/train6.log - INFO - evaluate:test
2019-02-21 17:47:53,675 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1635 phrases; correct: 1399.

2019-02-21 17:47:53,675 - log/train6.log - INFO - accuracy:  97.07%; precision:  85.57%; recall:  84.94%; FB1:  85.25

2019-02-21 17:47:53,675 - log/train6.log - INFO -                 C: precision:  89.74%; recall:  92.61%; FB1:  91.15  1062

2019-02-21 17:47:53,675 - log/train6.log - INFO -               IND: precision:  70.00%; recall:  59.57%; FB1:  64.37  40

2019-02-21 17:47:53,675 - log/train6.log - INFO -               INS: precision:  70.79%; recall:  66.32%; FB1:  68.48  89

2019-02-21 17:47:53,675 - log/train6.log - INFO -                 L: precision:  66.32%; recall:  61.17%; FB1:  63.64  95

2019-02-21 17:47:53,676 - log/train6.log - INFO -                 P: precision:  91.12%; recall:  95.59%; FB1:  93.30  214

2019-02-21 17:47:53,676 - log/train6.log - INFO -               PRO: precision:  71.85%; recall:  57.40%; FB1:  63.82  135

2019-02-21 17:47:53,747 - log/train6.log - INFO - new best test f1 score:85.250
2019-02-21 17:47:55,619 - log/train6.log - INFO - iteration:26 step:100/10100, NER loss: 0.828937
2019-02-21 17:47:57,762 - log/train6.log - INFO - iteration:26 step:200/10100, NER loss: 0.962021
2019-02-21 17:48:00,001 - log/train6.log - INFO - iteration:26 step:300/10100, NER loss: 0.905387
2019-02-21 17:48:02,654 - log/train6.log - INFO - iteration:26 step:400/10100, NER loss: 1.189880
2019-02-21 17:48:05,028 - log/train6.log - INFO - iteration:26 step:500/10100, NER loss: 1.063768
2019-02-21 17:48:07,129 - log/train6.log - INFO - iteration:26 step:600/10100, NER loss: 1.117249
2019-02-21 17:48:09,347 - log/train6.log - INFO - iteration:26 step:700/10100, NER loss: 0.872004
2019-02-21 17:48:11,584 - log/train6.log - INFO - iteration:26 step:800/10100, NER loss: 0.867514
2019-02-21 17:48:14,278 - log/train6.log - INFO - iteration:26 step:900/10100, NER loss: 1.484058
2019-02-21 17:48:16,961 - log/train6.log - INFO - iteration:26 step:1000/10100, NER loss: 1.315505
2019-02-21 17:48:19,284 - log/train6.log - INFO - iteration:26 step:1100/10100, NER loss: 0.833279
2019-02-21 17:48:21,779 - log/train6.log - INFO - iteration:26 step:1200/10100, NER loss: 0.799242
2019-02-21 17:48:24,509 - log/train6.log - INFO - iteration:26 step:1300/10100, NER loss: 1.235945
2019-02-21 17:48:26,995 - log/train6.log - INFO - iteration:26 step:1400/10100, NER loss: 0.871980
2019-02-21 17:48:29,540 - log/train6.log - INFO - iteration:26 step:1500/10100, NER loss: 1.069862
2019-02-21 17:48:32,083 - log/train6.log - INFO - iteration:26 step:1600/10100, NER loss: 1.147828
2019-02-21 17:48:34,602 - log/train6.log - INFO - iteration:26 step:1700/10100, NER loss: 1.208681
2019-02-21 17:48:36,714 - log/train6.log - INFO - iteration:26 step:1800/10100, NER loss: 0.892689
2019-02-21 17:48:38,811 - log/train6.log - INFO - iteration:26 step:1900/10100, NER loss: 0.948108
2019-02-21 17:48:41,117 - log/train6.log - INFO - iteration:26 step:2000/10100, NER loss: 1.059126
2019-02-21 17:48:43,322 - log/train6.log - INFO - iteration:26 step:2100/10100, NER loss: 0.986129
2019-02-21 17:48:45,762 - log/train6.log - INFO - iteration:26 step:2200/10100, NER loss: 1.073806
2019-02-21 17:48:48,010 - log/train6.log - INFO - iteration:26 step:2300/10100, NER loss: 0.918450
2019-02-21 17:48:50,519 - log/train6.log - INFO - iteration:26 step:2400/10100, NER loss: 1.198624
2019-02-21 17:48:52,849 - log/train6.log - INFO - iteration:26 step:2500/10100, NER loss: 1.007091
2019-02-21 17:48:55,097 - log/train6.log - INFO - iteration:26 step:2600/10100, NER loss: 1.172978
2019-02-21 17:48:57,396 - log/train6.log - INFO - iteration:26 step:2700/10100, NER loss: 1.037202
2019-02-21 17:48:59,622 - log/train6.log - INFO - iteration:26 step:2800/10100, NER loss: 1.105340
2019-02-21 17:49:01,999 - log/train6.log - INFO - iteration:26 step:2900/10100, NER loss: 0.993984
2019-02-21 17:49:04,271 - log/train6.log - INFO - iteration:26 step:3000/10100, NER loss: 0.927939
2019-02-21 17:49:06,555 - log/train6.log - INFO - iteration:26 step:3100/10100, NER loss: 0.963542
2019-02-21 17:49:08,818 - log/train6.log - INFO - iteration:26 step:3200/10100, NER loss: 1.163472
2019-02-21 17:49:10,939 - log/train6.log - INFO - iteration:26 step:3300/10100, NER loss: 1.002921
2019-02-21 17:49:13,165 - log/train6.log - INFO - iteration:26 step:3400/10100, NER loss: 1.147912
2019-02-21 17:49:15,222 - log/train6.log - INFO - iteration:26 step:3500/10100, NER loss: 0.827892
2019-02-21 17:49:17,339 - log/train6.log - INFO - iteration:26 step:3600/10100, NER loss: 0.907871
2019-02-21 17:49:19,422 - log/train6.log - INFO - iteration:26 step:3700/10100, NER loss: 0.667098
2019-02-21 17:49:21,553 - log/train6.log - INFO - iteration:26 step:3800/10100, NER loss: 0.787320
2019-02-21 17:49:23,774 - log/train6.log - INFO - iteration:26 step:3900/10100, NER loss: 1.226537
2019-02-21 17:49:26,559 - log/train6.log - INFO - iteration:26 step:4000/10100, NER loss: 1.270039
2019-02-21 17:49:29,093 - log/train6.log - INFO - iteration:26 step:4100/10100, NER loss: 0.955290
2019-02-21 17:49:33,642 - log/train6.log - INFO - iteration:26 step:4200/10100, NER loss: 2.315668
2019-02-21 17:49:35,671 - log/train6.log - INFO - iteration:26 step:4300/10100, NER loss: 0.736183
2019-02-21 17:49:37,882 - log/train6.log - INFO - iteration:26 step:4400/10100, NER loss: 1.078250
2019-02-21 17:49:40,343 - log/train6.log - INFO - iteration:26 step:4500/10100, NER loss: 1.019626
2019-02-21 17:49:42,579 - log/train6.log - INFO - iteration:26 step:4600/10100, NER loss: 0.892869
2019-02-21 17:49:44,695 - log/train6.log - INFO - iteration:26 step:4700/10100, NER loss: 0.854204
2019-02-21 17:49:47,019 - log/train6.log - INFO - iteration:26 step:4800/10100, NER loss: 1.005056
2019-02-21 17:49:49,521 - log/train6.log - INFO - iteration:26 step:4900/10100, NER loss: 1.088533
2019-02-21 17:49:51,833 - log/train6.log - INFO - iteration:26 step:5000/10100, NER loss: 1.285746
2019-02-21 17:49:54,191 - log/train6.log - INFO - iteration:26 step:5100/10100, NER loss: 1.184653
2019-02-21 17:49:56,285 - log/train6.log - INFO - iteration:26 step:5200/10100, NER loss: 0.846336
2019-02-21 17:49:58,503 - log/train6.log - INFO - iteration:26 step:5300/10100, NER loss: 1.030054
2019-02-21 17:50:00,634 - log/train6.log - INFO - iteration:26 step:5400/10100, NER loss: 0.919876
2019-02-21 17:50:02,899 - log/train6.log - INFO - iteration:26 step:5500/10100, NER loss: 0.924984
2019-02-21 17:50:05,081 - log/train6.log - INFO - iteration:26 step:5600/10100, NER loss: 0.929552
2019-02-21 17:50:07,242 - log/train6.log - INFO - iteration:26 step:5700/10100, NER loss: 1.605739
2019-02-21 17:50:09,406 - log/train6.log - INFO - iteration:26 step:5800/10100, NER loss: 0.738776
2019-02-21 17:50:11,762 - log/train6.log - INFO - iteration:26 step:5900/10100, NER loss: 1.823838
2019-02-21 17:50:14,058 - log/train6.log - INFO - iteration:26 step:6000/10100, NER loss: 1.392193
2019-02-21 17:50:16,167 - log/train6.log - INFO - iteration:26 step:6100/10100, NER loss: 0.900818
2019-02-21 17:50:18,455 - log/train6.log - INFO - iteration:26 step:6200/10100, NER loss: 1.066497
2019-02-21 17:50:20,651 - log/train6.log - INFO - iteration:26 step:6300/10100, NER loss: 0.948432
2019-02-21 17:50:22,704 - log/train6.log - INFO - iteration:26 step:6400/10100, NER loss: 1.143532
2019-02-21 17:50:24,908 - log/train6.log - INFO - iteration:26 step:6500/10100, NER loss: 0.829923
2019-02-21 17:50:27,407 - log/train6.log - INFO - iteration:26 step:6600/10100, NER loss: 0.997401
2019-02-21 17:50:29,518 - log/train6.log - INFO - iteration:26 step:6700/10100, NER loss: 0.885230
2019-02-21 17:50:31,724 - log/train6.log - INFO - iteration:26 step:6800/10100, NER loss: 1.022040
2019-02-21 17:50:34,134 - log/train6.log - INFO - iteration:26 step:6900/10100, NER loss: 0.905859
2019-02-21 17:50:36,663 - log/train6.log - INFO - iteration:26 step:7000/10100, NER loss: 1.064236
2019-02-21 17:50:38,923 - log/train6.log - INFO - iteration:26 step:7100/10100, NER loss: 1.003758
2019-02-21 17:50:41,193 - log/train6.log - INFO - iteration:26 step:7200/10100, NER loss: 0.955505
2019-02-21 17:50:43,280 - log/train6.log - INFO - iteration:26 step:7300/10100, NER loss: 1.122573
2019-02-21 17:50:45,592 - log/train6.log - INFO - iteration:26 step:7400/10100, NER loss: 1.296988
2019-02-21 17:50:47,891 - log/train6.log - INFO - iteration:26 step:7500/10100, NER loss: 1.078513
2019-02-21 17:50:50,006 - log/train6.log - INFO - iteration:26 step:7600/10100, NER loss: 1.051950
2019-02-21 17:50:53,918 - log/train6.log - INFO - iteration:26 step:7700/10100, NER loss: 2.188581
2019-02-21 17:50:55,944 - log/train6.log - INFO - iteration:26 step:7800/10100, NER loss: 0.915575
2019-02-21 17:50:58,304 - log/train6.log - INFO - iteration:26 step:7900/10100, NER loss: 1.297332
2019-02-21 17:51:00,382 - log/train6.log - INFO - iteration:26 step:8000/10100, NER loss: 1.025587
2019-02-21 17:51:02,648 - log/train6.log - INFO - iteration:26 step:8100/10100, NER loss: 1.143470
2019-02-21 17:51:04,769 - log/train6.log - INFO - iteration:26 step:8200/10100, NER loss: 0.851028
2019-02-21 17:51:07,142 - log/train6.log - INFO - iteration:26 step:8300/10100, NER loss: 1.256374
2019-02-21 17:51:09,568 - log/train6.log - INFO - iteration:26 step:8400/10100, NER loss: 1.082625
2019-02-21 17:51:11,767 - log/train6.log - INFO - iteration:26 step:8500/10100, NER loss: 1.092085
2019-02-21 17:51:13,985 - log/train6.log - INFO - iteration:26 step:8600/10100, NER loss: 1.318864
2019-02-21 17:51:18,199 - log/train6.log - INFO - iteration:26 step:8700/10100, NER loss: 1.321280
2019-02-21 17:51:20,355 - log/train6.log - INFO - iteration:26 step:8800/10100, NER loss: 1.013961
2019-02-21 17:51:22,413 - log/train6.log - INFO - iteration:26 step:8900/10100, NER loss: 0.874030
2019-02-21 17:51:24,614 - log/train6.log - INFO - iteration:26 step:9000/10100, NER loss: 0.912039
2019-02-21 17:51:26,847 - log/train6.log - INFO - iteration:26 step:9100/10100, NER loss: 1.182467
2019-02-21 17:51:29,200 - log/train6.log - INFO - iteration:26 step:9200/10100, NER loss: 0.947661
2019-02-21 17:51:31,454 - log/train6.log - INFO - iteration:26 step:9300/10100, NER loss: 1.071877
2019-02-21 17:51:33,562 - log/train6.log - INFO - iteration:26 step:9400/10100, NER loss: 0.768996
2019-02-21 17:51:35,681 - log/train6.log - INFO - iteration:26 step:9500/10100, NER loss: 0.845936
2019-02-21 17:51:37,886 - log/train6.log - INFO - iteration:26 step:9600/10100, NER loss: 0.765516
2019-02-21 17:51:40,150 - log/train6.log - INFO - iteration:26 step:9700/10100, NER loss: 0.954075
2019-02-21 17:51:42,442 - log/train6.log - INFO - iteration:26 step:9800/10100, NER loss: 1.250616
2019-02-21 17:51:44,660 - log/train6.log - INFO - iteration:26 step:9900/10100, NER loss: 0.902616
2019-02-21 17:51:46,918 - log/train6.log - INFO - iteration:26 step:10000/10100, NER loss: 1.225403
2019-02-21 17:51:49,280 - log/train6.log - INFO - iteration:27 step:0/10100, NER loss: 1.117361
2019-02-21 17:51:49,280 - log/train6.log - INFO - evaluate:dev
2019-02-21 17:51:55,776 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5435 phrases; correct: 4277.

2019-02-21 17:51:55,776 - log/train6.log - INFO - accuracy:  95.58%; precision:  78.69%; recall:  73.15%; FB1:  75.82

2019-02-21 17:51:55,776 - log/train6.log - INFO -                 C: precision:  88.85%; recall:  86.28%; FB1:  87.54  3291

2019-02-21 17:51:55,776 - log/train6.log - INFO -               IND: precision:  43.40%; recall:  28.19%; FB1:  34.18  265

2019-02-21 17:51:55,776 - log/train6.log - INFO -               INS: precision:  70.40%; recall:  69.66%; FB1:  70.03  375

2019-02-21 17:51:55,776 - log/train6.log - INFO -                 L: precision:  56.67%; recall:  61.72%; FB1:  59.08  660

2019-02-21 17:51:55,776 - log/train6.log - INFO -                 P: precision:  88.08%; recall:  91.16%; FB1:  89.59  562

2019-02-21 17:51:55,776 - log/train6.log - INFO -               PRO: precision:  37.23%; recall:  20.11%; FB1:  26.12  282

2019-02-21 17:51:55,779 - log/train6.log - INFO - evaluate:test
2019-02-21 17:51:57,243 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1606 phrases; correct: 1385.

2019-02-21 17:51:57,243 - log/train6.log - INFO - accuracy:  97.31%; precision:  86.24%; recall:  84.09%; FB1:  85.15

2019-02-21 17:51:57,243 - log/train6.log - INFO -                 C: precision:  90.95%; recall:  90.86%; FB1:  90.91  1028

2019-02-21 17:51:57,243 - log/train6.log - INFO -               IND: precision:  65.31%; recall:  68.09%; FB1:  66.67  49

2019-02-21 17:51:57,243 - log/train6.log - INFO -               INS: precision:  75.90%; recall:  66.32%; FB1:  70.79  83

2019-02-21 17:51:57,243 - log/train6.log - INFO -                 L: precision:  60.36%; recall:  65.05%; FB1:  62.62  111

2019-02-21 17:51:57,243 - log/train6.log - INFO -                 P: precision:  91.55%; recall:  95.59%; FB1:  93.53  213

2019-02-21 17:51:57,243 - log/train6.log - INFO -               PRO: precision:  76.23%; recall:  55.03%; FB1:  63.92  122

2019-02-21 17:51:59,207 - log/train6.log - INFO - iteration:27 step:100/10100, NER loss: 1.119708
2019-02-21 17:52:01,227 - log/train6.log - INFO - iteration:27 step:200/10100, NER loss: 0.927422
2019-02-21 17:52:03,191 - log/train6.log - INFO - iteration:27 step:300/10100, NER loss: 0.994014
2019-02-21 17:52:05,356 - log/train6.log - INFO - iteration:27 step:400/10100, NER loss: 0.781753
2019-02-21 17:52:07,532 - log/train6.log - INFO - iteration:27 step:500/10100, NER loss: 0.902946
2019-02-21 17:52:09,793 - log/train6.log - INFO - iteration:27 step:600/10100, NER loss: 0.918146
2019-02-21 17:52:11,947 - log/train6.log - INFO - iteration:27 step:700/10100, NER loss: 0.929913
2019-02-21 17:52:14,129 - log/train6.log - INFO - iteration:27 step:800/10100, NER loss: 0.867081
2019-02-21 17:52:16,277 - log/train6.log - INFO - iteration:27 step:900/10100, NER loss: 0.909578
2019-02-21 17:52:18,685 - log/train6.log - INFO - iteration:27 step:1000/10100, NER loss: 1.102862
2019-02-21 17:52:20,931 - log/train6.log - INFO - iteration:27 step:1100/10100, NER loss: 1.102058
2019-02-21 17:52:22,993 - log/train6.log - INFO - iteration:27 step:1200/10100, NER loss: 0.913915
2019-02-21 17:52:25,081 - log/train6.log - INFO - iteration:27 step:1300/10100, NER loss: 0.832604
2019-02-21 17:52:27,463 - log/train6.log - INFO - iteration:27 step:1400/10100, NER loss: 1.000083
2019-02-21 17:52:29,701 - log/train6.log - INFO - iteration:27 step:1500/10100, NER loss: 0.919122
2019-02-21 17:52:31,809 - log/train6.log - INFO - iteration:27 step:1600/10100, NER loss: 0.967828
2019-02-21 17:52:33,880 - log/train6.log - INFO - iteration:27 step:1700/10100, NER loss: 0.938479
2019-02-21 17:52:36,094 - log/train6.log - INFO - iteration:27 step:1800/10100, NER loss: 1.012719
2019-02-21 17:52:38,387 - log/train6.log - INFO - iteration:27 step:1900/10100, NER loss: 1.039770
2019-02-21 17:52:40,743 - log/train6.log - INFO - iteration:27 step:2000/10100, NER loss: 1.228326
2019-02-21 17:52:42,829 - log/train6.log - INFO - iteration:27 step:2100/10100, NER loss: 0.723486
2019-02-21 17:52:45,156 - log/train6.log - INFO - iteration:27 step:2200/10100, NER loss: 1.064982
2019-02-21 17:52:47,426 - log/train6.log - INFO - iteration:27 step:2300/10100, NER loss: 0.881041
2019-02-21 17:52:49,575 - log/train6.log - INFO - iteration:27 step:2400/10100, NER loss: 1.158381
2019-02-21 17:52:52,484 - log/train6.log - INFO - iteration:27 step:2500/10100, NER loss: 1.385615
2019-02-21 17:52:54,874 - log/train6.log - INFO - iteration:27 step:2600/10100, NER loss: 1.012673
2019-02-21 17:52:57,114 - log/train6.log - INFO - iteration:27 step:2700/10100, NER loss: 0.960987
2019-02-21 17:52:59,551 - log/train6.log - INFO - iteration:27 step:2800/10100, NER loss: 1.072604
2019-02-21 17:53:01,607 - log/train6.log - INFO - iteration:27 step:2900/10100, NER loss: 0.918927
2019-02-21 17:53:03,763 - log/train6.log - INFO - iteration:27 step:3000/10100, NER loss: 0.971153
2019-02-21 17:53:05,994 - log/train6.log - INFO - iteration:27 step:3100/10100, NER loss: 1.094340
2019-02-21 17:53:08,204 - log/train6.log - INFO - iteration:27 step:3200/10100, NER loss: 0.798815
2019-02-21 17:53:10,539 - log/train6.log - INFO - iteration:27 step:3300/10100, NER loss: 0.862527
2019-02-21 17:53:12,853 - log/train6.log - INFO - iteration:27 step:3400/10100, NER loss: 1.092268
2019-02-21 17:53:15,235 - log/train6.log - INFO - iteration:27 step:3500/10100, NER loss: 1.250183
2019-02-21 17:53:17,588 - log/train6.log - INFO - iteration:27 step:3600/10100, NER loss: 0.909182
2019-02-21 17:53:19,841 - log/train6.log - INFO - iteration:27 step:3700/10100, NER loss: 0.886084
2019-02-21 17:53:23,808 - log/train6.log - INFO - iteration:27 step:3800/10100, NER loss: 1.488604
2019-02-21 17:53:25,996 - log/train6.log - INFO - iteration:27 step:3900/10100, NER loss: 1.045852
2019-02-21 17:53:28,225 - log/train6.log - INFO - iteration:27 step:4000/10100, NER loss: 1.193621
2019-02-21 17:53:30,575 - log/train6.log - INFO - iteration:27 step:4100/10100, NER loss: 1.089683
2019-02-21 17:53:32,635 - log/train6.log - INFO - iteration:27 step:4200/10100, NER loss: 1.157433
2019-02-21 17:53:36,684 - log/train6.log - INFO - iteration:27 step:4300/10100, NER loss: 1.269997
2019-02-21 17:53:38,937 - log/train6.log - INFO - iteration:27 step:4400/10100, NER loss: 1.089916
2019-02-21 17:53:41,304 - log/train6.log - INFO - iteration:27 step:4500/10100, NER loss: 1.230637
2019-02-21 17:53:43,598 - log/train6.log - INFO - iteration:27 step:4600/10100, NER loss: 0.963275
2019-02-21 17:53:45,698 - log/train6.log - INFO - iteration:27 step:4700/10100, NER loss: 1.157397
2019-02-21 17:53:48,163 - log/train6.log - INFO - iteration:27 step:4800/10100, NER loss: 1.095179
2019-02-21 17:53:50,517 - log/train6.log - INFO - iteration:27 step:4900/10100, NER loss: 1.157655
2019-02-21 17:53:52,869 - log/train6.log - INFO - iteration:27 step:5000/10100, NER loss: 0.985948
2019-02-21 17:53:55,036 - log/train6.log - INFO - iteration:27 step:5100/10100, NER loss: 0.924660
2019-02-21 17:53:57,043 - log/train6.log - INFO - iteration:27 step:5200/10100, NER loss: 0.717782
2019-02-21 17:53:59,451 - log/train6.log - INFO - iteration:27 step:5300/10100, NER loss: 1.275266
2019-02-21 17:54:01,680 - log/train6.log - INFO - iteration:27 step:5400/10100, NER loss: 1.108411
2019-02-21 17:54:03,670 - log/train6.log - INFO - iteration:27 step:5500/10100, NER loss: 0.929357
2019-02-21 17:54:05,668 - log/train6.log - INFO - iteration:27 step:5600/10100, NER loss: 0.883787
2019-02-21 17:54:07,847 - log/train6.log - INFO - iteration:27 step:5700/10100, NER loss: 1.049678
2019-02-21 17:54:09,958 - log/train6.log - INFO - iteration:27 step:5800/10100, NER loss: 0.774026
2019-02-21 17:54:12,172 - log/train6.log - INFO - iteration:27 step:5900/10100, NER loss: 0.819325
2019-02-21 17:54:14,321 - log/train6.log - INFO - iteration:27 step:6000/10100, NER loss: 1.068853
2019-02-21 17:54:16,594 - log/train6.log - INFO - iteration:27 step:6100/10100, NER loss: 0.913462
2019-02-21 17:54:18,639 - log/train6.log - INFO - iteration:27 step:6200/10100, NER loss: 1.162326
2019-02-21 17:54:20,806 - log/train6.log - INFO - iteration:27 step:6300/10100, NER loss: 1.054800
2019-02-21 17:54:22,958 - log/train6.log - INFO - iteration:27 step:6400/10100, NER loss: 0.701427
2019-02-21 17:54:27,424 - log/train6.log - INFO - iteration:27 step:6500/10100, NER loss: 1.764513
2019-02-21 17:54:29,508 - log/train6.log - INFO - iteration:27 step:6600/10100, NER loss: 1.144491
2019-02-21 17:54:31,580 - log/train6.log - INFO - iteration:27 step:6700/10100, NER loss: 0.809972
2019-02-21 17:54:34,022 - log/train6.log - INFO - iteration:27 step:6800/10100, NER loss: 1.288286
2019-02-21 17:54:36,239 - log/train6.log - INFO - iteration:27 step:6900/10100, NER loss: 0.990428
2019-02-21 17:54:38,795 - log/train6.log - INFO - iteration:27 step:7000/10100, NER loss: 1.259801
2019-02-21 17:54:41,048 - log/train6.log - INFO - iteration:27 step:7100/10100, NER loss: 1.006226
2019-02-21 17:54:43,302 - log/train6.log - INFO - iteration:27 step:7200/10100, NER loss: 0.777982
2019-02-21 17:54:45,410 - log/train6.log - INFO - iteration:27 step:7300/10100, NER loss: 0.778190
2019-02-21 17:54:47,501 - log/train6.log - INFO - iteration:27 step:7400/10100, NER loss: 1.009477
2019-02-21 17:54:49,785 - log/train6.log - INFO - iteration:27 step:7500/10100, NER loss: 1.171554
2019-02-21 17:54:52,053 - log/train6.log - INFO - iteration:27 step:7600/10100, NER loss: 1.316929
2019-02-21 17:54:54,388 - log/train6.log - INFO - iteration:27 step:7700/10100, NER loss: 1.044245
2019-02-21 17:54:56,832 - log/train6.log - INFO - iteration:27 step:7800/10100, NER loss: 1.189649
2019-02-21 17:54:59,218 - log/train6.log - INFO - iteration:27 step:7900/10100, NER loss: 1.238689
2019-02-21 17:55:01,405 - log/train6.log - INFO - iteration:27 step:8000/10100, NER loss: 1.032045
2019-02-21 17:55:03,761 - log/train6.log - INFO - iteration:27 step:8100/10100, NER loss: 0.996167
2019-02-21 17:55:05,867 - log/train6.log - INFO - iteration:27 step:8200/10100, NER loss: 0.873243
2019-02-21 17:55:07,976 - log/train6.log - INFO - iteration:27 step:8300/10100, NER loss: 0.912793
2019-02-21 17:55:10,141 - log/train6.log - INFO - iteration:27 step:8400/10100, NER loss: 1.089536
2019-02-21 17:55:12,585 - log/train6.log - INFO - iteration:27 step:8500/10100, NER loss: 0.967455
2019-02-21 17:55:14,800 - log/train6.log - INFO - iteration:27 step:8600/10100, NER loss: 1.574735
2019-02-21 17:55:17,111 - log/train6.log - INFO - iteration:27 step:8700/10100, NER loss: 1.019817
2019-02-21 17:55:19,344 - log/train6.log - INFO - iteration:27 step:8800/10100, NER loss: 1.273351
2019-02-21 17:55:21,830 - log/train6.log - INFO - iteration:27 step:8900/10100, NER loss: 1.127749
2019-02-21 17:55:23,856 - log/train6.log - INFO - iteration:27 step:9000/10100, NER loss: 0.820068
2019-02-21 17:55:26,372 - log/train6.log - INFO - iteration:27 step:9100/10100, NER loss: 1.064989
2019-02-21 17:55:28,720 - log/train6.log - INFO - iteration:27 step:9200/10100, NER loss: 1.056675
2019-02-21 17:55:30,855 - log/train6.log - INFO - iteration:27 step:9300/10100, NER loss: 1.002573
2019-02-21 17:55:33,095 - log/train6.log - INFO - iteration:27 step:9400/10100, NER loss: 0.868950
2019-02-21 17:55:35,321 - log/train6.log - INFO - iteration:27 step:9500/10100, NER loss: 0.961135
2019-02-21 17:55:37,527 - log/train6.log - INFO - iteration:27 step:9600/10100, NER loss: 1.103865
2019-02-21 17:55:39,651 - log/train6.log - INFO - iteration:27 step:9700/10100, NER loss: 0.980019
2019-02-21 17:55:41,879 - log/train6.log - INFO - iteration:27 step:9800/10100, NER loss: 0.967214
2019-02-21 17:55:44,410 - log/train6.log - INFO - iteration:27 step:9900/10100, NER loss: 1.181440
2019-02-21 17:55:46,826 - log/train6.log - INFO - iteration:27 step:10000/10100, NER loss: 0.891356
2019-02-21 17:55:49,012 - log/train6.log - INFO - iteration:28 step:0/10100, NER loss: 1.006943
2019-02-21 17:55:49,012 - log/train6.log - INFO - evaluate:dev
2019-02-21 17:55:55,491 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5536 phrases; correct: 4320.

2019-02-21 17:55:55,492 - log/train6.log - INFO - accuracy:  95.46%; precision:  78.03%; recall:  73.88%; FB1:  75.90

2019-02-21 17:55:55,492 - log/train6.log - INFO -                 C: precision:  85.38%; recall:  88.73%; FB1:  87.02  3522

2019-02-21 17:55:55,492 - log/train6.log - INFO -               IND: precision:  44.19%; recall:  28.92%; FB1:  34.96  267

2019-02-21 17:55:55,492 - log/train6.log - INFO -               INS: precision:  76.02%; recall:  68.60%; FB1:  72.12  342

2019-02-21 17:55:55,493 - log/train6.log - INFO -                 L: precision:  57.19%; recall:  56.44%; FB1:  56.81  598

2019-02-21 17:55:55,493 - log/train6.log - INFO -                 P: precision:  89.86%; recall:  91.34%; FB1:  90.59  552

2019-02-21 17:55:55,493 - log/train6.log - INFO -               PRO: precision:  38.04%; recall:  18.58%; FB1:  24.97  255

2019-02-21 17:55:55,498 - log/train6.log - INFO - evaluate:test
2019-02-21 17:55:56,981 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1605 phrases; correct: 1378.

2019-02-21 17:55:56,981 - log/train6.log - INFO - accuracy:  97.05%; precision:  85.86%; recall:  83.67%; FB1:  84.75

2019-02-21 17:55:56,981 - log/train6.log - INFO -                 C: precision:  89.42%; recall:  92.81%; FB1:  91.08  1068

2019-02-21 17:55:56,981 - log/train6.log - INFO -               IND: precision:  66.67%; recall:  68.09%; FB1:  67.37  48

2019-02-21 17:55:56,981 - log/train6.log - INFO -               INS: precision:  74.03%; recall:  60.00%; FB1:  66.28  77

2019-02-21 17:55:56,982 - log/train6.log - INFO -                 L: precision:  60.40%; recall:  59.22%; FB1:  59.80  101

2019-02-21 17:55:56,982 - log/train6.log - INFO -                 P: precision:  91.87%; recall:  94.12%; FB1:  92.98  209

2019-02-21 17:55:56,982 - log/train6.log - INFO -               PRO: precision:  79.41%; recall:  47.93%; FB1:  59.78  102

2019-02-21 17:55:58,971 - log/train6.log - INFO - iteration:28 step:100/10100, NER loss: 0.833431
2019-02-21 17:56:00,772 - log/train6.log - INFO - iteration:28 step:200/10100, NER loss: 0.841777
2019-02-21 17:56:02,710 - log/train6.log - INFO - iteration:28 step:300/10100, NER loss: 0.878574
2019-02-21 17:56:05,098 - log/train6.log - INFO - iteration:28 step:400/10100, NER loss: 1.137524
2019-02-21 17:56:07,466 - log/train6.log - INFO - iteration:28 step:500/10100, NER loss: 1.158584
2019-02-21 17:56:09,988 - log/train6.log - INFO - iteration:28 step:600/10100, NER loss: 1.031761
2019-02-21 17:56:12,418 - log/train6.log - INFO - iteration:28 step:700/10100, NER loss: 1.091913
2019-02-21 17:56:14,542 - log/train6.log - INFO - iteration:28 step:800/10100, NER loss: 0.768860
2019-02-21 17:56:16,724 - log/train6.log - INFO - iteration:28 step:900/10100, NER loss: 0.998078
2019-02-21 17:56:19,037 - log/train6.log - INFO - iteration:28 step:1000/10100, NER loss: 0.873050
2019-02-21 17:56:21,272 - log/train6.log - INFO - iteration:28 step:1100/10100, NER loss: 1.105028
2019-02-21 17:56:23,589 - log/train6.log - INFO - iteration:28 step:1200/10100, NER loss: 0.968891
2019-02-21 17:56:25,938 - log/train6.log - INFO - iteration:28 step:1300/10100, NER loss: 1.292635
2019-02-21 17:56:28,108 - log/train6.log - INFO - iteration:28 step:1400/10100, NER loss: 1.002158
2019-02-21 17:56:32,713 - log/train6.log - INFO - iteration:28 step:1500/10100, NER loss: 1.691699
2019-02-21 17:56:34,995 - log/train6.log - INFO - iteration:28 step:1600/10100, NER loss: 0.967872
2019-02-21 17:56:37,233 - log/train6.log - INFO - iteration:28 step:1700/10100, NER loss: 0.924679
2019-02-21 17:56:39,605 - log/train6.log - INFO - iteration:28 step:1800/10100, NER loss: 1.007725
2019-02-21 17:56:41,711 - log/train6.log - INFO - iteration:28 step:1900/10100, NER loss: 0.975942
2019-02-21 17:56:43,650 - log/train6.log - INFO - iteration:28 step:2000/10100, NER loss: 0.686369
2019-02-21 17:56:45,963 - log/train6.log - INFO - iteration:28 step:2100/10100, NER loss: 1.025595
2019-02-21 17:56:47,880 - log/train6.log - INFO - iteration:28 step:2200/10100, NER loss: 0.613121
2019-02-21 17:56:50,003 - log/train6.log - INFO - iteration:28 step:2300/10100, NER loss: 0.891089
2019-02-21 17:56:52,160 - log/train6.log - INFO - iteration:28 step:2400/10100, NER loss: 0.792101
2019-02-21 17:56:54,245 - log/train6.log - INFO - iteration:28 step:2500/10100, NER loss: 0.823971
2019-02-21 17:56:56,535 - log/train6.log - INFO - iteration:28 step:2600/10100, NER loss: 0.917989
2019-02-21 17:56:58,788 - log/train6.log - INFO - iteration:28 step:2700/10100, NER loss: 0.858870
2019-02-21 17:57:01,022 - log/train6.log - INFO - iteration:28 step:2800/10100, NER loss: 0.953918
2019-02-21 17:57:03,127 - log/train6.log - INFO - iteration:28 step:2900/10100, NER loss: 0.976613
2019-02-21 17:57:05,023 - log/train6.log - INFO - iteration:28 step:3000/10100, NER loss: 0.670496
2019-02-21 17:57:07,137 - log/train6.log - INFO - iteration:28 step:3100/10100, NER loss: 0.878471
2019-02-21 17:57:09,524 - log/train6.log - INFO - iteration:28 step:3200/10100, NER loss: 1.070355
2019-02-21 17:57:11,612 - log/train6.log - INFO - iteration:28 step:3300/10100, NER loss: 1.058574
2019-02-21 17:57:13,888 - log/train6.log - INFO - iteration:28 step:3400/10100, NER loss: 1.107888
2019-02-21 17:57:16,185 - log/train6.log - INFO - iteration:28 step:3500/10100, NER loss: 1.130891
2019-02-21 17:57:18,557 - log/train6.log - INFO - iteration:28 step:3600/10100, NER loss: 1.083697
2019-02-21 17:57:20,902 - log/train6.log - INFO - iteration:28 step:3700/10100, NER loss: 1.018383
2019-02-21 17:57:23,153 - log/train6.log - INFO - iteration:28 step:3800/10100, NER loss: 0.811789
2019-02-21 17:57:25,543 - log/train6.log - INFO - iteration:28 step:3900/10100, NER loss: 0.946762
2019-02-21 17:57:27,956 - log/train6.log - INFO - iteration:28 step:4000/10100, NER loss: 1.021464
2019-02-21 17:57:30,318 - log/train6.log - INFO - iteration:28 step:4100/10100, NER loss: 1.051966
2019-02-21 17:57:32,453 - log/train6.log - INFO - iteration:28 step:4200/10100, NER loss: 0.801883
2019-02-21 17:57:34,638 - log/train6.log - INFO - iteration:28 step:4300/10100, NER loss: 0.867253
2019-02-21 17:57:37,183 - log/train6.log - INFO - iteration:28 step:4400/10100, NER loss: 1.254517
2019-02-21 17:57:39,648 - log/train6.log - INFO - iteration:28 step:4500/10100, NER loss: 1.276020
2019-02-21 17:57:41,816 - log/train6.log - INFO - iteration:28 step:4600/10100, NER loss: 0.887702
2019-02-21 17:57:44,084 - log/train6.log - INFO - iteration:28 step:4700/10100, NER loss: 1.238519
2019-02-21 17:57:46,157 - log/train6.log - INFO - iteration:28 step:4800/10100, NER loss: 1.126448
2019-02-21 17:57:50,387 - log/train6.log - INFO - iteration:28 step:4900/10100, NER loss: 1.345271
2019-02-21 17:57:52,768 - log/train6.log - INFO - iteration:28 step:5000/10100, NER loss: 1.056318
2019-02-21 17:57:54,804 - log/train6.log - INFO - iteration:28 step:5100/10100, NER loss: 0.884746
2019-02-21 17:57:57,016 - log/train6.log - INFO - iteration:28 step:5200/10100, NER loss: 0.958007
2019-02-21 17:57:59,173 - log/train6.log - INFO - iteration:28 step:5300/10100, NER loss: 0.856731
2019-02-21 17:58:01,423 - log/train6.log - INFO - iteration:28 step:5400/10100, NER loss: 1.093210
2019-02-21 17:58:03,499 - log/train6.log - INFO - iteration:28 step:5500/10100, NER loss: 0.926653
2019-02-21 17:58:05,851 - log/train6.log - INFO - iteration:28 step:5600/10100, NER loss: 1.270031
2019-02-21 17:58:07,965 - log/train6.log - INFO - iteration:28 step:5700/10100, NER loss: 0.701231
2019-02-21 17:58:10,059 - log/train6.log - INFO - iteration:28 step:5800/10100, NER loss: 0.942442
2019-02-21 17:58:14,335 - log/train6.log - INFO - iteration:28 step:5900/10100, NER loss: 1.580423
2019-02-21 17:58:16,416 - log/train6.log - INFO - iteration:28 step:6000/10100, NER loss: 0.801972
2019-02-21 17:58:18,747 - log/train6.log - INFO - iteration:28 step:6100/10100, NER loss: 0.891072
2019-02-21 17:58:21,044 - log/train6.log - INFO - iteration:28 step:6200/10100, NER loss: 1.069969
2019-02-21 17:58:23,252 - log/train6.log - INFO - iteration:28 step:6300/10100, NER loss: 0.942589
2019-02-21 17:58:25,435 - log/train6.log - INFO - iteration:28 step:6400/10100, NER loss: 1.153429
2019-02-21 17:58:27,793 - log/train6.log - INFO - iteration:28 step:6500/10100, NER loss: 0.911118
2019-02-21 17:58:30,035 - log/train6.log - INFO - iteration:28 step:6600/10100, NER loss: 1.236589
2019-02-21 17:58:32,254 - log/train6.log - INFO - iteration:28 step:6700/10100, NER loss: 1.050449
2019-02-21 17:58:34,448 - log/train6.log - INFO - iteration:28 step:6800/10100, NER loss: 0.967831
2019-02-21 17:58:36,600 - log/train6.log - INFO - iteration:28 step:6900/10100, NER loss: 0.946194
2019-02-21 17:58:38,725 - log/train6.log - INFO - iteration:28 step:7000/10100, NER loss: 1.001348
2019-02-21 17:58:41,000 - log/train6.log - INFO - iteration:28 step:7100/10100, NER loss: 1.150430
2019-02-21 17:58:43,313 - log/train6.log - INFO - iteration:28 step:7200/10100, NER loss: 1.050333
2019-02-21 17:58:45,618 - log/train6.log - INFO - iteration:28 step:7300/10100, NER loss: 1.071783
2019-02-21 17:58:47,849 - log/train6.log - INFO - iteration:28 step:7400/10100, NER loss: 1.111344
2019-02-21 17:58:49,944 - log/train6.log - INFO - iteration:28 step:7500/10100, NER loss: 0.813714
2019-02-21 17:58:52,252 - log/train6.log - INFO - iteration:28 step:7600/10100, NER loss: 0.948888
2019-02-21 17:58:54,313 - log/train6.log - INFO - iteration:28 step:7700/10100, NER loss: 1.081346
2019-02-21 17:58:56,558 - log/train6.log - INFO - iteration:28 step:7800/10100, NER loss: 1.094370
2019-02-21 17:58:58,846 - log/train6.log - INFO - iteration:28 step:7900/10100, NER loss: 0.890003
2019-02-21 17:59:00,785 - log/train6.log - INFO - iteration:28 step:8000/10100, NER loss: 0.790515
2019-02-21 17:59:03,079 - log/train6.log - INFO - iteration:28 step:8100/10100, NER loss: 0.941212
2019-02-21 17:59:05,316 - log/train6.log - INFO - iteration:28 step:8200/10100, NER loss: 1.179480
2019-02-21 17:59:07,912 - log/train6.log - INFO - iteration:28 step:8300/10100, NER loss: 1.569655
2019-02-21 17:59:10,244 - log/train6.log - INFO - iteration:28 step:8400/10100, NER loss: 1.589106
2019-02-21 17:59:12,276 - log/train6.log - INFO - iteration:28 step:8500/10100, NER loss: 1.011591
2019-02-21 17:59:14,900 - log/train6.log - INFO - iteration:28 step:8600/10100, NER loss: 1.220625
2019-02-21 17:59:17,151 - log/train6.log - INFO - iteration:28 step:8700/10100, NER loss: 1.044511
2019-02-21 17:59:19,345 - log/train6.log - INFO - iteration:28 step:8800/10100, NER loss: 0.957178
2019-02-21 17:59:21,512 - log/train6.log - INFO - iteration:28 step:8900/10100, NER loss: 0.989452
2019-02-21 17:59:23,692 - log/train6.log - INFO - iteration:28 step:9000/10100, NER loss: 1.326379
2019-02-21 17:59:25,819 - log/train6.log - INFO - iteration:28 step:9100/10100, NER loss: 0.847359
2019-02-21 17:59:28,122 - log/train6.log - INFO - iteration:28 step:9200/10100, NER loss: 1.055477
2019-02-21 17:59:30,364 - log/train6.log - INFO - iteration:28 step:9300/10100, NER loss: 1.146111
2019-02-21 17:59:32,587 - log/train6.log - INFO - iteration:28 step:9400/10100, NER loss: 1.095445
2019-02-21 17:59:34,804 - log/train6.log - INFO - iteration:28 step:9500/10100, NER loss: 1.125219
2019-02-21 17:59:37,101 - log/train6.log - INFO - iteration:28 step:9600/10100, NER loss: 1.052797
2019-02-21 17:59:39,568 - log/train6.log - INFO - iteration:28 step:9700/10100, NER loss: 1.161332
2019-02-21 17:59:41,865 - log/train6.log - INFO - iteration:28 step:9800/10100, NER loss: 1.086572
2019-02-21 17:59:44,186 - log/train6.log - INFO - iteration:28 step:9900/10100, NER loss: 0.886812
2019-02-21 17:59:46,298 - log/train6.log - INFO - iteration:28 step:10000/10100, NER loss: 0.749294
2019-02-21 17:59:49,358 - log/train6.log - INFO - iteration:29 step:0/10100, NER loss: 1.321509
2019-02-21 17:59:49,358 - log/train6.log - INFO - evaluate:dev
2019-02-21 17:59:56,042 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5262 phrases; correct: 4248.

2019-02-21 17:59:56,042 - log/train6.log - INFO - accuracy:  95.53%; precision:  80.73%; recall:  72.65%; FB1:  76.48

2019-02-21 17:59:56,042 - log/train6.log - INFO -                 C: precision:  88.70%; recall:  87.58%; FB1:  88.14  3346

2019-02-21 17:59:56,042 - log/train6.log - INFO -               IND: precision:  44.65%; recall:  23.53%; FB1:  30.82  215

2019-02-21 17:59:56,042 - log/train6.log - INFO -               INS: precision:  75.36%; recall:  69.39%; FB1:  72.25  349

2019-02-21 17:59:56,042 - log/train6.log - INFO -                 L: precision:  56.18%; recall:  63.04%; FB1:  59.41  680

2019-02-21 17:59:56,042 - log/train6.log - INFO -                 P: precision:  90.86%; recall:  89.69%; FB1:  90.27  536

2019-02-21 17:59:56,042 - log/train6.log - INFO -               PRO: precision:  38.24%; recall:   9.96%; FB1:  15.81  136

2019-02-21 17:59:56,045 - log/train6.log - INFO - evaluate:test
2019-02-21 17:59:57,551 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1559 phrases; correct: 1352.

2019-02-21 17:59:57,552 - log/train6.log - INFO - accuracy:  96.91%; precision:  86.72%; recall:  82.09%; FB1:  84.34

2019-02-21 17:59:57,552 - log/train6.log - INFO -                 C: precision:  90.34%; recall:  91.84%; FB1:  91.08  1046

2019-02-21 17:59:57,552 - log/train6.log - INFO -               IND: precision:  67.44%; recall:  61.70%; FB1:  64.44  43

2019-02-21 17:59:57,552 - log/train6.log - INFO -               INS: precision:  73.17%; recall:  63.16%; FB1:  67.80  82

2019-02-21 17:59:57,552 - log/train6.log - INFO -                 L: precision:  61.11%; recall:  64.08%; FB1:  62.56  108

2019-02-21 17:59:57,552 - log/train6.log - INFO -                 P: precision:  91.94%; recall:  95.10%; FB1:  93.49  211

2019-02-21 17:59:57,552 - log/train6.log - INFO -               PRO: precision:  84.06%; recall:  34.32%; FB1:  48.74  69

2019-02-21 18:00:00,091 - log/train6.log - INFO - iteration:29 step:100/10100, NER loss: 1.465171
2019-02-21 18:00:04,792 - log/train6.log - INFO - iteration:29 step:200/10100, NER loss: 1.583330
2019-02-21 18:00:07,536 - log/train6.log - INFO - iteration:29 step:300/10100, NER loss: 1.026668
2019-02-21 18:00:09,654 - log/train6.log - INFO - iteration:29 step:400/10100, NER loss: 0.909436
2019-02-21 18:00:12,009 - log/train6.log - INFO - iteration:29 step:500/10100, NER loss: 0.787016
2019-02-21 18:00:14,427 - log/train6.log - INFO - iteration:29 step:600/10100, NER loss: 1.108327
2019-02-21 18:00:16,896 - log/train6.log - INFO - iteration:29 step:700/10100, NER loss: 1.010726
2019-02-21 18:00:19,289 - log/train6.log - INFO - iteration:29 step:800/10100, NER loss: 0.907905
2019-02-21 18:00:21,581 - log/train6.log - INFO - iteration:29 step:900/10100, NER loss: 1.299152
2019-02-21 18:00:24,118 - log/train6.log - INFO - iteration:29 step:1000/10100, NER loss: 1.025833
2019-02-21 18:00:26,500 - log/train6.log - INFO - iteration:29 step:1100/10100, NER loss: 0.855477
2019-02-21 18:00:30,430 - log/train6.log - INFO - iteration:29 step:1200/10100, NER loss: 1.805047
2019-02-21 18:00:32,650 - log/train6.log - INFO - iteration:29 step:1300/10100, NER loss: 0.961171
2019-02-21 18:00:34,886 - log/train6.log - INFO - iteration:29 step:1400/10100, NER loss: 0.967544
2019-02-21 18:00:37,171 - log/train6.log - INFO - iteration:29 step:1500/10100, NER loss: 1.183248
2019-02-21 18:00:39,303 - log/train6.log - INFO - iteration:29 step:1600/10100, NER loss: 0.888395
2019-02-21 18:00:41,678 - log/train6.log - INFO - iteration:29 step:1700/10100, NER loss: 1.177907
2019-02-21 18:00:44,064 - log/train6.log - INFO - iteration:29 step:1800/10100, NER loss: 0.797534
2019-02-21 18:00:46,135 - log/train6.log - INFO - iteration:29 step:1900/10100, NER loss: 0.727802
2019-02-21 18:00:48,332 - log/train6.log - INFO - iteration:29 step:2000/10100, NER loss: 1.013306
2019-02-21 18:00:50,529 - log/train6.log - INFO - iteration:29 step:2100/10100, NER loss: 1.122418
2019-02-21 18:00:52,826 - log/train6.log - INFO - iteration:29 step:2200/10100, NER loss: 1.006754
2019-02-21 18:00:54,747 - log/train6.log - INFO - iteration:29 step:2300/10100, NER loss: 0.940581
2019-02-21 18:00:57,054 - log/train6.log - INFO - iteration:29 step:2400/10100, NER loss: 1.016492
2019-02-21 18:00:59,270 - log/train6.log - INFO - iteration:29 step:2500/10100, NER loss: 1.012408
2019-02-21 18:01:01,519 - log/train6.log - INFO - iteration:29 step:2600/10100, NER loss: 0.894522
2019-02-21 18:01:03,800 - log/train6.log - INFO - iteration:29 step:2700/10100, NER loss: 0.981458
2019-02-21 18:01:06,043 - log/train6.log - INFO - iteration:29 step:2800/10100, NER loss: 0.770557
2019-02-21 18:01:08,295 - log/train6.log - INFO - iteration:29 step:2900/10100, NER loss: 0.906213
2019-02-21 18:01:10,469 - log/train6.log - INFO - iteration:29 step:3000/10100, NER loss: 0.933554
2019-02-21 18:01:12,895 - log/train6.log - INFO - iteration:29 step:3100/10100, NER loss: 1.165365
2019-02-21 18:01:15,193 - log/train6.log - INFO - iteration:29 step:3200/10100, NER loss: 0.874767
2019-02-21 18:01:17,647 - log/train6.log - INFO - iteration:29 step:3300/10100, NER loss: 1.173475
2019-02-21 18:01:19,965 - log/train6.log - INFO - iteration:29 step:3400/10100, NER loss: 1.106467
2019-02-21 18:01:22,321 - log/train6.log - INFO - iteration:29 step:3500/10100, NER loss: 1.218062
2019-02-21 18:01:24,691 - log/train6.log - INFO - iteration:29 step:3600/10100, NER loss: 1.067991
2019-02-21 18:01:27,032 - log/train6.log - INFO - iteration:29 step:3700/10100, NER loss: 1.167661
2019-02-21 18:01:29,237 - log/train6.log - INFO - iteration:29 step:3800/10100, NER loss: 0.967079
2019-02-21 18:01:31,818 - log/train6.log - INFO - iteration:29 step:3900/10100, NER loss: 1.323795
2019-02-21 18:01:34,031 - log/train6.log - INFO - iteration:29 step:4000/10100, NER loss: 0.985879
2019-02-21 18:01:36,388 - log/train6.log - INFO - iteration:29 step:4100/10100, NER loss: 1.009771
2019-02-21 18:01:39,106 - log/train6.log - INFO - iteration:29 step:4200/10100, NER loss: 1.049060
2019-02-21 18:01:41,077 - log/train6.log - INFO - iteration:29 step:4300/10100, NER loss: 0.777839
2019-02-21 18:01:43,339 - log/train6.log - INFO - iteration:29 step:4400/10100, NER loss: 0.782152
2019-02-21 18:01:45,515 - log/train6.log - INFO - iteration:29 step:4500/10100, NER loss: 0.797260
2019-02-21 18:01:47,920 - log/train6.log - INFO - iteration:29 step:4600/10100, NER loss: 0.905017
2019-02-21 18:01:50,115 - log/train6.log - INFO - iteration:29 step:4700/10100, NER loss: 0.764365
2019-02-21 18:01:52,019 - log/train6.log - INFO - iteration:29 step:4800/10100, NER loss: 0.788002
2019-02-21 18:01:54,213 - log/train6.log - INFO - iteration:29 step:4900/10100, NER loss: 1.251144
2019-02-21 18:01:56,542 - log/train6.log - INFO - iteration:29 step:5000/10100, NER loss: 1.255899
2019-02-21 18:01:58,643 - log/train6.log - INFO - iteration:29 step:5100/10100, NER loss: 0.893345
2019-02-21 18:02:00,951 - log/train6.log - INFO - iteration:29 step:5200/10100, NER loss: 1.062288
2019-02-21 18:02:03,224 - log/train6.log - INFO - iteration:29 step:5300/10100, NER loss: 1.028323
2019-02-21 18:02:05,383 - log/train6.log - INFO - iteration:29 step:5400/10100, NER loss: 0.834103
2019-02-21 18:02:07,804 - log/train6.log - INFO - iteration:29 step:5500/10100, NER loss: 1.077437
2019-02-21 18:02:09,917 - log/train6.log - INFO - iteration:29 step:5600/10100, NER loss: 0.808668
2019-02-21 18:02:12,182 - log/train6.log - INFO - iteration:29 step:5700/10100, NER loss: 0.887363
2019-02-21 18:02:14,502 - log/train6.log - INFO - iteration:29 step:5800/10100, NER loss: 1.211599
2019-02-21 18:02:16,766 - log/train6.log - INFO - iteration:29 step:5900/10100, NER loss: 0.901086
2019-02-21 18:02:19,057 - log/train6.log - INFO - iteration:29 step:6000/10100, NER loss: 1.080661
2019-02-21 18:02:21,331 - log/train6.log - INFO - iteration:29 step:6100/10100, NER loss: 1.084816
2019-02-21 18:02:23,630 - log/train6.log - INFO - iteration:29 step:6200/10100, NER loss: 0.905488
2019-02-21 18:02:25,845 - log/train6.log - INFO - iteration:29 step:6300/10100, NER loss: 1.033061
2019-02-21 18:02:28,478 - log/train6.log - INFO - iteration:29 step:6400/10100, NER loss: 1.278771
2019-02-21 18:02:30,793 - log/train6.log - INFO - iteration:29 step:6500/10100, NER loss: 1.100829
2019-02-21 18:02:33,022 - log/train6.log - INFO - iteration:29 step:6600/10100, NER loss: 0.892883
2019-02-21 18:02:35,021 - log/train6.log - INFO - iteration:29 step:6700/10100, NER loss: 0.806428
2019-02-21 18:02:37,269 - log/train6.log - INFO - iteration:29 step:6800/10100, NER loss: 0.872531
2019-02-21 18:02:39,518 - log/train6.log - INFO - iteration:29 step:6900/10100, NER loss: 0.701574
2019-02-21 18:02:41,659 - log/train6.log - INFO - iteration:29 step:7000/10100, NER loss: 0.803621
2019-02-21 18:02:43,994 - log/train6.log - INFO - iteration:29 step:7100/10100, NER loss: 1.120317
2019-02-21 18:02:46,164 - log/train6.log - INFO - iteration:29 step:7200/10100, NER loss: 0.905603
2019-02-21 18:02:48,430 - log/train6.log - INFO - iteration:29 step:7300/10100, NER loss: 0.978643
2019-02-21 18:02:50,546 - log/train6.log - INFO - iteration:29 step:7400/10100, NER loss: 1.061364
2019-02-21 18:02:52,761 - log/train6.log - INFO - iteration:29 step:7500/10100, NER loss: 1.043702
2019-02-21 18:02:55,085 - log/train6.log - INFO - iteration:29 step:7600/10100, NER loss: 0.924540
2019-02-21 18:02:57,423 - log/train6.log - INFO - iteration:29 step:7700/10100, NER loss: 0.983555
2019-02-21 18:02:59,586 - log/train6.log - INFO - iteration:29 step:7800/10100, NER loss: 0.988731
2019-02-21 18:03:01,867 - log/train6.log - INFO - iteration:29 step:7900/10100, NER loss: 0.872142
2019-02-21 18:03:04,013 - log/train6.log - INFO - iteration:29 step:8000/10100, NER loss: 0.805296
2019-02-21 18:03:06,098 - log/train6.log - INFO - iteration:29 step:8100/10100, NER loss: 0.869646
2019-02-21 18:03:08,594 - log/train6.log - INFO - iteration:29 step:8200/10100, NER loss: 1.354658
2019-02-21 18:03:11,198 - log/train6.log - INFO - iteration:29 step:8300/10100, NER loss: 1.188629
2019-02-21 18:03:13,681 - log/train6.log - INFO - iteration:29 step:8400/10100, NER loss: 1.022725
2019-02-21 18:03:18,312 - log/train6.log - INFO - iteration:29 step:8500/10100, NER loss: 2.237726
2019-02-21 18:03:20,384 - log/train6.log - INFO - iteration:29 step:8600/10100, NER loss: 0.844965
2019-02-21 18:03:22,591 - log/train6.log - INFO - iteration:29 step:8700/10100, NER loss: 0.945123
2019-02-21 18:03:24,797 - log/train6.log - INFO - iteration:29 step:8800/10100, NER loss: 1.021653
2019-02-21 18:03:26,998 - log/train6.log - INFO - iteration:29 step:8900/10100, NER loss: 0.952487
2019-02-21 18:03:28,968 - log/train6.log - INFO - iteration:29 step:9000/10100, NER loss: 0.775971
2019-02-21 18:03:31,074 - log/train6.log - INFO - iteration:29 step:9100/10100, NER loss: 1.023046
2019-02-21 18:03:33,324 - log/train6.log - INFO - iteration:29 step:9200/10100, NER loss: 1.069402
2019-02-21 18:03:35,316 - log/train6.log - INFO - iteration:29 step:9300/10100, NER loss: 0.776294
2019-02-21 18:03:37,555 - log/train6.log - INFO - iteration:29 step:9400/10100, NER loss: 1.049347
2019-02-21 18:03:39,898 - log/train6.log - INFO - iteration:29 step:9500/10100, NER loss: 1.056107
2019-02-21 18:03:42,356 - log/train6.log - INFO - iteration:29 step:9600/10100, NER loss: 1.113572
2019-02-21 18:03:44,662 - log/train6.log - INFO - iteration:29 step:9700/10100, NER loss: 1.080043
2019-02-21 18:03:47,113 - log/train6.log - INFO - iteration:29 step:9800/10100, NER loss: 1.174379
2019-02-21 18:03:49,208 - log/train6.log - INFO - iteration:29 step:9900/10100, NER loss: 1.141262
2019-02-21 18:03:51,464 - log/train6.log - INFO - iteration:29 step:10000/10100, NER loss: 0.994580
2019-02-21 18:03:53,496 - log/train6.log - INFO - iteration:30 step:0/10100, NER loss: 0.897896
2019-02-21 18:03:53,496 - log/train6.log - INFO - evaluate:dev
2019-02-21 18:03:59,977 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5217 phrases; correct: 4192.

2019-02-21 18:03:59,977 - log/train6.log - INFO - accuracy:  95.32%; precision:  80.35%; recall:  71.69%; FB1:  75.78

2019-02-21 18:03:59,977 - log/train6.log - INFO -                 C: precision:  87.47%; recall:  87.78%; FB1:  87.63  3401

2019-02-21 18:03:59,978 - log/train6.log - INFO -               IND: precision:  48.07%; recall:  21.32%; FB1:  29.54  181

2019-02-21 18:03:59,978 - log/train6.log - INFO -               INS: precision:  76.18%; recall:  68.34%; FB1:  72.04  340

2019-02-21 18:03:59,978 - log/train6.log - INFO -                 L: precision:  54.80%; recall:  48.02%; FB1:  51.19  531

2019-02-21 18:03:59,978 - log/train6.log - INFO -                 P: precision:  87.50%; recall:  91.53%; FB1:  89.47  568

2019-02-21 18:03:59,978 - log/train6.log - INFO -               PRO: precision:  42.35%; recall:  15.90%; FB1:  23.12  196

2019-02-21 18:03:59,981 - log/train6.log - INFO - evaluate:test
2019-02-21 18:04:01,446 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1584 phrases; correct: 1364.

2019-02-21 18:04:01,446 - log/train6.log - INFO - accuracy:  97.03%; precision:  86.11%; recall:  82.82%; FB1:  84.43

2019-02-21 18:04:01,446 - log/train6.log - INFO -                 C: precision:  89.35%; recall:  92.13%; FB1:  90.72  1061

2019-02-21 18:04:01,446 - log/train6.log - INFO -               IND: precision:  69.23%; recall:  57.45%; FB1:  62.79  39

2019-02-21 18:04:01,446 - log/train6.log - INFO -               INS: precision:  74.07%; recall:  63.16%; FB1:  68.18  81

2019-02-21 18:04:01,446 - log/train6.log - INFO -                 L: precision:  62.16%; recall:  66.99%; FB1:  64.49  111

2019-02-21 18:04:01,446 - log/train6.log - INFO -                 P: precision:  91.98%; recall:  95.59%; FB1:  93.75  212

2019-02-21 18:04:01,446 - log/train6.log - INFO -               PRO: precision:  81.25%; recall:  38.46%; FB1:  52.21  80

2019-02-21 18:04:03,513 - log/train6.log - INFO - iteration:30 step:100/10100, NER loss: 0.956819
2019-02-21 18:04:05,544 - log/train6.log - INFO - iteration:30 step:200/10100, NER loss: 1.095822
2019-02-21 18:04:07,841 - log/train6.log - INFO - iteration:30 step:300/10100, NER loss: 1.024123
2019-02-21 18:04:10,114 - log/train6.log - INFO - iteration:30 step:400/10100, NER loss: 0.890553
2019-02-21 18:04:12,513 - log/train6.log - INFO - iteration:30 step:500/10100, NER loss: 0.938473
2019-02-21 18:04:14,968 - log/train6.log - INFO - iteration:30 step:600/10100, NER loss: 1.244868
2019-02-21 18:04:17,119 - log/train6.log - INFO - iteration:30 step:700/10100, NER loss: 0.811612
2019-02-21 18:04:19,299 - log/train6.log - INFO - iteration:30 step:800/10100, NER loss: 0.911549
2019-02-21 18:04:21,517 - log/train6.log - INFO - iteration:30 step:900/10100, NER loss: 0.935249
2019-02-21 18:04:23,686 - log/train6.log - INFO - iteration:30 step:1000/10100, NER loss: 0.747749
2019-02-21 18:04:25,929 - log/train6.log - INFO - iteration:30 step:1100/10100, NER loss: 0.893794
2019-02-21 18:04:28,051 - log/train6.log - INFO - iteration:30 step:1200/10100, NER loss: 0.859810
2019-02-21 18:04:30,278 - log/train6.log - INFO - iteration:30 step:1300/10100, NER loss: 1.114343
2019-02-21 18:04:32,356 - log/train6.log - INFO - iteration:30 step:1400/10100, NER loss: 0.860703
2019-02-21 18:04:34,574 - log/train6.log - INFO - iteration:30 step:1500/10100, NER loss: 0.907213
2019-02-21 18:04:36,463 - log/train6.log - INFO - iteration:30 step:1600/10100, NER loss: 0.909837
2019-02-21 18:04:38,797 - log/train6.log - INFO - iteration:30 step:1700/10100, NER loss: 0.868165
2019-02-21 18:04:40,873 - log/train6.log - INFO - iteration:30 step:1800/10100, NER loss: 0.819578
2019-02-21 18:04:43,159 - log/train6.log - INFO - iteration:30 step:1900/10100, NER loss: 0.953232
2019-02-21 18:04:45,235 - log/train6.log - INFO - iteration:30 step:2000/10100, NER loss: 0.741908
2019-02-21 18:04:47,388 - log/train6.log - INFO - iteration:30 step:2100/10100, NER loss: 0.799283
2019-02-21 18:04:49,622 - log/train6.log - INFO - iteration:30 step:2200/10100, NER loss: 0.968187
2019-02-21 18:04:51,683 - log/train6.log - INFO - iteration:30 step:2300/10100, NER loss: 0.766722
2019-02-21 18:04:55,984 - log/train6.log - INFO - iteration:30 step:2400/10100, NER loss: 1.606590
2019-02-21 18:04:58,351 - log/train6.log - INFO - iteration:30 step:2500/10100, NER loss: 1.096616
2019-02-21 18:05:00,497 - log/train6.log - INFO - iteration:30 step:2600/10100, NER loss: 0.934076
2019-02-21 18:05:02,857 - log/train6.log - INFO - iteration:30 step:2700/10100, NER loss: 1.128501
2019-02-21 18:05:05,275 - log/train6.log - INFO - iteration:30 step:2800/10100, NER loss: 0.910192
2019-02-21 18:05:07,567 - log/train6.log - INFO - iteration:30 step:2900/10100, NER loss: 0.700153
2019-02-21 18:05:12,060 - log/train6.log - INFO - iteration:30 step:3000/10100, NER loss: 1.647646
2019-02-21 18:05:14,544 - log/train6.log - INFO - iteration:30 step:3100/10100, NER loss: 1.290650
2019-02-21 18:05:16,798 - log/train6.log - INFO - iteration:30 step:3200/10100, NER loss: 1.041036
2019-02-21 18:05:18,884 - log/train6.log - INFO - iteration:30 step:3300/10100, NER loss: 0.789488
2019-02-21 18:05:21,281 - log/train6.log - INFO - iteration:30 step:3400/10100, NER loss: 0.878852
2019-02-21 18:05:23,702 - log/train6.log - INFO - iteration:30 step:3500/10100, NER loss: 1.038835
2019-02-21 18:05:25,742 - log/train6.log - INFO - iteration:30 step:3600/10100, NER loss: 0.772057
2019-02-21 18:05:28,030 - log/train6.log - INFO - iteration:30 step:3700/10100, NER loss: 0.906456
2019-02-21 18:05:30,212 - log/train6.log - INFO - iteration:30 step:3800/10100, NER loss: 0.931020
2019-02-21 18:05:32,448 - log/train6.log - INFO - iteration:30 step:3900/10100, NER loss: 1.066500
2019-02-21 18:05:34,426 - log/train6.log - INFO - iteration:30 step:4000/10100, NER loss: 0.821736
2019-02-21 18:05:36,464 - log/train6.log - INFO - iteration:30 step:4100/10100, NER loss: 0.907419
2019-02-21 18:05:38,553 - log/train6.log - INFO - iteration:30 step:4200/10100, NER loss: 0.961715
2019-02-21 18:05:40,822 - log/train6.log - INFO - iteration:30 step:4300/10100, NER loss: 0.864983
2019-02-21 18:05:43,174 - log/train6.log - INFO - iteration:30 step:4400/10100, NER loss: 1.073562
2019-02-21 18:05:45,161 - log/train6.log - INFO - iteration:30 step:4500/10100, NER loss: 0.704098
2019-02-21 18:05:47,515 - log/train6.log - INFO - iteration:30 step:4600/10100, NER loss: 0.824649
2019-02-21 18:05:49,780 - log/train6.log - INFO - iteration:30 step:4700/10100, NER loss: 0.924029
2019-02-21 18:05:51,903 - log/train6.log - INFO - iteration:30 step:4800/10100, NER loss: 0.860328
2019-02-21 18:05:54,264 - log/train6.log - INFO - iteration:30 step:4900/10100, NER loss: 1.471643
2019-02-21 18:05:56,409 - log/train6.log - INFO - iteration:30 step:5000/10100, NER loss: 0.759654
2019-02-21 18:05:58,770 - log/train6.log - INFO - iteration:30 step:5100/10100, NER loss: 1.479028
2019-02-21 18:06:01,162 - log/train6.log - INFO - iteration:30 step:5200/10100, NER loss: 0.999061
2019-02-21 18:06:03,519 - log/train6.log - INFO - iteration:30 step:5300/10100, NER loss: 0.937030
2019-02-21 18:06:05,614 - log/train6.log - INFO - iteration:30 step:5400/10100, NER loss: 0.973620
2019-02-21 18:06:07,778 - log/train6.log - INFO - iteration:30 step:5500/10100, NER loss: 0.924272
2019-02-21 18:06:10,049 - log/train6.log - INFO - iteration:30 step:5600/10100, NER loss: 0.980095
2019-02-21 18:06:12,406 - log/train6.log - INFO - iteration:30 step:5700/10100, NER loss: 1.090268
2019-02-21 18:06:14,535 - log/train6.log - INFO - iteration:30 step:5800/10100, NER loss: 0.920463
2019-02-21 18:06:16,657 - log/train6.log - INFO - iteration:30 step:5900/10100, NER loss: 1.022863
2019-02-21 18:06:19,090 - log/train6.log - INFO - iteration:30 step:6000/10100, NER loss: 0.994017
2019-02-21 18:06:21,100 - log/train6.log - INFO - iteration:30 step:6100/10100, NER loss: 0.705042
2019-02-21 18:06:23,302 - log/train6.log - INFO - iteration:30 step:6200/10100, NER loss: 0.870229
2019-02-21 18:06:25,536 - log/train6.log - INFO - iteration:30 step:6300/10100, NER loss: 0.851546
2019-02-21 18:06:27,754 - log/train6.log - INFO - iteration:30 step:6400/10100, NER loss: 1.002782
2019-02-21 18:06:30,023 - log/train6.log - INFO - iteration:30 step:6500/10100, NER loss: 0.946954
2019-02-21 18:06:32,109 - log/train6.log - INFO - iteration:30 step:6600/10100, NER loss: 1.180972
2019-02-21 18:06:34,167 - log/train6.log - INFO - iteration:30 step:6700/10100, NER loss: 0.931168
2019-02-21 18:06:36,089 - log/train6.log - INFO - iteration:30 step:6800/10100, NER loss: 0.973879
2019-02-21 18:06:38,438 - log/train6.log - INFO - iteration:30 step:6900/10100, NER loss: 1.165349
2019-02-21 18:06:40,863 - log/train6.log - INFO - iteration:30 step:7000/10100, NER loss: 0.946484
2019-02-21 18:06:43,147 - log/train6.log - INFO - iteration:30 step:7100/10100, NER loss: 1.148279
2019-02-21 18:06:45,916 - log/train6.log - INFO - iteration:30 step:7200/10100, NER loss: 1.303743
2019-02-21 18:06:48,125 - log/train6.log - INFO - iteration:30 step:7300/10100, NER loss: 0.969286
2019-02-21 18:06:50,220 - log/train6.log - INFO - iteration:30 step:7400/10100, NER loss: 0.993528
2019-02-21 18:06:52,557 - log/train6.log - INFO - iteration:30 step:7500/10100, NER loss: 1.250090
2019-02-21 18:06:54,882 - log/train6.log - INFO - iteration:30 step:7600/10100, NER loss: 1.272982
2019-02-21 18:06:57,120 - log/train6.log - INFO - iteration:30 step:7700/10100, NER loss: 1.207425
2019-02-21 18:06:59,316 - log/train6.log - INFO - iteration:30 step:7800/10100, NER loss: 0.998158
2019-02-21 18:07:03,291 - log/train6.log - INFO - iteration:30 step:7900/10100, NER loss: 1.259547
2019-02-21 18:07:05,470 - log/train6.log - INFO - iteration:30 step:8000/10100, NER loss: 0.955375
2019-02-21 18:07:08,044 - log/train6.log - INFO - iteration:30 step:8100/10100, NER loss: 1.267990
2019-02-21 18:07:10,198 - log/train6.log - INFO - iteration:30 step:8200/10100, NER loss: 0.999463
2019-02-21 18:07:12,397 - log/train6.log - INFO - iteration:30 step:8300/10100, NER loss: 1.287161
2019-02-21 18:07:14,821 - log/train6.log - INFO - iteration:30 step:8400/10100, NER loss: 1.205123
2019-02-21 18:07:17,044 - log/train6.log - INFO - iteration:30 step:8500/10100, NER loss: 0.870520
2019-02-21 18:07:19,308 - log/train6.log - INFO - iteration:30 step:8600/10100, NER loss: 1.015262
2019-02-21 18:07:21,486 - log/train6.log - INFO - iteration:30 step:8700/10100, NER loss: 1.040543
2019-02-21 18:07:23,817 - log/train6.log - INFO - iteration:30 step:8800/10100, NER loss: 0.974201
2019-02-21 18:07:26,030 - log/train6.log - INFO - iteration:30 step:8900/10100, NER loss: 0.911805
2019-02-21 18:07:28,125 - log/train6.log - INFO - iteration:30 step:9000/10100, NER loss: 0.926694
2019-02-21 18:07:30,491 - log/train6.log - INFO - iteration:30 step:9100/10100, NER loss: 1.077474
2019-02-21 18:07:32,832 - log/train6.log - INFO - iteration:30 step:9200/10100, NER loss: 0.996298
2019-02-21 18:07:35,223 - log/train6.log - INFO - iteration:30 step:9300/10100, NER loss: 1.218149
2019-02-21 18:07:37,311 - log/train6.log - INFO - iteration:30 step:9400/10100, NER loss: 0.963586
2019-02-21 18:07:39,288 - log/train6.log - INFO - iteration:30 step:9500/10100, NER loss: 0.868375
2019-02-21 18:07:41,447 - log/train6.log - INFO - iteration:30 step:9600/10100, NER loss: 0.853285
2019-02-21 18:07:43,544 - log/train6.log - INFO - iteration:30 step:9700/10100, NER loss: 0.714369
2019-02-21 18:07:45,852 - log/train6.log - INFO - iteration:30 step:9800/10100, NER loss: 1.140578
2019-02-21 18:07:48,113 - log/train6.log - INFO - iteration:30 step:9900/10100, NER loss: 1.223359
2019-02-21 18:07:50,537 - log/train6.log - INFO - iteration:30 step:10000/10100, NER loss: 1.171894
2019-02-21 18:07:52,509 - log/train6.log - INFO - iteration:31 step:0/10100, NER loss: 0.790759
2019-02-21 18:07:52,510 - log/train6.log - INFO - evaluate:dev
2019-02-21 18:07:59,044 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5800 phrases; correct: 4430.

2019-02-21 18:07:59,045 - log/train6.log - INFO - accuracy:  95.42%; precision:  76.38%; recall:  75.77%; FB1:  76.07

2019-02-21 18:07:59,045 - log/train6.log - INFO -                 C: precision:  84.51%; recall:  89.35%; FB1:  86.86  3583

2019-02-21 18:07:59,045 - log/train6.log - INFO -               IND: precision:  46.50%; recall:  27.70%; FB1:  34.72  243

2019-02-21 18:07:59,045 - log/train6.log - INFO -               INS: precision:  75.68%; recall:  65.70%; FB1:  70.34  329

2019-02-21 18:07:59,045 - log/train6.log - INFO -                 L: precision:  61.25%; recall:  64.69%; FB1:  62.92  640

2019-02-21 18:07:59,045 - log/train6.log - INFO -                 P: precision:  89.05%; recall:  92.82%; FB1:  90.89  566

2019-02-21 18:07:59,045 - log/train6.log - INFO -               PRO: precision:  32.80%; recall:  27.59%; FB1:  29.97  439

2019-02-21 18:07:59,048 - log/train6.log - INFO - evaluate:test
2019-02-21 18:08:00,529 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1685 phrases; correct: 1410.

2019-02-21 18:08:00,530 - log/train6.log - INFO - accuracy:  96.85%; precision:  83.68%; recall:  85.61%; FB1:  84.63

2019-02-21 18:08:00,530 - log/train6.log - INFO -                 C: precision:  87.25%; recall:  93.10%; FB1:  90.08  1098

2019-02-21 18:08:00,530 - log/train6.log - INFO -               IND: precision:  63.04%; recall:  61.70%; FB1:  62.37  46

2019-02-21 18:08:00,530 - log/train6.log - INFO -               INS: precision:  75.95%; recall:  63.16%; FB1:  68.97  79

2019-02-21 18:08:00,530 - log/train6.log - INFO -                 L: precision:  65.66%; recall:  63.11%; FB1:  64.36  99

2019-02-21 18:08:00,530 - log/train6.log - INFO -                 P: precision:  90.14%; recall:  94.12%; FB1:  92.09  213

2019-02-21 18:08:00,530 - log/train6.log - INFO -               PRO: precision:  70.67%; recall:  62.72%; FB1:  66.46  150

2019-02-21 18:08:02,736 - log/train6.log - INFO - iteration:31 step:100/10100, NER loss: 1.208842
2019-02-21 18:08:04,816 - log/train6.log - INFO - iteration:31 step:200/10100, NER loss: 0.826636
2019-02-21 18:08:06,921 - log/train6.log - INFO - iteration:31 step:300/10100, NER loss: 0.846688
2019-02-21 18:08:09,250 - log/train6.log - INFO - iteration:31 step:400/10100, NER loss: 1.300376
2019-02-21 18:08:11,424 - log/train6.log - INFO - iteration:31 step:500/10100, NER loss: 0.939366
2019-02-21 18:08:15,829 - log/train6.log - INFO - iteration:31 step:600/10100, NER loss: 1.496637
2019-02-21 18:08:17,988 - log/train6.log - INFO - iteration:31 step:700/10100, NER loss: 0.886776
2019-02-21 18:08:20,372 - log/train6.log - INFO - iteration:31 step:800/10100, NER loss: 1.012712
2019-02-21 18:08:23,354 - log/train6.log - INFO - iteration:31 step:900/10100, NER loss: 1.599219
2019-02-21 18:08:25,542 - log/train6.log - INFO - iteration:31 step:1000/10100, NER loss: 0.826815
2019-02-21 18:08:27,699 - log/train6.log - INFO - iteration:31 step:1100/10100, NER loss: 1.095403
2019-02-21 18:08:30,186 - log/train6.log - INFO - iteration:31 step:1200/10100, NER loss: 1.278794
2019-02-21 18:08:32,473 - log/train6.log - INFO - iteration:31 step:1300/10100, NER loss: 1.053340
2019-02-21 18:08:34,678 - log/train6.log - INFO - iteration:31 step:1400/10100, NER loss: 1.031037
2019-02-21 18:08:37,132 - log/train6.log - INFO - iteration:31 step:1500/10100, NER loss: 1.268135
2019-02-21 18:08:39,214 - log/train6.log - INFO - iteration:31 step:1600/10100, NER loss: 0.839621
2019-02-21 18:08:41,450 - log/train6.log - INFO - iteration:31 step:1700/10100, NER loss: 0.836347
2019-02-21 18:08:43,667 - log/train6.log - INFO - iteration:31 step:1800/10100, NER loss: 0.946210
2019-02-21 18:08:46,000 - log/train6.log - INFO - iteration:31 step:1900/10100, NER loss: 1.010710
2019-02-21 18:08:48,200 - log/train6.log - INFO - iteration:31 step:2000/10100, NER loss: 0.832214
2019-02-21 18:08:50,430 - log/train6.log - INFO - iteration:31 step:2100/10100, NER loss: 1.045567
2019-02-21 18:08:52,471 - log/train6.log - INFO - iteration:31 step:2200/10100, NER loss: 1.035958
2019-02-21 18:08:54,697 - log/train6.log - INFO - iteration:31 step:2300/10100, NER loss: 0.779510
2019-02-21 18:08:56,758 - log/train6.log - INFO - iteration:31 step:2400/10100, NER loss: 0.883187
2019-02-21 18:08:59,055 - log/train6.log - INFO - iteration:31 step:2500/10100, NER loss: 1.121699
2019-02-21 18:09:01,234 - log/train6.log - INFO - iteration:31 step:2600/10100, NER loss: 0.822733
2019-02-21 18:09:03,344 - log/train6.log - INFO - iteration:31 step:2700/10100, NER loss: 0.898362
2019-02-21 18:09:05,420 - log/train6.log - INFO - iteration:31 step:2800/10100, NER loss: 0.982177
2019-02-21 18:09:07,733 - log/train6.log - INFO - iteration:31 step:2900/10100, NER loss: 0.944763
2019-02-21 18:09:10,166 - log/train6.log - INFO - iteration:31 step:3000/10100, NER loss: 1.048802
2019-02-21 18:09:12,267 - log/train6.log - INFO - iteration:31 step:3100/10100, NER loss: 0.836890
2019-02-21 18:09:14,398 - log/train6.log - INFO - iteration:31 step:3200/10100, NER loss: 0.738463
2019-02-21 18:09:16,475 - log/train6.log - INFO - iteration:31 step:3300/10100, NER loss: 0.726365
2019-02-21 18:09:18,793 - log/train6.log - INFO - iteration:31 step:3400/10100, NER loss: 1.011613
2019-02-21 18:09:20,862 - log/train6.log - INFO - iteration:31 step:3500/10100, NER loss: 0.944745
2019-02-21 18:09:23,128 - log/train6.log - INFO - iteration:31 step:3600/10100, NER loss: 1.090721
2019-02-21 18:09:25,295 - log/train6.log - INFO - iteration:31 step:3700/10100, NER loss: 0.959439
2019-02-21 18:09:27,491 - log/train6.log - INFO - iteration:31 step:3800/10100, NER loss: 0.957863
2019-02-21 18:09:29,597 - log/train6.log - INFO - iteration:31 step:3900/10100, NER loss: 1.040809
2019-02-21 18:09:31,743 - log/train6.log - INFO - iteration:31 step:4000/10100, NER loss: 0.928432
2019-02-21 18:09:33,970 - log/train6.log - INFO - iteration:31 step:4100/10100, NER loss: 1.095218
2019-02-21 18:09:36,210 - log/train6.log - INFO - iteration:31 step:4200/10100, NER loss: 0.782923
2019-02-21 18:09:38,506 - log/train6.log - INFO - iteration:31 step:4300/10100, NER loss: 1.144279
2019-02-21 18:09:40,801 - log/train6.log - INFO - iteration:31 step:4400/10100, NER loss: 1.117142
2019-02-21 18:09:43,056 - log/train6.log - INFO - iteration:31 step:4500/10100, NER loss: 1.053681
2019-02-21 18:09:45,280 - log/train6.log - INFO - iteration:31 step:4600/10100, NER loss: 0.881652
2019-02-21 18:09:47,351 - log/train6.log - INFO - iteration:31 step:4700/10100, NER loss: 0.863474
2019-02-21 18:09:49,674 - log/train6.log - INFO - iteration:31 step:4800/10100, NER loss: 1.011774
2019-02-21 18:09:51,885 - log/train6.log - INFO - iteration:31 step:4900/10100, NER loss: 1.025698
2019-02-21 18:09:54,084 - log/train6.log - INFO - iteration:31 step:5000/10100, NER loss: 0.975674
2019-02-21 18:09:56,281 - log/train6.log - INFO - iteration:31 step:5100/10100, NER loss: 0.913767
2019-02-21 18:09:58,485 - log/train6.log - INFO - iteration:31 step:5200/10100, NER loss: 0.810682
2019-02-21 18:10:00,712 - log/train6.log - INFO - iteration:31 step:5300/10100, NER loss: 0.815187
2019-02-21 18:10:02,880 - log/train6.log - INFO - iteration:31 step:5400/10100, NER loss: 1.049958
2019-02-21 18:10:06,906 - log/train6.log - INFO - iteration:31 step:5500/10100, NER loss: 1.988117
2019-02-21 18:10:09,228 - log/train6.log - INFO - iteration:31 step:5600/10100, NER loss: 0.874213
2019-02-21 18:10:11,573 - log/train6.log - INFO - iteration:31 step:5700/10100, NER loss: 1.011629
2019-02-21 18:10:13,691 - log/train6.log - INFO - iteration:31 step:5800/10100, NER loss: 0.866786
2019-02-21 18:10:16,117 - log/train6.log - INFO - iteration:31 step:5900/10100, NER loss: 1.010090
2019-02-21 18:10:18,584 - log/train6.log - INFO - iteration:31 step:6000/10100, NER loss: 1.235748
2019-02-21 18:10:20,566 - log/train6.log - INFO - iteration:31 step:6100/10100, NER loss: 0.822609
2019-02-21 18:10:22,634 - log/train6.log - INFO - iteration:31 step:6200/10100, NER loss: 0.945364
2019-02-21 18:10:24,646 - log/train6.log - INFO - iteration:31 step:6300/10100, NER loss: 0.742034
2019-02-21 18:10:27,044 - log/train6.log - INFO - iteration:31 step:6400/10100, NER loss: 1.238067
2019-02-21 18:10:29,282 - log/train6.log - INFO - iteration:31 step:6500/10100, NER loss: 1.061924
2019-02-21 18:10:31,578 - log/train6.log - INFO - iteration:31 step:6600/10100, NER loss: 0.980723
2019-02-21 18:10:33,726 - log/train6.log - INFO - iteration:31 step:6700/10100, NER loss: 0.951504
2019-02-21 18:10:36,101 - log/train6.log - INFO - iteration:31 step:6800/10100, NER loss: 1.398803
2019-02-21 18:10:38,157 - log/train6.log - INFO - iteration:31 step:6900/10100, NER loss: 0.841925
2019-02-21 18:10:40,350 - log/train6.log - INFO - iteration:31 step:7000/10100, NER loss: 0.959191
2019-02-21 18:10:42,386 - log/train6.log - INFO - iteration:31 step:7100/10100, NER loss: 0.755191
2019-02-21 18:10:44,639 - log/train6.log - INFO - iteration:31 step:7200/10100, NER loss: 0.979079
2019-02-21 18:10:46,936 - log/train6.log - INFO - iteration:31 step:7300/10100, NER loss: 0.999375
2019-02-21 18:10:49,388 - log/train6.log - INFO - iteration:31 step:7400/10100, NER loss: 1.240280
2019-02-21 18:10:51,762 - log/train6.log - INFO - iteration:31 step:7500/10100, NER loss: 1.291133
2019-02-21 18:10:53,998 - log/train6.log - INFO - iteration:31 step:7600/10100, NER loss: 0.847834
2019-02-21 18:10:56,105 - log/train6.log - INFO - iteration:31 step:7700/10100, NER loss: 0.746286
2019-02-21 18:10:58,391 - log/train6.log - INFO - iteration:31 step:7800/10100, NER loss: 0.939242
2019-02-21 18:11:00,517 - log/train6.log - INFO - iteration:31 step:7900/10100, NER loss: 0.905849
2019-02-21 18:11:02,790 - log/train6.log - INFO - iteration:31 step:8000/10100, NER loss: 0.917358
2019-02-21 18:11:04,957 - log/train6.log - INFO - iteration:31 step:8100/10100, NER loss: 0.921933
2019-02-21 18:11:07,106 - log/train6.log - INFO - iteration:31 step:8200/10100, NER loss: 0.809834
2019-02-21 18:11:09,313 - log/train6.log - INFO - iteration:31 step:8300/10100, NER loss: 0.952092
2019-02-21 18:11:11,666 - log/train6.log - INFO - iteration:31 step:8400/10100, NER loss: 0.960001
2019-02-21 18:11:13,774 - log/train6.log - INFO - iteration:31 step:8500/10100, NER loss: 0.780121
2019-02-21 18:11:15,903 - log/train6.log - INFO - iteration:31 step:8600/10100, NER loss: 0.774838
2019-02-21 18:11:17,916 - log/train6.log - INFO - iteration:31 step:8700/10100, NER loss: 0.733326
2019-02-21 18:11:21,945 - log/train6.log - INFO - iteration:31 step:8800/10100, NER loss: 1.329596
2019-02-21 18:11:24,273 - log/train6.log - INFO - iteration:31 step:8900/10100, NER loss: 1.091639
2019-02-21 18:11:26,616 - log/train6.log - INFO - iteration:31 step:9000/10100, NER loss: 1.040514
2019-02-21 18:11:28,791 - log/train6.log - INFO - iteration:31 step:9100/10100, NER loss: 1.008548
2019-02-21 18:11:31,026 - log/train6.log - INFO - iteration:31 step:9200/10100, NER loss: 0.985566
2019-02-21 18:11:33,192 - log/train6.log - INFO - iteration:31 step:9300/10100, NER loss: 1.136139
2019-02-21 18:11:35,404 - log/train6.log - INFO - iteration:31 step:9400/10100, NER loss: 0.932894
2019-02-21 18:11:37,606 - log/train6.log - INFO - iteration:31 step:9500/10100, NER loss: 0.842653
2019-02-21 18:11:39,696 - log/train6.log - INFO - iteration:31 step:9600/10100, NER loss: 0.769051
2019-02-21 18:11:41,858 - log/train6.log - INFO - iteration:31 step:9700/10100, NER loss: 0.947285
2019-02-21 18:11:44,224 - log/train6.log - INFO - iteration:31 step:9800/10100, NER loss: 0.920144
2019-02-21 18:11:46,468 - log/train6.log - INFO - iteration:31 step:9900/10100, NER loss: 0.911686
2019-02-21 18:11:48,640 - log/train6.log - INFO - iteration:31 step:10000/10100, NER loss: 0.924929
2019-02-21 18:11:50,939 - log/train6.log - INFO - iteration:32 step:0/10100, NER loss: 0.917931
2019-02-21 18:11:50,939 - log/train6.log - INFO - evaluate:dev
2019-02-21 18:11:57,405 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5454 phrases; correct: 4294.

2019-02-21 18:11:57,405 - log/train6.log - INFO - accuracy:  95.38%; precision:  78.73%; recall:  73.44%; FB1:  75.99

2019-02-21 18:11:57,406 - log/train6.log - INFO -                 C: precision:  86.90%; recall:  88.26%; FB1:  87.57  3442

2019-02-21 18:11:57,406 - log/train6.log - INFO -               IND: precision:  45.80%; recall:  26.72%; FB1:  33.75  238

2019-02-21 18:11:57,406 - log/train6.log - INFO -               INS: precision:  66.58%; recall:  70.45%; FB1:  68.46  401

2019-02-21 18:11:57,406 - log/train6.log - INFO -                 L: precision:  60.00%; recall:  53.96%; FB1:  56.82  545

2019-02-21 18:11:57,406 - log/train6.log - INFO -                 P: precision:  86.96%; recall:  92.08%; FB1:  89.45  575

2019-02-21 18:11:57,406 - log/train6.log - INFO -               PRO: precision:  39.53%; recall:  19.16%; FB1:  25.81  253

2019-02-21 18:11:57,409 - log/train6.log - INFO - evaluate:test
2019-02-21 18:11:58,883 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1612 phrases; correct: 1375.

2019-02-21 18:11:58,883 - log/train6.log - INFO - accuracy:  96.89%; precision:  85.30%; recall:  83.49%; FB1:  84.38

2019-02-21 18:11:58,883 - log/train6.log - INFO -                 C: precision:  88.98%; recall:  91.84%; FB1:  90.39  1062

2019-02-21 18:11:58,883 - log/train6.log - INFO -               IND: precision:  64.00%; recall:  68.09%; FB1:  65.98  50

2019-02-21 18:11:58,883 - log/train6.log - INFO -               INS: precision:  67.03%; recall:  64.21%; FB1:  65.59  91

2019-02-21 18:11:58,883 - log/train6.log - INFO -                 L: precision:  66.32%; recall:  61.17%; FB1:  63.64  95

2019-02-21 18:11:58,883 - log/train6.log - INFO -                 P: precision:  88.94%; recall:  94.61%; FB1:  91.69  217

2019-02-21 18:11:58,883 - log/train6.log - INFO -               PRO: precision:  83.51%; recall:  47.93%; FB1:  60.90  97

2019-02-21 18:12:00,951 - log/train6.log - INFO - iteration:32 step:100/10100, NER loss: 1.012712
2019-02-21 18:12:03,050 - log/train6.log - INFO - iteration:32 step:200/10100, NER loss: 1.048306
2019-02-21 18:12:05,022 - log/train6.log - INFO - iteration:32 step:300/10100, NER loss: 0.933731
2019-02-21 18:12:07,014 - log/train6.log - INFO - iteration:32 step:400/10100, NER loss: 0.777316
2019-02-21 18:12:09,240 - log/train6.log - INFO - iteration:32 step:500/10100, NER loss: 0.793759
2019-02-21 18:12:11,306 - log/train6.log - INFO - iteration:32 step:600/10100, NER loss: 0.848363
2019-02-21 18:12:13,505 - log/train6.log - INFO - iteration:32 step:700/10100, NER loss: 0.911451
2019-02-21 18:12:15,748 - log/train6.log - INFO - iteration:32 step:800/10100, NER loss: 1.000984
2019-02-21 18:12:17,873 - log/train6.log - INFO - iteration:32 step:900/10100, NER loss: 1.019595
2019-02-21 18:12:20,081 - log/train6.log - INFO - iteration:32 step:1000/10100, NER loss: 0.829223
2019-02-21 18:12:22,349 - log/train6.log - INFO - iteration:32 step:1100/10100, NER loss: 0.878299
2019-02-21 18:12:24,439 - log/train6.log - INFO - iteration:32 step:1200/10100, NER loss: 0.880746
2019-02-21 18:12:26,578 - log/train6.log - INFO - iteration:32 step:1300/10100, NER loss: 1.003971
2019-02-21 18:12:28,715 - log/train6.log - INFO - iteration:32 step:1400/10100, NER loss: 0.878528
2019-02-21 18:12:30,887 - log/train6.log - INFO - iteration:32 step:1500/10100, NER loss: 0.918231
2019-02-21 18:12:33,066 - log/train6.log - INFO - iteration:32 step:1600/10100, NER loss: 1.033392
2019-02-21 18:12:35,332 - log/train6.log - INFO - iteration:32 step:1700/10100, NER loss: 1.122343
2019-02-21 18:12:37,692 - log/train6.log - INFO - iteration:32 step:1800/10100, NER loss: 0.873862
2019-02-21 18:12:39,867 - log/train6.log - INFO - iteration:32 step:1900/10100, NER loss: 0.903787
2019-02-21 18:12:44,032 - log/train6.log - INFO - iteration:32 step:2000/10100, NER loss: 1.459448
2019-02-21 18:12:46,314 - log/train6.log - INFO - iteration:32 step:2100/10100, NER loss: 0.892044
2019-02-21 18:12:48,689 - log/train6.log - INFO - iteration:32 step:2200/10100, NER loss: 0.964344
2019-02-21 18:12:50,933 - log/train6.log - INFO - iteration:32 step:2300/10100, NER loss: 1.104443
2019-02-21 18:12:52,886 - log/train6.log - INFO - iteration:32 step:2400/10100, NER loss: 0.716934
2019-02-21 18:12:55,104 - log/train6.log - INFO - iteration:32 step:2500/10100, NER loss: 0.922811
2019-02-21 18:12:57,270 - log/train6.log - INFO - iteration:32 step:2600/10100, NER loss: 0.779379
2019-02-21 18:12:59,298 - log/train6.log - INFO - iteration:32 step:2700/10100, NER loss: 0.711159
2019-02-21 18:13:01,516 - log/train6.log - INFO - iteration:32 step:2800/10100, NER loss: 0.887043
2019-02-21 18:13:03,735 - log/train6.log - INFO - iteration:32 step:2900/10100, NER loss: 0.821989
2019-02-21 18:13:06,205 - log/train6.log - INFO - iteration:32 step:3000/10100, NER loss: 1.038205
2019-02-21 18:13:08,494 - log/train6.log - INFO - iteration:32 step:3100/10100, NER loss: 1.135181
2019-02-21 18:13:10,682 - log/train6.log - INFO - iteration:32 step:3200/10100, NER loss: 0.832578
2019-02-21 18:13:12,928 - log/train6.log - INFO - iteration:32 step:3300/10100, NER loss: 0.883295
2019-02-21 18:13:15,343 - log/train6.log - INFO - iteration:32 step:3400/10100, NER loss: 1.041517
2019-02-21 18:13:17,792 - log/train6.log - INFO - iteration:32 step:3500/10100, NER loss: 0.898652
2019-02-21 18:13:19,988 - log/train6.log - INFO - iteration:32 step:3600/10100, NER loss: 0.819936
2019-02-21 18:13:22,187 - log/train6.log - INFO - iteration:32 step:3700/10100, NER loss: 0.881586
2019-02-21 18:13:24,329 - log/train6.log - INFO - iteration:32 step:3800/10100, NER loss: 0.995420
2019-02-21 18:13:26,405 - log/train6.log - INFO - iteration:32 step:3900/10100, NER loss: 0.946445
2019-02-21 18:13:28,700 - log/train6.log - INFO - iteration:32 step:4000/10100, NER loss: 0.908641
2019-02-21 18:13:30,784 - log/train6.log - INFO - iteration:32 step:4100/10100, NER loss: 0.884412
2019-02-21 18:13:33,006 - log/train6.log - INFO - iteration:32 step:4200/10100, NER loss: 1.113734
2019-02-21 18:13:35,266 - log/train6.log - INFO - iteration:32 step:4300/10100, NER loss: 0.986948
2019-02-21 18:13:37,455 - log/train6.log - INFO - iteration:32 step:4400/10100, NER loss: 0.934043
2019-02-21 18:13:39,623 - log/train6.log - INFO - iteration:32 step:4500/10100, NER loss: 0.900003
2019-02-21 18:13:41,955 - log/train6.log - INFO - iteration:32 step:4600/10100, NER loss: 0.946992
2019-02-21 18:13:44,338 - log/train6.log - INFO - iteration:32 step:4700/10100, NER loss: 0.974693
2019-02-21 18:13:46,699 - log/train6.log - INFO - iteration:32 step:4800/10100, NER loss: 1.272029
2019-02-21 18:13:48,949 - log/train6.log - INFO - iteration:32 step:4900/10100, NER loss: 1.241992
2019-02-21 18:13:53,414 - log/train6.log - INFO - iteration:32 step:5000/10100, NER loss: 1.984928
2019-02-21 18:13:55,519 - log/train6.log - INFO - iteration:32 step:5100/10100, NER loss: 1.028243
2019-02-21 18:13:57,663 - log/train6.log - INFO - iteration:32 step:5200/10100, NER loss: 0.961634
2019-02-21 18:13:59,996 - log/train6.log - INFO - iteration:32 step:5300/10100, NER loss: 1.001640
2019-02-21 18:14:02,108 - log/train6.log - INFO - iteration:32 step:5400/10100, NER loss: 0.845199
2019-02-21 18:14:04,487 - log/train6.log - INFO - iteration:32 step:5500/10100, NER loss: 1.065958
2019-02-21 18:14:06,663 - log/train6.log - INFO - iteration:32 step:5600/10100, NER loss: 0.905741
2019-02-21 18:14:08,969 - log/train6.log - INFO - iteration:32 step:5700/10100, NER loss: 1.136207
2019-02-21 18:14:11,066 - log/train6.log - INFO - iteration:32 step:5800/10100, NER loss: 0.839855
2019-02-21 18:14:13,561 - log/train6.log - INFO - iteration:32 step:5900/10100, NER loss: 1.102272
2019-02-21 18:14:15,772 - log/train6.log - INFO - iteration:32 step:6000/10100, NER loss: 1.003676
2019-02-21 18:14:20,128 - log/train6.log - INFO - iteration:32 step:6100/10100, NER loss: 1.565189
2019-02-21 18:14:22,183 - log/train6.log - INFO - iteration:32 step:6200/10100, NER loss: 0.831183
2019-02-21 18:14:24,581 - log/train6.log - INFO - iteration:32 step:6300/10100, NER loss: 1.146910
2019-02-21 18:14:26,827 - log/train6.log - INFO - iteration:32 step:6400/10100, NER loss: 1.067269
2019-02-21 18:14:28,925 - log/train6.log - INFO - iteration:32 step:6500/10100, NER loss: 0.907755
2019-02-21 18:14:31,220 - log/train6.log - INFO - iteration:32 step:6600/10100, NER loss: 0.935370
2019-02-21 18:14:33,644 - log/train6.log - INFO - iteration:32 step:6700/10100, NER loss: 1.230442
2019-02-21 18:14:35,909 - log/train6.log - INFO - iteration:32 step:6800/10100, NER loss: 1.084582
2019-02-21 18:14:38,204 - log/train6.log - INFO - iteration:32 step:6900/10100, NER loss: 0.969588
2019-02-21 18:14:40,164 - log/train6.log - INFO - iteration:32 step:7000/10100, NER loss: 0.660939
2019-02-21 18:14:42,382 - log/train6.log - INFO - iteration:32 step:7100/10100, NER loss: 0.916225
2019-02-21 18:14:44,484 - log/train6.log - INFO - iteration:32 step:7200/10100, NER loss: 0.839976
2019-02-21 18:14:46,704 - log/train6.log - INFO - iteration:32 step:7300/10100, NER loss: 1.030365
2019-02-21 18:14:48,764 - log/train6.log - INFO - iteration:32 step:7400/10100, NER loss: 0.704815
2019-02-21 18:14:51,041 - log/train6.log - INFO - iteration:32 step:7500/10100, NER loss: 0.975822
2019-02-21 18:14:53,156 - log/train6.log - INFO - iteration:32 step:7600/10100, NER loss: 0.885236
2019-02-21 18:14:55,262 - log/train6.log - INFO - iteration:32 step:7700/10100, NER loss: 0.809182
2019-02-21 18:14:57,566 - log/train6.log - INFO - iteration:32 step:7800/10100, NER loss: 0.989157
2019-02-21 18:14:59,946 - log/train6.log - INFO - iteration:32 step:7900/10100, NER loss: 1.081260
2019-02-21 18:15:02,059 - log/train6.log - INFO - iteration:32 step:8000/10100, NER loss: 0.849950
2019-02-21 18:15:04,180 - log/train6.log - INFO - iteration:32 step:8100/10100, NER loss: 0.811348
2019-02-21 18:15:06,269 - log/train6.log - INFO - iteration:32 step:8200/10100, NER loss: 0.858202
2019-02-21 18:15:08,409 - log/train6.log - INFO - iteration:32 step:8300/10100, NER loss: 0.771327
2019-02-21 18:15:10,741 - log/train6.log - INFO - iteration:32 step:8400/10100, NER loss: 1.146252
2019-02-21 18:15:12,937 - log/train6.log - INFO - iteration:32 step:8500/10100, NER loss: 1.151385
2019-02-21 18:15:15,353 - log/train6.log - INFO - iteration:32 step:8600/10100, NER loss: 1.111697
2019-02-21 18:15:18,259 - log/train6.log - INFO - iteration:32 step:8700/10100, NER loss: 1.382437
2019-02-21 18:15:20,402 - log/train6.log - INFO - iteration:32 step:8800/10100, NER loss: 0.888147
2019-02-21 18:15:22,475 - log/train6.log - INFO - iteration:32 step:8900/10100, NER loss: 1.033903
2019-02-21 18:15:24,764 - log/train6.log - INFO - iteration:32 step:9000/10100, NER loss: 1.076713
2019-02-21 18:15:27,013 - log/train6.log - INFO - iteration:32 step:9100/10100, NER loss: 0.961610
2019-02-21 18:15:29,087 - log/train6.log - INFO - iteration:32 step:9200/10100, NER loss: 0.781843
2019-02-21 18:15:30,971 - log/train6.log - INFO - iteration:32 step:9300/10100, NER loss: 0.627849
2019-02-21 18:15:33,170 - log/train6.log - INFO - iteration:32 step:9400/10100, NER loss: 1.093130
2019-02-21 18:15:35,481 - log/train6.log - INFO - iteration:32 step:9500/10100, NER loss: 1.104099
2019-02-21 18:15:37,785 - log/train6.log - INFO - iteration:32 step:9600/10100, NER loss: 0.940714
2019-02-21 18:15:39,889 - log/train6.log - INFO - iteration:32 step:9700/10100, NER loss: 0.940788
2019-02-21 18:15:42,132 - log/train6.log - INFO - iteration:32 step:9800/10100, NER loss: 0.917961
2019-02-21 18:15:44,245 - log/train6.log - INFO - iteration:32 step:9900/10100, NER loss: 0.900451
2019-02-21 18:15:46,685 - log/train6.log - INFO - iteration:32 step:10000/10100, NER loss: 1.250767
2019-02-21 18:15:48,974 - log/train6.log - INFO - iteration:33 step:0/10100, NER loss: 0.854194
2019-02-21 18:15:48,974 - log/train6.log - INFO - evaluate:dev
2019-02-21 18:15:55,438 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5524 phrases; correct: 4299.

2019-02-21 18:15:55,438 - log/train6.log - INFO - accuracy:  95.37%; precision:  77.82%; recall:  73.52%; FB1:  75.61

2019-02-21 18:15:55,438 - log/train6.log - INFO -                 C: precision:  88.29%; recall:  87.19%; FB1:  87.74  3347

2019-02-21 18:15:55,438 - log/train6.log - INFO -               IND: precision:  54.60%; recall:  21.81%; FB1:  31.17  163

2019-02-21 18:15:55,438 - log/train6.log - INFO -               INS: precision:  72.40%; recall:  69.92%; FB1:  71.14  366

2019-02-21 18:15:55,438 - log/train6.log - INFO -                 L: precision:  53.20%; recall:  52.15%; FB1:  52.67  594

2019-02-21 18:15:55,438 - log/train6.log - INFO -                 P: precision:  89.09%; recall:  91.71%; FB1:  90.38  559

2019-02-21 18:15:55,438 - log/train6.log - INFO -               PRO: precision:  35.56%; recall:  33.72%; FB1:  34.61  495

2019-02-21 18:15:55,442 - log/train6.log - INFO - evaluate:test
2019-02-21 18:15:56,909 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1660 phrases; correct: 1396.

2019-02-21 18:15:56,909 - log/train6.log - INFO - accuracy:  96.92%; precision:  84.10%; recall:  84.76%; FB1:  84.43

2019-02-21 18:15:56,909 - log/train6.log - INFO -                 C: precision:  89.68%; recall:  91.25%; FB1:  90.46  1047

2019-02-21 18:15:56,909 - log/train6.log - INFO -               IND: precision:  75.00%; recall:  63.83%; FB1:  68.97  40

2019-02-21 18:15:56,909 - log/train6.log - INFO -               INS: precision:  70.11%; recall:  64.21%; FB1:  67.03  87

2019-02-21 18:15:56,909 - log/train6.log - INFO -                 L: precision:  59.26%; recall:  62.14%; FB1:  60.66  108

2019-02-21 18:15:56,909 - log/train6.log - INFO -                 P: precision:  90.14%; recall:  94.12%; FB1:  92.09  213

2019-02-21 18:15:56,909 - log/train6.log - INFO -               PRO: precision:  66.67%; recall:  65.09%; FB1:  65.87  165

2019-02-21 18:15:58,992 - log/train6.log - INFO - iteration:33 step:100/10100, NER loss: 0.766788
2019-02-21 18:16:01,052 - log/train6.log - INFO - iteration:33 step:200/10100, NER loss: 0.904286
2019-02-21 18:16:03,107 - log/train6.log - INFO - iteration:33 step:300/10100, NER loss: 0.985406
2019-02-21 18:16:05,365 - log/train6.log - INFO - iteration:33 step:400/10100, NER loss: 0.886287
2019-02-21 18:16:07,425 - log/train6.log - INFO - iteration:33 step:500/10100, NER loss: 1.013150
2019-02-21 18:16:10,446 - log/train6.log - INFO - iteration:33 step:600/10100, NER loss: 1.519690
2019-02-21 18:16:12,501 - log/train6.log - INFO - iteration:33 step:700/10100, NER loss: 0.762672
2019-02-21 18:16:14,617 - log/train6.log - INFO - iteration:33 step:800/10100, NER loss: 0.718765
2019-02-21 18:16:16,920 - log/train6.log - INFO - iteration:33 step:900/10100, NER loss: 1.218481
2019-02-21 18:16:19,439 - log/train6.log - INFO - iteration:33 step:1000/10100, NER loss: 1.207887
2019-02-21 18:16:21,492 - log/train6.log - INFO - iteration:33 step:1100/10100, NER loss: 0.777598
2019-02-21 18:16:23,829 - log/train6.log - INFO - iteration:33 step:1200/10100, NER loss: 0.847469
2019-02-21 18:16:25,898 - log/train6.log - INFO - iteration:33 step:1300/10100, NER loss: 0.672635
2019-02-21 18:16:28,117 - log/train6.log - INFO - iteration:33 step:1400/10100, NER loss: 0.903166
2019-02-21 18:16:30,410 - log/train6.log - INFO - iteration:33 step:1500/10100, NER loss: 0.934573
2019-02-21 18:16:32,558 - log/train6.log - INFO - iteration:33 step:1600/10100, NER loss: 0.706320
2019-02-21 18:16:34,587 - log/train6.log - INFO - iteration:33 step:1700/10100, NER loss: 0.967279
2019-02-21 18:16:36,856 - log/train6.log - INFO - iteration:33 step:1800/10100, NER loss: 1.000587
2019-02-21 18:16:39,172 - log/train6.log - INFO - iteration:33 step:1900/10100, NER loss: 1.013088
2019-02-21 18:16:41,437 - log/train6.log - INFO - iteration:33 step:2000/10100, NER loss: 0.937158
2019-02-21 18:16:43,555 - log/train6.log - INFO - iteration:33 step:2100/10100, NER loss: 0.833865
2019-02-21 18:16:45,752 - log/train6.log - INFO - iteration:33 step:2200/10100, NER loss: 1.260897
2019-02-21 18:16:47,879 - log/train6.log - INFO - iteration:33 step:2300/10100, NER loss: 0.868655
2019-02-21 18:16:49,908 - log/train6.log - INFO - iteration:33 step:2400/10100, NER loss: 0.788112
2019-02-21 18:16:51,898 - log/train6.log - INFO - iteration:33 step:2500/10100, NER loss: 0.861284
2019-02-21 18:16:54,175 - log/train6.log - INFO - iteration:33 step:2600/10100, NER loss: 1.199117
2019-02-21 18:16:56,479 - log/train6.log - INFO - iteration:33 step:2700/10100, NER loss: 0.769153
2019-02-21 18:16:58,520 - log/train6.log - INFO - iteration:33 step:2800/10100, NER loss: 0.866234
2019-02-21 18:17:00,740 - log/train6.log - INFO - iteration:33 step:2900/10100, NER loss: 0.974935
2019-02-21 18:17:02,932 - log/train6.log - INFO - iteration:33 step:3000/10100, NER loss: 1.007874
2019-02-21 18:17:05,121 - log/train6.log - INFO - iteration:33 step:3100/10100, NER loss: 0.947041
2019-02-21 18:17:07,332 - log/train6.log - INFO - iteration:33 step:3200/10100, NER loss: 0.818597
2019-02-21 18:17:09,388 - log/train6.log - INFO - iteration:33 step:3300/10100, NER loss: 0.747955
2019-02-21 18:17:11,668 - log/train6.log - INFO - iteration:33 step:3400/10100, NER loss: 1.122117
2019-02-21 18:17:13,687 - log/train6.log - INFO - iteration:33 step:3500/10100, NER loss: 0.731130
2019-02-21 18:17:17,658 - log/train6.log - INFO - iteration:33 step:3600/10100, NER loss: 1.101222
2019-02-21 18:17:19,738 - log/train6.log - INFO - iteration:33 step:3700/10100, NER loss: 0.943225
2019-02-21 18:17:21,808 - log/train6.log - INFO - iteration:33 step:3800/10100, NER loss: 0.769581
2019-02-21 18:17:24,272 - log/train6.log - INFO - iteration:33 step:3900/10100, NER loss: 1.063347
2019-02-21 18:17:26,372 - log/train6.log - INFO - iteration:33 step:4000/10100, NER loss: 0.868514
2019-02-21 18:17:28,421 - log/train6.log - INFO - iteration:33 step:4100/10100, NER loss: 0.923274
2019-02-21 18:17:30,785 - log/train6.log - INFO - iteration:33 step:4200/10100, NER loss: 0.993099
2019-02-21 18:17:32,994 - log/train6.log - INFO - iteration:33 step:4300/10100, NER loss: 0.782648
2019-02-21 18:17:34,948 - log/train6.log - INFO - iteration:33 step:4400/10100, NER loss: 0.716171
2019-02-21 18:17:37,314 - log/train6.log - INFO - iteration:33 step:4500/10100, NER loss: 1.064916
2019-02-21 18:17:39,609 - log/train6.log - INFO - iteration:33 step:4600/10100, NER loss: 1.279171
2019-02-21 18:17:41,877 - log/train6.log - INFO - iteration:33 step:4700/10100, NER loss: 0.950907
2019-02-21 18:17:44,251 - log/train6.log - INFO - iteration:33 step:4800/10100, NER loss: 1.109736
2019-02-21 18:17:46,426 - log/train6.log - INFO - iteration:33 step:4900/10100, NER loss: 0.934455
2019-02-21 18:17:48,743 - log/train6.log - INFO - iteration:33 step:5000/10100, NER loss: 0.801214
2019-02-21 18:17:50,877 - log/train6.log - INFO - iteration:33 step:5100/10100, NER loss: 0.783650
2019-02-21 18:17:52,934 - log/train6.log - INFO - iteration:33 step:5200/10100, NER loss: 0.831885
2019-02-21 18:17:57,103 - log/train6.log - INFO - iteration:33 step:5300/10100, NER loss: 1.313636
2019-02-21 18:17:59,620 - log/train6.log - INFO - iteration:33 step:5400/10100, NER loss: 1.039621
2019-02-21 18:18:01,936 - log/train6.log - INFO - iteration:33 step:5500/10100, NER loss: 0.848178
2019-02-21 18:18:04,363 - log/train6.log - INFO - iteration:33 step:5600/10100, NER loss: 1.034682
2019-02-21 18:18:08,983 - log/train6.log - INFO - iteration:33 step:5700/10100, NER loss: 1.479831
2019-02-21 18:18:11,193 - log/train6.log - INFO - iteration:33 step:5800/10100, NER loss: 1.184724
2019-02-21 18:18:13,600 - log/train6.log - INFO - iteration:33 step:5900/10100, NER loss: 0.982563
2019-02-21 18:18:15,828 - log/train6.log - INFO - iteration:33 step:6000/10100, NER loss: 1.081442
2019-02-21 18:18:18,053 - log/train6.log - INFO - iteration:33 step:6100/10100, NER loss: 0.972258
2019-02-21 18:18:20,456 - log/train6.log - INFO - iteration:33 step:6200/10100, NER loss: 0.911293
2019-02-21 18:18:22,685 - log/train6.log - INFO - iteration:33 step:6300/10100, NER loss: 0.809950
2019-02-21 18:18:24,851 - log/train6.log - INFO - iteration:33 step:6400/10100, NER loss: 0.834630
2019-02-21 18:18:27,259 - log/train6.log - INFO - iteration:33 step:6500/10100, NER loss: 0.999936
2019-02-21 18:18:29,602 - log/train6.log - INFO - iteration:33 step:6600/10100, NER loss: 1.004048
2019-02-21 18:18:31,745 - log/train6.log - INFO - iteration:33 step:6700/10100, NER loss: 0.784949
2019-02-21 18:18:34,035 - log/train6.log - INFO - iteration:33 step:6800/10100, NER loss: 0.790631
2019-02-21 18:18:36,189 - log/train6.log - INFO - iteration:33 step:6900/10100, NER loss: 0.825662
2019-02-21 18:18:38,362 - log/train6.log - INFO - iteration:33 step:7000/10100, NER loss: 0.768211
2019-02-21 18:18:40,667 - log/train6.log - INFO - iteration:33 step:7100/10100, NER loss: 0.983093
2019-02-21 18:18:42,766 - log/train6.log - INFO - iteration:33 step:7200/10100, NER loss: 0.741537
2019-02-21 18:18:45,121 - log/train6.log - INFO - iteration:33 step:7300/10100, NER loss: 1.076120
2019-02-21 18:18:47,319 - log/train6.log - INFO - iteration:33 step:7400/10100, NER loss: 0.974912
2019-02-21 18:18:49,599 - log/train6.log - INFO - iteration:33 step:7500/10100, NER loss: 1.052406
2019-02-21 18:18:51,885 - log/train6.log - INFO - iteration:33 step:7600/10100, NER loss: 1.119106
2019-02-21 18:18:54,273 - log/train6.log - INFO - iteration:33 step:7700/10100, NER loss: 1.295229
2019-02-21 18:18:56,092 - log/train6.log - INFO - iteration:33 step:7800/10100, NER loss: 0.710591
2019-02-21 18:18:58,186 - log/train6.log - INFO - iteration:33 step:7900/10100, NER loss: 0.784642
2019-02-21 18:19:00,277 - log/train6.log - INFO - iteration:33 step:8000/10100, NER loss: 0.970408
2019-02-21 18:19:02,466 - log/train6.log - INFO - iteration:33 step:8100/10100, NER loss: 0.753291
2019-02-21 18:19:04,518 - log/train6.log - INFO - iteration:33 step:8200/10100, NER loss: 0.809860
2019-02-21 18:19:06,588 - log/train6.log - INFO - iteration:33 step:8300/10100, NER loss: 0.688037
2019-02-21 18:19:08,853 - log/train6.log - INFO - iteration:33 step:8400/10100, NER loss: 0.875238
2019-02-21 18:19:10,989 - log/train6.log - INFO - iteration:33 step:8500/10100, NER loss: 0.803119
2019-02-21 18:19:13,317 - log/train6.log - INFO - iteration:33 step:8600/10100, NER loss: 1.016588
2019-02-21 18:19:15,594 - log/train6.log - INFO - iteration:33 step:8700/10100, NER loss: 1.034736
2019-02-21 18:19:17,852 - log/train6.log - INFO - iteration:33 step:8800/10100, NER loss: 1.030114
2019-02-21 18:19:20,150 - log/train6.log - INFO - iteration:33 step:8900/10100, NER loss: 1.079190
2019-02-21 18:19:22,408 - log/train6.log - INFO - iteration:33 step:9000/10100, NER loss: 0.851842
2019-02-21 18:19:24,623 - log/train6.log - INFO - iteration:33 step:9100/10100, NER loss: 1.078555
2019-02-21 18:19:26,684 - log/train6.log - INFO - iteration:33 step:9200/10100, NER loss: 0.708915
2019-02-21 18:19:28,798 - log/train6.log - INFO - iteration:33 step:9300/10100, NER loss: 0.977755
2019-02-21 18:19:30,924 - log/train6.log - INFO - iteration:33 step:9400/10100, NER loss: 0.990739
2019-02-21 18:19:33,132 - log/train6.log - INFO - iteration:33 step:9500/10100, NER loss: 0.945476
2019-02-21 18:19:35,506 - log/train6.log - INFO - iteration:33 step:9600/10100, NER loss: 1.079252
2019-02-21 18:19:37,938 - log/train6.log - INFO - iteration:33 step:9700/10100, NER loss: 1.326023
2019-02-21 18:19:40,192 - log/train6.log - INFO - iteration:33 step:9800/10100, NER loss: 0.817346
2019-02-21 18:19:42,584 - log/train6.log - INFO - iteration:33 step:9900/10100, NER loss: 1.011378
2019-02-21 18:19:44,891 - log/train6.log - INFO - iteration:33 step:10000/10100, NER loss: 0.904861
2019-02-21 18:19:47,316 - log/train6.log - INFO - iteration:34 step:0/10100, NER loss: 1.127324
2019-02-21 18:19:47,316 - log/train6.log - INFO - evaluate:dev
2019-02-21 18:19:53,797 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 6157 phrases; correct: 4413.

2019-02-21 18:19:53,797 - log/train6.log - INFO - accuracy:  93.92%; precision:  71.67%; recall:  75.47%; FB1:  73.53

2019-02-21 18:19:53,797 - log/train6.log - INFO -                 C: precision:  82.95%; recall:  89.02%; FB1:  85.88  3637

2019-02-21 18:19:53,798 - log/train6.log - INFO -               IND: precision:  34.55%; recall:  37.01%; FB1:  35.74  437

2019-02-21 18:19:53,798 - log/train6.log - INFO -               INS: precision:  50.56%; recall:  71.50%; FB1:  59.23  536

2019-02-21 18:19:53,798 - log/train6.log - INFO -                 L: precision:  60.75%; recall:  56.44%; FB1:  58.51  563

2019-02-21 18:19:53,798 - log/train6.log - INFO -                 P: precision:  87.11%; recall:  92.08%; FB1:  89.53  574

2019-02-21 18:19:53,798 - log/train6.log - INFO -               PRO: precision:  32.20%; recall:  25.29%; FB1:  28.33  410

2019-02-21 18:19:53,801 - log/train6.log - INFO - evaluate:test
2019-02-21 18:19:55,274 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1751 phrases; correct: 1388.

2019-02-21 18:19:55,274 - log/train6.log - INFO - accuracy:  96.05%; precision:  79.27%; recall:  84.27%; FB1:  81.70

2019-02-21 18:19:55,274 - log/train6.log - INFO -                 C: precision:  87.07%; recall:  92.91%; FB1:  89.89  1098

2019-02-21 18:19:55,274 - log/train6.log - INFO -               IND: precision:  38.04%; recall:  74.47%; FB1:  50.36  92

2019-02-21 18:19:55,274 - log/train6.log - INFO -               INS: precision:  55.20%; recall:  72.63%; FB1:  62.73  125

2019-02-21 18:19:55,274 - log/train6.log - INFO -                 L: precision:  64.77%; recall:  55.34%; FB1:  59.69  88

2019-02-21 18:19:55,274 - log/train6.log - INFO -                 P: precision:  91.90%; recall:  94.61%; FB1:  93.24  210

2019-02-21 18:19:55,274 - log/train6.log - INFO -               PRO: precision:  56.52%; recall:  46.15%; FB1:  50.81  138

2019-02-21 18:19:57,641 - log/train6.log - INFO - iteration:34 step:100/10100, NER loss: 1.166870
2019-02-21 18:19:59,962 - log/train6.log - INFO - iteration:34 step:200/10100, NER loss: 1.098930
2019-02-21 18:20:02,383 - log/train6.log - INFO - iteration:34 step:300/10100, NER loss: 1.101538
2019-02-21 18:20:04,424 - log/train6.log - INFO - iteration:34 step:400/10100, NER loss: 0.765130
2019-02-21 18:20:06,687 - log/train6.log - INFO - iteration:34 step:500/10100, NER loss: 0.862853
2019-02-21 18:20:08,722 - log/train6.log - INFO - iteration:34 step:600/10100, NER loss: 0.811033
2019-02-21 18:20:10,904 - log/train6.log - INFO - iteration:34 step:700/10100, NER loss: 1.117505
2019-02-21 18:20:12,991 - log/train6.log - INFO - iteration:34 step:800/10100, NER loss: 0.780577
2019-02-21 18:20:15,244 - log/train6.log - INFO - iteration:34 step:900/10100, NER loss: 0.855027
2019-02-21 18:20:19,749 - log/train6.log - INFO - iteration:34 step:1000/10100, NER loss: 2.129246
2019-02-21 18:20:21,946 - log/train6.log - INFO - iteration:34 step:1100/10100, NER loss: 0.909304
2019-02-21 18:20:23,929 - log/train6.log - INFO - iteration:34 step:1200/10100, NER loss: 0.802506
2019-02-21 18:20:25,983 - log/train6.log - INFO - iteration:34 step:1300/10100, NER loss: 0.802071
2019-02-21 18:20:28,180 - log/train6.log - INFO - iteration:34 step:1400/10100, NER loss: 0.753124
2019-02-21 18:20:30,233 - log/train6.log - INFO - iteration:34 step:1500/10100, NER loss: 0.818003
2019-02-21 18:20:32,435 - log/train6.log - INFO - iteration:34 step:1600/10100, NER loss: 0.856774
2019-02-21 18:20:34,594 - log/train6.log - INFO - iteration:34 step:1700/10100, NER loss: 1.020057
2019-02-21 18:20:36,811 - log/train6.log - INFO - iteration:34 step:1800/10100, NER loss: 0.986030
2019-02-21 18:20:39,099 - log/train6.log - INFO - iteration:34 step:1900/10100, NER loss: 1.061821
2019-02-21 18:20:41,400 - log/train6.log - INFO - iteration:34 step:2000/10100, NER loss: 0.892404
2019-02-21 18:20:43,543 - log/train6.log - INFO - iteration:34 step:2100/10100, NER loss: 0.907596
2019-02-21 18:20:45,744 - log/train6.log - INFO - iteration:34 step:2200/10100, NER loss: 0.756710
2019-02-21 18:20:47,866 - log/train6.log - INFO - iteration:34 step:2300/10100, NER loss: 0.737219
2019-02-21 18:20:50,043 - log/train6.log - INFO - iteration:34 step:2400/10100, NER loss: 0.778072
2019-02-21 18:20:52,226 - log/train6.log - INFO - iteration:34 step:2500/10100, NER loss: 0.962475
2019-02-21 18:20:54,472 - log/train6.log - INFO - iteration:34 step:2600/10100, NER loss: 0.969771
2019-02-21 18:20:56,635 - log/train6.log - INFO - iteration:34 step:2700/10100, NER loss: 0.888153
2019-02-21 18:21:01,080 - log/train6.log - INFO - iteration:34 step:2800/10100, NER loss: 2.747556
2019-02-21 18:21:03,210 - log/train6.log - INFO - iteration:34 step:2900/10100, NER loss: 0.911896
2019-02-21 18:21:05,556 - log/train6.log - INFO - iteration:34 step:3000/10100, NER loss: 1.165860
2019-02-21 18:21:07,684 - log/train6.log - INFO - iteration:34 step:3100/10100, NER loss: 0.728378
2019-02-21 18:21:10,315 - log/train6.log - INFO - iteration:34 step:3200/10100, NER loss: 1.218748
2019-02-21 18:21:12,489 - log/train6.log - INFO - iteration:34 step:3300/10100, NER loss: 0.816849
2019-02-21 18:21:14,855 - log/train6.log - INFO - iteration:34 step:3400/10100, NER loss: 0.913488
2019-02-21 18:21:16,884 - log/train6.log - INFO - iteration:34 step:3500/10100, NER loss: 0.667911
2019-02-21 18:21:19,284 - log/train6.log - INFO - iteration:34 step:3600/10100, NER loss: 0.949759
2019-02-21 18:21:21,384 - log/train6.log - INFO - iteration:34 step:3700/10100, NER loss: 0.805157
2019-02-21 18:21:23,737 - log/train6.log - INFO - iteration:34 step:3800/10100, NER loss: 0.987019
2019-02-21 18:21:25,940 - log/train6.log - INFO - iteration:34 step:3900/10100, NER loss: 0.999482
2019-02-21 18:21:28,049 - log/train6.log - INFO - iteration:34 step:4000/10100, NER loss: 0.825941
2019-02-21 18:21:30,259 - log/train6.log - INFO - iteration:34 step:4100/10100, NER loss: 0.904802
2019-02-21 18:21:32,474 - log/train6.log - INFO - iteration:34 step:4200/10100, NER loss: 0.966156
2019-02-21 18:21:34,618 - log/train6.log - INFO - iteration:34 step:4300/10100, NER loss: 0.976659
2019-02-21 18:21:37,017 - log/train6.log - INFO - iteration:34 step:4400/10100, NER loss: 1.024608
2019-02-21 18:21:39,104 - log/train6.log - INFO - iteration:34 step:4500/10100, NER loss: 0.865830
2019-02-21 18:21:41,149 - log/train6.log - INFO - iteration:34 step:4600/10100, NER loss: 1.069063
2019-02-21 18:21:43,191 - log/train6.log - INFO - iteration:34 step:4700/10100, NER loss: 0.752459
2019-02-21 18:21:45,299 - log/train6.log - INFO - iteration:34 step:4800/10100, NER loss: 0.871534
2019-02-21 18:21:47,504 - log/train6.log - INFO - iteration:34 step:4900/10100, NER loss: 1.169741
2019-02-21 18:21:49,683 - log/train6.log - INFO - iteration:34 step:5000/10100, NER loss: 1.005678
2019-02-21 18:21:52,151 - log/train6.log - INFO - iteration:34 step:5100/10100, NER loss: 0.946662
2019-02-21 18:21:54,360 - log/train6.log - INFO - iteration:34 step:5200/10100, NER loss: 0.948740
2019-02-21 18:21:56,604 - log/train6.log - INFO - iteration:34 step:5300/10100, NER loss: 1.036644
2019-02-21 18:21:59,125 - log/train6.log - INFO - iteration:34 step:5400/10100, NER loss: 1.088578
2019-02-21 18:22:01,229 - log/train6.log - INFO - iteration:34 step:5500/10100, NER loss: 0.815122
2019-02-21 18:22:03,503 - log/train6.log - INFO - iteration:34 step:5600/10100, NER loss: 0.979612
2019-02-21 18:22:05,429 - log/train6.log - INFO - iteration:34 step:5700/10100, NER loss: 0.919863
2019-02-21 18:22:07,736 - log/train6.log - INFO - iteration:34 step:5800/10100, NER loss: 1.140096
2019-02-21 18:22:09,866 - log/train6.log - INFO - iteration:34 step:5900/10100, NER loss: 0.782161
2019-02-21 18:22:11,940 - log/train6.log - INFO - iteration:34 step:6000/10100, NER loss: 0.990242
2019-02-21 18:22:13,836 - log/train6.log - INFO - iteration:34 step:6100/10100, NER loss: 0.753176
2019-02-21 18:22:16,017 - log/train6.log - INFO - iteration:34 step:6200/10100, NER loss: 0.773655
2019-02-21 18:22:18,395 - log/train6.log - INFO - iteration:34 step:6300/10100, NER loss: 1.011274
2019-02-21 18:22:20,647 - log/train6.log - INFO - iteration:34 step:6400/10100, NER loss: 0.941950
2019-02-21 18:22:22,947 - log/train6.log - INFO - iteration:34 step:6500/10100, NER loss: 1.180986
2019-02-21 18:22:25,471 - log/train6.log - INFO - iteration:34 step:6600/10100, NER loss: 1.065659
2019-02-21 18:22:27,638 - log/train6.log - INFO - iteration:34 step:6700/10100, NER loss: 0.839288
2019-02-21 18:22:29,877 - log/train6.log - INFO - iteration:34 step:6800/10100, NER loss: 0.839302
2019-02-21 18:22:31,949 - log/train6.log - INFO - iteration:34 step:6900/10100, NER loss: 0.970994
2019-02-21 18:22:34,108 - log/train6.log - INFO - iteration:34 step:7000/10100, NER loss: 0.889627
2019-02-21 18:22:36,333 - log/train6.log - INFO - iteration:34 step:7100/10100, NER loss: 0.843192
2019-02-21 18:22:38,764 - log/train6.log - INFO - iteration:34 step:7200/10100, NER loss: 1.051740
2019-02-21 18:22:41,225 - log/train6.log - INFO - iteration:34 step:7300/10100, NER loss: 1.191156
2019-02-21 18:22:43,573 - log/train6.log - INFO - iteration:34 step:7400/10100, NER loss: 0.850064
2019-02-21 18:22:45,982 - log/train6.log - INFO - iteration:34 step:7500/10100, NER loss: 1.143281
2019-02-21 18:22:48,263 - log/train6.log - INFO - iteration:34 step:7600/10100, NER loss: 0.983536
2019-02-21 18:22:50,404 - log/train6.log - INFO - iteration:34 step:7700/10100, NER loss: 0.793341
2019-02-21 18:22:52,709 - log/train6.log - INFO - iteration:34 step:7800/10100, NER loss: 0.839036
2019-02-21 18:22:54,633 - log/train6.log - INFO - iteration:34 step:7900/10100, NER loss: 0.673385
2019-02-21 18:22:56,738 - log/train6.log - INFO - iteration:34 step:8000/10100, NER loss: 1.016540
2019-02-21 18:22:58,895 - log/train6.log - INFO - iteration:34 step:8100/10100, NER loss: 0.914257
2019-02-21 18:23:01,110 - log/train6.log - INFO - iteration:34 step:8200/10100, NER loss: 1.017767
2019-02-21 18:23:03,510 - log/train6.log - INFO - iteration:34 step:8300/10100, NER loss: 1.026601
2019-02-21 18:23:06,226 - log/train6.log - INFO - iteration:34 step:8400/10100, NER loss: 1.069384
2019-02-21 18:23:08,599 - log/train6.log - INFO - iteration:34 step:8500/10100, NER loss: 0.909848
2019-02-21 18:23:10,893 - log/train6.log - INFO - iteration:34 step:8600/10100, NER loss: 1.199242
2019-02-21 18:23:13,195 - log/train6.log - INFO - iteration:34 step:8700/10100, NER loss: 0.910343
2019-02-21 18:23:15,235 - log/train6.log - INFO - iteration:34 step:8800/10100, NER loss: 0.978359
2019-02-21 18:23:17,427 - log/train6.log - INFO - iteration:34 step:8900/10100, NER loss: 0.928333
2019-02-21 18:23:19,683 - log/train6.log - INFO - iteration:34 step:9000/10100, NER loss: 1.086765
2019-02-21 18:23:21,870 - log/train6.log - INFO - iteration:34 step:9100/10100, NER loss: 0.813384
2019-02-21 18:23:24,241 - log/train6.log - INFO - iteration:34 step:9200/10100, NER loss: 1.137606
2019-02-21 18:23:26,480 - log/train6.log - INFO - iteration:34 step:9300/10100, NER loss: 1.030145
2019-02-21 18:23:30,467 - log/train6.log - INFO - iteration:34 step:9400/10100, NER loss: 1.394884
2019-02-21 18:23:32,891 - log/train6.log - INFO - iteration:34 step:9500/10100, NER loss: 1.008500
2019-02-21 18:23:34,925 - log/train6.log - INFO - iteration:34 step:9600/10100, NER loss: 1.283650
2019-02-21 18:23:37,161 - log/train6.log - INFO - iteration:34 step:9700/10100, NER loss: 0.990350
2019-02-21 18:23:39,318 - log/train6.log - INFO - iteration:34 step:9800/10100, NER loss: 0.743670
2019-02-21 18:23:41,668 - log/train6.log - INFO - iteration:34 step:9900/10100, NER loss: 1.134382
2019-02-21 18:23:43,832 - log/train6.log - INFO - iteration:34 step:10000/10100, NER loss: 0.844119
2019-02-21 18:23:45,881 - log/train6.log - INFO - iteration:35 step:0/10100, NER loss: 0.859976
2019-02-21 18:23:45,881 - log/train6.log - INFO - evaluate:dev
2019-02-21 18:23:52,427 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5424 phrases; correct: 4251.

2019-02-21 18:23:52,427 - log/train6.log - INFO - accuracy:  95.25%; precision:  78.37%; recall:  72.70%; FB1:  75.43

2019-02-21 18:23:52,427 - log/train6.log - INFO -                 C: precision:  87.05%; recall:  88.23%; FB1:  87.63  3435

2019-02-21 18:23:52,427 - log/train6.log - INFO -               IND: precision:  36.32%; recall:  34.80%; FB1:  35.54  391

2019-02-21 18:23:52,427 - log/train6.log - INFO -               INS: precision:  71.93%; recall:  69.66%; FB1:  70.78  367

2019-02-21 18:23:52,427 - log/train6.log - INFO -                 L: precision:  55.17%; recall:  49.34%; FB1:  52.09  542

2019-02-21 18:23:52,427 - log/train6.log - INFO -                 P: precision:  89.25%; recall:  91.71%; FB1:  90.46  558

2019-02-21 18:23:52,427 - log/train6.log - INFO -               PRO: precision:  44.27%; recall:  11.11%; FB1:  17.76  131

2019-02-21 18:23:52,430 - log/train6.log - INFO - evaluate:test
2019-02-21 18:23:53,902 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1613 phrases; correct: 1369.

2019-02-21 18:23:53,902 - log/train6.log - INFO - accuracy:  96.68%; precision:  84.87%; recall:  83.12%; FB1:  83.99

2019-02-21 18:23:53,903 - log/train6.log - INFO -                 C: precision:  89.92%; recall:  91.93%; FB1:  90.92  1052

2019-02-21 18:23:53,903 - log/train6.log - INFO -               IND: precision:  40.70%; recall:  74.47%; FB1:  52.63  86

2019-02-21 18:23:53,903 - log/train6.log - INFO -               INS: precision:  69.32%; recall:  64.21%; FB1:  66.67  88

2019-02-21 18:23:53,903 - log/train6.log - INFO -                 L: precision:  67.35%; recall:  64.08%; FB1:  65.67  98

2019-02-21 18:23:53,903 - log/train6.log - INFO -                 P: precision:  91.51%; recall:  95.10%; FB1:  93.27  212

2019-02-21 18:23:53,903 - log/train6.log - INFO -               PRO: precision:  87.01%; recall:  39.64%; FB1:  54.47  77

2019-02-21 18:23:55,768 - log/train6.log - INFO - iteration:35 step:100/10100, NER loss: 0.700160
2019-02-21 18:23:57,969 - log/train6.log - INFO - iteration:35 step:200/10100, NER loss: 0.855121
2019-02-21 18:24:00,024 - log/train6.log - INFO - iteration:35 step:300/10100, NER loss: 0.895642
2019-02-21 18:24:02,285 - log/train6.log - INFO - iteration:35 step:400/10100, NER loss: 0.872159
2019-02-21 18:24:04,454 - log/train6.log - INFO - iteration:35 step:500/10100, NER loss: 0.849555
2019-02-21 18:24:06,586 - log/train6.log - INFO - iteration:35 step:600/10100, NER loss: 0.990529
2019-02-21 18:24:08,792 - log/train6.log - INFO - iteration:35 step:700/10100, NER loss: 1.004405
2019-02-21 18:24:10,943 - log/train6.log - INFO - iteration:35 step:800/10100, NER loss: 0.968523
2019-02-21 18:24:13,236 - log/train6.log - INFO - iteration:35 step:900/10100, NER loss: 0.850549
2019-02-21 18:24:15,277 - log/train6.log - INFO - iteration:35 step:1000/10100, NER loss: 0.817817
2019-02-21 18:24:17,534 - log/train6.log - INFO - iteration:35 step:1100/10100, NER loss: 1.252514
2019-02-21 18:24:19,680 - log/train6.log - INFO - iteration:35 step:1200/10100, NER loss: 0.967924
2019-02-21 18:24:21,954 - log/train6.log - INFO - iteration:35 step:1300/10100, NER loss: 1.057566
2019-02-21 18:24:24,416 - log/train6.log - INFO - iteration:35 step:1400/10100, NER loss: 1.108602
2019-02-21 18:24:27,001 - log/train6.log - INFO - iteration:35 step:1500/10100, NER loss: 1.094376
2019-02-21 18:24:29,150 - log/train6.log - INFO - iteration:35 step:1600/10100, NER loss: 0.919871
2019-02-21 18:24:31,177 - log/train6.log - INFO - iteration:35 step:1700/10100, NER loss: 0.954278
2019-02-21 18:24:33,353 - log/train6.log - INFO - iteration:35 step:1800/10100, NER loss: 0.858939
2019-02-21 18:24:35,292 - log/train6.log - INFO - iteration:35 step:1900/10100, NER loss: 0.781015
2019-02-21 18:24:37,430 - log/train6.log - INFO - iteration:35 step:2000/10100, NER loss: 0.844303
2019-02-21 18:24:39,536 - log/train6.log - INFO - iteration:35 step:2100/10100, NER loss: 0.812965
2019-02-21 18:24:41,477 - log/train6.log - INFO - iteration:35 step:2200/10100, NER loss: 0.648704
2019-02-21 18:24:43,567 - log/train6.log - INFO - iteration:35 step:2300/10100, NER loss: 0.770999
2019-02-21 18:24:45,970 - log/train6.log - INFO - iteration:35 step:2400/10100, NER loss: 0.980561
2019-02-21 18:24:48,090 - log/train6.log - INFO - iteration:35 step:2500/10100, NER loss: 0.779878
2019-02-21 18:24:50,292 - log/train6.log - INFO - iteration:35 step:2600/10100, NER loss: 0.945283
2019-02-21 18:24:52,327 - log/train6.log - INFO - iteration:35 step:2700/10100, NER loss: 1.060359
2019-02-21 18:24:54,512 - log/train6.log - INFO - iteration:35 step:2800/10100, NER loss: 0.908689
2019-02-21 18:24:58,459 - log/train6.log - INFO - iteration:35 step:2900/10100, NER loss: 1.116176
2019-02-21 18:25:00,576 - log/train6.log - INFO - iteration:35 step:3000/10100, NER loss: 0.819028
2019-02-21 18:25:02,662 - log/train6.log - INFO - iteration:35 step:3100/10100, NER loss: 0.919194
2019-02-21 18:25:04,726 - log/train6.log - INFO - iteration:35 step:3200/10100, NER loss: 0.900156
2019-02-21 18:25:07,007 - log/train6.log - INFO - iteration:35 step:3300/10100, NER loss: 0.745164
2019-02-21 18:25:09,137 - log/train6.log - INFO - iteration:35 step:3400/10100, NER loss: 0.741011
2019-02-21 18:25:11,357 - log/train6.log - INFO - iteration:35 step:3500/10100, NER loss: 1.007731
2019-02-21 18:25:13,588 - log/train6.log - INFO - iteration:35 step:3600/10100, NER loss: 0.810660
2019-02-21 18:25:15,869 - log/train6.log - INFO - iteration:35 step:3700/10100, NER loss: 1.023941
2019-02-21 18:25:18,081 - log/train6.log - INFO - iteration:35 step:3800/10100, NER loss: 0.803762
2019-02-21 18:25:20,366 - log/train6.log - INFO - iteration:35 step:3900/10100, NER loss: 1.032737
2019-02-21 18:25:22,596 - log/train6.log - INFO - iteration:35 step:4000/10100, NER loss: 0.846708
2019-02-21 18:25:24,956 - log/train6.log - INFO - iteration:35 step:4100/10100, NER loss: 1.128353
2019-02-21 18:25:27,481 - log/train6.log - INFO - iteration:35 step:4200/10100, NER loss: 1.005383
2019-02-21 18:25:29,663 - log/train6.log - INFO - iteration:35 step:4300/10100, NER loss: 0.769849
2019-02-21 18:25:31,672 - log/train6.log - INFO - iteration:35 step:4400/10100, NER loss: 0.762383
2019-02-21 18:25:34,132 - log/train6.log - INFO - iteration:35 step:4500/10100, NER loss: 1.136308
2019-02-21 18:25:36,269 - log/train6.log - INFO - iteration:35 step:4600/10100, NER loss: 0.918406
2019-02-21 18:25:38,564 - log/train6.log - INFO - iteration:35 step:4700/10100, NER loss: 0.857005
2019-02-21 18:25:41,045 - log/train6.log - INFO - iteration:35 step:4800/10100, NER loss: 0.896855
2019-02-21 18:25:43,588 - log/train6.log - INFO - iteration:35 step:4900/10100, NER loss: 1.229835
2019-02-21 18:25:45,744 - log/train6.log - INFO - iteration:35 step:5000/10100, NER loss: 0.808613
2019-02-21 18:25:48,055 - log/train6.log - INFO - iteration:35 step:5100/10100, NER loss: 1.055993
2019-02-21 18:25:50,370 - log/train6.log - INFO - iteration:35 step:5200/10100, NER loss: 1.025430
2019-02-21 18:25:52,575 - log/train6.log - INFO - iteration:35 step:5300/10100, NER loss: 0.857637
2019-02-21 18:25:54,644 - log/train6.log - INFO - iteration:35 step:5400/10100, NER loss: 0.859531
2019-02-21 18:25:57,387 - log/train6.log - INFO - iteration:35 step:5500/10100, NER loss: 1.109902
2019-02-21 18:25:59,564 - log/train6.log - INFO - iteration:35 step:5600/10100, NER loss: 0.783180
2019-02-21 18:26:01,769 - log/train6.log - INFO - iteration:35 step:5700/10100, NER loss: 0.814521
2019-02-21 18:26:04,127 - log/train6.log - INFO - iteration:35 step:5800/10100, NER loss: 0.958073
2019-02-21 18:26:06,068 - log/train6.log - INFO - iteration:35 step:5900/10100, NER loss: 0.808407
2019-02-21 18:26:08,127 - log/train6.log - INFO - iteration:35 step:6000/10100, NER loss: 0.689936
2019-02-21 18:26:10,240 - log/train6.log - INFO - iteration:35 step:6100/10100, NER loss: 0.945896
2019-02-21 18:26:12,380 - log/train6.log - INFO - iteration:35 step:6200/10100, NER loss: 1.080951
2019-02-21 18:26:14,591 - log/train6.log - INFO - iteration:35 step:6300/10100, NER loss: 0.777099
2019-02-21 18:26:17,030 - log/train6.log - INFO - iteration:35 step:6400/10100, NER loss: 1.184168
2019-02-21 18:26:19,422 - log/train6.log - INFO - iteration:35 step:6500/10100, NER loss: 1.116296
2019-02-21 18:26:21,621 - log/train6.log - INFO - iteration:35 step:6600/10100, NER loss: 0.756371
2019-02-21 18:26:23,970 - log/train6.log - INFO - iteration:35 step:6700/10100, NER loss: 1.023764
2019-02-21 18:26:26,526 - log/train6.log - INFO - iteration:35 step:6800/10100, NER loss: 1.111119
2019-02-21 18:26:28,912 - log/train6.log - INFO - iteration:35 step:6900/10100, NER loss: 1.132152
2019-02-21 18:26:30,827 - log/train6.log - INFO - iteration:35 step:7000/10100, NER loss: 0.901480
2019-02-21 18:26:33,005 - log/train6.log - INFO - iteration:35 step:7100/10100, NER loss: 0.802426
2019-02-21 18:26:35,192 - log/train6.log - INFO - iteration:35 step:7200/10100, NER loss: 1.021524
2019-02-21 18:26:37,352 - log/train6.log - INFO - iteration:35 step:7300/10100, NER loss: 0.822499
2019-02-21 18:26:39,525 - log/train6.log - INFO - iteration:35 step:7400/10100, NER loss: 1.010949
2019-02-21 18:26:41,862 - log/train6.log - INFO - iteration:35 step:7500/10100, NER loss: 0.871128
2019-02-21 18:26:44,274 - log/train6.log - INFO - iteration:35 step:7600/10100, NER loss: 1.011799
2019-02-21 18:26:46,602 - log/train6.log - INFO - iteration:35 step:7700/10100, NER loss: 0.850003
2019-02-21 18:26:49,042 - log/train6.log - INFO - iteration:35 step:7800/10100, NER loss: 1.197456
2019-02-21 18:26:51,144 - log/train6.log - INFO - iteration:35 step:7900/10100, NER loss: 0.820167
2019-02-21 18:26:53,447 - log/train6.log - INFO - iteration:35 step:8000/10100, NER loss: 0.936253
2019-02-21 18:26:55,502 - log/train6.log - INFO - iteration:35 step:8100/10100, NER loss: 0.886969
2019-02-21 18:26:57,656 - log/train6.log - INFO - iteration:35 step:8200/10100, NER loss: 0.839070
2019-02-21 18:26:59,801 - log/train6.log - INFO - iteration:35 step:8300/10100, NER loss: 0.839499
2019-02-21 18:27:01,997 - log/train6.log - INFO - iteration:35 step:8400/10100, NER loss: 1.059829
2019-02-21 18:27:04,152 - log/train6.log - INFO - iteration:35 step:8500/10100, NER loss: 0.875500
2019-02-21 18:27:06,202 - log/train6.log - INFO - iteration:35 step:8600/10100, NER loss: 0.827711
2019-02-21 18:27:08,498 - log/train6.log - INFO - iteration:35 step:8700/10100, NER loss: 1.091022
2019-02-21 18:27:10,523 - log/train6.log - INFO - iteration:35 step:8800/10100, NER loss: 0.769392
2019-02-21 18:27:12,991 - log/train6.log - INFO - iteration:35 step:8900/10100, NER loss: 1.102002
2019-02-21 18:27:15,090 - log/train6.log - INFO - iteration:35 step:9000/10100, NER loss: 0.793527
2019-02-21 18:27:17,251 - log/train6.log - INFO - iteration:35 step:9100/10100, NER loss: 0.823987
2019-02-21 18:27:19,435 - log/train6.log - INFO - iteration:35 step:9200/10100, NER loss: 1.008829
2019-02-21 18:27:21,654 - log/train6.log - INFO - iteration:35 step:9300/10100, NER loss: 0.906927
2019-02-21 18:27:23,877 - log/train6.log - INFO - iteration:35 step:9400/10100, NER loss: 0.969406
2019-02-21 18:27:26,056 - log/train6.log - INFO - iteration:35 step:9500/10100, NER loss: 1.028880
2019-02-21 18:27:30,170 - log/train6.log - INFO - iteration:35 step:9600/10100, NER loss: 1.181679
2019-02-21 18:27:32,291 - log/train6.log - INFO - iteration:35 step:9700/10100, NER loss: 0.844771
2019-02-21 18:27:34,430 - log/train6.log - INFO - iteration:35 step:9800/10100, NER loss: 0.762137
2019-02-21 18:27:37,074 - log/train6.log - INFO - iteration:35 step:9900/10100, NER loss: 1.203696
2019-02-21 18:27:41,609 - log/train6.log - INFO - iteration:35 step:10000/10100, NER loss: 1.645243
2019-02-21 18:27:43,848 - log/train6.log - INFO - iteration:36 step:0/10100, NER loss: 1.074251
2019-02-21 18:27:43,848 - log/train6.log - INFO - evaluate:dev
2019-02-21 18:27:50,304 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5367 phrases; correct: 4176.

2019-02-21 18:27:50,304 - log/train6.log - INFO - accuracy:  94.98%; precision:  77.81%; recall:  71.42%; FB1:  74.48

2019-02-21 18:27:50,304 - log/train6.log - INFO -                 C: precision:  89.16%; recall:  86.16%; FB1:  87.64  3275

2019-02-21 18:27:50,304 - log/train6.log - INFO -               IND: precision:  39.67%; recall:  29.66%; FB1:  33.94  305

2019-02-21 18:27:50,304 - log/train6.log - INFO -               INS: precision:  66.50%; recall:  72.30%; FB1:  69.28  412

2019-02-21 18:27:50,304 - log/train6.log - INFO -                 L: precision:  54.72%; recall:  42.08%; FB1:  47.57  466

2019-02-21 18:27:50,305 - log/train6.log - INFO -                 P: precision:  90.62%; recall:  90.79%; FB1:  90.71  544

2019-02-21 18:27:50,305 - log/train6.log - INFO -               PRO: precision:  30.96%; recall:  21.65%; FB1:  25.48  365

2019-02-21 18:27:50,308 - log/train6.log - INFO - evaluate:test
2019-02-21 18:27:51,773 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1603 phrases; correct: 1364.

2019-02-21 18:27:51,773 - log/train6.log - INFO - accuracy:  96.74%; precision:  85.09%; recall:  82.82%; FB1:  83.94

2019-02-21 18:27:51,773 - log/train6.log - INFO -                 C: precision:  90.64%; recall:  90.38%; FB1:  90.51  1026

2019-02-21 18:27:51,773 - log/train6.log - INFO -               IND: precision:  52.83%; recall:  59.57%; FB1:  56.00  53

2019-02-21 18:27:51,773 - log/train6.log - INFO -               INS: precision:  66.32%; recall:  66.32%; FB1:  66.32  95

2019-02-21 18:27:51,773 - log/train6.log - INFO -                 L: precision:  65.26%; recall:  60.19%; FB1:  62.63  95

2019-02-21 18:27:51,773 - log/train6.log - INFO -                 P: precision:  93.56%; recall:  92.65%; FB1:  93.10  202

2019-02-21 18:27:51,773 - log/train6.log - INFO -               PRO: precision:  69.70%; recall:  54.44%; FB1:  61.13  132

2019-02-21 18:27:53,921 - log/train6.log - INFO - iteration:36 step:100/10100, NER loss: 0.896647
2019-02-21 18:27:55,983 - log/train6.log - INFO - iteration:36 step:200/10100, NER loss: 0.975467
2019-02-21 18:27:57,902 - log/train6.log - INFO - iteration:36 step:300/10100, NER loss: 0.810258
2019-02-21 18:27:59,861 - log/train6.log - INFO - iteration:36 step:400/10100, NER loss: 0.792003
2019-02-21 18:28:02,217 - log/train6.log - INFO - iteration:36 step:500/10100, NER loss: 1.039656
2019-02-21 18:28:04,747 - log/train6.log - INFO - iteration:36 step:600/10100, NER loss: 1.243930
2019-02-21 18:28:06,982 - log/train6.log - INFO - iteration:36 step:700/10100, NER loss: 0.864708
2019-02-21 18:28:09,188 - log/train6.log - INFO - iteration:36 step:800/10100, NER loss: 0.998601
2019-02-21 18:28:11,024 - log/train6.log - INFO - iteration:36 step:900/10100, NER loss: 0.534231
2019-02-21 18:28:13,349 - log/train6.log - INFO - iteration:36 step:1000/10100, NER loss: 1.018417
2019-02-21 18:28:15,344 - log/train6.log - INFO - iteration:36 step:1100/10100, NER loss: 0.670748
2019-02-21 18:28:17,388 - log/train6.log - INFO - iteration:36 step:1200/10100, NER loss: 0.873796
2019-02-21 18:28:19,614 - log/train6.log - INFO - iteration:36 step:1300/10100, NER loss: 0.888895
2019-02-21 18:28:21,914 - log/train6.log - INFO - iteration:36 step:1400/10100, NER loss: 0.912472
2019-02-21 18:28:24,150 - log/train6.log - INFO - iteration:36 step:1500/10100, NER loss: 0.965936
2019-02-21 18:28:26,577 - log/train6.log - INFO - iteration:36 step:1600/10100, NER loss: 0.992364
2019-02-21 18:28:28,508 - log/train6.log - INFO - iteration:36 step:1700/10100, NER loss: 0.789597
2019-02-21 18:28:30,692 - log/train6.log - INFO - iteration:36 step:1800/10100, NER loss: 0.809911
2019-02-21 18:28:33,327 - log/train6.log - INFO - iteration:36 step:1900/10100, NER loss: 1.101095
2019-02-21 18:28:35,317 - log/train6.log - INFO - iteration:36 step:2000/10100, NER loss: 0.724858
2019-02-21 18:28:37,537 - log/train6.log - INFO - iteration:36 step:2100/10100, NER loss: 0.948700
2019-02-21 18:28:39,818 - log/train6.log - INFO - iteration:36 step:2200/10100, NER loss: 0.793974
2019-02-21 18:28:41,958 - log/train6.log - INFO - iteration:36 step:2300/10100, NER loss: 0.952168
2019-02-21 18:28:44,206 - log/train6.log - INFO - iteration:36 step:2400/10100, NER loss: 0.835553
2019-02-21 18:28:46,663 - log/train6.log - INFO - iteration:36 step:2500/10100, NER loss: 0.849328
2019-02-21 18:28:49,007 - log/train6.log - INFO - iteration:36 step:2600/10100, NER loss: 0.948128
2019-02-21 18:28:51,049 - log/train6.log - INFO - iteration:36 step:2700/10100, NER loss: 0.793616
2019-02-21 18:28:54,955 - log/train6.log - INFO - iteration:36 step:2800/10100, NER loss: 1.148703
2019-02-21 18:28:57,250 - log/train6.log - INFO - iteration:36 step:2900/10100, NER loss: 0.999302
2019-02-21 18:28:59,356 - log/train6.log - INFO - iteration:36 step:3000/10100, NER loss: 0.959823
2019-02-21 18:29:01,706 - log/train6.log - INFO - iteration:36 step:3100/10100, NER loss: 1.050191
2019-02-21 18:29:03,700 - log/train6.log - INFO - iteration:36 step:3200/10100, NER loss: 0.920118
2019-02-21 18:29:05,739 - log/train6.log - INFO - iteration:36 step:3300/10100, NER loss: 0.795769
2019-02-21 18:29:08,037 - log/train6.log - INFO - iteration:36 step:3400/10100, NER loss: 1.014675
2019-02-21 18:29:10,353 - log/train6.log - INFO - iteration:36 step:3500/10100, NER loss: 1.146544
2019-02-21 18:29:12,535 - log/train6.log - INFO - iteration:36 step:3600/10100, NER loss: 1.054832
2019-02-21 18:29:14,740 - log/train6.log - INFO - iteration:36 step:3700/10100, NER loss: 1.132091
2019-02-21 18:29:17,021 - log/train6.log - INFO - iteration:36 step:3800/10100, NER loss: 0.942922
2019-02-21 18:29:19,385 - log/train6.log - INFO - iteration:36 step:3900/10100, NER loss: 0.898827
2019-02-21 18:29:21,760 - log/train6.log - INFO - iteration:36 step:4000/10100, NER loss: 1.011781
2019-02-21 18:29:24,000 - log/train6.log - INFO - iteration:36 step:4100/10100, NER loss: 1.038528
2019-02-21 18:29:26,245 - log/train6.log - INFO - iteration:36 step:4200/10100, NER loss: 0.964097
2019-02-21 18:29:28,178 - log/train6.log - INFO - iteration:36 step:4300/10100, NER loss: 0.602689
2019-02-21 18:29:30,327 - log/train6.log - INFO - iteration:36 step:4400/10100, NER loss: 0.810194
2019-02-21 18:29:32,464 - log/train6.log - INFO - iteration:36 step:4500/10100, NER loss: 0.835464
2019-02-21 18:29:34,590 - log/train6.log - INFO - iteration:36 step:4600/10100, NER loss: 0.802424
2019-02-21 18:29:36,958 - log/train6.log - INFO - iteration:36 step:4700/10100, NER loss: 0.845940
2019-02-21 18:29:39,244 - log/train6.log - INFO - iteration:36 step:4800/10100, NER loss: 1.090956
2019-02-21 18:29:41,387 - log/train6.log - INFO - iteration:36 step:4900/10100, NER loss: 0.893287
2019-02-21 18:29:43,697 - log/train6.log - INFO - iteration:36 step:5000/10100, NER loss: 0.831113
2019-02-21 18:29:46,001 - log/train6.log - INFO - iteration:36 step:5100/10100, NER loss: 0.910184
2019-02-21 18:29:48,254 - log/train6.log - INFO - iteration:36 step:5200/10100, NER loss: 1.049822
2019-02-21 18:29:50,674 - log/train6.log - INFO - iteration:36 step:5300/10100, NER loss: 1.223242
2019-02-21 18:29:52,983 - log/train6.log - INFO - iteration:36 step:5400/10100, NER loss: 1.079385
2019-02-21 18:29:55,405 - log/train6.log - INFO - iteration:36 step:5500/10100, NER loss: 1.081727
2019-02-21 18:29:57,732 - log/train6.log - INFO - iteration:36 step:5600/10100, NER loss: 1.001473
2019-02-21 18:29:59,841 - log/train6.log - INFO - iteration:36 step:5700/10100, NER loss: 0.785502
2019-02-21 18:30:02,083 - log/train6.log - INFO - iteration:36 step:5800/10100, NER loss: 0.849735
2019-02-21 18:30:04,351 - log/train6.log - INFO - iteration:36 step:5900/10100, NER loss: 0.903836
2019-02-21 18:30:06,218 - log/train6.log - INFO - iteration:36 step:6000/10100, NER loss: 0.691152
2019-02-21 18:30:08,395 - log/train6.log - INFO - iteration:36 step:6100/10100, NER loss: 0.924177
2019-02-21 18:30:10,660 - log/train6.log - INFO - iteration:36 step:6200/10100, NER loss: 0.846704
2019-02-21 18:30:12,800 - log/train6.log - INFO - iteration:36 step:6300/10100, NER loss: 0.939744
2019-02-21 18:30:14,843 - log/train6.log - INFO - iteration:36 step:6400/10100, NER loss: 0.865476
2019-02-21 18:30:17,314 - log/train6.log - INFO - iteration:36 step:6500/10100, NER loss: 0.957172
2019-02-21 18:30:19,531 - log/train6.log - INFO - iteration:36 step:6600/10100, NER loss: 0.798299
2019-02-21 18:30:21,661 - log/train6.log - INFO - iteration:36 step:6700/10100, NER loss: 0.934629
2019-02-21 18:30:23,709 - log/train6.log - INFO - iteration:36 step:6800/10100, NER loss: 0.722980
2019-02-21 18:30:25,709 - log/train6.log - INFO - iteration:36 step:6900/10100, NER loss: 0.912442
2019-02-21 18:30:27,881 - log/train6.log - INFO - iteration:36 step:7000/10100, NER loss: 1.018580
2019-02-21 18:30:29,991 - log/train6.log - INFO - iteration:36 step:7100/10100, NER loss: 0.838972
2019-02-21 18:30:32,226 - log/train6.log - INFO - iteration:36 step:7200/10100, NER loss: 0.872579
2019-02-21 18:30:34,412 - log/train6.log - INFO - iteration:36 step:7300/10100, NER loss: 0.805310
2019-02-21 18:30:36,589 - log/train6.log - INFO - iteration:36 step:7400/10100, NER loss: 1.016603
2019-02-21 18:30:38,743 - log/train6.log - INFO - iteration:36 step:7500/10100, NER loss: 0.898213
2019-02-21 18:30:40,768 - log/train6.log - INFO - iteration:36 step:7600/10100, NER loss: 0.877320
2019-02-21 18:30:43,028 - log/train6.log - INFO - iteration:36 step:7700/10100, NER loss: 0.849464
2019-02-21 18:30:44,926 - log/train6.log - INFO - iteration:36 step:7800/10100, NER loss: 0.678222
2019-02-21 18:30:47,223 - log/train6.log - INFO - iteration:36 step:7900/10100, NER loss: 1.285058
2019-02-21 18:30:49,346 - log/train6.log - INFO - iteration:36 step:8000/10100, NER loss: 0.956611
2019-02-21 18:30:51,524 - log/train6.log - INFO - iteration:36 step:8100/10100, NER loss: 0.808007
2019-02-21 18:30:53,868 - log/train6.log - INFO - iteration:36 step:8200/10100, NER loss: 1.055489
2019-02-21 18:30:55,965 - log/train6.log - INFO - iteration:36 step:8300/10100, NER loss: 0.817816
2019-02-21 18:30:58,169 - log/train6.log - INFO - iteration:36 step:8400/10100, NER loss: 0.899674
2019-02-21 18:31:00,184 - log/train6.log - INFO - iteration:36 step:8500/10100, NER loss: 0.769246
2019-02-21 18:31:02,521 - log/train6.log - INFO - iteration:36 step:8600/10100, NER loss: 0.972046
2019-02-21 18:31:04,871 - log/train6.log - INFO - iteration:36 step:8700/10100, NER loss: 1.102574
2019-02-21 18:31:07,277 - log/train6.log - INFO - iteration:36 step:8800/10100, NER loss: 0.887713
2019-02-21 18:31:12,132 - log/train6.log - INFO - iteration:36 step:8900/10100, NER loss: 1.796417
2019-02-21 18:31:14,516 - log/train6.log - INFO - iteration:36 step:9000/10100, NER loss: 1.060016
2019-02-21 18:31:16,547 - log/train6.log - INFO - iteration:36 step:9100/10100, NER loss: 0.702945
2019-02-21 18:31:18,894 - log/train6.log - INFO - iteration:36 step:9200/10100, NER loss: 1.029005
2019-02-21 18:31:21,340 - log/train6.log - INFO - iteration:36 step:9300/10100, NER loss: 1.115986
2019-02-21 18:31:25,576 - log/train6.log - INFO - iteration:36 step:9400/10100, NER loss: 1.503428
2019-02-21 18:31:27,921 - log/train6.log - INFO - iteration:36 step:9500/10100, NER loss: 1.032570
2019-02-21 18:31:30,099 - log/train6.log - INFO - iteration:36 step:9600/10100, NER loss: 1.013453
2019-02-21 18:31:32,412 - log/train6.log - INFO - iteration:36 step:9700/10100, NER loss: 0.945262
2019-02-21 18:31:34,577 - log/train6.log - INFO - iteration:36 step:9800/10100, NER loss: 0.917245
2019-02-21 18:31:36,732 - log/train6.log - INFO - iteration:36 step:9900/10100, NER loss: 0.926986
2019-02-21 18:31:39,113 - log/train6.log - INFO - iteration:36 step:10000/10100, NER loss: 1.172825
2019-02-21 18:31:41,650 - log/train6.log - INFO - iteration:37 step:0/10100, NER loss: 1.057468
2019-02-21 18:31:41,650 - log/train6.log - INFO - evaluate:dev
2019-02-21 18:31:48,165 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5667 phrases; correct: 4324.

2019-02-21 18:31:48,165 - log/train6.log - INFO - accuracy:  95.21%; precision:  76.30%; recall:  73.95%; FB1:  75.11

2019-02-21 18:31:48,165 - log/train6.log - INFO -                 C: precision:  85.34%; recall:  89.64%; FB1:  87.44  3560

2019-02-21 18:31:48,165 - log/train6.log - INFO -               IND: precision:  44.21%; recall:  26.23%; FB1:  32.92  242

2019-02-21 18:31:48,165 - log/train6.log - INFO -               INS: precision:  66.92%; recall:  70.45%; FB1:  68.64  399

2019-02-21 18:31:48,165 - log/train6.log - INFO -                 L: precision:  54.96%; recall:  47.52%; FB1:  50.97  524

2019-02-21 18:31:48,165 - log/train6.log - INFO -                 P: precision:  88.43%; recall:  90.06%; FB1:  89.23  553

2019-02-21 18:31:48,165 - log/train6.log - INFO -               PRO: precision:  34.70%; recall:  25.86%; FB1:  29.64  389

2019-02-21 18:31:48,168 - log/train6.log - INFO - evaluate:test
2019-02-21 18:31:49,640 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1693 phrases; correct: 1392.

2019-02-21 18:31:49,640 - log/train6.log - INFO - accuracy:  96.77%; precision:  82.22%; recall:  84.52%; FB1:  83.35

2019-02-21 18:31:49,640 - log/train6.log - INFO -                 C: precision:  86.21%; recall:  92.32%; FB1:  89.16  1102

2019-02-21 18:31:49,640 - log/train6.log - INFO -               IND: precision:  59.57%; recall:  59.57%; FB1:  59.57  47

2019-02-21 18:31:49,640 - log/train6.log - INFO -               INS: precision:  68.48%; recall:  66.32%; FB1:  67.38  92

2019-02-21 18:31:49,640 - log/train6.log - INFO -                 L: precision:  60.75%; recall:  63.11%; FB1:  61.90  107

2019-02-21 18:31:49,640 - log/train6.log - INFO -                 P: precision:  93.20%; recall:  94.12%; FB1:  93.66  206

2019-02-21 18:31:49,640 - log/train6.log - INFO -               PRO: precision:  67.63%; recall:  55.62%; FB1:  61.04  139

2019-02-21 18:31:51,576 - log/train6.log - INFO - iteration:37 step:100/10100, NER loss: 0.863271
2019-02-21 18:31:53,668 - log/train6.log - INFO - iteration:37 step:200/10100, NER loss: 1.079945
2019-02-21 18:31:55,735 - log/train6.log - INFO - iteration:37 step:300/10100, NER loss: 1.093978
2019-02-21 18:31:57,798 - log/train6.log - INFO - iteration:37 step:400/10100, NER loss: 0.824799
2019-02-21 18:32:00,231 - log/train6.log - INFO - iteration:37 step:500/10100, NER loss: 1.008420
2019-02-21 18:32:02,200 - log/train6.log - INFO - iteration:37 step:600/10100, NER loss: 0.635855
2019-02-21 18:32:04,443 - log/train6.log - INFO - iteration:37 step:700/10100, NER loss: 0.847457
2019-02-21 18:32:06,556 - log/train6.log - INFO - iteration:37 step:800/10100, NER loss: 0.777345
2019-02-21 18:32:10,763 - log/train6.log - INFO - iteration:37 step:900/10100, NER loss: 1.223534
2019-02-21 18:32:12,825 - log/train6.log - INFO - iteration:37 step:1000/10100, NER loss: 0.834619
2019-02-21 18:32:15,272 - log/train6.log - INFO - iteration:37 step:1100/10100, NER loss: 1.227513
2019-02-21 18:32:19,307 - log/train6.log - INFO - iteration:37 step:1200/10100, NER loss: 1.134649
2019-02-21 18:32:21,503 - log/train6.log - INFO - iteration:37 step:1300/10100, NER loss: 0.863398
2019-02-21 18:32:23,656 - log/train6.log - INFO - iteration:37 step:1400/10100, NER loss: 0.933234
2019-02-21 18:32:25,716 - log/train6.log - INFO - iteration:37 step:1500/10100, NER loss: 0.973373
2019-02-21 18:32:27,870 - log/train6.log - INFO - iteration:37 step:1600/10100, NER loss: 0.762451
2019-02-21 18:32:30,169 - log/train6.log - INFO - iteration:37 step:1700/10100, NER loss: 0.854761
2019-02-21 18:32:32,524 - log/train6.log - INFO - iteration:37 step:1800/10100, NER loss: 1.000981
2019-02-21 18:32:34,649 - log/train6.log - INFO - iteration:37 step:1900/10100, NER loss: 0.785212
2019-02-21 18:32:36,887 - log/train6.log - INFO - iteration:37 step:2000/10100, NER loss: 0.972745
2019-02-21 18:32:39,141 - log/train6.log - INFO - iteration:37 step:2100/10100, NER loss: 1.027411
2019-02-21 18:32:41,319 - log/train6.log - INFO - iteration:37 step:2200/10100, NER loss: 0.743212
2019-02-21 18:32:43,553 - log/train6.log - INFO - iteration:37 step:2300/10100, NER loss: 0.864617
2019-02-21 18:32:45,725 - log/train6.log - INFO - iteration:37 step:2400/10100, NER loss: 0.887501
2019-02-21 18:32:48,073 - log/train6.log - INFO - iteration:37 step:2500/10100, NER loss: 1.066072
2019-02-21 18:32:50,104 - log/train6.log - INFO - iteration:37 step:2600/10100, NER loss: 0.973648
2019-02-21 18:32:52,447 - log/train6.log - INFO - iteration:37 step:2700/10100, NER loss: 0.924246
2019-02-21 18:32:54,812 - log/train6.log - INFO - iteration:37 step:2800/10100, NER loss: 1.047054
2019-02-21 18:32:59,115 - log/train6.log - INFO - iteration:37 step:2900/10100, NER loss: 1.133866
2019-02-21 18:33:01,170 - log/train6.log - INFO - iteration:37 step:3000/10100, NER loss: 0.835440
2019-02-21 18:33:03,447 - log/train6.log - INFO - iteration:37 step:3100/10100, NER loss: 0.853330
2019-02-21 18:33:05,784 - log/train6.log - INFO - iteration:37 step:3200/10100, NER loss: 1.198005
2019-02-21 18:33:08,160 - log/train6.log - INFO - iteration:37 step:3300/10100, NER loss: 1.110898
2019-02-21 18:33:10,318 - log/train6.log - INFO - iteration:37 step:3400/10100, NER loss: 0.784266
2019-02-21 18:33:12,417 - log/train6.log - INFO - iteration:37 step:3500/10100, NER loss: 0.871275
2019-02-21 18:33:14,798 - log/train6.log - INFO - iteration:37 step:3600/10100, NER loss: 0.955403
2019-02-21 18:33:16,976 - log/train6.log - INFO - iteration:37 step:3700/10100, NER loss: 0.816779
2019-02-21 18:33:19,124 - log/train6.log - INFO - iteration:37 step:3800/10100, NER loss: 0.776908
2019-02-21 18:33:21,334 - log/train6.log - INFO - iteration:37 step:3900/10100, NER loss: 1.036039
2019-02-21 18:33:23,630 - log/train6.log - INFO - iteration:37 step:4000/10100, NER loss: 0.884086
2019-02-21 18:33:25,948 - log/train6.log - INFO - iteration:37 step:4100/10100, NER loss: 0.857233
2019-02-21 18:33:28,512 - log/train6.log - INFO - iteration:37 step:4200/10100, NER loss: 1.050234
2019-02-21 18:33:30,865 - log/train6.log - INFO - iteration:37 step:4300/10100, NER loss: 0.850922
2019-02-21 18:33:33,081 - log/train6.log - INFO - iteration:37 step:4400/10100, NER loss: 0.796059
2019-02-21 18:33:35,203 - log/train6.log - INFO - iteration:37 step:4500/10100, NER loss: 1.030074
2019-02-21 18:33:37,304 - log/train6.log - INFO - iteration:37 step:4600/10100, NER loss: 0.711002
2019-02-21 18:33:39,726 - log/train6.log - INFO - iteration:37 step:4700/10100, NER loss: 0.916387
2019-02-21 18:33:41,963 - log/train6.log - INFO - iteration:37 step:4800/10100, NER loss: 0.919758
2019-02-21 18:33:44,139 - log/train6.log - INFO - iteration:37 step:4900/10100, NER loss: 0.838348
2019-02-21 18:33:46,208 - log/train6.log - INFO - iteration:37 step:5000/10100, NER loss: 1.033163
2019-02-21 18:33:48,211 - log/train6.log - INFO - iteration:37 step:5100/10100, NER loss: 0.698952
2019-02-21 18:33:50,421 - log/train6.log - INFO - iteration:37 step:5200/10100, NER loss: 1.022624
2019-02-21 18:33:52,511 - log/train6.log - INFO - iteration:37 step:5300/10100, NER loss: 0.808613
2019-02-21 18:33:54,563 - log/train6.log - INFO - iteration:37 step:5400/10100, NER loss: 0.710782
2019-02-21 18:33:56,643 - log/train6.log - INFO - iteration:37 step:5500/10100, NER loss: 0.818408
2019-02-21 18:33:58,870 - log/train6.log - INFO - iteration:37 step:5600/10100, NER loss: 0.852637
2019-02-21 18:34:01,046 - log/train6.log - INFO - iteration:37 step:5700/10100, NER loss: 0.796399
2019-02-21 18:34:03,531 - log/train6.log - INFO - iteration:37 step:5800/10100, NER loss: 1.005763
2019-02-21 18:34:05,632 - log/train6.log - INFO - iteration:37 step:5900/10100, NER loss: 0.837586
2019-02-21 18:34:07,871 - log/train6.log - INFO - iteration:37 step:6000/10100, NER loss: 0.733273
2019-02-21 18:34:10,243 - log/train6.log - INFO - iteration:37 step:6100/10100, NER loss: 0.902771
2019-02-21 18:34:12,347 - log/train6.log - INFO - iteration:37 step:6200/10100, NER loss: 0.910765
2019-02-21 18:34:14,874 - log/train6.log - INFO - iteration:37 step:6300/10100, NER loss: 1.199787
2019-02-21 18:34:17,242 - log/train6.log - INFO - iteration:37 step:6400/10100, NER loss: 1.082119
2019-02-21 18:34:19,456 - log/train6.log - INFO - iteration:37 step:6500/10100, NER loss: 0.913477
2019-02-21 18:34:21,969 - log/train6.log - INFO - iteration:37 step:6600/10100, NER loss: 1.107927
2019-02-21 18:34:24,170 - log/train6.log - INFO - iteration:37 step:6700/10100, NER loss: 1.011384
2019-02-21 18:34:26,476 - log/train6.log - INFO - iteration:37 step:6800/10100, NER loss: 0.925061
2019-02-21 18:34:28,697 - log/train6.log - INFO - iteration:37 step:6900/10100, NER loss: 0.823714
2019-02-21 18:34:31,139 - log/train6.log - INFO - iteration:37 step:7000/10100, NER loss: 1.012335
2019-02-21 18:34:33,195 - log/train6.log - INFO - iteration:37 step:7100/10100, NER loss: 0.737230
2019-02-21 18:34:35,529 - log/train6.log - INFO - iteration:37 step:7200/10100, NER loss: 0.990012
2019-02-21 18:34:37,582 - log/train6.log - INFO - iteration:37 step:7300/10100, NER loss: 1.013139
2019-02-21 18:34:39,990 - log/train6.log - INFO - iteration:37 step:7400/10100, NER loss: 0.887244
2019-02-21 18:34:42,258 - log/train6.log - INFO - iteration:37 step:7500/10100, NER loss: 0.942446
2019-02-21 18:34:44,487 - log/train6.log - INFO - iteration:37 step:7600/10100, NER loss: 0.797679
2019-02-21 18:34:46,597 - log/train6.log - INFO - iteration:37 step:7700/10100, NER loss: 0.692306
2019-02-21 18:34:48,610 - log/train6.log - INFO - iteration:37 step:7800/10100, NER loss: 0.884385
2019-02-21 18:34:50,739 - log/train6.log - INFO - iteration:37 step:7900/10100, NER loss: 0.771272
2019-02-21 18:34:52,993 - log/train6.log - INFO - iteration:37 step:8000/10100, NER loss: 0.916674
2019-02-21 18:34:55,153 - log/train6.log - INFO - iteration:37 step:8100/10100, NER loss: 0.989619
2019-02-21 18:34:57,441 - log/train6.log - INFO - iteration:37 step:8200/10100, NER loss: 0.745437
2019-02-21 18:34:59,798 - log/train6.log - INFO - iteration:37 step:8300/10100, NER loss: 1.016310
2019-02-21 18:35:02,130 - log/train6.log - INFO - iteration:37 step:8400/10100, NER loss: 1.088459
2019-02-21 18:35:04,387 - log/train6.log - INFO - iteration:37 step:8500/10100, NER loss: 0.811589
2019-02-21 18:35:06,742 - log/train6.log - INFO - iteration:37 step:8600/10100, NER loss: 1.110986
2019-02-21 18:35:08,938 - log/train6.log - INFO - iteration:37 step:8700/10100, NER loss: 0.775096
2019-02-21 18:35:11,179 - log/train6.log - INFO - iteration:37 step:8800/10100, NER loss: 1.200399
2019-02-21 18:35:13,429 - log/train6.log - INFO - iteration:37 step:8900/10100, NER loss: 0.830511
2019-02-21 18:35:15,643 - log/train6.log - INFO - iteration:37 step:9000/10100, NER loss: 0.752454
2019-02-21 18:35:17,820 - log/train6.log - INFO - iteration:37 step:9100/10100, NER loss: 0.865015
2019-02-21 18:35:19,978 - log/train6.log - INFO - iteration:37 step:9200/10100, NER loss: 0.893087
2019-02-21 18:35:22,364 - log/train6.log - INFO - iteration:37 step:9300/10100, NER loss: 1.250887
2019-02-21 18:35:24,498 - log/train6.log - INFO - iteration:37 step:9400/10100, NER loss: 0.676500
2019-02-21 18:35:26,605 - log/train6.log - INFO - iteration:37 step:9500/10100, NER loss: 0.921616
2019-02-21 18:35:29,015 - log/train6.log - INFO - iteration:37 step:9600/10100, NER loss: 1.074687
2019-02-21 18:35:31,307 - log/train6.log - INFO - iteration:37 step:9700/10100, NER loss: 0.959529
2019-02-21 18:35:33,364 - log/train6.log - INFO - iteration:37 step:9800/10100, NER loss: 0.810402
2019-02-21 18:35:35,475 - log/train6.log - INFO - iteration:37 step:9900/10100, NER loss: 0.888654
2019-02-21 18:35:37,955 - log/train6.log - INFO - iteration:37 step:10000/10100, NER loss: 1.107589
2019-02-21 18:35:40,193 - log/train6.log - INFO - iteration:38 step:0/10100, NER loss: 0.830017
2019-02-21 18:35:40,193 - log/train6.log - INFO - evaluate:dev
2019-02-21 18:35:46,640 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5878 phrases; correct: 4396.

2019-02-21 18:35:46,640 - log/train6.log - INFO - accuracy:  95.15%; precision:  74.79%; recall:  75.18%; FB1:  74.99

2019-02-21 18:35:46,640 - log/train6.log - INFO -                 C: precision:  86.01%; recall:  88.32%; FB1:  87.15  3480

2019-02-21 18:35:46,640 - log/train6.log - INFO -               IND: precision:  40.07%; recall:  29.17%; FB1:  33.76  297

2019-02-21 18:35:46,640 - log/train6.log - INFO -               INS: precision:  68.26%; recall:  71.50%; FB1:  69.85  397

2019-02-21 18:35:46,640 - log/train6.log - INFO -                 L: precision:  61.99%; recall:  55.45%; FB1:  58.54  542

2019-02-21 18:35:46,640 - log/train6.log - INFO -                 P: precision:  86.69%; recall:  91.16%; FB1:  88.87  571

2019-02-21 18:35:46,640 - log/train6.log - INFO -               PRO: precision:  30.80%; recall:  34.87%; FB1:  32.70  591

2019-02-21 18:35:46,643 - log/train6.log - INFO - evaluate:test
2019-02-21 18:35:48,096 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1708 phrases; correct: 1396.

2019-02-21 18:35:48,096 - log/train6.log - INFO - accuracy:  96.54%; precision:  81.73%; recall:  84.76%; FB1:  83.22

2019-02-21 18:35:48,096 - log/train6.log - INFO -                 C: precision:  89.25%; recall:  91.93%; FB1:  90.57  1060

2019-02-21 18:35:48,096 - log/train6.log - INFO -               IND: precision:  50.79%; recall:  68.09%; FB1:  58.18  63

2019-02-21 18:35:48,096 - log/train6.log - INFO -               INS: precision:  67.37%; recall:  67.37%; FB1:  67.37  95

2019-02-21 18:35:48,096 - log/train6.log - INFO -                 L: precision:  67.68%; recall:  65.05%; FB1:  66.34  99

2019-02-21 18:35:48,096 - log/train6.log - INFO -                 P: precision:  91.98%; recall:  95.59%; FB1:  93.75  212

2019-02-21 18:35:48,096 - log/train6.log - INFO -               PRO: precision:  51.40%; recall:  54.44%; FB1:  52.87  179

2019-02-21 18:35:50,220 - log/train6.log - INFO - iteration:38 step:100/10100, NER loss: 0.859182
2019-02-21 18:35:52,376 - log/train6.log - INFO - iteration:38 step:200/10100, NER loss: 0.917347
2019-02-21 18:35:54,605 - log/train6.log - INFO - iteration:38 step:300/10100, NER loss: 0.977440
2019-02-21 18:35:56,485 - log/train6.log - INFO - iteration:38 step:400/10100, NER loss: 0.679115
2019-02-21 18:35:58,605 - log/train6.log - INFO - iteration:38 step:500/10100, NER loss: 0.844884
2019-02-21 18:36:00,733 - log/train6.log - INFO - iteration:38 step:600/10100, NER loss: 0.677045
2019-02-21 18:36:03,045 - log/train6.log - INFO - iteration:38 step:700/10100, NER loss: 0.813181
2019-02-21 18:36:05,385 - log/train6.log - INFO - iteration:38 step:800/10100, NER loss: 0.845324
2019-02-21 18:36:07,593 - log/train6.log - INFO - iteration:38 step:900/10100, NER loss: 0.948193
2019-02-21 18:36:09,976 - log/train6.log - INFO - iteration:38 step:1000/10100, NER loss: 0.903270
2019-02-21 18:36:12,036 - log/train6.log - INFO - iteration:38 step:1100/10100, NER loss: 0.947718
2019-02-21 18:36:14,286 - log/train6.log - INFO - iteration:38 step:1200/10100, NER loss: 0.849764
2019-02-21 18:36:16,754 - log/train6.log - INFO - iteration:38 step:1300/10100, NER loss: 0.857928
2019-02-21 18:36:19,526 - log/train6.log - INFO - iteration:38 step:1400/10100, NER loss: 1.249869
2019-02-21 18:36:21,588 - log/train6.log - INFO - iteration:38 step:1500/10100, NER loss: 0.758890
2019-02-21 18:36:23,727 - log/train6.log - INFO - iteration:38 step:1600/10100, NER loss: 0.891235
2019-02-21 18:36:26,103 - log/train6.log - INFO - iteration:38 step:1700/10100, NER loss: 1.093151
2019-02-21 18:36:28,287 - log/train6.log - INFO - iteration:38 step:1800/10100, NER loss: 0.752314
2019-02-21 18:36:30,466 - log/train6.log - INFO - iteration:38 step:1900/10100, NER loss: 0.852763
2019-02-21 18:36:32,548 - log/train6.log - INFO - iteration:38 step:2000/10100, NER loss: 1.043593
2019-02-21 18:36:34,838 - log/train6.log - INFO - iteration:38 step:2100/10100, NER loss: 1.031924
2019-02-21 18:36:36,884 - log/train6.log - INFO - iteration:38 step:2200/10100, NER loss: 0.969608
2019-02-21 18:36:39,344 - log/train6.log - INFO - iteration:38 step:2300/10100, NER loss: 1.088447
2019-02-21 18:36:41,443 - log/train6.log - INFO - iteration:38 step:2400/10100, NER loss: 0.909076
2019-02-21 18:36:43,663 - log/train6.log - INFO - iteration:38 step:2500/10100, NER loss: 1.025944
2019-02-21 18:36:45,940 - log/train6.log - INFO - iteration:38 step:2600/10100, NER loss: 0.845447
2019-02-21 18:36:48,132 - log/train6.log - INFO - iteration:38 step:2700/10100, NER loss: 0.874734
2019-02-21 18:36:50,461 - log/train6.log - INFO - iteration:38 step:2800/10100, NER loss: 0.951150
2019-02-21 18:36:52,723 - log/train6.log - INFO - iteration:38 step:2900/10100, NER loss: 1.033222
2019-02-21 18:36:54,913 - log/train6.log - INFO - iteration:38 step:3000/10100, NER loss: 1.120357
2019-02-21 18:36:57,202 - log/train6.log - INFO - iteration:38 step:3100/10100, NER loss: 0.971849
2019-02-21 18:36:59,356 - log/train6.log - INFO - iteration:38 step:3200/10100, NER loss: 1.027678
2019-02-21 18:37:01,684 - log/train6.log - INFO - iteration:38 step:3300/10100, NER loss: 1.024344
2019-02-21 18:37:03,990 - log/train6.log - INFO - iteration:38 step:3400/10100, NER loss: 0.845126
2019-02-21 18:37:06,109 - log/train6.log - INFO - iteration:38 step:3500/10100, NER loss: 0.791020
2019-02-21 18:37:08,338 - log/train6.log - INFO - iteration:38 step:3600/10100, NER loss: 0.879953
2019-02-21 18:37:10,319 - log/train6.log - INFO - iteration:38 step:3700/10100, NER loss: 0.682000
2019-02-21 18:37:12,522 - log/train6.log - INFO - iteration:38 step:3800/10100, NER loss: 0.820656
2019-02-21 18:37:14,754 - log/train6.log - INFO - iteration:38 step:3900/10100, NER loss: 0.867951
2019-02-21 18:37:16,888 - log/train6.log - INFO - iteration:38 step:4000/10100, NER loss: 0.738141
2019-02-21 18:37:19,176 - log/train6.log - INFO - iteration:38 step:4100/10100, NER loss: 0.841144
2019-02-21 18:37:21,494 - log/train6.log - INFO - iteration:38 step:4200/10100, NER loss: 1.076647
2019-02-21 18:37:23,824 - log/train6.log - INFO - iteration:38 step:4300/10100, NER loss: 0.970788
2019-02-21 18:37:26,165 - log/train6.log - INFO - iteration:38 step:4400/10100, NER loss: 1.013506
2019-02-21 18:37:28,608 - log/train6.log - INFO - iteration:38 step:4500/10100, NER loss: 0.950862
2019-02-21 18:37:30,963 - log/train6.log - INFO - iteration:38 step:4600/10100, NER loss: 0.991614
2019-02-21 18:37:33,404 - log/train6.log - INFO - iteration:38 step:4700/10100, NER loss: 1.500970
2019-02-21 18:37:35,608 - log/train6.log - INFO - iteration:38 step:4800/10100, NER loss: 0.859111
2019-02-21 18:37:37,669 - log/train6.log - INFO - iteration:38 step:4900/10100, NER loss: 0.807713
2019-02-21 18:37:39,764 - log/train6.log - INFO - iteration:38 step:5000/10100, NER loss: 0.911760
2019-02-21 18:37:41,824 - log/train6.log - INFO - iteration:38 step:5100/10100, NER loss: 0.866301
2019-02-21 18:37:44,105 - log/train6.log - INFO - iteration:38 step:5200/10100, NER loss: 1.020512
2019-02-21 18:37:46,064 - log/train6.log - INFO - iteration:38 step:5300/10100, NER loss: 0.833765
2019-02-21 18:37:48,391 - log/train6.log - INFO - iteration:38 step:5400/10100, NER loss: 1.127572
2019-02-21 18:37:50,615 - log/train6.log - INFO - iteration:38 step:5500/10100, NER loss: 0.938375
2019-02-21 18:37:53,208 - log/train6.log - INFO - iteration:38 step:5600/10100, NER loss: 1.262682
2019-02-21 18:37:55,745 - log/train6.log - INFO - iteration:38 step:5700/10100, NER loss: 1.071455
2019-02-21 18:37:58,173 - log/train6.log - INFO - iteration:38 step:5800/10100, NER loss: 1.050892
2019-02-21 18:38:00,170 - log/train6.log - INFO - iteration:38 step:5900/10100, NER loss: 0.695533
2019-02-21 18:38:04,224 - log/train6.log - INFO - iteration:38 step:6000/10100, NER loss: 1.452367
2019-02-21 18:38:06,245 - log/train6.log - INFO - iteration:38 step:6100/10100, NER loss: 0.874657
2019-02-21 18:38:08,428 - log/train6.log - INFO - iteration:38 step:6200/10100, NER loss: 0.769242
2019-02-21 18:38:10,753 - log/train6.log - INFO - iteration:38 step:6300/10100, NER loss: 1.011023
2019-02-21 18:38:12,953 - log/train6.log - INFO - iteration:38 step:6400/10100, NER loss: 0.932858
2019-02-21 18:38:17,218 - log/train6.log - INFO - iteration:38 step:6500/10100, NER loss: 1.687216
2019-02-21 18:38:19,300 - log/train6.log - INFO - iteration:38 step:6600/10100, NER loss: 0.796466
2019-02-21 18:38:21,461 - log/train6.log - INFO - iteration:38 step:6700/10100, NER loss: 0.711632
2019-02-21 18:38:23,439 - log/train6.log - INFO - iteration:38 step:6800/10100, NER loss: 0.739123
2019-02-21 18:38:25,630 - log/train6.log - INFO - iteration:38 step:6900/10100, NER loss: 1.011477
2019-02-21 18:38:27,743 - log/train6.log - INFO - iteration:38 step:7000/10100, NER loss: 0.665996
2019-02-21 18:38:29,942 - log/train6.log - INFO - iteration:38 step:7100/10100, NER loss: 0.905733
2019-02-21 18:38:32,190 - log/train6.log - INFO - iteration:38 step:7200/10100, NER loss: 0.870850
2019-02-21 18:38:34,460 - log/train6.log - INFO - iteration:38 step:7300/10100, NER loss: 1.065585
2019-02-21 18:38:36,711 - log/train6.log - INFO - iteration:38 step:7400/10100, NER loss: 0.912629
2019-02-21 18:38:38,816 - log/train6.log - INFO - iteration:38 step:7500/10100, NER loss: 0.860285
2019-02-21 18:38:41,023 - log/train6.log - INFO - iteration:38 step:7600/10100, NER loss: 0.821128
2019-02-21 18:38:43,207 - log/train6.log - INFO - iteration:38 step:7700/10100, NER loss: 0.776999
2019-02-21 18:38:45,437 - log/train6.log - INFO - iteration:38 step:7800/10100, NER loss: 0.856943
2019-02-21 18:38:47,589 - log/train6.log - INFO - iteration:38 step:7900/10100, NER loss: 0.858110
2019-02-21 18:38:49,883 - log/train6.log - INFO - iteration:38 step:8000/10100, NER loss: 0.834206
2019-02-21 18:38:52,075 - log/train6.log - INFO - iteration:38 step:8100/10100, NER loss: 0.802734
2019-02-21 18:38:54,271 - log/train6.log - INFO - iteration:38 step:8200/10100, NER loss: 0.748188
2019-02-21 18:38:56,494 - log/train6.log - INFO - iteration:38 step:8300/10100, NER loss: 0.749964
2019-02-21 18:38:58,682 - log/train6.log - INFO - iteration:38 step:8400/10100, NER loss: 0.959500
2019-02-21 18:39:00,802 - log/train6.log - INFO - iteration:38 step:8500/10100, NER loss: 0.917554
2019-02-21 18:39:02,936 - log/train6.log - INFO - iteration:38 step:8600/10100, NER loss: 0.840780
2019-02-21 18:39:05,264 - log/train6.log - INFO - iteration:38 step:8700/10100, NER loss: 0.892482
2019-02-21 18:39:07,747 - log/train6.log - INFO - iteration:38 step:8800/10100, NER loss: 1.153409
2019-02-21 18:39:09,887 - log/train6.log - INFO - iteration:38 step:8900/10100, NER loss: 0.705020
2019-02-21 18:39:12,280 - log/train6.log - INFO - iteration:38 step:9000/10100, NER loss: 0.847417
2019-02-21 18:39:14,500 - log/train6.log - INFO - iteration:38 step:9100/10100, NER loss: 1.168548
2019-02-21 18:39:16,834 - log/train6.log - INFO - iteration:38 step:9200/10100, NER loss: 1.014677
2019-02-21 18:39:18,968 - log/train6.log - INFO - iteration:38 step:9300/10100, NER loss: 0.711237
2019-02-21 18:39:22,921 - log/train6.log - INFO - iteration:38 step:9400/10100, NER loss: 1.546449
2019-02-21 18:39:25,026 - log/train6.log - INFO - iteration:38 step:9500/10100, NER loss: 0.970042
2019-02-21 18:39:27,328 - log/train6.log - INFO - iteration:38 step:9600/10100, NER loss: 0.973135
2019-02-21 18:39:29,653 - log/train6.log - INFO - iteration:38 step:9700/10100, NER loss: 0.937150
2019-02-21 18:39:31,849 - log/train6.log - INFO - iteration:38 step:9800/10100, NER loss: 0.810046
2019-02-21 18:39:34,140 - log/train6.log - INFO - iteration:38 step:9900/10100, NER loss: 1.071191
2019-02-21 18:39:36,516 - log/train6.log - INFO - iteration:38 step:10000/10100, NER loss: 1.092568
2019-02-21 18:39:38,473 - log/train6.log - INFO - iteration:39 step:0/10100, NER loss: 0.759217
2019-02-21 18:39:38,473 - log/train6.log - INFO - evaluate:dev
2019-02-21 18:39:45,009 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5811 phrases; correct: 4377.

2019-02-21 18:39:45,009 - log/train6.log - INFO - accuracy:  95.22%; precision:  75.32%; recall:  74.86%; FB1:  75.09

2019-02-21 18:39:45,009 - log/train6.log - INFO -                 C: precision:  86.69%; recall:  87.46%; FB1:  87.07  3419

2019-02-21 18:39:45,009 - log/train6.log - INFO -               IND: precision:  46.73%; recall:  24.51%; FB1:  32.15  214

2019-02-21 18:39:45,009 - log/train6.log - INFO -               INS: precision:  56.73%; recall:  72.30%; FB1:  63.57  483

2019-02-21 18:39:45,009 - log/train6.log - INFO -                 L: precision:  61.58%; recall:  63.20%; FB1:  62.38  622

2019-02-21 18:39:45,009 - log/train6.log - INFO -                 P: precision:  86.37%; recall:  93.37%; FB1:  89.73  587

2019-02-21 18:39:45,009 - log/train6.log - INFO -               PRO: precision:  30.66%; recall:  28.54%; FB1:  29.56  486

2019-02-21 18:39:45,012 - log/train6.log - INFO - evaluate:test
2019-02-21 18:39:46,490 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1697 phrases; correct: 1395.

2019-02-21 18:39:46,490 - log/train6.log - INFO - accuracy:  96.60%; precision:  82.20%; recall:  84.70%; FB1:  83.43

2019-02-21 18:39:46,491 - log/train6.log - INFO -                 C: precision:  89.92%; recall:  91.93%; FB1:  90.92  1052

2019-02-21 18:39:46,491 - log/train6.log - INFO -               IND: precision:  66.67%; recall:  68.09%; FB1:  67.37  48

2019-02-21 18:39:46,491 - log/train6.log - INFO -               INS: precision:  58.62%; recall:  71.58%; FB1:  64.45  116

2019-02-21 18:39:46,491 - log/train6.log - INFO -                 L: precision:  56.76%; recall:  61.17%; FB1:  58.88  111

2019-02-21 18:39:46,491 - log/train6.log - INFO -                 P: precision:  91.04%; recall:  94.61%; FB1:  92.79  212

2019-02-21 18:39:46,491 - log/train6.log - INFO -               PRO: precision:  58.86%; recall:  55.03%; FB1:  56.88  158

2019-02-21 18:39:48,402 - log/train6.log - INFO - iteration:39 step:100/10100, NER loss: 0.695778
2019-02-21 18:39:50,610 - log/train6.log - INFO - iteration:39 step:200/10100, NER loss: 0.958391
2019-02-21 18:39:52,592 - log/train6.log - INFO - iteration:39 step:300/10100, NER loss: 1.011030
2019-02-21 18:39:54,773 - log/train6.log - INFO - iteration:39 step:400/10100, NER loss: 0.920264
2019-02-21 18:39:56,924 - log/train6.log - INFO - iteration:39 step:500/10100, NER loss: 0.944200
2019-02-21 18:39:59,086 - log/train6.log - INFO - iteration:39 step:600/10100, NER loss: 0.804328
2019-02-21 18:40:01,376 - log/train6.log - INFO - iteration:39 step:700/10100, NER loss: 1.171976
2019-02-21 18:40:03,604 - log/train6.log - INFO - iteration:39 step:800/10100, NER loss: 0.918348
2019-02-21 18:40:05,763 - log/train6.log - INFO - iteration:39 step:900/10100, NER loss: 0.734411
2019-02-21 18:40:07,918 - log/train6.log - INFO - iteration:39 step:1000/10100, NER loss: 0.873094
2019-02-21 18:40:10,194 - log/train6.log - INFO - iteration:39 step:1100/10100, NER loss: 1.017177
2019-02-21 18:40:12,499 - log/train6.log - INFO - iteration:39 step:1200/10100, NER loss: 0.977922
2019-02-21 18:40:14,761 - log/train6.log - INFO - iteration:39 step:1300/10100, NER loss: 0.974172
2019-02-21 18:40:16,696 - log/train6.log - INFO - iteration:39 step:1400/10100, NER loss: 0.802690
2019-02-21 18:40:18,982 - log/train6.log - INFO - iteration:39 step:1500/10100, NER loss: 0.922949
2019-02-21 18:40:21,030 - log/train6.log - INFO - iteration:39 step:1600/10100, NER loss: 0.632986
2019-02-21 18:40:23,390 - log/train6.log - INFO - iteration:39 step:1700/10100, NER loss: 1.114603
2019-02-21 18:40:25,511 - log/train6.log - INFO - iteration:39 step:1800/10100, NER loss: 0.686162
2019-02-21 18:40:27,568 - log/train6.log - INFO - iteration:39 step:1900/10100, NER loss: 0.797165
2019-02-21 18:40:29,694 - log/train6.log - INFO - iteration:39 step:2000/10100, NER loss: 0.872140
2019-02-21 18:40:31,892 - log/train6.log - INFO - iteration:39 step:2100/10100, NER loss: 0.907359
2019-02-21 18:40:34,148 - log/train6.log - INFO - iteration:39 step:2200/10100, NER loss: 0.961388
2019-02-21 18:40:36,400 - log/train6.log - INFO - iteration:39 step:2300/10100, NER loss: 0.899688
2019-02-21 18:40:38,602 - log/train6.log - INFO - iteration:39 step:2400/10100, NER loss: 0.817044
2019-02-21 18:40:40,656 - log/train6.log - INFO - iteration:39 step:2500/10100, NER loss: 0.828037
2019-02-21 18:40:42,914 - log/train6.log - INFO - iteration:39 step:2600/10100, NER loss: 0.896969
2019-02-21 18:40:45,126 - log/train6.log - INFO - iteration:39 step:2700/10100, NER loss: 0.918144
2019-02-21 18:40:47,353 - log/train6.log - INFO - iteration:39 step:2800/10100, NER loss: 0.814950
2019-02-21 18:40:49,606 - log/train6.log - INFO - iteration:39 step:2900/10100, NER loss: 0.851994
2019-02-21 18:40:51,969 - log/train6.log - INFO - iteration:39 step:3000/10100, NER loss: 1.012424
2019-02-21 18:40:54,044 - log/train6.log - INFO - iteration:39 step:3100/10100, NER loss: 0.874333
2019-02-21 18:40:56,192 - log/train6.log - INFO - iteration:39 step:3200/10100, NER loss: 0.951764
2019-02-21 18:40:58,415 - log/train6.log - INFO - iteration:39 step:3300/10100, NER loss: 0.754526
2019-02-21 18:41:00,583 - log/train6.log - INFO - iteration:39 step:3400/10100, NER loss: 0.905115
2019-02-21 18:41:02,774 - log/train6.log - INFO - iteration:39 step:3500/10100, NER loss: 0.744064
2019-02-21 18:41:04,959 - log/train6.log - INFO - iteration:39 step:3600/10100, NER loss: 0.777261
2019-02-21 18:41:07,142 - log/train6.log - INFO - iteration:39 step:3700/10100, NER loss: 0.811795
2019-02-21 18:41:09,454 - log/train6.log - INFO - iteration:39 step:3800/10100, NER loss: 0.831688
2019-02-21 18:41:11,644 - log/train6.log - INFO - iteration:39 step:3900/10100, NER loss: 0.873000
2019-02-21 18:41:14,013 - log/train6.log - INFO - iteration:39 step:4000/10100, NER loss: 1.106763
2019-02-21 18:41:16,265 - log/train6.log - INFO - iteration:39 step:4100/10100, NER loss: 0.811739
2019-02-21 18:41:18,316 - log/train6.log - INFO - iteration:39 step:4200/10100, NER loss: 0.856896
2019-02-21 18:41:20,342 - log/train6.log - INFO - iteration:39 step:4300/10100, NER loss: 0.866897
2019-02-21 18:41:22,410 - log/train6.log - INFO - iteration:39 step:4400/10100, NER loss: 0.888347
2019-02-21 18:41:24,695 - log/train6.log - INFO - iteration:39 step:4500/10100, NER loss: 0.786313
2019-02-21 18:41:27,067 - log/train6.log - INFO - iteration:39 step:4600/10100, NER loss: 1.193515
2019-02-21 18:41:29,314 - log/train6.log - INFO - iteration:39 step:4700/10100, NER loss: 0.953318
2019-02-21 18:41:31,363 - log/train6.log - INFO - iteration:39 step:4800/10100, NER loss: 0.717369
2019-02-21 18:41:33,572 - log/train6.log - INFO - iteration:39 step:4900/10100, NER loss: 1.065791
2019-02-21 18:41:35,787 - log/train6.log - INFO - iteration:39 step:5000/10100, NER loss: 1.028043
2019-02-21 18:41:37,938 - log/train6.log - INFO - iteration:39 step:5100/10100, NER loss: 0.997296
2019-02-21 18:41:40,208 - log/train6.log - INFO - iteration:39 step:5200/10100, NER loss: 0.853730
2019-02-21 18:41:42,413 - log/train6.log - INFO - iteration:39 step:5300/10100, NER loss: 0.822979
2019-02-21 18:41:44,841 - log/train6.log - INFO - iteration:39 step:5400/10100, NER loss: 1.161040
2019-02-21 18:41:47,189 - log/train6.log - INFO - iteration:39 step:5500/10100, NER loss: 0.860119
2019-02-21 18:41:49,493 - log/train6.log - INFO - iteration:39 step:5600/10100, NER loss: 0.975672
2019-02-21 18:41:51,684 - log/train6.log - INFO - iteration:39 step:5700/10100, NER loss: 0.960465
2019-02-21 18:41:53,935 - log/train6.log - INFO - iteration:39 step:5800/10100, NER loss: 0.763016
2019-02-21 18:41:56,190 - log/train6.log - INFO - iteration:39 step:5900/10100, NER loss: 0.826734
2019-02-21 18:41:58,416 - log/train6.log - INFO - iteration:39 step:6000/10100, NER loss: 1.121848
2019-02-21 18:42:00,934 - log/train6.log - INFO - iteration:39 step:6100/10100, NER loss: 0.921491
2019-02-21 18:42:03,225 - log/train6.log - INFO - iteration:39 step:6200/10100, NER loss: 1.007646
2019-02-21 18:42:05,370 - log/train6.log - INFO - iteration:39 step:6300/10100, NER loss: 0.810058
2019-02-21 18:42:07,564 - log/train6.log - INFO - iteration:39 step:6400/10100, NER loss: 0.881525
2019-02-21 18:42:09,739 - log/train6.log - INFO - iteration:39 step:6500/10100, NER loss: 0.766551
2019-02-21 18:42:12,061 - log/train6.log - INFO - iteration:39 step:6600/10100, NER loss: 1.008080
2019-02-21 18:42:16,173 - log/train6.log - INFO - iteration:39 step:6700/10100, NER loss: 1.675918
2019-02-21 18:42:18,236 - log/train6.log - INFO - iteration:39 step:6800/10100, NER loss: 0.782599
2019-02-21 18:42:22,527 - log/train6.log - INFO - iteration:39 step:6900/10100, NER loss: 1.757303
2019-02-21 18:42:24,658 - log/train6.log - INFO - iteration:39 step:7000/10100, NER loss: 1.049222
2019-02-21 18:42:27,001 - log/train6.log - INFO - iteration:39 step:7100/10100, NER loss: 0.927416
2019-02-21 18:42:31,484 - log/train6.log - INFO - iteration:39 step:7200/10100, NER loss: 1.959485
2019-02-21 18:42:33,767 - log/train6.log - INFO - iteration:39 step:7300/10100, NER loss: 0.997337
2019-02-21 18:42:35,962 - log/train6.log - INFO - iteration:39 step:7400/10100, NER loss: 0.882862
2019-02-21 18:42:38,235 - log/train6.log - INFO - iteration:39 step:7500/10100, NER loss: 0.899815
2019-02-21 18:42:40,409 - log/train6.log - INFO - iteration:39 step:7600/10100, NER loss: 0.987564
2019-02-21 18:42:42,793 - log/train6.log - INFO - iteration:39 step:7700/10100, NER loss: 0.981093
2019-02-21 18:42:45,126 - log/train6.log - INFO - iteration:39 step:7800/10100, NER loss: 0.916714
2019-02-21 18:42:47,284 - log/train6.log - INFO - iteration:39 step:7900/10100, NER loss: 0.806094
2019-02-21 18:42:49,617 - log/train6.log - INFO - iteration:39 step:8000/10100, NER loss: 0.911238
2019-02-21 18:42:51,710 - log/train6.log - INFO - iteration:39 step:8100/10100, NER loss: 0.801165
2019-02-21 18:42:53,802 - log/train6.log - INFO - iteration:39 step:8200/10100, NER loss: 0.917598
2019-02-21 18:42:56,058 - log/train6.log - INFO - iteration:39 step:8300/10100, NER loss: 0.828972
2019-02-21 18:42:58,241 - log/train6.log - INFO - iteration:39 step:8400/10100, NER loss: 0.941061
2019-02-21 18:43:00,276 - log/train6.log - INFO - iteration:39 step:8500/10100, NER loss: 0.990231
2019-02-21 18:43:02,412 - log/train6.log - INFO - iteration:39 step:8600/10100, NER loss: 1.016036
2019-02-21 18:43:04,538 - log/train6.log - INFO - iteration:39 step:8700/10100, NER loss: 0.809547
2019-02-21 18:43:06,516 - log/train6.log - INFO - iteration:39 step:8800/10100, NER loss: 0.782848
2019-02-21 18:43:08,650 - log/train6.log - INFO - iteration:39 step:8900/10100, NER loss: 0.968503
2019-02-21 18:43:10,948 - log/train6.log - INFO - iteration:39 step:9000/10100, NER loss: 0.981510
2019-02-21 18:43:13,206 - log/train6.log - INFO - iteration:39 step:9100/10100, NER loss: 0.905350
2019-02-21 18:43:15,393 - log/train6.log - INFO - iteration:39 step:9200/10100, NER loss: 0.783000
2019-02-21 18:43:17,633 - log/train6.log - INFO - iteration:39 step:9300/10100, NER loss: 0.949799
2019-02-21 18:43:19,844 - log/train6.log - INFO - iteration:39 step:9400/10100, NER loss: 0.767225
2019-02-21 18:43:22,109 - log/train6.log - INFO - iteration:39 step:9500/10100, NER loss: 1.047515
2019-02-21 18:43:24,209 - log/train6.log - INFO - iteration:39 step:9600/10100, NER loss: 0.845881
2019-02-21 18:43:26,469 - log/train6.log - INFO - iteration:39 step:9700/10100, NER loss: 1.031596
2019-02-21 18:43:28,861 - log/train6.log - INFO - iteration:39 step:9800/10100, NER loss: 1.151181
2019-02-21 18:43:31,117 - log/train6.log - INFO - iteration:39 step:9900/10100, NER loss: 0.807480
2019-02-21 18:43:33,204 - log/train6.log - INFO - iteration:39 step:10000/10100, NER loss: 0.820414
2019-02-21 18:43:36,032 - log/train6.log - INFO - iteration:40 step:0/10100, NER loss: 1.199104
2019-02-21 18:43:36,032 - log/train6.log - INFO - evaluate:dev
2019-02-21 18:43:42,511 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5898 phrases; correct: 4388.

2019-02-21 18:43:42,511 - log/train6.log - INFO - accuracy:  95.20%; precision:  74.40%; recall:  75.05%; FB1:  74.72

2019-02-21 18:43:42,511 - log/train6.log - INFO -                 C: precision:  88.08%; recall:  86.13%; FB1:  87.10  3314

2019-02-21 18:43:42,511 - log/train6.log - INFO -               IND: precision:  40.62%; recall:  31.86%; FB1:  35.71  320

2019-02-21 18:43:42,511 - log/train6.log - INFO -               INS: precision:  63.40%; recall:  71.77%; FB1:  67.33  429

2019-02-21 18:43:42,511 - log/train6.log - INFO -                 L: precision:  56.59%; recall:  67.99%; FB1:  61.77  728

2019-02-21 18:43:42,511 - log/train6.log - INFO -                 P: precision:  81.73%; recall:  92.27%; FB1:  86.68  613

2019-02-21 18:43:42,511 - log/train6.log - INFO -               PRO: precision:  31.17%; recall:  29.50%; FB1:  30.31  494

2019-02-21 18:43:42,515 - log/train6.log - INFO - evaluate:test
2019-02-21 18:43:43,972 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1712 phrases; correct: 1399.

2019-02-21 18:43:43,972 - log/train6.log - INFO - accuracy:  96.61%; precision:  81.72%; recall:  84.94%; FB1:  83.30

2019-02-21 18:43:43,972 - log/train6.log - INFO -                 C: precision:  90.69%; recall:  90.86%; FB1:  90.78  1031

2019-02-21 18:43:43,973 - log/train6.log - INFO -               IND: precision:  50.00%; recall:  70.21%; FB1:  58.41  66

2019-02-21 18:43:43,973 - log/train6.log - INFO -               INS: precision:  64.65%; recall:  67.37%; FB1:  65.98  99

2019-02-21 18:43:43,973 - log/train6.log - INFO -                 L: precision:  55.28%; recall:  66.02%; FB1:  60.18  123

2019-02-21 18:43:43,973 - log/train6.log - INFO -                 P: precision:  86.22%; recall:  95.10%; FB1:  90.44  225

2019-02-21 18:43:43,973 - log/train6.log - INFO -               PRO: precision:  62.50%; recall:  62.13%; FB1:  62.31  168

2019-02-21 18:43:46,178 - log/train6.log - INFO - iteration:40 step:100/10100, NER loss: 0.930375
2019-02-21 18:43:48,207 - log/train6.log - INFO - iteration:40 step:200/10100, NER loss: 0.813620
2019-02-21 18:43:50,545 - log/train6.log - INFO - iteration:40 step:300/10100, NER loss: 0.936319
2019-02-21 18:43:53,031 - log/train6.log - INFO - iteration:40 step:400/10100, NER loss: 1.221706
2019-02-21 18:43:55,061 - log/train6.log - INFO - iteration:40 step:500/10100, NER loss: 0.769593
2019-02-21 18:43:57,375 - log/train6.log - INFO - iteration:40 step:600/10100, NER loss: 0.946857
2019-02-21 18:43:59,484 - log/train6.log - INFO - iteration:40 step:700/10100, NER loss: 0.853416
2019-02-21 18:44:01,631 - log/train6.log - INFO - iteration:40 step:800/10100, NER loss: 0.744955
2019-02-21 18:44:03,880 - log/train6.log - INFO - iteration:40 step:900/10100, NER loss: 0.883580
2019-02-21 18:44:05,922 - log/train6.log - INFO - iteration:40 step:1000/10100, NER loss: 0.667839
2019-02-21 18:44:07,961 - log/train6.log - INFO - iteration:40 step:1100/10100, NER loss: 0.897655
2019-02-21 18:44:10,001 - log/train6.log - INFO - iteration:40 step:1200/10100, NER loss: 0.783126
2019-02-21 18:44:12,276 - log/train6.log - INFO - iteration:40 step:1300/10100, NER loss: 1.084200
2019-02-21 18:44:14,552 - log/train6.log - INFO - iteration:40 step:1400/10100, NER loss: 0.998442
2019-02-21 18:44:16,757 - log/train6.log - INFO - iteration:40 step:1500/10100, NER loss: 0.739756
2019-02-21 18:44:18,928 - log/train6.log - INFO - iteration:40 step:1600/10100, NER loss: 0.884044
2019-02-21 18:44:21,175 - log/train6.log - INFO - iteration:40 step:1700/10100, NER loss: 0.772261
2019-02-21 18:44:23,607 - log/train6.log - INFO - iteration:40 step:1800/10100, NER loss: 1.072617
2019-02-21 18:44:25,716 - log/train6.log - INFO - iteration:40 step:1900/10100, NER loss: 0.846947
2019-02-21 18:44:27,692 - log/train6.log - INFO - iteration:40 step:2000/10100, NER loss: 0.756678
2019-02-21 18:44:29,895 - log/train6.log - INFO - iteration:40 step:2100/10100, NER loss: 0.879580
2019-02-21 18:44:32,544 - log/train6.log - INFO - iteration:40 step:2200/10100, NER loss: 1.253329
2019-02-21 18:44:34,938 - log/train6.log - INFO - iteration:40 step:2300/10100, NER loss: 0.917568
2019-02-21 18:44:37,060 - log/train6.log - INFO - iteration:40 step:2400/10100, NER loss: 0.870486
2019-02-21 18:44:39,061 - log/train6.log - INFO - iteration:40 step:2500/10100, NER loss: 0.747770
2019-02-21 18:44:41,232 - log/train6.log - INFO - iteration:40 step:2600/10100, NER loss: 0.944237
2019-02-21 18:44:43,530 - log/train6.log - INFO - iteration:40 step:2700/10100, NER loss: 0.874902
2019-02-21 18:44:45,813 - log/train6.log - INFO - iteration:40 step:2800/10100, NER loss: 1.014318
2019-02-21 18:44:48,138 - log/train6.log - INFO - iteration:40 step:2900/10100, NER loss: 0.816593
2019-02-21 18:44:50,090 - log/train6.log - INFO - iteration:40 step:3000/10100, NER loss: 0.674329
2019-02-21 18:44:52,303 - log/train6.log - INFO - iteration:40 step:3100/10100, NER loss: 0.879667
2019-02-21 18:44:54,325 - log/train6.log - INFO - iteration:40 step:3200/10100, NER loss: 0.967516
2019-02-21 18:44:56,537 - log/train6.log - INFO - iteration:40 step:3300/10100, NER loss: 0.736659
2019-02-21 18:44:58,699 - log/train6.log - INFO - iteration:40 step:3400/10100, NER loss: 1.022112
2019-02-21 18:45:02,656 - log/train6.log - INFO - iteration:40 step:3500/10100, NER loss: 1.043167
2019-02-21 18:45:04,903 - log/train6.log - INFO - iteration:40 step:3600/10100, NER loss: 0.907653
2019-02-21 18:45:07,184 - log/train6.log - INFO - iteration:40 step:3700/10100, NER loss: 0.986434
2019-02-21 18:45:09,458 - log/train6.log - INFO - iteration:40 step:3800/10100, NER loss: 0.884281
2019-02-21 18:45:11,517 - log/train6.log - INFO - iteration:40 step:3900/10100, NER loss: 0.811400
2019-02-21 18:45:13,641 - log/train6.log - INFO - iteration:40 step:4000/10100, NER loss: 0.887185
2019-02-21 18:45:15,611 - log/train6.log - INFO - iteration:40 step:4100/10100, NER loss: 0.695046
2019-02-21 18:45:17,812 - log/train6.log - INFO - iteration:40 step:4200/10100, NER loss: 0.996861
2019-02-21 18:45:19,932 - log/train6.log - INFO - iteration:40 step:4300/10100, NER loss: 0.877524
2019-02-21 18:45:22,096 - log/train6.log - INFO - iteration:40 step:4400/10100, NER loss: 0.972214
2019-02-21 18:45:26,495 - log/train6.log - INFO - iteration:40 step:4500/10100, NER loss: 1.384931
2019-02-21 18:45:28,751 - log/train6.log - INFO - iteration:40 step:4600/10100, NER loss: 0.824127
2019-02-21 18:45:31,010 - log/train6.log - INFO - iteration:40 step:4700/10100, NER loss: 1.075072
2019-02-21 18:45:33,401 - log/train6.log - INFO - iteration:40 step:4800/10100, NER loss: 0.856187
2019-02-21 18:45:35,777 - log/train6.log - INFO - iteration:40 step:4900/10100, NER loss: 1.057921
2019-02-21 18:45:37,961 - log/train6.log - INFO - iteration:40 step:5000/10100, NER loss: 0.935556
2019-02-21 18:45:40,248 - log/train6.log - INFO - iteration:40 step:5100/10100, NER loss: 0.753729
2019-02-21 18:45:42,522 - log/train6.log - INFO - iteration:40 step:5200/10100, NER loss: 0.949411
2019-02-21 18:45:44,932 - log/train6.log - INFO - iteration:40 step:5300/10100, NER loss: 0.854136
2019-02-21 18:45:47,170 - log/train6.log - INFO - iteration:40 step:5400/10100, NER loss: 0.885674
2019-02-21 18:45:49,188 - log/train6.log - INFO - iteration:40 step:5500/10100, NER loss: 0.616476
2019-02-21 18:45:51,467 - log/train6.log - INFO - iteration:40 step:5600/10100, NER loss: 0.878571
2019-02-21 18:45:53,809 - log/train6.log - INFO - iteration:40 step:5700/10100, NER loss: 1.117152
2019-02-21 18:45:56,315 - log/train6.log - INFO - iteration:40 step:5800/10100, NER loss: 1.192645
2019-02-21 18:45:58,400 - log/train6.log - INFO - iteration:40 step:5900/10100, NER loss: 0.788368
2019-02-21 18:46:00,794 - log/train6.log - INFO - iteration:40 step:6000/10100, NER loss: 1.024555
2019-02-21 18:46:02,979 - log/train6.log - INFO - iteration:40 step:6100/10100, NER loss: 0.798346
2019-02-21 18:46:05,151 - log/train6.log - INFO - iteration:40 step:6200/10100, NER loss: 0.907337
2019-02-21 18:46:07,354 - log/train6.log - INFO - iteration:40 step:6300/10100, NER loss: 0.688959
2019-02-21 18:46:09,611 - log/train6.log - INFO - iteration:40 step:6400/10100, NER loss: 0.955436
2019-02-21 18:46:11,608 - log/train6.log - INFO - iteration:40 step:6500/10100, NER loss: 0.889148
2019-02-21 18:46:13,686 - log/train6.log - INFO - iteration:40 step:6600/10100, NER loss: 0.742955
2019-02-21 18:46:15,867 - log/train6.log - INFO - iteration:40 step:6700/10100, NER loss: 0.799706
2019-02-21 18:46:18,074 - log/train6.log - INFO - iteration:40 step:6800/10100, NER loss: 0.799063
2019-02-21 18:46:20,256 - log/train6.log - INFO - iteration:40 step:6900/10100, NER loss: 1.054243
2019-02-21 18:46:22,436 - log/train6.log - INFO - iteration:40 step:7000/10100, NER loss: 0.882432
2019-02-21 18:46:24,516 - log/train6.log - INFO - iteration:40 step:7100/10100, NER loss: 0.758978
2019-02-21 18:46:29,011 - log/train6.log - INFO - iteration:40 step:7200/10100, NER loss: 1.625116
2019-02-21 18:46:31,340 - log/train6.log - INFO - iteration:40 step:7300/10100, NER loss: 0.958768
2019-02-21 18:46:33,624 - log/train6.log - INFO - iteration:40 step:7400/10100, NER loss: 1.083144
2019-02-21 18:46:35,585 - log/train6.log - INFO - iteration:40 step:7500/10100, NER loss: 0.895924
2019-02-21 18:46:37,641 - log/train6.log - INFO - iteration:40 step:7600/10100, NER loss: 0.746971
2019-02-21 18:46:39,810 - log/train6.log - INFO - iteration:40 step:7700/10100, NER loss: 0.896314
2019-02-21 18:46:42,098 - log/train6.log - INFO - iteration:40 step:7800/10100, NER loss: 0.937327
2019-02-21 18:46:44,176 - log/train6.log - INFO - iteration:40 step:7900/10100, NER loss: 0.694996
2019-02-21 18:46:46,490 - log/train6.log - INFO - iteration:40 step:8000/10100, NER loss: 0.932051
2019-02-21 18:46:48,576 - log/train6.log - INFO - iteration:40 step:8100/10100, NER loss: 0.705492
2019-02-21 18:46:50,800 - log/train6.log - INFO - iteration:40 step:8200/10100, NER loss: 0.808625
2019-02-21 18:46:53,065 - log/train6.log - INFO - iteration:40 step:8300/10100, NER loss: 1.126278
2019-02-21 18:46:55,298 - log/train6.log - INFO - iteration:40 step:8400/10100, NER loss: 0.994159
2019-02-21 18:46:57,460 - log/train6.log - INFO - iteration:40 step:8500/10100, NER loss: 0.834915
2019-02-21 18:46:59,558 - log/train6.log - INFO - iteration:40 step:8600/10100, NER loss: 0.873563
2019-02-21 18:47:01,774 - log/train6.log - INFO - iteration:40 step:8700/10100, NER loss: 1.041184
2019-02-21 18:47:04,044 - log/train6.log - INFO - iteration:40 step:8800/10100, NER loss: 0.892828
2019-02-21 18:47:06,264 - log/train6.log - INFO - iteration:40 step:8900/10100, NER loss: 1.012677
2019-02-21 18:47:08,384 - log/train6.log - INFO - iteration:40 step:9000/10100, NER loss: 0.811387
2019-02-21 18:47:10,759 - log/train6.log - INFO - iteration:40 step:9100/10100, NER loss: 0.939334
2019-02-21 18:47:12,861 - log/train6.log - INFO - iteration:40 step:9200/10100, NER loss: 0.893204
2019-02-21 18:47:15,199 - log/train6.log - INFO - iteration:40 step:9300/10100, NER loss: 0.932530
2019-02-21 18:47:17,460 - log/train6.log - INFO - iteration:40 step:9400/10100, NER loss: 0.911793
2019-02-21 18:47:19,710 - log/train6.log - INFO - iteration:40 step:9500/10100, NER loss: 0.834125
2019-02-21 18:47:22,040 - log/train6.log - INFO - iteration:40 step:9600/10100, NER loss: 1.105392
2019-02-21 18:47:24,288 - log/train6.log - INFO - iteration:40 step:9700/10100, NER loss: 0.927274
2019-02-21 18:47:26,790 - log/train6.log - INFO - iteration:40 step:9800/10100, NER loss: 1.172818
2019-02-21 18:47:28,987 - log/train6.log - INFO - iteration:40 step:9900/10100, NER loss: 0.986030
2019-02-21 18:47:31,227 - log/train6.log - INFO - iteration:40 step:10000/10100, NER loss: 0.887341
2019-02-21 18:47:33,667 - log/train6.log - INFO - iteration:41 step:0/10100, NER loss: 0.994289
2019-02-21 18:47:33,667 - log/train6.log - INFO - evaluate:dev
2019-02-21 18:47:40,199 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 6262 phrases; correct: 4457.

2019-02-21 18:47:40,199 - log/train6.log - INFO - accuracy:  94.80%; precision:  71.18%; recall:  76.23%; FB1:  73.61

2019-02-21 18:47:40,200 - log/train6.log - INFO -                 C: precision:  85.71%; recall:  88.85%; FB1:  87.25  3513

2019-02-21 18:47:40,200 - log/train6.log - INFO -               IND: precision:  23.31%; recall:  42.16%; FB1:  30.02  738

2019-02-21 18:47:40,200 - log/train6.log - INFO -               INS: precision:  65.88%; recall:  73.35%; FB1:  69.41  422

2019-02-21 18:47:40,200 - log/train6.log - INFO -                 L: precision:  59.12%; recall:  62.05%; FB1:  60.55  636

2019-02-21 18:47:40,200 - log/train6.log - INFO -                 P: precision:  89.13%; recall:  92.08%; FB1:  90.58  561

2019-02-21 18:47:40,200 - log/train6.log - INFO -               PRO: precision:  30.61%; recall:  22.99%; FB1:  26.26  392

2019-02-21 18:47:40,203 - log/train6.log - INFO - evaluate:test
2019-02-21 18:47:41,700 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1773 phrases; correct: 1384.

2019-02-21 18:47:41,700 - log/train6.log - INFO - accuracy:  96.01%; precision:  78.06%; recall:  84.03%; FB1:  80.94

2019-02-21 18:47:41,700 - log/train6.log - INFO -                 C: precision:  88.66%; recall:  91.93%; FB1:  90.27  1067

2019-02-21 18:47:41,700 - log/train6.log - INFO -               IND: precision:  24.67%; recall:  78.72%; FB1:  37.56  150

2019-02-21 18:47:41,700 - log/train6.log - INFO -               INS: precision:  64.65%; recall:  67.37%; FB1:  65.98  99

2019-02-21 18:47:41,700 - log/train6.log - INFO -                 L: precision:  58.65%; recall:  59.22%; FB1:  58.94  104

2019-02-21 18:47:41,700 - log/train6.log - INFO -                 P: precision:  91.51%; recall:  95.10%; FB1:  93.27  212

2019-02-21 18:47:41,700 - log/train6.log - INFO -               PRO: precision:  58.16%; recall:  48.52%; FB1:  52.90  141

2019-02-21 18:47:43,850 - log/train6.log - INFO - iteration:41 step:100/10100, NER loss: 0.944354
2019-02-21 18:47:45,716 - log/train6.log - INFO - iteration:41 step:200/10100, NER loss: 0.877348
2019-02-21 18:47:47,836 - log/train6.log - INFO - iteration:41 step:300/10100, NER loss: 0.880736
2019-02-21 18:47:51,906 - log/train6.log - INFO - iteration:41 step:400/10100, NER loss: 1.159228
2019-02-21 18:47:54,307 - log/train6.log - INFO - iteration:41 step:500/10100, NER loss: 1.000914
2019-02-21 18:47:56,563 - log/train6.log - INFO - iteration:41 step:600/10100, NER loss: 0.855839
2019-02-21 18:47:59,073 - log/train6.log - INFO - iteration:41 step:700/10100, NER loss: 1.056389
2019-02-21 18:48:01,330 - log/train6.log - INFO - iteration:41 step:800/10100, NER loss: 0.923742
2019-02-21 18:48:03,699 - log/train6.log - INFO - iteration:41 step:900/10100, NER loss: 0.930004
2019-02-21 18:48:06,109 - log/train6.log - INFO - iteration:41 step:1000/10100, NER loss: 0.752774
2019-02-21 18:48:08,136 - log/train6.log - INFO - iteration:41 step:1100/10100, NER loss: 0.832759
2019-02-21 18:48:10,414 - log/train6.log - INFO - iteration:41 step:1200/10100, NER loss: 0.911755
2019-02-21 18:48:12,459 - log/train6.log - INFO - iteration:41 step:1300/10100, NER loss: 0.773682
2019-02-21 18:48:14,621 - log/train6.log - INFO - iteration:41 step:1400/10100, NER loss: 0.792186
2019-02-21 18:48:16,810 - log/train6.log - INFO - iteration:41 step:1500/10100, NER loss: 0.881809
2019-02-21 18:48:19,039 - log/train6.log - INFO - iteration:41 step:1600/10100, NER loss: 1.066587
2019-02-21 18:48:21,098 - log/train6.log - INFO - iteration:41 step:1700/10100, NER loss: 0.698700
2019-02-21 18:48:23,114 - log/train6.log - INFO - iteration:41 step:1800/10100, NER loss: 0.803289
2019-02-21 18:48:25,187 - log/train6.log - INFO - iteration:41 step:1900/10100, NER loss: 0.950142
2019-02-21 18:48:27,224 - log/train6.log - INFO - iteration:41 step:2000/10100, NER loss: 0.935148
2019-02-21 18:48:29,506 - log/train6.log - INFO - iteration:41 step:2100/10100, NER loss: 1.103789
2019-02-21 18:48:31,728 - log/train6.log - INFO - iteration:41 step:2200/10100, NER loss: 0.844163
2019-02-21 18:48:33,997 - log/train6.log - INFO - iteration:41 step:2300/10100, NER loss: 0.820547
2019-02-21 18:48:36,102 - log/train6.log - INFO - iteration:41 step:2400/10100, NER loss: 1.037283
2019-02-21 18:48:38,246 - log/train6.log - INFO - iteration:41 step:2500/10100, NER loss: 0.914151
2019-02-21 18:48:40,509 - log/train6.log - INFO - iteration:41 step:2600/10100, NER loss: 0.940726
2019-02-21 18:48:42,766 - log/train6.log - INFO - iteration:41 step:2700/10100, NER loss: 0.917827
2019-02-21 18:48:45,076 - log/train6.log - INFO - iteration:41 step:2800/10100, NER loss: 0.997133
2019-02-21 18:48:47,236 - log/train6.log - INFO - iteration:41 step:2900/10100, NER loss: 0.991232
2019-02-21 18:48:49,390 - log/train6.log - INFO - iteration:41 step:3000/10100, NER loss: 0.790906
2019-02-21 18:48:51,506 - log/train6.log - INFO - iteration:41 step:3100/10100, NER loss: 0.838199
2019-02-21 18:48:53,869 - log/train6.log - INFO - iteration:41 step:3200/10100, NER loss: 1.072872
2019-02-21 18:48:55,937 - log/train6.log - INFO - iteration:41 step:3300/10100, NER loss: 0.888428
2019-02-21 18:48:58,435 - log/train6.log - INFO - iteration:41 step:3400/10100, NER loss: 1.179568
2019-02-21 18:49:00,837 - log/train6.log - INFO - iteration:41 step:3500/10100, NER loss: 1.043841
2019-02-21 18:49:02,898 - log/train6.log - INFO - iteration:41 step:3600/10100, NER loss: 0.802720
2019-02-21 18:49:05,031 - log/train6.log - INFO - iteration:41 step:3700/10100, NER loss: 0.861051
2019-02-21 18:49:07,003 - log/train6.log - INFO - iteration:41 step:3800/10100, NER loss: 0.677619
2019-02-21 18:49:09,042 - log/train6.log - INFO - iteration:41 step:3900/10100, NER loss: 0.739931
2019-02-21 18:49:11,410 - log/train6.log - INFO - iteration:41 step:4000/10100, NER loss: 0.913727
2019-02-21 18:49:15,782 - log/train6.log - INFO - iteration:41 step:4100/10100, NER loss: 1.126043
2019-02-21 18:49:17,893 - log/train6.log - INFO - iteration:41 step:4200/10100, NER loss: 0.819647
2019-02-21 18:49:20,177 - log/train6.log - INFO - iteration:41 step:4300/10100, NER loss: 0.777336
2019-02-21 18:49:22,382 - log/train6.log - INFO - iteration:41 step:4400/10100, NER loss: 1.016895
2019-02-21 18:49:24,584 - log/train6.log - INFO - iteration:41 step:4500/10100, NER loss: 0.829638
2019-02-21 18:49:26,746 - log/train6.log - INFO - iteration:41 step:4600/10100, NER loss: 0.829288
2019-02-21 18:49:29,171 - log/train6.log - INFO - iteration:41 step:4700/10100, NER loss: 0.927197
2019-02-21 18:49:31,498 - log/train6.log - INFO - iteration:41 step:4800/10100, NER loss: 0.955437
2019-02-21 18:49:33,722 - log/train6.log - INFO - iteration:41 step:4900/10100, NER loss: 0.804703
2019-02-21 18:49:36,140 - log/train6.log - INFO - iteration:41 step:5000/10100, NER loss: 0.945286
2019-02-21 18:49:38,393 - log/train6.log - INFO - iteration:41 step:5100/10100, NER loss: 0.744208
2019-02-21 18:49:40,672 - log/train6.log - INFO - iteration:41 step:5200/10100, NER loss: 0.882892
2019-02-21 18:49:42,834 - log/train6.log - INFO - iteration:41 step:5300/10100, NER loss: 1.017110
2019-02-21 18:49:45,051 - log/train6.log - INFO - iteration:41 step:5400/10100, NER loss: 0.858793
2019-02-21 18:49:47,364 - log/train6.log - INFO - iteration:41 step:5500/10100, NER loss: 0.911241
2019-02-21 18:49:49,508 - log/train6.log - INFO - iteration:41 step:5600/10100, NER loss: 0.960020
2019-02-21 18:49:51,735 - log/train6.log - INFO - iteration:41 step:5700/10100, NER loss: 0.943489
2019-02-21 18:49:54,011 - log/train6.log - INFO - iteration:41 step:5800/10100, NER loss: 0.872544
2019-02-21 18:49:56,281 - log/train6.log - INFO - iteration:41 step:5900/10100, NER loss: 0.865610
2019-02-21 18:49:58,645 - log/train6.log - INFO - iteration:41 step:6000/10100, NER loss: 0.975594
2019-02-21 18:50:00,807 - log/train6.log - INFO - iteration:41 step:6100/10100, NER loss: 0.722774
2019-02-21 18:50:02,905 - log/train6.log - INFO - iteration:41 step:6200/10100, NER loss: 0.758981
2019-02-21 18:50:04,900 - log/train6.log - INFO - iteration:41 step:6300/10100, NER loss: 0.565445
2019-02-21 18:50:06,966 - log/train6.log - INFO - iteration:41 step:6400/10100, NER loss: 0.723523
2019-02-21 18:50:09,158 - log/train6.log - INFO - iteration:41 step:6500/10100, NER loss: 0.842079
2019-02-21 18:50:11,529 - log/train6.log - INFO - iteration:41 step:6600/10100, NER loss: 0.977684
2019-02-21 18:50:13,832 - log/train6.log - INFO - iteration:41 step:6700/10100, NER loss: 0.987553
2019-02-21 18:50:15,910 - log/train6.log - INFO - iteration:41 step:6800/10100, NER loss: 0.896615
2019-02-21 18:50:18,077 - log/train6.log - INFO - iteration:41 step:6900/10100, NER loss: 0.796881
2019-02-21 18:50:20,083 - log/train6.log - INFO - iteration:41 step:7000/10100, NER loss: 0.629374
2019-02-21 18:50:22,257 - log/train6.log - INFO - iteration:41 step:7100/10100, NER loss: 0.760815
2019-02-21 18:50:24,339 - log/train6.log - INFO - iteration:41 step:7200/10100, NER loss: 0.864037
2019-02-21 18:50:26,494 - log/train6.log - INFO - iteration:41 step:7300/10100, NER loss: 0.879079
2019-02-21 18:50:28,608 - log/train6.log - INFO - iteration:41 step:7400/10100, NER loss: 0.754488
2019-02-21 18:50:30,719 - log/train6.log - INFO - iteration:41 step:7500/10100, NER loss: 0.675856
2019-02-21 18:50:32,847 - log/train6.log - INFO - iteration:41 step:7600/10100, NER loss: 1.015124
2019-02-21 18:50:35,066 - log/train6.log - INFO - iteration:41 step:7700/10100, NER loss: 0.976593
2019-02-21 18:50:37,164 - log/train6.log - INFO - iteration:41 step:7800/10100, NER loss: 0.889805
2019-02-21 18:50:39,375 - log/train6.log - INFO - iteration:41 step:7900/10100, NER loss: 0.930075
2019-02-21 18:50:41,591 - log/train6.log - INFO - iteration:41 step:8000/10100, NER loss: 1.092620
2019-02-21 18:50:43,794 - log/train6.log - INFO - iteration:41 step:8100/10100, NER loss: 0.975286
2019-02-21 18:50:45,756 - log/train6.log - INFO - iteration:41 step:8200/10100, NER loss: 0.695232
2019-02-21 18:50:48,138 - log/train6.log - INFO - iteration:41 step:8300/10100, NER loss: 1.034495
2019-02-21 18:50:50,407 - log/train6.log - INFO - iteration:41 step:8400/10100, NER loss: 0.758803
2019-02-21 18:50:52,482 - log/train6.log - INFO - iteration:41 step:8500/10100, NER loss: 0.694473
2019-02-21 18:50:57,100 - log/train6.log - INFO - iteration:41 step:8600/10100, NER loss: 3.842169
2019-02-21 18:50:59,453 - log/train6.log - INFO - iteration:41 step:8700/10100, NER loss: 1.306441
2019-02-21 18:51:01,516 - log/train6.log - INFO - iteration:41 step:8800/10100, NER loss: 0.852091
2019-02-21 18:51:03,914 - log/train6.log - INFO - iteration:41 step:8900/10100, NER loss: 0.947290
2019-02-21 18:51:06,204 - log/train6.log - INFO - iteration:41 step:9000/10100, NER loss: 1.192671
2019-02-21 18:51:08,453 - log/train6.log - INFO - iteration:41 step:9100/10100, NER loss: 0.878923
2019-02-21 18:51:10,739 - log/train6.log - INFO - iteration:41 step:9200/10100, NER loss: 0.895394
2019-02-21 18:51:12,969 - log/train6.log - INFO - iteration:41 step:9300/10100, NER loss: 0.875133
2019-02-21 18:51:15,238 - log/train6.log - INFO - iteration:41 step:9400/10100, NER loss: 0.947550
2019-02-21 18:51:17,502 - log/train6.log - INFO - iteration:41 step:9500/10100, NER loss: 1.099423
2019-02-21 18:51:19,759 - log/train6.log - INFO - iteration:41 step:9600/10100, NER loss: 1.007632
2019-02-21 18:51:22,438 - log/train6.log - INFO - iteration:41 step:9700/10100, NER loss: 1.274520
2019-02-21 18:51:24,983 - log/train6.log - INFO - iteration:41 step:9800/10100, NER loss: 1.125876
2019-02-21 18:51:27,048 - log/train6.log - INFO - iteration:41 step:9900/10100, NER loss: 0.797837
2019-02-21 18:51:29,261 - log/train6.log - INFO - iteration:41 step:10000/10100, NER loss: 0.931544
2019-02-21 18:51:31,365 - log/train6.log - INFO - iteration:42 step:0/10100, NER loss: 0.725421
2019-02-21 18:51:31,365 - log/train6.log - INFO - evaluate:dev
2019-02-21 18:51:37,868 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5690 phrases; correct: 4345.

2019-02-21 18:51:37,869 - log/train6.log - INFO - accuracy:  95.26%; precision:  76.36%; recall:  74.31%; FB1:  75.32

2019-02-21 18:51:37,869 - log/train6.log - INFO -                 C: precision:  88.70%; recall:  87.34%; FB1:  88.02  3337

2019-02-21 18:51:37,870 - log/train6.log - INFO -               IND: precision:  40.14%; recall:  28.92%; FB1:  33.62  294

2019-02-21 18:51:37,870 - log/train6.log - INFO -               INS: precision:  62.81%; recall:  74.41%; FB1:  68.12  449

2019-02-21 18:51:37,870 - log/train6.log - INFO -                 L: precision:  55.88%; recall:  56.44%; FB1:  56.16  612

2019-02-21 18:51:37,870 - log/train6.log - INFO -                 P: precision:  88.39%; recall:  91.16%; FB1:  89.76  560

2019-02-21 18:51:37,870 - log/train6.log - INFO -               PRO: precision:  33.79%; recall:  28.35%; FB1:  30.83  438

2019-02-21 18:51:37,873 - log/train6.log - INFO - evaluate:test
2019-02-21 18:51:39,327 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1666 phrases; correct: 1389.

2019-02-21 18:51:39,327 - log/train6.log - INFO - accuracy:  96.70%; precision:  83.37%; recall:  84.34%; FB1:  83.85

2019-02-21 18:51:39,328 - log/train6.log - INFO -                 C: precision:  90.70%; recall:  90.96%; FB1:  90.83  1032

2019-02-21 18:51:39,328 - log/train6.log - INFO -               IND: precision:  57.41%; recall:  65.96%; FB1:  61.39  54

2019-02-21 18:51:39,328 - log/train6.log - INFO -               INS: precision:  66.00%; recall:  69.47%; FB1:  67.69  100

2019-02-21 18:51:39,328 - log/train6.log - INFO -                 L: precision:  60.36%; recall:  65.05%; FB1:  62.62  111

2019-02-21 18:51:39,328 - log/train6.log - INFO -                 P: precision:  91.08%; recall:  95.10%; FB1:  93.05  213

2019-02-21 18:51:39,328 - log/train6.log - INFO -               PRO: precision:  60.90%; recall:  56.21%; FB1:  58.46  156

2019-02-21 18:51:41,221 - log/train6.log - INFO - iteration:42 step:100/10100, NER loss: 0.766638
2019-02-21 18:51:43,421 - log/train6.log - INFO - iteration:42 step:200/10100, NER loss: 0.837968
2019-02-21 18:51:45,682 - log/train6.log - INFO - iteration:42 step:300/10100, NER loss: 0.989182
2019-02-21 18:51:47,884 - log/train6.log - INFO - iteration:42 step:400/10100, NER loss: 0.946001
2019-02-21 18:51:50,120 - log/train6.log - INFO - iteration:42 step:500/10100, NER loss: 0.891192
2019-02-21 18:51:52,348 - log/train6.log - INFO - iteration:42 step:600/10100, NER loss: 0.963636
2019-02-21 18:51:54,316 - log/train6.log - INFO - iteration:42 step:700/10100, NER loss: 0.991731
2019-02-21 18:51:56,671 - log/train6.log - INFO - iteration:42 step:800/10100, NER loss: 0.934528
2019-02-21 18:51:58,745 - log/train6.log - INFO - iteration:42 step:900/10100, NER loss: 0.757448
2019-02-21 18:52:00,773 - log/train6.log - INFO - iteration:42 step:1000/10100, NER loss: 0.775161
2019-02-21 18:52:03,123 - log/train6.log - INFO - iteration:42 step:1100/10100, NER loss: 0.867322
2019-02-21 18:52:05,292 - log/train6.log - INFO - iteration:42 step:1200/10100, NER loss: 1.052047
2019-02-21 18:52:07,672 - log/train6.log - INFO - iteration:42 step:1300/10100, NER loss: 0.826083
2019-02-21 18:52:09,981 - log/train6.log - INFO - iteration:42 step:1400/10100, NER loss: 0.828424
2019-02-21 18:52:14,668 - log/train6.log - INFO - iteration:42 step:1500/10100, NER loss: 1.308111
2019-02-21 18:52:16,818 - log/train6.log - INFO - iteration:42 step:1600/10100, NER loss: 0.832939
2019-02-21 18:52:18,797 - log/train6.log - INFO - iteration:42 step:1700/10100, NER loss: 0.877922
2019-02-21 18:52:21,151 - log/train6.log - INFO - iteration:42 step:1800/10100, NER loss: 0.813794
2019-02-21 18:52:23,339 - log/train6.log - INFO - iteration:42 step:1900/10100, NER loss: 0.791105
2019-02-21 18:52:25,562 - log/train6.log - INFO - iteration:42 step:2000/10100, NER loss: 0.933839
2019-02-21 18:52:28,055 - log/train6.log - INFO - iteration:42 step:2100/10100, NER loss: 1.049130
2019-02-21 18:52:30,292 - log/train6.log - INFO - iteration:42 step:2200/10100, NER loss: 1.016046
2019-02-21 18:52:32,481 - log/train6.log - INFO - iteration:42 step:2300/10100, NER loss: 0.956987
2019-02-21 18:52:34,779 - log/train6.log - INFO - iteration:42 step:2400/10100, NER loss: 0.952926
2019-02-21 18:52:36,926 - log/train6.log - INFO - iteration:42 step:2500/10100, NER loss: 0.860011
2019-02-21 18:52:39,235 - log/train6.log - INFO - iteration:42 step:2600/10100, NER loss: 0.866800
2019-02-21 18:52:43,439 - log/train6.log - INFO - iteration:42 step:2700/10100, NER loss: 1.636856
2019-02-21 18:52:45,483 - log/train6.log - INFO - iteration:42 step:2800/10100, NER loss: 0.640989
2019-02-21 18:52:47,771 - log/train6.log - INFO - iteration:42 step:2900/10100, NER loss: 0.907879
2019-02-21 18:52:49,799 - log/train6.log - INFO - iteration:42 step:3000/10100, NER loss: 0.799016
2019-02-21 18:52:54,003 - log/train6.log - INFO - iteration:42 step:3100/10100, NER loss: 1.515082
2019-02-21 18:52:56,141 - log/train6.log - INFO - iteration:42 step:3200/10100, NER loss: 0.752843
2019-02-21 18:52:58,501 - log/train6.log - INFO - iteration:42 step:3300/10100, NER loss: 0.925444
2019-02-21 18:53:00,638 - log/train6.log - INFO - iteration:42 step:3400/10100, NER loss: 0.862601
2019-02-21 18:53:02,961 - log/train6.log - INFO - iteration:42 step:3500/10100, NER loss: 0.934264
2019-02-21 18:53:05,263 - log/train6.log - INFO - iteration:42 step:3600/10100, NER loss: 0.956254
2019-02-21 18:53:07,556 - log/train6.log - INFO - iteration:42 step:3700/10100, NER loss: 0.930421
2019-02-21 18:53:09,726 - log/train6.log - INFO - iteration:42 step:3800/10100, NER loss: 0.895849
2019-02-21 18:53:11,954 - log/train6.log - INFO - iteration:42 step:3900/10100, NER loss: 0.880322
2019-02-21 18:53:14,649 - log/train6.log - INFO - iteration:42 step:4000/10100, NER loss: 1.168401
2019-02-21 18:53:16,934 - log/train6.log - INFO - iteration:42 step:4100/10100, NER loss: 0.930322
2019-02-21 18:53:19,345 - log/train6.log - INFO - iteration:42 step:4200/10100, NER loss: 1.170780
2019-02-21 18:53:21,507 - log/train6.log - INFO - iteration:42 step:4300/10100, NER loss: 0.865864
2019-02-21 18:53:24,057 - log/train6.log - INFO - iteration:42 step:4400/10100, NER loss: 1.193447
2019-02-21 18:53:26,243 - log/train6.log - INFO - iteration:42 step:4500/10100, NER loss: 0.973329
2019-02-21 18:53:28,557 - log/train6.log - INFO - iteration:42 step:4600/10100, NER loss: 0.971400
2019-02-21 18:53:31,119 - log/train6.log - INFO - iteration:42 step:4700/10100, NER loss: 0.968499
2019-02-21 18:53:33,323 - log/train6.log - INFO - iteration:42 step:4800/10100, NER loss: 0.942119
2019-02-21 18:53:35,396 - log/train6.log - INFO - iteration:42 step:4900/10100, NER loss: 0.720003
2019-02-21 18:53:37,483 - log/train6.log - INFO - iteration:42 step:5000/10100, NER loss: 0.890552
2019-02-21 18:53:39,507 - log/train6.log - INFO - iteration:42 step:5100/10100, NER loss: 0.827386
2019-02-21 18:53:41,827 - log/train6.log - INFO - iteration:42 step:5200/10100, NER loss: 1.097851
2019-02-21 18:53:43,742 - log/train6.log - INFO - iteration:42 step:5300/10100, NER loss: 0.752986
2019-02-21 18:53:46,047 - log/train6.log - INFO - iteration:42 step:5400/10100, NER loss: 0.998846
2019-02-21 18:53:48,297 - log/train6.log - INFO - iteration:42 step:5500/10100, NER loss: 0.827350
2019-02-21 18:53:50,503 - log/train6.log - INFO - iteration:42 step:5600/10100, NER loss: 0.842249
2019-02-21 18:53:52,599 - log/train6.log - INFO - iteration:42 step:5700/10100, NER loss: 0.697047
2019-02-21 18:53:54,702 - log/train6.log - INFO - iteration:42 step:5800/10100, NER loss: 0.757086
2019-02-21 18:53:57,103 - log/train6.log - INFO - iteration:42 step:5900/10100, NER loss: 1.013648
2019-02-21 18:53:59,294 - log/train6.log - INFO - iteration:42 step:6000/10100, NER loss: 0.973908
2019-02-21 18:54:01,704 - log/train6.log - INFO - iteration:42 step:6100/10100, NER loss: 1.074589
2019-02-21 18:54:03,870 - log/train6.log - INFO - iteration:42 step:6200/10100, NER loss: 0.727983
2019-02-21 18:54:06,014 - log/train6.log - INFO - iteration:42 step:6300/10100, NER loss: 0.826519
2019-02-21 18:54:08,044 - log/train6.log - INFO - iteration:42 step:6400/10100, NER loss: 0.751493
2019-02-21 18:54:10,196 - log/train6.log - INFO - iteration:42 step:6500/10100, NER loss: 0.826065
2019-02-21 18:54:12,289 - log/train6.log - INFO - iteration:42 step:6600/10100, NER loss: 0.679724
2019-02-21 18:54:14,511 - log/train6.log - INFO - iteration:42 step:6700/10100, NER loss: 0.742013
2019-02-21 18:54:16,629 - log/train6.log - INFO - iteration:42 step:6800/10100, NER loss: 0.881463
2019-02-21 18:54:18,674 - log/train6.log - INFO - iteration:42 step:6900/10100, NER loss: 0.667757
2019-02-21 18:54:20,627 - log/train6.log - INFO - iteration:42 step:7000/10100, NER loss: 0.806811
2019-02-21 18:54:22,935 - log/train6.log - INFO - iteration:42 step:7100/10100, NER loss: 1.024108
2019-02-21 18:54:25,171 - log/train6.log - INFO - iteration:42 step:7200/10100, NER loss: 0.904916
2019-02-21 18:54:27,493 - log/train6.log - INFO - iteration:42 step:7300/10100, NER loss: 0.847306
2019-02-21 18:54:29,642 - log/train6.log - INFO - iteration:42 step:7400/10100, NER loss: 0.794950
2019-02-21 18:54:31,918 - log/train6.log - INFO - iteration:42 step:7500/10100, NER loss: 0.843304
2019-02-21 18:54:33,981 - log/train6.log - INFO - iteration:42 step:7600/10100, NER loss: 0.908629
2019-02-21 18:54:36,214 - log/train6.log - INFO - iteration:42 step:7700/10100, NER loss: 1.084991
2019-02-21 18:54:38,514 - log/train6.log - INFO - iteration:42 step:7800/10100, NER loss: 0.999611
2019-02-21 18:54:40,595 - log/train6.log - INFO - iteration:42 step:7900/10100, NER loss: 0.826408
2019-02-21 18:54:42,924 - log/train6.log - INFO - iteration:42 step:8000/10100, NER loss: 0.839666
2019-02-21 18:54:45,228 - log/train6.log - INFO - iteration:42 step:8100/10100, NER loss: 0.884510
2019-02-21 18:54:47,754 - log/train6.log - INFO - iteration:42 step:8200/10100, NER loss: 0.932672
2019-02-21 18:54:49,861 - log/train6.log - INFO - iteration:42 step:8300/10100, NER loss: 0.905711
2019-02-21 18:54:52,035 - log/train6.log - INFO - iteration:42 step:8400/10100, NER loss: 0.902576
2019-02-21 18:54:54,213 - log/train6.log - INFO - iteration:42 step:8500/10100, NER loss: 0.822748
2019-02-21 18:54:56,304 - log/train6.log - INFO - iteration:42 step:8600/10100, NER loss: 0.824701
2019-02-21 18:54:58,440 - log/train6.log - INFO - iteration:42 step:8700/10100, NER loss: 0.805650
2019-02-21 18:55:00,589 - log/train6.log - INFO - iteration:42 step:8800/10100, NER loss: 0.810607
2019-02-21 18:55:02,833 - log/train6.log - INFO - iteration:42 step:8900/10100, NER loss: 0.977892
2019-02-21 18:55:05,171 - log/train6.log - INFO - iteration:42 step:9000/10100, NER loss: 1.037304
2019-02-21 18:55:07,256 - log/train6.log - INFO - iteration:42 step:9100/10100, NER loss: 0.736617
2019-02-21 18:55:09,552 - log/train6.log - INFO - iteration:42 step:9200/10100, NER loss: 0.997567
2019-02-21 18:55:11,978 - log/train6.log - INFO - iteration:42 step:9300/10100, NER loss: 0.988544
2019-02-21 18:55:14,115 - log/train6.log - INFO - iteration:42 step:9400/10100, NER loss: 0.786829
2019-02-21 18:55:16,329 - log/train6.log - INFO - iteration:42 step:9500/10100, NER loss: 1.023898
2019-02-21 18:55:18,469 - log/train6.log - INFO - iteration:42 step:9600/10100, NER loss: 0.924008
2019-02-21 18:55:20,816 - log/train6.log - INFO - iteration:42 step:9700/10100, NER loss: 1.074280
2019-02-21 18:55:23,202 - log/train6.log - INFO - iteration:42 step:9800/10100, NER loss: 0.928955
2019-02-21 18:55:25,249 - log/train6.log - INFO - iteration:42 step:9900/10100, NER loss: 0.755944
2019-02-21 18:55:27,372 - log/train6.log - INFO - iteration:42 step:10000/10100, NER loss: 0.810867
2019-02-21 18:55:29,556 - log/train6.log - INFO - iteration:43 step:0/10100, NER loss: 0.972130
2019-02-21 18:55:29,556 - log/train6.log - INFO - evaluate:dev
2019-02-21 18:55:36,040 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5828 phrases; correct: 4387.

2019-02-21 18:55:36,040 - log/train6.log - INFO - accuracy:  95.27%; precision:  75.27%; recall:  75.03%; FB1:  75.15

2019-02-21 18:55:36,040 - log/train6.log - INFO -                 C: precision:  84.22%; recall:  89.29%; FB1:  86.68  3593

2019-02-21 18:55:36,040 - log/train6.log - INFO -               IND: precision:  33.41%; recall:  34.07%; FB1:  33.74  416

2019-02-21 18:55:36,040 - log/train6.log - INFO -               INS: precision:  72.40%; recall:  69.92%; FB1:  71.14  366

2019-02-21 18:55:36,040 - log/train6.log - INFO -                 L: precision:  56.56%; recall:  59.08%; FB1:  57.79  633

2019-02-21 18:55:36,040 - log/train6.log - INFO -                 P: precision:  87.22%; recall:  91.71%; FB1:  89.41  571

2019-02-21 18:55:36,040 - log/train6.log - INFO -               PRO: precision:  40.56%; recall:  19.35%; FB1:  26.20  249

2019-02-21 18:55:36,043 - log/train6.log - INFO - evaluate:test
2019-02-21 18:55:37,512 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1704 phrases; correct: 1392.

2019-02-21 18:55:37,512 - log/train6.log - INFO - accuracy:  96.64%; precision:  81.69%; recall:  84.52%; FB1:  83.08

2019-02-21 18:55:37,512 - log/train6.log - INFO -                 C: precision:  87.27%; recall:  92.61%; FB1:  89.86  1092

2019-02-21 18:55:37,513 - log/train6.log - INFO -               IND: precision:  40.23%; recall:  74.47%; FB1:  52.24  87

2019-02-21 18:55:37,513 - log/train6.log - INFO -               INS: precision:  65.96%; recall:  65.26%; FB1:  65.61  94

2019-02-21 18:55:37,513 - log/train6.log - INFO -                 L: precision:  58.49%; recall:  60.19%; FB1:  59.33  106

2019-02-21 18:55:37,513 - log/train6.log - INFO -                 P: precision:  90.74%; recall:  96.08%; FB1:  93.33  216

2019-02-21 18:55:37,513 - log/train6.log - INFO -               PRO: precision:  77.06%; recall:  49.70%; FB1:  60.43  109

2019-02-21 18:55:39,504 - log/train6.log - INFO - iteration:43 step:100/10100, NER loss: 0.816915
2019-02-21 18:55:43,607 - log/train6.log - INFO - iteration:43 step:200/10100, NER loss: 1.043833
2019-02-21 18:55:45,957 - log/train6.log - INFO - iteration:43 step:300/10100, NER loss: 0.877592
2019-02-21 18:55:48,122 - log/train6.log - INFO - iteration:43 step:400/10100, NER loss: 0.903008
2019-02-21 18:55:50,409 - log/train6.log - INFO - iteration:43 step:500/10100, NER loss: 0.930793
2019-02-21 18:55:52,605 - log/train6.log - INFO - iteration:43 step:600/10100, NER loss: 1.083544
2019-02-21 18:55:54,946 - log/train6.log - INFO - iteration:43 step:700/10100, NER loss: 1.026916
2019-02-21 18:55:57,101 - log/train6.log - INFO - iteration:43 step:800/10100, NER loss: 0.810238
2019-02-21 18:55:59,479 - log/train6.log - INFO - iteration:43 step:900/10100, NER loss: 0.893580
2019-02-21 18:56:01,708 - log/train6.log - INFO - iteration:43 step:1000/10100, NER loss: 0.888763
2019-02-21 18:56:03,928 - log/train6.log - INFO - iteration:43 step:1100/10100, NER loss: 0.827008
2019-02-21 18:56:05,992 - log/train6.log - INFO - iteration:43 step:1200/10100, NER loss: 0.935630
2019-02-21 18:56:08,351 - log/train6.log - INFO - iteration:43 step:1300/10100, NER loss: 0.992631
2019-02-21 18:56:10,494 - log/train6.log - INFO - iteration:43 step:1400/10100, NER loss: 0.881961
2019-02-21 18:56:12,542 - log/train6.log - INFO - iteration:43 step:1500/10100, NER loss: 0.794229
2019-02-21 18:56:14,454 - log/train6.log - INFO - iteration:43 step:1600/10100, NER loss: 0.699282
2019-02-21 18:56:16,472 - log/train6.log - INFO - iteration:43 step:1700/10100, NER loss: 0.772612
2019-02-21 18:56:18,680 - log/train6.log - INFO - iteration:43 step:1800/10100, NER loss: 0.958123
2019-02-21 18:56:21,358 - log/train6.log - INFO - iteration:43 step:1900/10100, NER loss: 1.067053
2019-02-21 18:56:23,368 - log/train6.log - INFO - iteration:43 step:2000/10100, NER loss: 0.772260
2019-02-21 18:56:25,524 - log/train6.log - INFO - iteration:43 step:2100/10100, NER loss: 0.672546
2019-02-21 18:56:27,601 - log/train6.log - INFO - iteration:43 step:2200/10100, NER loss: 0.901206
2019-02-21 18:56:29,816 - log/train6.log - INFO - iteration:43 step:2300/10100, NER loss: 0.930177
2019-02-21 18:56:31,932 - log/train6.log - INFO - iteration:43 step:2400/10100, NER loss: 0.849604
2019-02-21 18:56:34,196 - log/train6.log - INFO - iteration:43 step:2500/10100, NER loss: 1.096882
2019-02-21 18:56:36,385 - log/train6.log - INFO - iteration:43 step:2600/10100, NER loss: 1.035019
2019-02-21 18:56:38,427 - log/train6.log - INFO - iteration:43 step:2700/10100, NER loss: 0.746233
2019-02-21 18:56:40,642 - log/train6.log - INFO - iteration:43 step:2800/10100, NER loss: 0.922228
2019-02-21 18:56:43,088 - log/train6.log - INFO - iteration:43 step:2900/10100, NER loss: 0.975529
2019-02-21 18:56:45,203 - log/train6.log - INFO - iteration:43 step:3000/10100, NER loss: 0.700570
2019-02-21 18:56:47,527 - log/train6.log - INFO - iteration:43 step:3100/10100, NER loss: 0.981131
2019-02-21 18:56:49,860 - log/train6.log - INFO - iteration:43 step:3200/10100, NER loss: 1.029141
2019-02-21 18:56:52,201 - log/train6.log - INFO - iteration:43 step:3300/10100, NER loss: 0.994800
2019-02-21 18:56:54,450 - log/train6.log - INFO - iteration:43 step:3400/10100, NER loss: 0.874585
2019-02-21 18:56:56,678 - log/train6.log - INFO - iteration:43 step:3500/10100, NER loss: 0.928280
2019-02-21 18:56:59,064 - log/train6.log - INFO - iteration:43 step:3600/10100, NER loss: 1.152161
2019-02-21 18:57:02,979 - log/train6.log - INFO - iteration:43 step:3700/10100, NER loss: 0.888793
2019-02-21 18:57:05,365 - log/train6.log - INFO - iteration:43 step:3800/10100, NER loss: 1.168406
2019-02-21 18:57:07,732 - log/train6.log - INFO - iteration:43 step:3900/10100, NER loss: 1.012441
2019-02-21 18:57:09,886 - log/train6.log - INFO - iteration:43 step:4000/10100, NER loss: 1.016930
2019-02-21 18:57:12,120 - log/train6.log - INFO - iteration:43 step:4100/10100, NER loss: 0.946975
2019-02-21 18:57:14,203 - log/train6.log - INFO - iteration:43 step:4200/10100, NER loss: 0.705540
2019-02-21 18:57:16,582 - log/train6.log - INFO - iteration:43 step:4300/10100, NER loss: 1.057901
2019-02-21 18:57:18,725 - log/train6.log - INFO - iteration:43 step:4400/10100, NER loss: 0.904918
2019-02-21 18:57:20,991 - log/train6.log - INFO - iteration:43 step:4500/10100, NER loss: 0.851478
2019-02-21 18:57:23,318 - log/train6.log - INFO - iteration:43 step:4600/10100, NER loss: 0.904446
2019-02-21 18:57:25,762 - log/train6.log - INFO - iteration:43 step:4700/10100, NER loss: 0.996642
2019-02-21 18:57:28,043 - log/train6.log - INFO - iteration:43 step:4800/10100, NER loss: 0.857166
2019-02-21 18:57:30,195 - log/train6.log - INFO - iteration:43 step:4900/10100, NER loss: 0.740741
2019-02-21 18:57:32,443 - log/train6.log - INFO - iteration:43 step:5000/10100, NER loss: 0.919526
2019-02-21 18:57:34,745 - log/train6.log - INFO - iteration:43 step:5100/10100, NER loss: 0.966678
2019-02-21 18:57:37,342 - log/train6.log - INFO - iteration:43 step:5200/10100, NER loss: 1.137243
2019-02-21 18:57:39,635 - log/train6.log - INFO - iteration:43 step:5300/10100, NER loss: 0.990137
2019-02-21 18:57:41,922 - log/train6.log - INFO - iteration:43 step:5400/10100, NER loss: 0.803054
2019-02-21 18:57:44,349 - log/train6.log - INFO - iteration:43 step:5500/10100, NER loss: 0.912661
2019-02-21 18:57:46,554 - log/train6.log - INFO - iteration:43 step:5600/10100, NER loss: 0.855107
2019-02-21 18:57:48,757 - log/train6.log - INFO - iteration:43 step:5700/10100, NER loss: 0.928330
2019-02-21 18:57:50,972 - log/train6.log - INFO - iteration:43 step:5800/10100, NER loss: 0.887017
2019-02-21 18:57:52,988 - log/train6.log - INFO - iteration:43 step:5900/10100, NER loss: 0.740931
2019-02-21 18:57:55,090 - log/train6.log - INFO - iteration:43 step:6000/10100, NER loss: 0.769570
2019-02-21 18:57:57,457 - log/train6.log - INFO - iteration:43 step:6100/10100, NER loss: 0.788077
2019-02-21 18:57:59,521 - log/train6.log - INFO - iteration:43 step:6200/10100, NER loss: 0.906533
2019-02-21 18:58:01,959 - log/train6.log - INFO - iteration:43 step:6300/10100, NER loss: 0.806462
2019-02-21 18:58:04,030 - log/train6.log - INFO - iteration:43 step:6400/10100, NER loss: 0.775834
2019-02-21 18:58:06,244 - log/train6.log - INFO - iteration:43 step:6500/10100, NER loss: 0.906276
2019-02-21 18:58:08,498 - log/train6.log - INFO - iteration:43 step:6600/10100, NER loss: 0.844096
2019-02-21 18:58:10,551 - log/train6.log - INFO - iteration:43 step:6700/10100, NER loss: 0.830848
2019-02-21 18:58:12,623 - log/train6.log - INFO - iteration:43 step:6800/10100, NER loss: 0.698148
2019-02-21 18:58:14,796 - log/train6.log - INFO - iteration:43 step:6900/10100, NER loss: 0.830221
2019-02-21 18:58:16,936 - log/train6.log - INFO - iteration:43 step:7000/10100, NER loss: 0.832567
2019-02-21 18:58:18,893 - log/train6.log - INFO - iteration:43 step:7100/10100, NER loss: 0.655272
2019-02-21 18:58:20,928 - log/train6.log - INFO - iteration:43 step:7200/10100, NER loss: 0.706356
2019-02-21 18:58:23,092 - log/train6.log - INFO - iteration:43 step:7300/10100, NER loss: 0.804950
2019-02-21 18:58:25,418 - log/train6.log - INFO - iteration:43 step:7400/10100, NER loss: 1.072970
2019-02-21 18:58:27,381 - log/train6.log - INFO - iteration:43 step:7500/10100, NER loss: 0.783169
2019-02-21 18:58:29,773 - log/train6.log - INFO - iteration:43 step:7600/10100, NER loss: 1.315363
2019-02-21 18:58:32,080 - log/train6.log - INFO - iteration:43 step:7700/10100, NER loss: 0.718862
2019-02-21 18:58:34,256 - log/train6.log - INFO - iteration:43 step:7800/10100, NER loss: 0.977770
2019-02-21 18:58:36,501 - log/train6.log - INFO - iteration:43 step:7900/10100, NER loss: 1.156288
2019-02-21 18:58:38,677 - log/train6.log - INFO - iteration:43 step:8000/10100, NER loss: 0.843209
2019-02-21 18:58:40,932 - log/train6.log - INFO - iteration:43 step:8100/10100, NER loss: 0.911866
2019-02-21 18:58:42,957 - log/train6.log - INFO - iteration:43 step:8200/10100, NER loss: 0.717501
2019-02-21 18:58:45,095 - log/train6.log - INFO - iteration:43 step:8300/10100, NER loss: 0.730352
2019-02-21 18:58:47,292 - log/train6.log - INFO - iteration:43 step:8400/10100, NER loss: 0.798576
2019-02-21 18:58:49,654 - log/train6.log - INFO - iteration:43 step:8500/10100, NER loss: 1.060848
2019-02-21 18:58:51,938 - log/train6.log - INFO - iteration:43 step:8600/10100, NER loss: 1.149455
2019-02-21 18:58:54,123 - log/train6.log - INFO - iteration:43 step:8700/10100, NER loss: 0.781583
2019-02-21 18:58:56,446 - log/train6.log - INFO - iteration:43 step:8800/10100, NER loss: 0.999868
2019-02-21 18:58:58,723 - log/train6.log - INFO - iteration:43 step:8900/10100, NER loss: 0.902892
2019-02-21 18:59:00,722 - log/train6.log - INFO - iteration:43 step:9000/10100, NER loss: 0.781262
2019-02-21 18:59:03,052 - log/train6.log - INFO - iteration:43 step:9100/10100, NER loss: 0.891396
2019-02-21 18:59:05,119 - log/train6.log - INFO - iteration:43 step:9200/10100, NER loss: 0.735102
2019-02-21 18:59:06,998 - log/train6.log - INFO - iteration:43 step:9300/10100, NER loss: 0.739473
2019-02-21 18:59:09,226 - log/train6.log - INFO - iteration:43 step:9400/10100, NER loss: 0.859404
2019-02-21 18:59:11,413 - log/train6.log - INFO - iteration:43 step:9500/10100, NER loss: 0.711242
2019-02-21 18:59:13,614 - log/train6.log - INFO - iteration:43 step:9600/10100, NER loss: 0.935496
2019-02-21 18:59:15,720 - log/train6.log - INFO - iteration:43 step:9700/10100, NER loss: 1.064456
2019-02-21 18:59:17,830 - log/train6.log - INFO - iteration:43 step:9800/10100, NER loss: 0.914500
2019-02-21 18:59:21,831 - log/train6.log - INFO - iteration:43 step:9900/10100, NER loss: 1.384157
2019-02-21 18:59:24,174 - log/train6.log - INFO - iteration:43 step:10000/10100, NER loss: 0.907541
2019-02-21 18:59:26,656 - log/train6.log - INFO - iteration:44 step:0/10100, NER loss: 1.069932
2019-02-21 18:59:26,656 - log/train6.log - INFO - evaluate:dev
2019-02-21 18:59:33,101 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5738 phrases; correct: 4375.

2019-02-21 18:59:33,102 - log/train6.log - INFO - accuracy:  95.40%; precision:  76.25%; recall:  74.82%; FB1:  75.53

2019-02-21 18:59:33,102 - log/train6.log - INFO -                 C: precision:  86.73%; recall:  88.14%; FB1:  87.43  3444

2019-02-21 18:59:33,102 - log/train6.log - INFO -               IND: precision:  37.24%; recall:  35.78%; FB1:  36.50  392

2019-02-21 18:59:33,102 - log/train6.log - INFO -               INS: precision:  69.50%; recall:  69.13%; FB1:  69.31  377

2019-02-21 18:59:33,102 - log/train6.log - INFO -                 L: precision:  55.60%; recall:  63.86%; FB1:  59.45  696

2019-02-21 18:59:33,102 - log/train6.log - INFO -                 P: precision:  87.61%; recall:  91.16%; FB1:  89.35  565

2019-02-21 18:59:33,102 - log/train6.log - INFO -               PRO: precision:  37.12%; recall:  18.77%; FB1:  24.94  264

2019-02-21 18:59:33,105 - log/train6.log - INFO - evaluate:test
2019-02-21 18:59:34,575 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1662 phrases; correct: 1374.

2019-02-21 18:59:34,576 - log/train6.log - INFO - accuracy:  96.69%; precision:  82.67%; recall:  83.42%; FB1:  83.05

2019-02-21 18:59:34,576 - log/train6.log - INFO -                 C: precision:  88.98%; recall:  91.84%; FB1:  90.39  1062

2019-02-21 18:59:34,576 - log/train6.log - INFO -               IND: precision:  41.25%; recall:  70.21%; FB1:  51.97  80

2019-02-21 18:59:34,576 - log/train6.log - INFO -               INS: precision:  64.52%; recall:  63.16%; FB1:  63.83  93

2019-02-21 18:59:34,576 - log/train6.log - INFO -                 L: precision:  55.96%; recall:  59.22%; FB1:  57.55  109

2019-02-21 18:59:34,576 - log/train6.log - INFO -                 P: precision:  90.70%; recall:  95.59%; FB1:  93.08  215

2019-02-21 18:59:34,576 - log/train6.log - INFO -               PRO: precision:  77.67%; recall:  47.34%; FB1:  58.82  103

2019-02-21 18:59:36,689 - log/train6.log - INFO - iteration:44 step:100/10100, NER loss: 0.851250
2019-02-21 18:59:40,902 - log/train6.log - INFO - iteration:44 step:200/10100, NER loss: 1.646839
2019-02-21 18:59:43,155 - log/train6.log - INFO - iteration:44 step:300/10100, NER loss: 0.973544
2019-02-21 18:59:45,292 - log/train6.log - INFO - iteration:44 step:400/10100, NER loss: 0.759709
2019-02-21 18:59:47,544 - log/train6.log - INFO - iteration:44 step:500/10100, NER loss: 1.031177
2019-02-21 18:59:49,675 - log/train6.log - INFO - iteration:44 step:600/10100, NER loss: 0.845052
2019-02-21 18:59:51,934 - log/train6.log - INFO - iteration:44 step:700/10100, NER loss: 0.917354
2019-02-21 18:59:53,984 - log/train6.log - INFO - iteration:44 step:800/10100, NER loss: 0.760436
2019-02-21 18:59:56,117 - log/train6.log - INFO - iteration:44 step:900/10100, NER loss: 0.924748
2019-02-21 18:59:58,226 - log/train6.log - INFO - iteration:44 step:1000/10100, NER loss: 0.686789
2019-02-21 19:00:00,688 - log/train6.log - INFO - iteration:44 step:1100/10100, NER loss: 1.137334
2019-02-21 19:00:02,776 - log/train6.log - INFO - iteration:44 step:1200/10100, NER loss: 0.640458
2019-02-21 19:00:05,265 - log/train6.log - INFO - iteration:44 step:1300/10100, NER loss: 0.814815
2019-02-21 19:00:07,588 - log/train6.log - INFO - iteration:44 step:1400/10100, NER loss: 0.924350
2019-02-21 19:00:09,717 - log/train6.log - INFO - iteration:44 step:1500/10100, NER loss: 0.883981
2019-02-21 19:00:11,909 - log/train6.log - INFO - iteration:44 step:1600/10100, NER loss: 0.947238
2019-02-21 19:00:14,110 - log/train6.log - INFO - iteration:44 step:1700/10100, NER loss: 0.817830
2019-02-21 19:00:16,320 - log/train6.log - INFO - iteration:44 step:1800/10100, NER loss: 0.884517
2019-02-21 19:00:18,571 - log/train6.log - INFO - iteration:44 step:1900/10100, NER loss: 0.814923
2019-02-21 19:00:21,015 - log/train6.log - INFO - iteration:44 step:2000/10100, NER loss: 1.008156
2019-02-21 19:00:23,023 - log/train6.log - INFO - iteration:44 step:2100/10100, NER loss: 0.720723
2019-02-21 19:00:25,245 - log/train6.log - INFO - iteration:44 step:2200/10100, NER loss: 0.843730
2019-02-21 19:00:27,504 - log/train6.log - INFO - iteration:44 step:2300/10100, NER loss: 0.969576
2019-02-21 19:00:29,592 - log/train6.log - INFO - iteration:44 step:2400/10100, NER loss: 0.772277
2019-02-21 19:00:31,626 - log/train6.log - INFO - iteration:44 step:2500/10100, NER loss: 0.844741
2019-02-21 19:00:33,705 - log/train6.log - INFO - iteration:44 step:2600/10100, NER loss: 0.814749
2019-02-21 19:00:35,933 - log/train6.log - INFO - iteration:44 step:2700/10100, NER loss: 0.881939
2019-02-21 19:00:38,263 - log/train6.log - INFO - iteration:44 step:2800/10100, NER loss: 1.017704
2019-02-21 19:00:40,455 - log/train6.log - INFO - iteration:44 step:2900/10100, NER loss: 0.865605
2019-02-21 19:00:42,757 - log/train6.log - INFO - iteration:44 step:3000/10100, NER loss: 1.192571
2019-02-21 19:00:45,159 - log/train6.log - INFO - iteration:44 step:3100/10100, NER loss: 1.070886
2019-02-21 19:00:47,399 - log/train6.log - INFO - iteration:44 step:3200/10100, NER loss: 0.901534
2019-02-21 19:00:49,688 - log/train6.log - INFO - iteration:44 step:3300/10100, NER loss: 0.880024
2019-02-21 19:00:51,957 - log/train6.log - INFO - iteration:44 step:3400/10100, NER loss: 0.829771
2019-02-21 19:00:54,187 - log/train6.log - INFO - iteration:44 step:3500/10100, NER loss: 0.814243
2019-02-21 19:00:56,445 - log/train6.log - INFO - iteration:44 step:3600/10100, NER loss: 0.897569
2019-02-21 19:00:58,438 - log/train6.log - INFO - iteration:44 step:3700/10100, NER loss: 0.759685
2019-02-21 19:01:00,470 - log/train6.log - INFO - iteration:44 step:3800/10100, NER loss: 0.773244
2019-02-21 19:01:02,837 - log/train6.log - INFO - iteration:44 step:3900/10100, NER loss: 1.133394
2019-02-21 19:01:05,275 - log/train6.log - INFO - iteration:44 step:4000/10100, NER loss: 1.095780
2019-02-21 19:01:07,504 - log/train6.log - INFO - iteration:44 step:4100/10100, NER loss: 0.984290
2019-02-21 19:01:09,838 - log/train6.log - INFO - iteration:44 step:4200/10100, NER loss: 0.952348
2019-02-21 19:01:11,959 - log/train6.log - INFO - iteration:44 step:4300/10100, NER loss: 0.809709
2019-02-21 19:01:14,095 - log/train6.log - INFO - iteration:44 step:4400/10100, NER loss: 0.846211
2019-02-21 19:01:16,401 - log/train6.log - INFO - iteration:44 step:4500/10100, NER loss: 0.762629
2019-02-21 19:01:18,356 - log/train6.log - INFO - iteration:44 step:4600/10100, NER loss: 0.708686
2019-02-21 19:01:20,551 - log/train6.log - INFO - iteration:44 step:4700/10100, NER loss: 0.750103
2019-02-21 19:01:22,508 - log/train6.log - INFO - iteration:44 step:4800/10100, NER loss: 0.781291
2019-02-21 19:01:25,157 - log/train6.log - INFO - iteration:44 step:4900/10100, NER loss: 1.151167
2019-02-21 19:01:27,326 - log/train6.log - INFO - iteration:44 step:5000/10100, NER loss: 0.872986
2019-02-21 19:01:29,637 - log/train6.log - INFO - iteration:44 step:5100/10100, NER loss: 1.004205
2019-02-21 19:01:31,988 - log/train6.log - INFO - iteration:44 step:5200/10100, NER loss: 0.948035
2019-02-21 19:01:34,299 - log/train6.log - INFO - iteration:44 step:5300/10100, NER loss: 0.978014
2019-02-21 19:01:36,712 - log/train6.log - INFO - iteration:44 step:5400/10100, NER loss: 0.919727
2019-02-21 19:01:40,909 - log/train6.log - INFO - iteration:44 step:5500/10100, NER loss: 2.598083
2019-02-21 19:01:44,829 - log/train6.log - INFO - iteration:44 step:5600/10100, NER loss: 2.052347
2019-02-21 19:01:46,825 - log/train6.log - INFO - iteration:44 step:5700/10100, NER loss: 0.736010
2019-02-21 19:01:48,926 - log/train6.log - INFO - iteration:44 step:5800/10100, NER loss: 0.815183
2019-02-21 19:01:51,174 - log/train6.log - INFO - iteration:44 step:5900/10100, NER loss: 1.020454
2019-02-21 19:01:53,374 - log/train6.log - INFO - iteration:44 step:6000/10100, NER loss: 0.908550
2019-02-21 19:01:55,392 - log/train6.log - INFO - iteration:44 step:6100/10100, NER loss: 0.682472
2019-02-21 19:01:57,674 - log/train6.log - INFO - iteration:44 step:6200/10100, NER loss: 1.178530
2019-02-21 19:01:59,777 - log/train6.log - INFO - iteration:44 step:6300/10100, NER loss: 0.865065
2019-02-21 19:02:01,949 - log/train6.log - INFO - iteration:44 step:6400/10100, NER loss: 0.848707
2019-02-21 19:02:04,258 - log/train6.log - INFO - iteration:44 step:6500/10100, NER loss: 0.929128
2019-02-21 19:02:06,439 - log/train6.log - INFO - iteration:44 step:6600/10100, NER loss: 1.135973
2019-02-21 19:02:08,817 - log/train6.log - INFO - iteration:44 step:6700/10100, NER loss: 1.014032
2019-02-21 19:02:10,968 - log/train6.log - INFO - iteration:44 step:6800/10100, NER loss: 0.731057
2019-02-21 19:02:13,147 - log/train6.log - INFO - iteration:44 step:6900/10100, NER loss: 0.966613
2019-02-21 19:02:15,545 - log/train6.log - INFO - iteration:44 step:7000/10100, NER loss: 0.923505
2019-02-21 19:02:18,125 - log/train6.log - INFO - iteration:44 step:7100/10100, NER loss: 1.064102
2019-02-21 19:02:20,379 - log/train6.log - INFO - iteration:44 step:7200/10100, NER loss: 0.809948
2019-02-21 19:02:22,498 - log/train6.log - INFO - iteration:44 step:7300/10100, NER loss: 1.013652
2019-02-21 19:02:24,794 - log/train6.log - INFO - iteration:44 step:7400/10100, NER loss: 0.900221
2019-02-21 19:02:27,152 - log/train6.log - INFO - iteration:44 step:7500/10100, NER loss: 0.931915
2019-02-21 19:02:29,367 - log/train6.log - INFO - iteration:44 step:7600/10100, NER loss: 0.788754
2019-02-21 19:02:31,501 - log/train6.log - INFO - iteration:44 step:7700/10100, NER loss: 1.092328
2019-02-21 19:02:33,513 - log/train6.log - INFO - iteration:44 step:7800/10100, NER loss: 0.721384
2019-02-21 19:02:35,676 - log/train6.log - INFO - iteration:44 step:7900/10100, NER loss: 0.762884
2019-02-21 19:02:37,862 - log/train6.log - INFO - iteration:44 step:8000/10100, NER loss: 0.803850
2019-02-21 19:02:40,225 - log/train6.log - INFO - iteration:44 step:8100/10100, NER loss: 0.915393
2019-02-21 19:02:42,372 - log/train6.log - INFO - iteration:44 step:8200/10100, NER loss: 0.733977
2019-02-21 19:02:44,467 - log/train6.log - INFO - iteration:44 step:8300/10100, NER loss: 0.730646
2019-02-21 19:02:46,732 - log/train6.log - INFO - iteration:44 step:8400/10100, NER loss: 0.853494
2019-02-21 19:02:48,907 - log/train6.log - INFO - iteration:44 step:8500/10100, NER loss: 0.904501
2019-02-21 19:02:50,964 - log/train6.log - INFO - iteration:44 step:8600/10100, NER loss: 0.812479
2019-02-21 19:02:53,119 - log/train6.log - INFO - iteration:44 step:8700/10100, NER loss: 0.869780
2019-02-21 19:02:55,550 - log/train6.log - INFO - iteration:44 step:8800/10100, NER loss: 0.994228
2019-02-21 19:02:57,888 - log/train6.log - INFO - iteration:44 step:8900/10100, NER loss: 0.908248
2019-02-21 19:03:00,125 - log/train6.log - INFO - iteration:44 step:9000/10100, NER loss: 0.852025
2019-02-21 19:03:02,248 - log/train6.log - INFO - iteration:44 step:9100/10100, NER loss: 0.886876
2019-02-21 19:03:04,459 - log/train6.log - INFO - iteration:44 step:9200/10100, NER loss: 0.920492
2019-02-21 19:03:06,512 - log/train6.log - INFO - iteration:44 step:9300/10100, NER loss: 0.852787
2019-02-21 19:03:08,606 - log/train6.log - INFO - iteration:44 step:9400/10100, NER loss: 0.751236
2019-02-21 19:03:10,719 - log/train6.log - INFO - iteration:44 step:9500/10100, NER loss: 0.928131
2019-02-21 19:03:12,867 - log/train6.log - INFO - iteration:44 step:9600/10100, NER loss: 0.817632
2019-02-21 19:03:15,244 - log/train6.log - INFO - iteration:44 step:9700/10100, NER loss: 1.033417
2019-02-21 19:03:17,378 - log/train6.log - INFO - iteration:44 step:9800/10100, NER loss: 1.010297
2019-02-21 19:03:19,672 - log/train6.log - INFO - iteration:44 step:9900/10100, NER loss: 0.807958
2019-02-21 19:03:21,747 - log/train6.log - INFO - iteration:44 step:10000/10100, NER loss: 0.875753
2019-02-21 19:03:23,745 - log/train6.log - INFO - iteration:45 step:0/10100, NER loss: 0.824903
2019-02-21 19:03:23,745 - log/train6.log - INFO - evaluate:dev
2019-02-21 19:03:30,274 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5555 phrases; correct: 4315.

2019-02-21 19:03:30,275 - log/train6.log - INFO - accuracy:  95.45%; precision:  77.68%; recall:  73.80%; FB1:  75.69

2019-02-21 19:03:30,275 - log/train6.log - INFO -                 C: precision:  87.78%; recall:  86.69%; FB1:  87.23  3347

2019-02-21 19:03:30,275 - log/train6.log - INFO -               IND: precision:  41.23%; recall:  31.13%; FB1:  35.47  308

2019-02-21 19:03:30,275 - log/train6.log - INFO -               INS: precision:  69.42%; recall:  73.09%; FB1:  71.21  399

2019-02-21 19:03:30,275 - log/train6.log - INFO -                 L: precision:  57.58%; recall:  65.18%; FB1:  61.15  686

2019-02-21 19:03:30,275 - log/train6.log - INFO -                 P: precision:  82.17%; recall:  90.79%; FB1:  86.26  600

2019-02-21 19:03:30,275 - log/train6.log - INFO -               PRO: precision:  39.53%; recall:  16.28%; FB1:  23.07  215

2019-02-21 19:03:30,278 - log/train6.log - INFO - evaluate:test
2019-02-21 19:03:31,737 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1627 phrases; correct: 1358.

2019-02-21 19:03:31,737 - log/train6.log - INFO - accuracy:  96.63%; precision:  83.47%; recall:  82.45%; FB1:  82.96

2019-02-21 19:03:31,737 - log/train6.log - INFO -                 C: precision:  89.51%; recall:  91.25%; FB1:  90.38  1049

2019-02-21 19:03:31,737 - log/train6.log - INFO -               IND: precision:  47.62%; recall:  63.83%; FB1:  54.55  63

2019-02-21 19:03:31,737 - log/train6.log - INFO -               INS: precision:  61.22%; recall:  63.16%; FB1:  62.18  98

2019-02-21 19:03:31,737 - log/train6.log - INFO -                 L: precision:  57.94%; recall:  60.19%; FB1:  59.05  107

2019-02-21 19:03:31,737 - log/train6.log - INFO -                 P: precision:  88.99%; recall:  95.10%; FB1:  91.94  218

2019-02-21 19:03:31,737 - log/train6.log - INFO -               PRO: precision:  79.35%; recall:  43.20%; FB1:  55.94  92

2019-02-21 19:03:33,816 - log/train6.log - INFO - iteration:45 step:100/10100, NER loss: 0.967613
2019-02-21 19:03:36,024 - log/train6.log - INFO - iteration:45 step:200/10100, NER loss: 0.912262
2019-02-21 19:03:38,055 - log/train6.log - INFO - iteration:45 step:300/10100, NER loss: 0.769450
2019-02-21 19:03:40,397 - log/train6.log - INFO - iteration:45 step:400/10100, NER loss: 0.913953
2019-02-21 19:03:42,595 - log/train6.log - INFO - iteration:45 step:500/10100, NER loss: 0.916645
2019-02-21 19:03:44,686 - log/train6.log - INFO - iteration:45 step:600/10100, NER loss: 0.842893
2019-02-21 19:03:46,818 - log/train6.log - INFO - iteration:45 step:700/10100, NER loss: 0.818892
2019-02-21 19:03:49,151 - log/train6.log - INFO - iteration:45 step:800/10100, NER loss: 1.101163
2019-02-21 19:03:51,321 - log/train6.log - INFO - iteration:45 step:900/10100, NER loss: 0.975346
2019-02-21 19:03:53,442 - log/train6.log - INFO - iteration:45 step:1000/10100, NER loss: 0.875090
2019-02-21 19:03:55,405 - log/train6.log - INFO - iteration:45 step:1100/10100, NER loss: 0.630398
2019-02-21 19:03:57,470 - log/train6.log - INFO - iteration:45 step:1200/10100, NER loss: 0.830297
2019-02-21 19:03:59,737 - log/train6.log - INFO - iteration:45 step:1300/10100, NER loss: 0.822533
2019-02-21 19:04:03,994 - log/train6.log - INFO - iteration:45 step:1400/10100, NER loss: 1.415769
2019-02-21 19:04:06,314 - log/train6.log - INFO - iteration:45 step:1500/10100, NER loss: 0.929866
2019-02-21 19:04:08,563 - log/train6.log - INFO - iteration:45 step:1600/10100, NER loss: 0.959707
2019-02-21 19:04:10,843 - log/train6.log - INFO - iteration:45 step:1700/10100, NER loss: 1.124987
2019-02-21 19:04:13,263 - log/train6.log - INFO - iteration:45 step:1800/10100, NER loss: 1.133676
2019-02-21 19:04:15,238 - log/train6.log - INFO - iteration:45 step:1900/10100, NER loss: 0.993860
2019-02-21 19:04:17,464 - log/train6.log - INFO - iteration:45 step:2000/10100, NER loss: 1.067695
2019-02-21 19:04:19,497 - log/train6.log - INFO - iteration:45 step:2100/10100, NER loss: 0.806341
2019-02-21 19:04:21,739 - log/train6.log - INFO - iteration:45 step:2200/10100, NER loss: 0.837315
2019-02-21 19:04:24,058 - log/train6.log - INFO - iteration:45 step:2300/10100, NER loss: 0.928487
2019-02-21 19:04:26,036 - log/train6.log - INFO - iteration:45 step:2400/10100, NER loss: 0.735440
2019-02-21 19:04:28,653 - log/train6.log - INFO - iteration:45 step:2500/10100, NER loss: 1.230836
2019-02-21 19:04:30,926 - log/train6.log - INFO - iteration:45 step:2600/10100, NER loss: 0.871007
2019-02-21 19:04:33,219 - log/train6.log - INFO - iteration:45 step:2700/10100, NER loss: 0.910308
2019-02-21 19:04:35,294 - log/train6.log - INFO - iteration:45 step:2800/10100, NER loss: 0.932493
2019-02-21 19:04:37,549 - log/train6.log - INFO - iteration:45 step:2900/10100, NER loss: 0.961300
2019-02-21 19:04:39,842 - log/train6.log - INFO - iteration:45 step:3000/10100, NER loss: 0.880002
2019-02-21 19:04:41,971 - log/train6.log - INFO - iteration:45 step:3100/10100, NER loss: 0.855841
2019-02-21 19:04:44,363 - log/train6.log - INFO - iteration:45 step:3200/10100, NER loss: 0.929760
2019-02-21 19:04:46,588 - log/train6.log - INFO - iteration:45 step:3300/10100, NER loss: 0.867968
2019-02-21 19:04:48,877 - log/train6.log - INFO - iteration:45 step:3400/10100, NER loss: 0.963899
2019-02-21 19:04:50,809 - log/train6.log - INFO - iteration:45 step:3500/10100, NER loss: 0.668107
2019-02-21 19:04:53,134 - log/train6.log - INFO - iteration:45 step:3600/10100, NER loss: 0.915466
2019-02-21 19:04:55,355 - log/train6.log - INFO - iteration:45 step:3700/10100, NER loss: 0.839986
2019-02-21 19:04:57,438 - log/train6.log - INFO - iteration:45 step:3800/10100, NER loss: 0.789487
2019-02-21 19:04:59,469 - log/train6.log - INFO - iteration:45 step:3900/10100, NER loss: 0.769795
2019-02-21 19:05:01,673 - log/train6.log - INFO - iteration:45 step:4000/10100, NER loss: 0.801238
2019-02-21 19:05:04,026 - log/train6.log - INFO - iteration:45 step:4100/10100, NER loss: 0.851850
2019-02-21 19:05:05,959 - log/train6.log - INFO - iteration:45 step:4200/10100, NER loss: 0.635494
2019-02-21 19:05:09,974 - log/train6.log - INFO - iteration:45 step:4300/10100, NER loss: 1.462413
2019-02-21 19:05:11,991 - log/train6.log - INFO - iteration:45 step:4400/10100, NER loss: 0.848756
2019-02-21 19:05:13,959 - log/train6.log - INFO - iteration:45 step:4500/10100, NER loss: 0.662696
2019-02-21 19:05:16,703 - log/train6.log - INFO - iteration:45 step:4600/10100, NER loss: 1.167045
2019-02-21 19:05:18,775 - log/train6.log - INFO - iteration:45 step:4700/10100, NER loss: 0.864647
2019-02-21 19:05:20,942 - log/train6.log - INFO - iteration:45 step:4800/10100, NER loss: 0.800102
2019-02-21 19:05:23,201 - log/train6.log - INFO - iteration:45 step:4900/10100, NER loss: 0.939782
2019-02-21 19:05:25,407 - log/train6.log - INFO - iteration:45 step:5000/10100, NER loss: 0.815478
2019-02-21 19:05:27,432 - log/train6.log - INFO - iteration:45 step:5100/10100, NER loss: 0.839605
2019-02-21 19:05:29,719 - log/train6.log - INFO - iteration:45 step:5200/10100, NER loss: 1.029813
2019-02-21 19:05:31,949 - log/train6.log - INFO - iteration:45 step:5300/10100, NER loss: 0.996190
2019-02-21 19:05:33,982 - log/train6.log - INFO - iteration:45 step:5400/10100, NER loss: 0.722217
2019-02-21 19:05:36,118 - log/train6.log - INFO - iteration:45 step:5500/10100, NER loss: 0.739592
2019-02-21 19:05:38,075 - log/train6.log - INFO - iteration:45 step:5600/10100, NER loss: 0.694730
2019-02-21 19:05:40,446 - log/train6.log - INFO - iteration:45 step:5700/10100, NER loss: 0.987810
2019-02-21 19:05:42,611 - log/train6.log - INFO - iteration:45 step:5800/10100, NER loss: 0.961331
2019-02-21 19:05:44,928 - log/train6.log - INFO - iteration:45 step:5900/10100, NER loss: 0.993926
2019-02-21 19:05:47,226 - log/train6.log - INFO - iteration:45 step:6000/10100, NER loss: 0.936088
2019-02-21 19:05:49,625 - log/train6.log - INFO - iteration:45 step:6100/10100, NER loss: 1.106587
2019-02-21 19:05:51,624 - log/train6.log - INFO - iteration:45 step:6200/10100, NER loss: 0.731965
2019-02-21 19:05:53,741 - log/train6.log - INFO - iteration:45 step:6300/10100, NER loss: 0.856628
2019-02-21 19:05:55,909 - log/train6.log - INFO - iteration:45 step:6400/10100, NER loss: 0.945952
2019-02-21 19:05:58,179 - log/train6.log - INFO - iteration:45 step:6500/10100, NER loss: 0.978245
2019-02-21 19:06:00,482 - log/train6.log - INFO - iteration:45 step:6600/10100, NER loss: 0.895262
2019-02-21 19:06:02,542 - log/train6.log - INFO - iteration:45 step:6700/10100, NER loss: 0.919503
2019-02-21 19:06:04,531 - log/train6.log - INFO - iteration:45 step:6800/10100, NER loss: 0.626894
2019-02-21 19:06:09,304 - log/train6.log - INFO - iteration:45 step:6900/10100, NER loss: 2.280660
2019-02-21 19:06:11,386 - log/train6.log - INFO - iteration:45 step:7000/10100, NER loss: 0.803668
2019-02-21 19:06:13,737 - log/train6.log - INFO - iteration:45 step:7100/10100, NER loss: 0.888178
2019-02-21 19:06:15,983 - log/train6.log - INFO - iteration:45 step:7200/10100, NER loss: 0.846403
2019-02-21 19:06:18,210 - log/train6.log - INFO - iteration:45 step:7300/10100, NER loss: 1.157379
2019-02-21 19:06:20,719 - log/train6.log - INFO - iteration:45 step:7400/10100, NER loss: 1.024539
2019-02-21 19:06:22,992 - log/train6.log - INFO - iteration:45 step:7500/10100, NER loss: 0.826628
2019-02-21 19:06:25,165 - log/train6.log - INFO - iteration:45 step:7600/10100, NER loss: 0.826940
2019-02-21 19:06:27,405 - log/train6.log - INFO - iteration:45 step:7700/10100, NER loss: 0.873486
2019-02-21 19:06:29,954 - log/train6.log - INFO - iteration:45 step:7800/10100, NER loss: 1.007037
2019-02-21 19:06:32,372 - log/train6.log - INFO - iteration:45 step:7900/10100, NER loss: 1.058121
2019-02-21 19:06:34,589 - log/train6.log - INFO - iteration:45 step:8000/10100, NER loss: 0.811207
2019-02-21 19:06:36,781 - log/train6.log - INFO - iteration:45 step:8100/10100, NER loss: 0.871728
2019-02-21 19:06:38,915 - log/train6.log - INFO - iteration:45 step:8200/10100, NER loss: 0.882399
2019-02-21 19:06:40,980 - log/train6.log - INFO - iteration:45 step:8300/10100, NER loss: 0.761078
2019-02-21 19:06:43,364 - log/train6.log - INFO - iteration:45 step:8400/10100, NER loss: 1.035292
2019-02-21 19:06:45,588 - log/train6.log - INFO - iteration:45 step:8500/10100, NER loss: 0.730898
2019-02-21 19:06:47,967 - log/train6.log - INFO - iteration:45 step:8600/10100, NER loss: 0.984515
2019-02-21 19:06:50,346 - log/train6.log - INFO - iteration:45 step:8700/10100, NER loss: 0.959092
2019-02-21 19:06:52,520 - log/train6.log - INFO - iteration:45 step:8800/10100, NER loss: 0.862118
2019-02-21 19:06:54,829 - log/train6.log - INFO - iteration:45 step:8900/10100, NER loss: 0.782126
2019-02-21 19:06:57,154 - log/train6.log - INFO - iteration:45 step:9000/10100, NER loss: 0.956052
2019-02-21 19:06:59,304 - log/train6.log - INFO - iteration:45 step:9100/10100, NER loss: 0.760841
2019-02-21 19:07:01,550 - log/train6.log - INFO - iteration:45 step:9200/10100, NER loss: 0.827413
2019-02-21 19:07:03,675 - log/train6.log - INFO - iteration:45 step:9300/10100, NER loss: 0.840079
2019-02-21 19:07:05,826 - log/train6.log - INFO - iteration:45 step:9400/10100, NER loss: 0.822677
2019-02-21 19:07:07,835 - log/train6.log - INFO - iteration:45 step:9500/10100, NER loss: 0.777310
2019-02-21 19:07:09,947 - log/train6.log - INFO - iteration:45 step:9600/10100, NER loss: 0.775849
2019-02-21 19:07:12,323 - log/train6.log - INFO - iteration:45 step:9700/10100, NER loss: 0.913828
2019-02-21 19:07:14,627 - log/train6.log - INFO - iteration:45 step:9800/10100, NER loss: 0.891997
2019-02-21 19:07:16,893 - log/train6.log - INFO - iteration:45 step:9900/10100, NER loss: 1.056523
2019-02-21 19:07:18,988 - log/train6.log - INFO - iteration:45 step:10000/10100, NER loss: 0.866332
2019-02-21 19:07:21,093 - log/train6.log - INFO - iteration:46 step:0/10100, NER loss: 0.758962
2019-02-21 19:07:21,093 - log/train6.log - INFO - evaluate:dev
2019-02-21 19:07:27,626 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5014 phrases; correct: 3961.

2019-02-21 19:07:27,626 - log/train6.log - INFO - accuracy:  94.42%; precision:  79.00%; recall:  67.74%; FB1:  72.94

2019-02-21 19:07:27,626 - log/train6.log - INFO -                 C: precision:  90.60%; recall:  79.91%; FB1:  84.92  2989

2019-02-21 19:07:27,626 - log/train6.log - INFO -               IND: precision:  40.18%; recall:  33.09%; FB1:  36.29  336

2019-02-21 19:07:27,626 - log/train6.log - INFO -               INS: precision:  75.00%; recall:  68.07%; FB1:  71.37  344

2019-02-21 19:07:27,626 - log/train6.log - INFO -                 L: precision:  49.41%; recall:  48.35%; FB1:  48.87  593

2019-02-21 19:07:27,626 - log/train6.log - INFO -                 P: precision:  89.81%; recall:  89.32%; FB1:  89.57  540

2019-02-21 19:07:27,626 - log/train6.log - INFO -               PRO: precision:  38.68%; recall:  15.71%; FB1:  22.34  212

2019-02-21 19:07:27,630 - log/train6.log - INFO - evaluate:test
2019-02-21 19:07:29,097 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1554 phrases; correct: 1327.

2019-02-21 19:07:29,097 - log/train6.log - INFO - accuracy:  96.48%; precision:  85.39%; recall:  80.57%; FB1:  82.91

2019-02-21 19:07:29,097 - log/train6.log - INFO -                 C: precision:  91.86%; recall:  87.76%; FB1:  89.76  983

2019-02-21 19:07:29,097 - log/train6.log - INFO -               IND: precision:  49.18%; recall:  63.83%; FB1:  55.56  61

2019-02-21 19:07:29,097 - log/train6.log - INFO -               INS: precision:  70.65%; recall:  68.42%; FB1:  69.52  92

2019-02-21 19:07:29,097 - log/train6.log - INFO -                 L: precision:  52.89%; recall:  62.14%; FB1:  57.14  121

2019-02-21 19:07:29,097 - log/train6.log - INFO -                 P: precision:  93.66%; recall:  94.12%; FB1:  93.89  205

2019-02-21 19:07:29,097 - log/train6.log - INFO -               PRO: precision:  79.35%; recall:  43.20%; FB1:  55.94  92

2019-02-21 19:07:31,282 - log/train6.log - INFO - iteration:46 step:100/10100, NER loss: 0.997150
2019-02-21 19:07:33,222 - log/train6.log - INFO - iteration:46 step:200/10100, NER loss: 0.745909
2019-02-21 19:07:35,348 - log/train6.log - INFO - iteration:46 step:300/10100, NER loss: 0.824653
2019-02-21 19:07:37,388 - log/train6.log - INFO - iteration:46 step:400/10100, NER loss: 0.848112
2019-02-21 19:07:39,538 - log/train6.log - INFO - iteration:46 step:500/10100, NER loss: 0.858033
2019-02-21 19:07:41,606 - log/train6.log - INFO - iteration:46 step:600/10100, NER loss: 0.679168
2019-02-21 19:07:43,780 - log/train6.log - INFO - iteration:46 step:700/10100, NER loss: 0.899368
2019-02-21 19:07:47,894 - log/train6.log - INFO - iteration:46 step:800/10100, NER loss: 1.574994
2019-02-21 19:07:50,237 - log/train6.log - INFO - iteration:46 step:900/10100, NER loss: 0.899462
2019-02-21 19:07:52,331 - log/train6.log - INFO - iteration:46 step:1000/10100, NER loss: 0.810700
2019-02-21 19:07:54,770 - log/train6.log - INFO - iteration:46 step:1100/10100, NER loss: 1.089676
2019-02-21 19:07:57,096 - log/train6.log - INFO - iteration:46 step:1200/10100, NER loss: 0.983615
2019-02-21 19:07:59,296 - log/train6.log - INFO - iteration:46 step:1300/10100, NER loss: 0.946428
2019-02-21 19:08:01,486 - log/train6.log - INFO - iteration:46 step:1400/10100, NER loss: 0.906493
2019-02-21 19:08:03,656 - log/train6.log - INFO - iteration:46 step:1500/10100, NER loss: 0.837604
2019-02-21 19:08:05,785 - log/train6.log - INFO - iteration:46 step:1600/10100, NER loss: 0.852743
2019-02-21 19:08:07,695 - log/train6.log - INFO - iteration:46 step:1700/10100, NER loss: 0.667945
2019-02-21 19:08:09,791 - log/train6.log - INFO - iteration:46 step:1800/10100, NER loss: 0.768732
2019-02-21 19:08:12,228 - log/train6.log - INFO - iteration:46 step:1900/10100, NER loss: 0.870585
2019-02-21 19:08:14,608 - log/train6.log - INFO - iteration:46 step:2000/10100, NER loss: 1.151766
2019-02-21 19:08:16,924 - log/train6.log - INFO - iteration:46 step:2100/10100, NER loss: 1.263194
2019-02-21 19:08:19,090 - log/train6.log - INFO - iteration:46 step:2200/10100, NER loss: 0.769224
2019-02-21 19:08:21,643 - log/train6.log - INFO - iteration:46 step:2300/10100, NER loss: 1.015630
2019-02-21 19:08:25,722 - log/train6.log - INFO - iteration:46 step:2400/10100, NER loss: 1.297018
2019-02-21 19:08:27,757 - log/train6.log - INFO - iteration:46 step:2500/10100, NER loss: 0.860887
2019-02-21 19:08:32,212 - log/train6.log - INFO - iteration:46 step:2600/10100, NER loss: 1.908521
2019-02-21 19:08:34,414 - log/train6.log - INFO - iteration:46 step:2700/10100, NER loss: 0.900516
2019-02-21 19:08:36,584 - log/train6.log - INFO - iteration:46 step:2800/10100, NER loss: 1.102242
2019-02-21 19:08:38,963 - log/train6.log - INFO - iteration:46 step:2900/10100, NER loss: 1.449196
2019-02-21 19:08:41,385 - log/train6.log - INFO - iteration:46 step:3000/10100, NER loss: 1.037584
2019-02-21 19:08:43,713 - log/train6.log - INFO - iteration:46 step:3100/10100, NER loss: 0.830402
2019-02-21 19:08:45,780 - log/train6.log - INFO - iteration:46 step:3200/10100, NER loss: 0.794703
2019-02-21 19:08:47,829 - log/train6.log - INFO - iteration:46 step:3300/10100, NER loss: 0.790550
2019-02-21 19:08:50,085 - log/train6.log - INFO - iteration:46 step:3400/10100, NER loss: 0.956410
2019-02-21 19:08:52,126 - log/train6.log - INFO - iteration:46 step:3500/10100, NER loss: 0.846891
2019-02-21 19:08:54,266 - log/train6.log - INFO - iteration:46 step:3600/10100, NER loss: 0.870368
2019-02-21 19:08:56,342 - log/train6.log - INFO - iteration:46 step:3700/10100, NER loss: 0.873978
2019-02-21 19:08:58,568 - log/train6.log - INFO - iteration:46 step:3800/10100, NER loss: 0.995364
2019-02-21 19:09:00,935 - log/train6.log - INFO - iteration:46 step:3900/10100, NER loss: 1.001064
2019-02-21 19:09:03,396 - log/train6.log - INFO - iteration:46 step:4000/10100, NER loss: 0.918662
2019-02-21 19:09:05,506 - log/train6.log - INFO - iteration:46 step:4100/10100, NER loss: 0.779927
2019-02-21 19:09:07,737 - log/train6.log - INFO - iteration:46 step:4200/10100, NER loss: 1.118446
2019-02-21 19:09:09,947 - log/train6.log - INFO - iteration:46 step:4300/10100, NER loss: 0.860562
2019-02-21 19:09:12,153 - log/train6.log - INFO - iteration:46 step:4400/10100, NER loss: 0.768296
2019-02-21 19:09:14,224 - log/train6.log - INFO - iteration:46 step:4500/10100, NER loss: 0.636219
2019-02-21 19:09:16,612 - log/train6.log - INFO - iteration:46 step:4600/10100, NER loss: 0.896959
2019-02-21 19:09:18,842 - log/train6.log - INFO - iteration:46 step:4700/10100, NER loss: 0.836481
2019-02-21 19:09:21,090 - log/train6.log - INFO - iteration:46 step:4800/10100, NER loss: 0.856676
2019-02-21 19:09:23,290 - log/train6.log - INFO - iteration:46 step:4900/10100, NER loss: 0.945244
2019-02-21 19:09:25,479 - log/train6.log - INFO - iteration:46 step:5000/10100, NER loss: 0.792502
2019-02-21 19:09:27,666 - log/train6.log - INFO - iteration:46 step:5100/10100, NER loss: 1.014227
2019-02-21 19:09:29,984 - log/train6.log - INFO - iteration:46 step:5200/10100, NER loss: 0.890359
2019-02-21 19:09:32,190 - log/train6.log - INFO - iteration:46 step:5300/10100, NER loss: 0.830530
2019-02-21 19:09:34,329 - log/train6.log - INFO - iteration:46 step:5400/10100, NER loss: 0.774969
2019-02-21 19:09:36,467 - log/train6.log - INFO - iteration:46 step:5500/10100, NER loss: 0.848898
2019-02-21 19:09:38,732 - log/train6.log - INFO - iteration:46 step:5600/10100, NER loss: 0.911568
2019-02-21 19:09:40,858 - log/train6.log - INFO - iteration:46 step:5700/10100, NER loss: 0.830646
2019-02-21 19:09:42,955 - log/train6.log - INFO - iteration:46 step:5800/10100, NER loss: 0.788519
2019-02-21 19:09:45,113 - log/train6.log - INFO - iteration:46 step:5900/10100, NER loss: 1.075093
2019-02-21 19:09:47,166 - log/train6.log - INFO - iteration:46 step:6000/10100, NER loss: 0.837397
2019-02-21 19:09:49,491 - log/train6.log - INFO - iteration:46 step:6100/10100, NER loss: 0.933387
2019-02-21 19:09:51,878 - log/train6.log - INFO - iteration:46 step:6200/10100, NER loss: 1.109380
2019-02-21 19:09:54,159 - log/train6.log - INFO - iteration:46 step:6300/10100, NER loss: 1.199266
2019-02-21 19:09:56,382 - log/train6.log - INFO - iteration:46 step:6400/10100, NER loss: 0.962820
2019-02-21 19:09:58,542 - log/train6.log - INFO - iteration:46 step:6500/10100, NER loss: 0.824893
2019-02-21 19:10:00,813 - log/train6.log - INFO - iteration:46 step:6600/10100, NER loss: 0.957879
2019-02-21 19:10:03,066 - log/train6.log - INFO - iteration:46 step:6700/10100, NER loss: 0.832313
2019-02-21 19:10:05,220 - log/train6.log - INFO - iteration:46 step:6800/10100, NER loss: 0.738094
2019-02-21 19:10:07,507 - log/train6.log - INFO - iteration:46 step:6900/10100, NER loss: 0.836006
2019-02-21 19:10:09,686 - log/train6.log - INFO - iteration:46 step:7000/10100, NER loss: 0.882966
2019-02-21 19:10:11,917 - log/train6.log - INFO - iteration:46 step:7100/10100, NER loss: 0.732737
2019-02-21 19:10:13,796 - log/train6.log - INFO - iteration:46 step:7200/10100, NER loss: 0.563709
2019-02-21 19:10:15,918 - log/train6.log - INFO - iteration:46 step:7300/10100, NER loss: 0.861594
2019-02-21 19:10:18,232 - log/train6.log - INFO - iteration:46 step:7400/10100, NER loss: 0.938937
2019-02-21 19:10:20,476 - log/train6.log - INFO - iteration:46 step:7500/10100, NER loss: 0.868389
2019-02-21 19:10:22,657 - log/train6.log - INFO - iteration:46 step:7600/10100, NER loss: 0.760248
2019-02-21 19:10:24,873 - log/train6.log - INFO - iteration:46 step:7700/10100, NER loss: 0.751826
2019-02-21 19:10:27,095 - log/train6.log - INFO - iteration:46 step:7800/10100, NER loss: 0.812882
2019-02-21 19:10:29,235 - log/train6.log - INFO - iteration:46 step:7900/10100, NER loss: 0.825794
2019-02-21 19:10:31,418 - log/train6.log - INFO - iteration:46 step:8000/10100, NER loss: 0.878355
2019-02-21 19:10:33,849 - log/train6.log - INFO - iteration:46 step:8100/10100, NER loss: 0.994865
2019-02-21 19:10:35,786 - log/train6.log - INFO - iteration:46 step:8200/10100, NER loss: 0.620552
2019-02-21 19:10:38,077 - log/train6.log - INFO - iteration:46 step:8300/10100, NER loss: 0.970628
2019-02-21 19:10:40,308 - log/train6.log - INFO - iteration:46 step:8400/10100, NER loss: 0.885239
2019-02-21 19:10:42,606 - log/train6.log - INFO - iteration:46 step:8500/10100, NER loss: 1.243987
2019-02-21 19:10:44,561 - log/train6.log - INFO - iteration:46 step:8600/10100, NER loss: 0.662913
2019-02-21 19:10:46,798 - log/train6.log - INFO - iteration:46 step:8700/10100, NER loss: 0.840421
2019-02-21 19:10:48,928 - log/train6.log - INFO - iteration:46 step:8800/10100, NER loss: 0.838986
2019-02-21 19:10:51,185 - log/train6.log - INFO - iteration:46 step:8900/10100, NER loss: 0.857343
2019-02-21 19:10:53,349 - log/train6.log - INFO - iteration:46 step:9000/10100, NER loss: 0.857296
2019-02-21 19:10:55,806 - log/train6.log - INFO - iteration:46 step:9100/10100, NER loss: 1.187041
2019-02-21 19:10:58,053 - log/train6.log - INFO - iteration:46 step:9200/10100, NER loss: 0.814000
2019-02-21 19:11:00,273 - log/train6.log - INFO - iteration:46 step:9300/10100, NER loss: 0.942287
2019-02-21 19:11:02,458 - log/train6.log - INFO - iteration:46 step:9400/10100, NER loss: 1.099288
2019-02-21 19:11:04,515 - log/train6.log - INFO - iteration:46 step:9500/10100, NER loss: 0.748105
2019-02-21 19:11:06,555 - log/train6.log - INFO - iteration:46 step:9600/10100, NER loss: 0.685705
2019-02-21 19:11:08,799 - log/train6.log - INFO - iteration:46 step:9700/10100, NER loss: 0.964353
2019-02-21 19:11:11,044 - log/train6.log - INFO - iteration:46 step:9800/10100, NER loss: 0.830314
2019-02-21 19:11:13,229 - log/train6.log - INFO - iteration:46 step:9900/10100, NER loss: 0.743706
2019-02-21 19:11:15,498 - log/train6.log - INFO - iteration:46 step:10000/10100, NER loss: 0.999768
2019-02-21 19:11:18,053 - log/train6.log - INFO - iteration:47 step:0/10100, NER loss: 1.063516
2019-02-21 19:11:18,053 - log/train6.log - INFO - evaluate:dev
2019-02-21 19:11:24,549 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5185 phrases; correct: 4158.

2019-02-21 19:11:24,549 - log/train6.log - INFO - accuracy:  95.33%; precision:  80.19%; recall:  71.11%; FB1:  75.38

2019-02-21 19:11:24,550 - log/train6.log - INFO -                 C: precision:  86.87%; recall:  85.87%; FB1:  86.36  3350

2019-02-21 19:11:24,550 - log/train6.log - INFO -               IND: precision:  49.72%; recall:  21.57%; FB1:  30.09  177

2019-02-21 19:11:24,550 - log/train6.log - INFO -               INS: precision:  71.90%; recall:  68.87%; FB1:  70.35  363

2019-02-21 19:11:24,550 - log/train6.log - INFO -                 L: precision:  54.93%; recall:  62.54%; FB1:  58.49  690

2019-02-21 19:11:24,550 - log/train6.log - INFO -                 P: precision:  91.06%; recall:  90.06%; FB1:  90.56  537

2019-02-21 19:11:24,550 - log/train6.log - INFO -               PRO: precision:  45.59%; recall:   5.94%; FB1:  10.51  68

2019-02-21 19:11:24,553 - log/train6.log - INFO - evaluate:test
2019-02-21 19:11:26,018 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1548 phrases; correct: 1333.

2019-02-21 19:11:26,018 - log/train6.log - INFO - accuracy:  96.76%; precision:  86.11%; recall:  80.94%; FB1:  83.44

2019-02-21 19:11:26,018 - log/train6.log - INFO -                 C: precision:  90.18%; recall:  91.06%; FB1:  90.62  1039

2019-02-21 19:11:26,019 - log/train6.log - INFO -               IND: precision:  63.41%; recall:  55.32%; FB1:  59.09  41

2019-02-21 19:11:26,019 - log/train6.log - INFO -               INS: precision:  70.79%; recall:  66.32%; FB1:  68.48  89

2019-02-21 19:11:26,019 - log/train6.log - INFO -                 L: precision:  56.90%; recall:  64.08%; FB1:  60.27  116

2019-02-21 19:11:26,019 - log/train6.log - INFO -                 P: precision:  92.82%; recall:  95.10%; FB1:  93.95  209

2019-02-21 19:11:26,019 - log/train6.log - INFO -               PRO: precision:  87.04%; recall:  27.81%; FB1:  42.15  54

2019-02-21 19:11:28,128 - log/train6.log - INFO - iteration:47 step:100/10100, NER loss: 1.038239
2019-02-21 19:11:30,124 - log/train6.log - INFO - iteration:47 step:200/10100, NER loss: 0.828623
2019-02-21 19:11:32,263 - log/train6.log - INFO - iteration:47 step:300/10100, NER loss: 0.953441
2019-02-21 19:11:34,594 - log/train6.log - INFO - iteration:47 step:400/10100, NER loss: 0.978852
2019-02-21 19:11:37,264 - log/train6.log - INFO - iteration:47 step:500/10100, NER loss: 1.019079
2019-02-21 19:11:39,462 - log/train6.log - INFO - iteration:47 step:600/10100, NER loss: 0.904311
2019-02-21 19:11:41,651 - log/train6.log - INFO - iteration:47 step:700/10100, NER loss: 0.833466
2019-02-21 19:11:43,868 - log/train6.log - INFO - iteration:47 step:800/10100, NER loss: 0.757646
2019-02-21 19:11:45,939 - log/train6.log - INFO - iteration:47 step:900/10100, NER loss: 0.851339
2019-02-21 19:11:48,410 - log/train6.log - INFO - iteration:47 step:1000/10100, NER loss: 1.019246
2019-02-21 19:11:50,570 - log/train6.log - INFO - iteration:47 step:1100/10100, NER loss: 0.838161
2019-02-21 19:11:52,742 - log/train6.log - INFO - iteration:47 step:1200/10100, NER loss: 0.814700
2019-02-21 19:11:55,095 - log/train6.log - INFO - iteration:47 step:1300/10100, NER loss: 0.830779
2019-02-21 19:11:57,421 - log/train6.log - INFO - iteration:47 step:1400/10100, NER loss: 1.020903
2019-02-21 19:11:59,593 - log/train6.log - INFO - iteration:47 step:1500/10100, NER loss: 0.759240
2019-02-21 19:12:01,695 - log/train6.log - INFO - iteration:47 step:1600/10100, NER loss: 0.793819
2019-02-21 19:12:03,724 - log/train6.log - INFO - iteration:47 step:1700/10100, NER loss: 0.737755
2019-02-21 19:12:06,051 - log/train6.log - INFO - iteration:47 step:1800/10100, NER loss: 0.830155
2019-02-21 19:12:08,241 - log/train6.log - INFO - iteration:47 step:1900/10100, NER loss: 0.828436
2019-02-21 19:12:10,305 - log/train6.log - INFO - iteration:47 step:2000/10100, NER loss: 0.705289
2019-02-21 19:12:12,330 - log/train6.log - INFO - iteration:47 step:2100/10100, NER loss: 0.866627
2019-02-21 19:12:14,422 - log/train6.log - INFO - iteration:47 step:2200/10100, NER loss: 0.790824
2019-02-21 19:12:16,438 - log/train6.log - INFO - iteration:47 step:2300/10100, NER loss: 1.066218
2019-02-21 19:12:18,811 - log/train6.log - INFO - iteration:47 step:2400/10100, NER loss: 1.017347
2019-02-21 19:12:21,027 - log/train6.log - INFO - iteration:47 step:2500/10100, NER loss: 0.857038
2019-02-21 19:12:23,083 - log/train6.log - INFO - iteration:47 step:2600/10100, NER loss: 0.711230
2019-02-21 19:12:25,109 - log/train6.log - INFO - iteration:47 step:2700/10100, NER loss: 0.824885
2019-02-21 19:12:27,640 - log/train6.log - INFO - iteration:47 step:2800/10100, NER loss: 0.878767
2019-02-21 19:12:29,735 - log/train6.log - INFO - iteration:47 step:2900/10100, NER loss: 0.718472
2019-02-21 19:12:32,091 - log/train6.log - INFO - iteration:47 step:3000/10100, NER loss: 1.117894
2019-02-21 19:12:34,282 - log/train6.log - INFO - iteration:47 step:3100/10100, NER loss: 0.970199
2019-02-21 19:12:36,552 - log/train6.log - INFO - iteration:47 step:3200/10100, NER loss: 0.942766
2019-02-21 19:12:38,694 - log/train6.log - INFO - iteration:47 step:3300/10100, NER loss: 0.730477
2019-02-21 19:12:40,812 - log/train6.log - INFO - iteration:47 step:3400/10100, NER loss: 0.806833
2019-02-21 19:12:42,970 - log/train6.log - INFO - iteration:47 step:3500/10100, NER loss: 0.857365
2019-02-21 19:12:45,406 - log/train6.log - INFO - iteration:47 step:3600/10100, NER loss: 0.983804
2019-02-21 19:12:47,604 - log/train6.log - INFO - iteration:47 step:3700/10100, NER loss: 0.849285
2019-02-21 19:12:51,915 - log/train6.log - INFO - iteration:47 step:3800/10100, NER loss: 1.609483
2019-02-21 19:12:54,263 - log/train6.log - INFO - iteration:47 step:3900/10100, NER loss: 0.903518
2019-02-21 19:12:56,376 - log/train6.log - INFO - iteration:47 step:4000/10100, NER loss: 0.902669
2019-02-21 19:13:00,788 - log/train6.log - INFO - iteration:47 step:4100/10100, NER loss: 1.754956
2019-02-21 19:13:02,899 - log/train6.log - INFO - iteration:47 step:4200/10100, NER loss: 0.856169
2019-02-21 19:13:04,972 - log/train6.log - INFO - iteration:47 step:4300/10100, NER loss: 0.910346
2019-02-21 19:13:07,387 - log/train6.log - INFO - iteration:47 step:4400/10100, NER loss: 0.982858
2019-02-21 19:13:09,686 - log/train6.log - INFO - iteration:47 step:4500/10100, NER loss: 0.784740
2019-02-21 19:13:11,924 - log/train6.log - INFO - iteration:47 step:4600/10100, NER loss: 0.910575
2019-02-21 19:13:14,327 - log/train6.log - INFO - iteration:47 step:4700/10100, NER loss: 0.957646
2019-02-21 19:13:16,712 - log/train6.log - INFO - iteration:47 step:4800/10100, NER loss: 0.733372
2019-02-21 19:13:18,737 - log/train6.log - INFO - iteration:47 step:4900/10100, NER loss: 0.816770
2019-02-21 19:13:21,186 - log/train6.log - INFO - iteration:47 step:5000/10100, NER loss: 1.128019
2019-02-21 19:13:23,465 - log/train6.log - INFO - iteration:47 step:5100/10100, NER loss: 0.977136
2019-02-21 19:13:25,600 - log/train6.log - INFO - iteration:47 step:5200/10100, NER loss: 0.970985
2019-02-21 19:13:27,693 - log/train6.log - INFO - iteration:47 step:5300/10100, NER loss: 1.016174
2019-02-21 19:13:29,874 - log/train6.log - INFO - iteration:47 step:5400/10100, NER loss: 0.861396
2019-02-21 19:13:32,112 - log/train6.log - INFO - iteration:47 step:5500/10100, NER loss: 0.939465
2019-02-21 19:13:34,194 - log/train6.log - INFO - iteration:47 step:5600/10100, NER loss: 0.931443
2019-02-21 19:13:36,469 - log/train6.log - INFO - iteration:47 step:5700/10100, NER loss: 0.978296
2019-02-21 19:13:38,729 - log/train6.log - INFO - iteration:47 step:5800/10100, NER loss: 0.859076
2019-02-21 19:13:40,983 - log/train6.log - INFO - iteration:47 step:5900/10100, NER loss: 0.865863
2019-02-21 19:13:43,319 - log/train6.log - INFO - iteration:47 step:6000/10100, NER loss: 1.167218
2019-02-21 19:13:45,529 - log/train6.log - INFO - iteration:47 step:6100/10100, NER loss: 0.895492
2019-02-21 19:13:47,813 - log/train6.log - INFO - iteration:47 step:6200/10100, NER loss: 0.788764
2019-02-21 19:13:50,077 - log/train6.log - INFO - iteration:47 step:6300/10100, NER loss: 0.843504
2019-02-21 19:13:52,479 - log/train6.log - INFO - iteration:47 step:6400/10100, NER loss: 0.921288
2019-02-21 19:13:54,925 - log/train6.log - INFO - iteration:47 step:6500/10100, NER loss: 1.076075
2019-02-21 19:13:57,199 - log/train6.log - INFO - iteration:47 step:6600/10100, NER loss: 0.921105
2019-02-21 19:13:59,355 - log/train6.log - INFO - iteration:47 step:6700/10100, NER loss: 0.770042
2019-02-21 19:14:01,500 - log/train6.log - INFO - iteration:47 step:6800/10100, NER loss: 0.871179
2019-02-21 19:14:03,478 - log/train6.log - INFO - iteration:47 step:6900/10100, NER loss: 0.803370
2019-02-21 19:14:05,735 - log/train6.log - INFO - iteration:47 step:7000/10100, NER loss: 0.938217
2019-02-21 19:14:08,008 - log/train6.log - INFO - iteration:47 step:7100/10100, NER loss: 0.877240
2019-02-21 19:14:10,257 - log/train6.log - INFO - iteration:47 step:7200/10100, NER loss: 0.782930
2019-02-21 19:14:12,441 - log/train6.log - INFO - iteration:47 step:7300/10100, NER loss: 0.932546
2019-02-21 19:14:14,622 - log/train6.log - INFO - iteration:47 step:7400/10100, NER loss: 1.022880
2019-02-21 19:14:16,871 - log/train6.log - INFO - iteration:47 step:7500/10100, NER loss: 0.923634
2019-02-21 19:14:18,851 - log/train6.log - INFO - iteration:47 step:7600/10100, NER loss: 0.687965
2019-02-21 19:14:20,732 - log/train6.log - INFO - iteration:47 step:7700/10100, NER loss: 0.803067
2019-02-21 19:14:22,827 - log/train6.log - INFO - iteration:47 step:7800/10100, NER loss: 0.859079
2019-02-21 19:14:24,897 - log/train6.log - INFO - iteration:47 step:7900/10100, NER loss: 0.738563
2019-02-21 19:14:27,065 - log/train6.log - INFO - iteration:47 step:8000/10100, NER loss: 0.861492
2019-02-21 19:14:31,135 - log/train6.log - INFO - iteration:47 step:8100/10100, NER loss: 1.591725
2019-02-21 19:14:33,338 - log/train6.log - INFO - iteration:47 step:8200/10100, NER loss: 0.884732
2019-02-21 19:14:35,512 - log/train6.log - INFO - iteration:47 step:8300/10100, NER loss: 1.090455
2019-02-21 19:14:37,662 - log/train6.log - INFO - iteration:47 step:8400/10100, NER loss: 0.866220
2019-02-21 19:14:39,874 - log/train6.log - INFO - iteration:47 step:8500/10100, NER loss: 0.842093
2019-02-21 19:14:42,160 - log/train6.log - INFO - iteration:47 step:8600/10100, NER loss: 0.930327
2019-02-21 19:14:44,400 - log/train6.log - INFO - iteration:47 step:8700/10100, NER loss: 0.909553
2019-02-21 19:14:46,408 - log/train6.log - INFO - iteration:47 step:8800/10100, NER loss: 0.858020
2019-02-21 19:14:48,595 - log/train6.log - INFO - iteration:47 step:8900/10100, NER loss: 0.809691
2019-02-21 19:14:50,653 - log/train6.log - INFO - iteration:47 step:9000/10100, NER loss: 0.752806
2019-02-21 19:14:52,663 - log/train6.log - INFO - iteration:47 step:9100/10100, NER loss: 0.742415
2019-02-21 19:14:54,872 - log/train6.log - INFO - iteration:47 step:9200/10100, NER loss: 0.863041
2019-02-21 19:14:56,977 - log/train6.log - INFO - iteration:47 step:9300/10100, NER loss: 0.667455
2019-02-21 19:14:58,961 - log/train6.log - INFO - iteration:47 step:9400/10100, NER loss: 1.018332
2019-02-21 19:15:01,080 - log/train6.log - INFO - iteration:47 step:9500/10100, NER loss: 0.774572
2019-02-21 19:15:03,565 - log/train6.log - INFO - iteration:47 step:9600/10100, NER loss: 1.259627
2019-02-21 19:15:05,937 - log/train6.log - INFO - iteration:47 step:9700/10100, NER loss: 0.963325
2019-02-21 19:15:07,893 - log/train6.log - INFO - iteration:47 step:9800/10100, NER loss: 0.696499
2019-02-21 19:15:10,176 - log/train6.log - INFO - iteration:47 step:9900/10100, NER loss: 0.971148
2019-02-21 19:15:12,316 - log/train6.log - INFO - iteration:47 step:10000/10100, NER loss: 1.014757
2019-02-21 19:15:14,563 - log/train6.log - INFO - iteration:48 step:0/10100, NER loss: 0.976623
2019-02-21 19:15:14,564 - log/train6.log - INFO - evaluate:dev
2019-02-21 19:15:21,070 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5598 phrases; correct: 4286.

2019-02-21 19:15:21,071 - log/train6.log - INFO - accuracy:  95.17%; precision:  76.56%; recall:  73.30%; FB1:  74.90

2019-02-21 19:15:21,071 - log/train6.log - INFO -                 C: precision:  84.87%; recall:  87.90%; FB1:  86.36  3510

2019-02-21 19:15:21,071 - log/train6.log - INFO -               IND: precision:  40.72%; recall:  30.64%; FB1:  34.97  307

2019-02-21 19:15:21,071 - log/train6.log - INFO -               INS: precision:  71.04%; recall:  68.60%; FB1:  69.80  366

2019-02-21 19:15:21,071 - log/train6.log - INFO -                 L: precision:  57.32%; recall:  52.31%; FB1:  54.70  553

2019-02-21 19:15:21,071 - log/train6.log - INFO -                 P: precision:  91.35%; recall:  89.50%; FB1:  90.42  532

2019-02-21 19:15:21,071 - log/train6.log - INFO -               PRO: precision:  36.06%; recall:  22.80%; FB1:  27.93  330

2019-02-21 19:15:21,074 - log/train6.log - INFO - evaluate:test
2019-02-21 19:15:22,537 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1640 phrases; correct: 1369.

2019-02-21 19:15:22,537 - log/train6.log - INFO - accuracy:  96.81%; precision:  83.48%; recall:  83.12%; FB1:  83.30

2019-02-21 19:15:22,537 - log/train6.log - INFO -                 C: precision:  87.45%; recall:  92.13%; FB1:  89.73  1084

2019-02-21 19:15:22,537 - log/train6.log - INFO -               IND: precision:  46.97%; recall:  65.96%; FB1:  54.87  66

2019-02-21 19:15:22,537 - log/train6.log - INFO -               INS: precision:  71.59%; recall:  66.32%; FB1:  68.85  88

2019-02-21 19:15:22,537 - log/train6.log - INFO -                 L: precision:  62.50%; recall:  53.40%; FB1:  57.59  88

2019-02-21 19:15:22,537 - log/train6.log - INFO -                 P: precision:  93.17%; recall:  93.63%; FB1:  93.40  205

2019-02-21 19:15:22,537 - log/train6.log - INFO -               PRO: precision:  74.31%; recall:  47.93%; FB1:  58.27  109

2019-02-21 19:15:24,668 - log/train6.log - INFO - iteration:48 step:100/10100, NER loss: 1.018147
2019-02-21 19:15:26,771 - log/train6.log - INFO - iteration:48 step:200/10100, NER loss: 1.023460
2019-02-21 19:15:29,061 - log/train6.log - INFO - iteration:48 step:300/10100, NER loss: 0.982983
2019-02-21 19:15:31,273 - log/train6.log - INFO - iteration:48 step:400/10100, NER loss: 0.991920
2019-02-21 19:15:33,471 - log/train6.log - INFO - iteration:48 step:500/10100, NER loss: 0.750338
2019-02-21 19:15:35,698 - log/train6.log - INFO - iteration:48 step:600/10100, NER loss: 0.951394
2019-02-21 19:15:38,022 - log/train6.log - INFO - iteration:48 step:700/10100, NER loss: 0.927329
2019-02-21 19:15:42,010 - log/train6.log - INFO - iteration:48 step:800/10100, NER loss: 1.473466
2019-02-21 19:15:44,183 - log/train6.log - INFO - iteration:48 step:900/10100, NER loss: 0.781513
2019-02-21 19:15:46,495 - log/train6.log - INFO - iteration:48 step:1000/10100, NER loss: 0.920918
2019-02-21 19:15:48,787 - log/train6.log - INFO - iteration:48 step:1100/10100, NER loss: 0.977225
2019-02-21 19:15:51,018 - log/train6.log - INFO - iteration:48 step:1200/10100, NER loss: 0.830477
2019-02-21 19:15:53,258 - log/train6.log - INFO - iteration:48 step:1300/10100, NER loss: 1.005615
2019-02-21 19:15:55,525 - log/train6.log - INFO - iteration:48 step:1400/10100, NER loss: 1.009195
2019-02-21 19:15:57,699 - log/train6.log - INFO - iteration:48 step:1500/10100, NER loss: 0.752716
2019-02-21 19:15:59,880 - log/train6.log - INFO - iteration:48 step:1600/10100, NER loss: 0.866841
2019-02-21 19:16:01,789 - log/train6.log - INFO - iteration:48 step:1700/10100, NER loss: 0.541583
2019-02-21 19:16:03,876 - log/train6.log - INFO - iteration:48 step:1800/10100, NER loss: 0.823434
2019-02-21 19:16:06,499 - log/train6.log - INFO - iteration:48 step:1900/10100, NER loss: 1.034828
2019-02-21 19:16:08,671 - log/train6.log - INFO - iteration:48 step:2000/10100, NER loss: 0.901744
2019-02-21 19:16:10,817 - log/train6.log - INFO - iteration:48 step:2100/10100, NER loss: 0.820553
2019-02-21 19:16:13,183 - log/train6.log - INFO - iteration:48 step:2200/10100, NER loss: 1.040038
2019-02-21 19:16:15,896 - log/train6.log - INFO - iteration:48 step:2300/10100, NER loss: 1.120346
2019-02-21 19:16:18,119 - log/train6.log - INFO - iteration:48 step:2400/10100, NER loss: 0.912496
2019-02-21 19:16:20,047 - log/train6.log - INFO - iteration:48 step:2500/10100, NER loss: 0.786180
2019-02-21 19:16:22,384 - log/train6.log - INFO - iteration:48 step:2600/10100, NER loss: 1.000686
2019-02-21 19:16:24,681 - log/train6.log - INFO - iteration:48 step:2700/10100, NER loss: 0.886464
2019-02-21 19:16:26,821 - log/train6.log - INFO - iteration:48 step:2800/10100, NER loss: 0.847976
2019-02-21 19:16:28,988 - log/train6.log - INFO - iteration:48 step:2900/10100, NER loss: 0.890861
2019-02-21 19:16:31,271 - log/train6.log - INFO - iteration:48 step:3000/10100, NER loss: 0.914822
2019-02-21 19:16:33,425 - log/train6.log - INFO - iteration:48 step:3100/10100, NER loss: 0.796106
2019-02-21 19:16:35,564 - log/train6.log - INFO - iteration:48 step:3200/10100, NER loss: 0.788300
2019-02-21 19:16:37,742 - log/train6.log - INFO - iteration:48 step:3300/10100, NER loss: 0.907658
2019-02-21 19:16:39,825 - log/train6.log - INFO - iteration:48 step:3400/10100, NER loss: 0.827241
2019-02-21 19:16:41,973 - log/train6.log - INFO - iteration:48 step:3500/10100, NER loss: 0.937765
2019-02-21 19:16:44,402 - log/train6.log - INFO - iteration:48 step:3600/10100, NER loss: 1.026058
2019-02-21 19:16:46,828 - log/train6.log - INFO - iteration:48 step:3700/10100, NER loss: 1.025448
2019-02-21 19:16:48,965 - log/train6.log - INFO - iteration:48 step:3800/10100, NER loss: 0.918039
2019-02-21 19:16:51,390 - log/train6.log - INFO - iteration:48 step:3900/10100, NER loss: 0.776011
2019-02-21 19:16:53,661 - log/train6.log - INFO - iteration:48 step:4000/10100, NER loss: 0.921992
2019-02-21 19:16:55,751 - log/train6.log - INFO - iteration:48 step:4100/10100, NER loss: 0.933722
2019-02-21 19:16:57,931 - log/train6.log - INFO - iteration:48 step:4200/10100, NER loss: 0.815763
2019-02-21 19:16:59,888 - log/train6.log - INFO - iteration:48 step:4300/10100, NER loss: 0.882475
2019-02-21 19:17:01,760 - log/train6.log - INFO - iteration:48 step:4400/10100, NER loss: 0.765171
2019-02-21 19:17:04,016 - log/train6.log - INFO - iteration:48 step:4500/10100, NER loss: 0.805531
2019-02-21 19:17:06,314 - log/train6.log - INFO - iteration:48 step:4600/10100, NER loss: 1.030043
2019-02-21 19:17:08,333 - log/train6.log - INFO - iteration:48 step:4700/10100, NER loss: 0.731585
2019-02-21 19:17:10,522 - log/train6.log - INFO - iteration:48 step:4800/10100, NER loss: 0.839253
2019-02-21 19:17:12,874 - log/train6.log - INFO - iteration:48 step:4900/10100, NER loss: 1.516867
2019-02-21 19:17:15,091 - log/train6.log - INFO - iteration:48 step:5000/10100, NER loss: 0.754103
2019-02-21 19:17:17,306 - log/train6.log - INFO - iteration:48 step:5100/10100, NER loss: 0.907353
2019-02-21 19:17:19,680 - log/train6.log - INFO - iteration:48 step:5200/10100, NER loss: 0.916555
2019-02-21 19:17:22,005 - log/train6.log - INFO - iteration:48 step:5300/10100, NER loss: 0.841361
2019-02-21 19:17:24,191 - log/train6.log - INFO - iteration:48 step:5400/10100, NER loss: 0.888122
2019-02-21 19:17:26,425 - log/train6.log - INFO - iteration:48 step:5500/10100, NER loss: 1.099599
2019-02-21 19:17:28,543 - log/train6.log - INFO - iteration:48 step:5600/10100, NER loss: 0.851269
2019-02-21 19:17:30,794 - log/train6.log - INFO - iteration:48 step:5700/10100, NER loss: 0.785933
2019-02-21 19:17:33,002 - log/train6.log - INFO - iteration:48 step:5800/10100, NER loss: 0.991057
2019-02-21 19:17:35,341 - log/train6.log - INFO - iteration:48 step:5900/10100, NER loss: 1.005286
2019-02-21 19:17:37,650 - log/train6.log - INFO - iteration:48 step:6000/10100, NER loss: 0.867115
2019-02-21 19:17:39,884 - log/train6.log - INFO - iteration:48 step:6100/10100, NER loss: 0.882264
2019-02-21 19:17:42,201 - log/train6.log - INFO - iteration:48 step:6200/10100, NER loss: 1.070310
2019-02-21 19:17:44,374 - log/train6.log - INFO - iteration:48 step:6300/10100, NER loss: 0.744289
2019-02-21 19:17:46,556 - log/train6.log - INFO - iteration:48 step:6400/10100, NER loss: 0.820743
2019-02-21 19:17:48,906 - log/train6.log - INFO - iteration:48 step:6500/10100, NER loss: 0.909796
2019-02-21 19:17:50,974 - log/train6.log - INFO - iteration:48 step:6600/10100, NER loss: 0.756037
2019-02-21 19:17:54,862 - log/train6.log - INFO - iteration:48 step:6700/10100, NER loss: 1.320970
2019-02-21 19:17:57,048 - log/train6.log - INFO - iteration:48 step:6800/10100, NER loss: 0.939591
2019-02-21 19:17:59,284 - log/train6.log - INFO - iteration:48 step:6900/10100, NER loss: 0.884238
2019-02-21 19:18:01,372 - log/train6.log - INFO - iteration:48 step:7000/10100, NER loss: 0.862733
2019-02-21 19:18:03,549 - log/train6.log - INFO - iteration:48 step:7100/10100, NER loss: 0.800230
2019-02-21 19:18:05,682 - log/train6.log - INFO - iteration:48 step:7200/10100, NER loss: 0.878613
2019-02-21 19:18:07,612 - log/train6.log - INFO - iteration:48 step:7300/10100, NER loss: 0.865402
2019-02-21 19:18:09,862 - log/train6.log - INFO - iteration:48 step:7400/10100, NER loss: 0.928539
2019-02-21 19:18:12,306 - log/train6.log - INFO - iteration:48 step:7500/10100, NER loss: 1.040990
2019-02-21 19:18:14,603 - log/train6.log - INFO - iteration:48 step:7600/10100, NER loss: 0.781717
2019-02-21 19:18:19,049 - log/train6.log - INFO - iteration:48 step:7700/10100, NER loss: 1.626020
2019-02-21 19:18:21,172 - log/train6.log - INFO - iteration:48 step:7800/10100, NER loss: 0.916904
2019-02-21 19:18:23,312 - log/train6.log - INFO - iteration:48 step:7900/10100, NER loss: 0.873181
2019-02-21 19:18:25,515 - log/train6.log - INFO - iteration:48 step:8000/10100, NER loss: 0.776852
2019-02-21 19:18:27,629 - log/train6.log - INFO - iteration:48 step:8100/10100, NER loss: 1.136447
2019-02-21 19:18:29,888 - log/train6.log - INFO - iteration:48 step:8200/10100, NER loss: 0.978402
2019-02-21 19:18:32,048 - log/train6.log - INFO - iteration:48 step:8300/10100, NER loss: 0.809649
2019-02-21 19:18:34,299 - log/train6.log - INFO - iteration:48 step:8400/10100, NER loss: 0.934542
2019-02-21 19:18:36,567 - log/train6.log - INFO - iteration:48 step:8500/10100, NER loss: 0.897857
2019-02-21 19:18:38,834 - log/train6.log - INFO - iteration:48 step:8600/10100, NER loss: 0.839000
2019-02-21 19:18:41,078 - log/train6.log - INFO - iteration:48 step:8700/10100, NER loss: 0.926328
2019-02-21 19:18:43,212 - log/train6.log - INFO - iteration:48 step:8800/10100, NER loss: 0.738533
2019-02-21 19:18:45,398 - log/train6.log - INFO - iteration:48 step:8900/10100, NER loss: 0.734768
2019-02-21 19:18:47,482 - log/train6.log - INFO - iteration:48 step:9000/10100, NER loss: 0.883508
2019-02-21 19:18:49,640 - log/train6.log - INFO - iteration:48 step:9100/10100, NER loss: 0.912150
2019-02-21 19:18:52,019 - log/train6.log - INFO - iteration:48 step:9200/10100, NER loss: 1.300130
2019-02-21 19:18:54,202 - log/train6.log - INFO - iteration:48 step:9300/10100, NER loss: 0.725085
2019-02-21 19:18:56,649 - log/train6.log - INFO - iteration:48 step:9400/10100, NER loss: 0.927258
2019-02-21 19:18:59,097 - log/train6.log - INFO - iteration:48 step:9500/10100, NER loss: 0.998058
2019-02-21 19:19:01,299 - log/train6.log - INFO - iteration:48 step:9600/10100, NER loss: 0.896504
2019-02-21 19:19:03,590 - log/train6.log - INFO - iteration:48 step:9700/10100, NER loss: 0.942196
2019-02-21 19:19:05,737 - log/train6.log - INFO - iteration:48 step:9800/10100, NER loss: 0.775867
2019-02-21 19:19:08,067 - log/train6.log - INFO - iteration:48 step:9900/10100, NER loss: 0.961951
2019-02-21 19:19:09,994 - log/train6.log - INFO - iteration:48 step:10000/10100, NER loss: 0.597998
2019-02-21 19:19:12,160 - log/train6.log - INFO - iteration:49 step:0/10100, NER loss: 0.763147
2019-02-21 19:19:12,160 - log/train6.log - INFO - evaluate:dev
2019-02-21 19:19:18,639 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5679 phrases; correct: 4328.

2019-02-21 19:19:18,639 - log/train6.log - INFO - accuracy:  95.29%; precision:  76.21%; recall:  74.02%; FB1:  75.10

2019-02-21 19:19:18,639 - log/train6.log - INFO -                 C: precision:  87.55%; recall:  87.78%; FB1:  87.67  3398

2019-02-21 19:19:18,639 - log/train6.log - INFO -               IND: precision:  45.53%; recall:  27.45%; FB1:  34.25  246

2019-02-21 19:19:18,639 - log/train6.log - INFO -               INS: precision:  70.47%; recall:  71.77%; FB1:  71.11  386

2019-02-21 19:19:18,639 - log/train6.log - INFO -                 L: precision:  49.02%; recall:  53.80%; FB1:  51.30  665

2019-02-21 19:19:18,639 - log/train6.log - INFO -                 P: precision:  90.07%; recall:  90.24%; FB1:  90.16  544

2019-02-21 19:19:18,639 - log/train6.log - INFO -               PRO: precision:  34.77%; recall:  29.31%; FB1:  31.81  440

2019-02-21 19:19:18,642 - log/train6.log - INFO - evaluate:test
2019-02-21 19:19:20,104 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1669 phrases; correct: 1394.

2019-02-21 19:19:20,104 - log/train6.log - INFO - accuracy:  96.94%; precision:  83.52%; recall:  84.64%; FB1:  84.08

2019-02-21 19:19:20,104 - log/train6.log - INFO -                 C: precision:  89.36%; recall:  91.45%; FB1:  90.39  1053

2019-02-21 19:19:20,104 - log/train6.log - INFO -               IND: precision:  64.58%; recall:  65.96%; FB1:  65.26  48

2019-02-21 19:19:20,104 - log/train6.log - INFO -               INS: precision:  68.75%; recall:  69.47%; FB1:  69.11  96

2019-02-21 19:19:20,104 - log/train6.log - INFO -                 L: precision:  54.39%; recall:  60.19%; FB1:  57.14  114

2019-02-21 19:19:20,104 - log/train6.log - INFO -                 P: precision:  92.79%; recall:  94.61%; FB1:  93.69  208

2019-02-21 19:19:20,104 - log/train6.log - INFO -               PRO: precision:  67.33%; recall:  59.76%; FB1:  63.32  150

2019-02-21 19:19:22,222 - log/train6.log - INFO - iteration:49 step:100/10100, NER loss: 0.986038
2019-02-21 19:19:24,311 - log/train6.log - INFO - iteration:49 step:200/10100, NER loss: 0.988017
2019-02-21 19:19:26,612 - log/train6.log - INFO - iteration:49 step:300/10100, NER loss: 1.123412
2019-02-21 19:19:28,904 - log/train6.log - INFO - iteration:49 step:400/10100, NER loss: 1.106790
2019-02-21 19:19:31,012 - log/train6.log - INFO - iteration:49 step:500/10100, NER loss: 0.664037
2019-02-21 19:19:33,234 - log/train6.log - INFO - iteration:49 step:600/10100, NER loss: 0.801819
2019-02-21 19:19:35,302 - log/train6.log - INFO - iteration:49 step:700/10100, NER loss: 0.819156
2019-02-21 19:19:37,686 - log/train6.log - INFO - iteration:49 step:800/10100, NER loss: 1.028110
2019-02-21 19:19:39,765 - log/train6.log - INFO - iteration:49 step:900/10100, NER loss: 0.817682
2019-02-21 19:19:42,019 - log/train6.log - INFO - iteration:49 step:1000/10100, NER loss: 0.881421
2019-02-21 19:19:44,410 - log/train6.log - INFO - iteration:49 step:1100/10100, NER loss: 0.950654
2019-02-21 19:19:46,712 - log/train6.log - INFO - iteration:49 step:1200/10100, NER loss: 1.070091
2019-02-21 19:19:48,795 - log/train6.log - INFO - iteration:49 step:1300/10100, NER loss: 0.723551
2019-02-21 19:19:51,101 - log/train6.log - INFO - iteration:49 step:1400/10100, NER loss: 0.791299
2019-02-21 19:19:53,272 - log/train6.log - INFO - iteration:49 step:1500/10100, NER loss: 0.726314
2019-02-21 19:19:55,631 - log/train6.log - INFO - iteration:49 step:1600/10100, NER loss: 0.996762
2019-02-21 19:19:57,824 - log/train6.log - INFO - iteration:49 step:1700/10100, NER loss: 0.849268
2019-02-21 19:19:59,995 - log/train6.log - INFO - iteration:49 step:1800/10100, NER loss: 0.933398
2019-02-21 19:20:01,950 - log/train6.log - INFO - iteration:49 step:1900/10100, NER loss: 0.643367
2019-02-21 19:20:04,106 - log/train6.log - INFO - iteration:49 step:2000/10100, NER loss: 0.871382
2019-02-21 19:20:06,436 - log/train6.log - INFO - iteration:49 step:2100/10100, NER loss: 1.061265
2019-02-21 19:20:08,571 - log/train6.log - INFO - iteration:49 step:2200/10100, NER loss: 0.885959
2019-02-21 19:20:10,853 - log/train6.log - INFO - iteration:49 step:2300/10100, NER loss: 0.800307
2019-02-21 19:20:12,973 - log/train6.log - INFO - iteration:49 step:2400/10100, NER loss: 0.832413
2019-02-21 19:20:15,251 - log/train6.log - INFO - iteration:49 step:2500/10100, NER loss: 0.870491
2019-02-21 19:20:17,322 - log/train6.log - INFO - iteration:49 step:2600/10100, NER loss: 0.771796
2019-02-21 19:20:19,420 - log/train6.log - INFO - iteration:49 step:2700/10100, NER loss: 0.893433
2019-02-21 19:20:21,593 - log/train6.log - INFO - iteration:49 step:2800/10100, NER loss: 0.775074
2019-02-21 19:20:23,938 - log/train6.log - INFO - iteration:49 step:2900/10100, NER loss: 1.026383
2019-02-21 19:20:26,121 - log/train6.log - INFO - iteration:49 step:3000/10100, NER loss: 0.978191
2019-02-21 19:20:28,284 - log/train6.log - INFO - iteration:49 step:3100/10100, NER loss: 0.851585
2019-02-21 19:20:30,357 - log/train6.log - INFO - iteration:49 step:3200/10100, NER loss: 0.798194
2019-02-21 19:20:32,525 - log/train6.log - INFO - iteration:49 step:3300/10100, NER loss: 0.849345
2019-02-21 19:20:34,663 - log/train6.log - INFO - iteration:49 step:3400/10100, NER loss: 0.835405
2019-02-21 19:20:36,924 - log/train6.log - INFO - iteration:49 step:3500/10100, NER loss: 0.887710
2019-02-21 19:20:38,946 - log/train6.log - INFO - iteration:49 step:3600/10100, NER loss: 0.672798
2019-02-21 19:20:41,127 - log/train6.log - INFO - iteration:49 step:3700/10100, NER loss: 1.003974
2019-02-21 19:20:43,382 - log/train6.log - INFO - iteration:49 step:3800/10100, NER loss: 0.802741
2019-02-21 19:20:45,455 - log/train6.log - INFO - iteration:49 step:3900/10100, NER loss: 0.742378
2019-02-21 19:20:47,671 - log/train6.log - INFO - iteration:49 step:4000/10100, NER loss: 0.845418
2019-02-21 19:20:49,915 - log/train6.log - INFO - iteration:49 step:4100/10100, NER loss: 0.869676
2019-02-21 19:20:52,117 - log/train6.log - INFO - iteration:49 step:4200/10100, NER loss: 0.862676
2019-02-21 19:20:54,279 - log/train6.log - INFO - iteration:49 step:4300/10100, NER loss: 0.919257
2019-02-21 19:20:56,681 - log/train6.log - INFO - iteration:49 step:4400/10100, NER loss: 1.030276
2019-02-21 19:20:58,826 - log/train6.log - INFO - iteration:49 step:4500/10100, NER loss: 0.791824
2019-02-21 19:21:01,291 - log/train6.log - INFO - iteration:49 step:4600/10100, NER loss: 0.960374
2019-02-21 19:21:03,353 - log/train6.log - INFO - iteration:49 step:4700/10100, NER loss: 0.917493
2019-02-21 19:21:05,789 - log/train6.log - INFO - iteration:49 step:4800/10100, NER loss: 0.924006
2019-02-21 19:21:07,919 - log/train6.log - INFO - iteration:49 step:4900/10100, NER loss: 0.942119
2019-02-21 19:21:12,467 - log/train6.log - INFO - iteration:49 step:5000/10100, NER loss: 1.886720
2019-02-21 19:21:14,732 - log/train6.log - INFO - iteration:49 step:5100/10100, NER loss: 0.912720
2019-02-21 19:21:17,008 - log/train6.log - INFO - iteration:49 step:5200/10100, NER loss: 0.842669
2019-02-21 19:21:19,417 - log/train6.log - INFO - iteration:49 step:5300/10100, NER loss: 0.958516
2019-02-21 19:21:21,660 - log/train6.log - INFO - iteration:49 step:5400/10100, NER loss: 0.921225
2019-02-21 19:21:24,078 - log/train6.log - INFO - iteration:49 step:5500/10100, NER loss: 0.873836
2019-02-21 19:21:26,749 - log/train6.log - INFO - iteration:49 step:5600/10100, NER loss: 1.179046
2019-02-21 19:21:28,803 - log/train6.log - INFO - iteration:49 step:5700/10100, NER loss: 0.817355
2019-02-21 19:21:31,145 - log/train6.log - INFO - iteration:49 step:5800/10100, NER loss: 1.062355
2019-02-21 19:21:33,179 - log/train6.log - INFO - iteration:49 step:5900/10100, NER loss: 0.812098
2019-02-21 19:21:35,454 - log/train6.log - INFO - iteration:49 step:6000/10100, NER loss: 0.888216
2019-02-21 19:21:37,642 - log/train6.log - INFO - iteration:49 step:6100/10100, NER loss: 0.909101
2019-02-21 19:21:39,787 - log/train6.log - INFO - iteration:49 step:6200/10100, NER loss: 0.799953
2019-02-21 19:21:41,896 - log/train6.log - INFO - iteration:49 step:6300/10100, NER loss: 0.696858
2019-02-21 19:21:44,133 - log/train6.log - INFO - iteration:49 step:6400/10100, NER loss: 0.832032
2019-02-21 19:21:46,338 - log/train6.log - INFO - iteration:49 step:6500/10100, NER loss: 0.997585
2019-02-21 19:21:48,690 - log/train6.log - INFO - iteration:49 step:6600/10100, NER loss: 0.982659
2019-02-21 19:21:50,962 - log/train6.log - INFO - iteration:49 step:6700/10100, NER loss: 0.853709
2019-02-21 19:21:53,119 - log/train6.log - INFO - iteration:49 step:6800/10100, NER loss: 0.845168
2019-02-21 19:21:55,140 - log/train6.log - INFO - iteration:49 step:6900/10100, NER loss: 0.718110
2019-02-21 19:21:57,231 - log/train6.log - INFO - iteration:49 step:7000/10100, NER loss: 0.844265
2019-02-21 19:21:59,356 - log/train6.log - INFO - iteration:49 step:7100/10100, NER loss: 0.810262
2019-02-21 19:22:01,572 - log/train6.log - INFO - iteration:49 step:7200/10100, NER loss: 1.064038
2019-02-21 19:22:03,914 - log/train6.log - INFO - iteration:49 step:7300/10100, NER loss: 1.037207
2019-02-21 19:22:06,260 - log/train6.log - INFO - iteration:49 step:7400/10100, NER loss: 0.964718
2019-02-21 19:22:08,350 - log/train6.log - INFO - iteration:49 step:7500/10100, NER loss: 0.849493
2019-02-21 19:22:10,650 - log/train6.log - INFO - iteration:49 step:7600/10100, NER loss: 0.904146
2019-02-21 19:22:12,900 - log/train6.log - INFO - iteration:49 step:7700/10100, NER loss: 1.021405
2019-02-21 19:22:14,919 - log/train6.log - INFO - iteration:49 step:7800/10100, NER loss: 0.690915
2019-02-21 19:22:16,918 - log/train6.log - INFO - iteration:49 step:7900/10100, NER loss: 0.826369
2019-02-21 19:22:19,063 - log/train6.log - INFO - iteration:49 step:8000/10100, NER loss: 0.945425
2019-02-21 19:22:21,231 - log/train6.log - INFO - iteration:49 step:8100/10100, NER loss: 0.725685
2019-02-21 19:22:25,254 - log/train6.log - INFO - iteration:49 step:8200/10100, NER loss: 1.688721
2019-02-21 19:22:27,287 - log/train6.log - INFO - iteration:49 step:8300/10100, NER loss: 0.831098
2019-02-21 19:22:29,679 - log/train6.log - INFO - iteration:49 step:8400/10100, NER loss: 0.859692
2019-02-21 19:22:31,923 - log/train6.log - INFO - iteration:49 step:8500/10100, NER loss: 0.905240
2019-02-21 19:22:34,189 - log/train6.log - INFO - iteration:49 step:8600/10100, NER loss: 0.853025
2019-02-21 19:22:36,307 - log/train6.log - INFO - iteration:49 step:8700/10100, NER loss: 0.795179
2019-02-21 19:22:38,554 - log/train6.log - INFO - iteration:49 step:8800/10100, NER loss: 0.670362
2019-02-21 19:22:40,790 - log/train6.log - INFO - iteration:49 step:8900/10100, NER loss: 0.870042
2019-02-21 19:22:43,164 - log/train6.log - INFO - iteration:49 step:9000/10100, NER loss: 1.022996
2019-02-21 19:22:45,382 - log/train6.log - INFO - iteration:49 step:9100/10100, NER loss: 0.854974
2019-02-21 19:22:47,594 - log/train6.log - INFO - iteration:49 step:9200/10100, NER loss: 0.951037
2019-02-21 19:22:49,886 - log/train6.log - INFO - iteration:49 step:9300/10100, NER loss: 0.927992
2019-02-21 19:22:51,998 - log/train6.log - INFO - iteration:49 step:9400/10100, NER loss: 1.266429
2019-02-21 19:22:54,191 - log/train6.log - INFO - iteration:49 step:9500/10100, NER loss: 0.812023
2019-02-21 19:22:56,435 - log/train6.log - INFO - iteration:49 step:9600/10100, NER loss: 0.954813
2019-02-21 19:22:58,527 - log/train6.log - INFO - iteration:49 step:9700/10100, NER loss: 0.673181
2019-02-21 19:23:00,714 - log/train6.log - INFO - iteration:49 step:9800/10100, NER loss: 0.931326
2019-02-21 19:23:03,128 - log/train6.log - INFO - iteration:49 step:9900/10100, NER loss: 1.049345
2019-02-21 19:23:07,311 - log/train6.log - INFO - iteration:49 step:10000/10100, NER loss: 1.427108
2019-02-21 19:23:09,490 - log/train6.log - INFO - iteration:50 step:0/10100, NER loss: 0.966545
2019-02-21 19:23:09,491 - log/train6.log - INFO - evaluate:dev
2019-02-21 19:23:15,908 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5306 phrases; correct: 4235.

2019-02-21 19:23:15,909 - log/train6.log - INFO - accuracy:  95.44%; precision:  79.82%; recall:  72.43%; FB1:  75.94

2019-02-21 19:23:15,909 - log/train6.log - INFO -                 C: precision:  87.72%; recall:  86.87%; FB1:  87.29  3356

2019-02-21 19:23:15,909 - log/train6.log - INFO -               IND: precision:  46.08%; recall:  24.51%; FB1:  32.00  217

2019-02-21 19:23:15,909 - log/train6.log - INFO -               INS: precision:  74.72%; recall:  69.39%; FB1:  71.96  352

2019-02-21 19:23:15,909 - log/train6.log - INFO -                 L: precision:  57.41%; recall:  60.07%; FB1:  58.71  634

2019-02-21 19:23:15,909 - log/train6.log - INFO -                 P: precision:  88.79%; recall:  90.42%; FB1:  89.60  553

2019-02-21 19:23:15,909 - log/train6.log - INFO -               PRO: precision:  37.63%; recall:  13.98%; FB1:  20.39  194

2019-02-21 19:23:15,912 - log/train6.log - INFO - evaluate:test
2019-02-21 19:23:17,369 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1571 phrases; correct: 1350.

2019-02-21 19:23:17,369 - log/train6.log - INFO - accuracy:  96.97%; precision:  85.93%; recall:  81.97%; FB1:  83.90

2019-02-21 19:23:17,369 - log/train6.log - INFO -                 C: precision:  89.77%; recall:  91.25%; FB1:  90.51  1046

2019-02-21 19:23:17,369 - log/train6.log - INFO -               IND: precision:  58.70%; recall:  57.45%; FB1:  58.06  46

2019-02-21 19:23:17,369 - log/train6.log - INFO -               INS: precision:  76.19%; recall:  67.37%; FB1:  71.51  84

2019-02-21 19:23:17,369 - log/train6.log - INFO -                 L: precision:  58.59%; recall:  56.31%; FB1:  57.43  99

2019-02-21 19:23:17,369 - log/train6.log - INFO -                 P: precision:  92.31%; recall:  94.12%; FB1:  93.20  208

2019-02-21 19:23:17,369 - log/train6.log - INFO -               PRO: precision:  79.55%; recall:  41.42%; FB1:  54.47  88

2019-02-21 19:23:19,261 - log/train6.log - INFO - iteration:50 step:100/10100, NER loss: 0.677196
2019-02-21 19:23:21,192 - log/train6.log - INFO - iteration:50 step:200/10100, NER loss: 0.713118
2019-02-21 19:23:23,319 - log/train6.log - INFO - iteration:50 step:300/10100, NER loss: 0.874037
2019-02-21 19:23:25,520 - log/train6.log - INFO - iteration:50 step:400/10100, NER loss: 0.902577
2019-02-21 19:23:27,587 - log/train6.log - INFO - iteration:50 step:500/10100, NER loss: 0.722671
2019-02-21 19:23:29,814 - log/train6.log - INFO - iteration:50 step:600/10100, NER loss: 0.784201
2019-02-21 19:23:31,967 - log/train6.log - INFO - iteration:50 step:700/10100, NER loss: 0.853173
2019-02-21 19:23:34,150 - log/train6.log - INFO - iteration:50 step:800/10100, NER loss: 0.838394
2019-02-21 19:23:36,181 - log/train6.log - INFO - iteration:50 step:900/10100, NER loss: 0.711887
2019-02-21 19:23:38,290 - log/train6.log - INFO - iteration:50 step:1000/10100, NER loss: 0.730122
2019-02-21 19:23:40,506 - log/train6.log - INFO - iteration:50 step:1100/10100, NER loss: 0.984784
2019-02-21 19:23:42,811 - log/train6.log - INFO - iteration:50 step:1200/10100, NER loss: 1.063148
2019-02-21 19:23:45,064 - log/train6.log - INFO - iteration:50 step:1300/10100, NER loss: 0.889146
2019-02-21 19:23:47,396 - log/train6.log - INFO - iteration:50 step:1400/10100, NER loss: 1.109750
2019-02-21 19:23:49,837 - log/train6.log - INFO - iteration:50 step:1500/10100, NER loss: 0.935637
2019-02-21 19:23:51,822 - log/train6.log - INFO - iteration:50 step:1600/10100, NER loss: 0.887408
2019-02-21 19:23:53,974 - log/train6.log - INFO - iteration:50 step:1700/10100, NER loss: 0.830236
2019-02-21 19:23:56,144 - log/train6.log - INFO - iteration:50 step:1800/10100, NER loss: 0.885882
2019-02-21 19:23:58,382 - log/train6.log - INFO - iteration:50 step:1900/10100, NER loss: 0.869498
2019-02-21 19:24:00,828 - log/train6.log - INFO - iteration:50 step:2000/10100, NER loss: 1.090970
2019-02-21 19:24:02,963 - log/train6.log - INFO - iteration:50 step:2100/10100, NER loss: 0.881388
2019-02-21 19:24:05,169 - log/train6.log - INFO - iteration:50 step:2200/10100, NER loss: 0.782801
2019-02-21 19:24:07,594 - log/train6.log - INFO - iteration:50 step:2300/10100, NER loss: 0.830566
2019-02-21 19:24:09,715 - log/train6.log - INFO - iteration:50 step:2400/10100, NER loss: 0.752515
2019-02-21 19:24:11,937 - log/train6.log - INFO - iteration:50 step:2500/10100, NER loss: 0.844490
2019-02-21 19:24:14,105 - log/train6.log - INFO - iteration:50 step:2600/10100, NER loss: 0.745522
2019-02-21 19:24:16,217 - log/train6.log - INFO - iteration:50 step:2700/10100, NER loss: 0.782773
2019-02-21 19:24:18,201 - log/train6.log - INFO - iteration:50 step:2800/10100, NER loss: 0.707807
2019-02-21 19:24:20,322 - log/train6.log - INFO - iteration:50 step:2900/10100, NER loss: 0.809215
2019-02-21 19:24:22,566 - log/train6.log - INFO - iteration:50 step:3000/10100, NER loss: 0.936042
2019-02-21 19:24:24,566 - log/train6.log - INFO - iteration:50 step:3100/10100, NER loss: 0.768131
2019-02-21 19:24:26,713 - log/train6.log - INFO - iteration:50 step:3200/10100, NER loss: 0.899696
2019-02-21 19:24:28,922 - log/train6.log - INFO - iteration:50 step:3300/10100, NER loss: 1.019531
2019-02-21 19:24:31,257 - log/train6.log - INFO - iteration:50 step:3400/10100, NER loss: 0.810511
2019-02-21 19:24:33,478 - log/train6.log - INFO - iteration:50 step:3500/10100, NER loss: 0.936107
2019-02-21 19:24:35,475 - log/train6.log - INFO - iteration:50 step:3600/10100, NER loss: 0.769145
2019-02-21 19:24:39,572 - log/train6.log - INFO - iteration:50 step:3700/10100, NER loss: 1.431198
2019-02-21 19:24:41,726 - log/train6.log - INFO - iteration:50 step:3800/10100, NER loss: 0.918342
2019-02-21 19:24:43,983 - log/train6.log - INFO - iteration:50 step:3900/10100, NER loss: 0.793918
2019-02-21 19:24:46,095 - log/train6.log - INFO - iteration:50 step:4000/10100, NER loss: 0.820674
2019-02-21 19:24:48,394 - log/train6.log - INFO - iteration:50 step:4100/10100, NER loss: 0.935198
2019-02-21 19:24:50,608 - log/train6.log - INFO - iteration:50 step:4200/10100, NER loss: 0.942715
2019-02-21 19:24:53,024 - log/train6.log - INFO - iteration:50 step:4300/10100, NER loss: 1.053102
2019-02-21 19:24:55,482 - log/train6.log - INFO - iteration:50 step:4400/10100, NER loss: 0.965203
2019-02-21 19:24:57,885 - log/train6.log - INFO - iteration:50 step:4500/10100, NER loss: 1.176489
2019-02-21 19:25:00,206 - log/train6.log - INFO - iteration:50 step:4600/10100, NER loss: 0.884140
2019-02-21 19:25:02,324 - log/train6.log - INFO - iteration:50 step:4700/10100, NER loss: 0.972062
2019-02-21 19:25:04,361 - log/train6.log - INFO - iteration:50 step:4800/10100, NER loss: 0.854640
2019-02-21 19:25:06,601 - log/train6.log - INFO - iteration:50 step:4900/10100, NER loss: 1.005024
2019-02-21 19:25:08,829 - log/train6.log - INFO - iteration:50 step:5000/10100, NER loss: 0.788542
2019-02-21 19:25:10,803 - log/train6.log - INFO - iteration:50 step:5100/10100, NER loss: 0.690217
2019-02-21 19:25:12,935 - log/train6.log - INFO - iteration:50 step:5200/10100, NER loss: 0.781061
2019-02-21 19:25:15,119 - log/train6.log - INFO - iteration:50 step:5300/10100, NER loss: 1.010565
2019-02-21 19:25:17,387 - log/train6.log - INFO - iteration:50 step:5400/10100, NER loss: 0.812848
2019-02-21 19:25:19,409 - log/train6.log - INFO - iteration:50 step:5500/10100, NER loss: 0.803728
2019-02-21 19:25:21,499 - log/train6.log - INFO - iteration:50 step:5600/10100, NER loss: 0.814147
2019-02-21 19:25:23,788 - log/train6.log - INFO - iteration:50 step:5700/10100, NER loss: 1.097642
2019-02-21 19:25:26,157 - log/train6.log - INFO - iteration:50 step:5800/10100, NER loss: 0.895665
2019-02-21 19:25:28,366 - log/train6.log - INFO - iteration:50 step:5900/10100, NER loss: 0.889810
2019-02-21 19:25:30,546 - log/train6.log - INFO - iteration:50 step:6000/10100, NER loss: 0.834619
2019-02-21 19:25:32,964 - log/train6.log - INFO - iteration:50 step:6100/10100, NER loss: 0.922008
2019-02-21 19:25:35,252 - log/train6.log - INFO - iteration:50 step:6200/10100, NER loss: 0.939251
2019-02-21 19:25:37,455 - log/train6.log - INFO - iteration:50 step:6300/10100, NER loss: 0.900568
2019-02-21 19:25:39,759 - log/train6.log - INFO - iteration:50 step:6400/10100, NER loss: 0.988269
2019-02-21 19:25:42,286 - log/train6.log - INFO - iteration:50 step:6500/10100, NER loss: 1.014995
2019-02-21 19:25:44,699 - log/train6.log - INFO - iteration:50 step:6600/10100, NER loss: 0.990994
2019-02-21 19:25:46,972 - log/train6.log - INFO - iteration:50 step:6700/10100, NER loss: 0.912991
2019-02-21 19:25:49,139 - log/train6.log - INFO - iteration:50 step:6800/10100, NER loss: 0.746976
2019-02-21 19:25:51,399 - log/train6.log - INFO - iteration:50 step:6900/10100, NER loss: 0.930422
2019-02-21 19:25:53,643 - log/train6.log - INFO - iteration:50 step:7000/10100, NER loss: 0.955105
2019-02-21 19:25:55,874 - log/train6.log - INFO - iteration:50 step:7100/10100, NER loss: 0.828728
2019-02-21 19:25:58,101 - log/train6.log - INFO - iteration:50 step:7200/10100, NER loss: 0.917458
2019-02-21 19:26:00,180 - log/train6.log - INFO - iteration:50 step:7300/10100, NER loss: 0.808088
2019-02-21 19:26:02,412 - log/train6.log - INFO - iteration:50 step:7400/10100, NER loss: 0.926504
2019-02-21 19:26:04,823 - log/train6.log - INFO - iteration:50 step:7500/10100, NER loss: 0.897117
2019-02-21 19:26:07,118 - log/train6.log - INFO - iteration:50 step:7600/10100, NER loss: 0.953258
2019-02-21 19:26:09,120 - log/train6.log - INFO - iteration:50 step:7700/10100, NER loss: 0.753468
2019-02-21 19:26:11,297 - log/train6.log - INFO - iteration:50 step:7800/10100, NER loss: 0.914081
2019-02-21 19:26:13,404 - log/train6.log - INFO - iteration:50 step:7900/10100, NER loss: 0.706374
2019-02-21 19:26:17,716 - log/train6.log - INFO - iteration:50 step:8000/10100, NER loss: 1.991021
2019-02-21 19:26:20,580 - log/train6.log - INFO - iteration:50 step:8100/10100, NER loss: 1.274410
2019-02-21 19:26:22,705 - log/train6.log - INFO - iteration:50 step:8200/10100, NER loss: 1.016300
2019-02-21 19:26:25,156 - log/train6.log - INFO - iteration:50 step:8300/10100, NER loss: 1.157938
2019-02-21 19:26:27,292 - log/train6.log - INFO - iteration:50 step:8400/10100, NER loss: 0.878051
2019-02-21 19:26:29,490 - log/train6.log - INFO - iteration:50 step:8500/10100, NER loss: 0.787845
2019-02-21 19:26:31,776 - log/train6.log - INFO - iteration:50 step:8600/10100, NER loss: 0.856008
2019-02-21 19:26:33,858 - log/train6.log - INFO - iteration:50 step:8700/10100, NER loss: 0.803351
2019-02-21 19:26:37,887 - log/train6.log - INFO - iteration:50 step:8800/10100, NER loss: 1.361888
2019-02-21 19:26:40,136 - log/train6.log - INFO - iteration:50 step:8900/10100, NER loss: 1.028913
2019-02-21 19:26:42,405 - log/train6.log - INFO - iteration:50 step:9000/10100, NER loss: 1.027225
2019-02-21 19:26:44,731 - log/train6.log - INFO - iteration:50 step:9100/10100, NER loss: 1.037103
2019-02-21 19:26:46,976 - log/train6.log - INFO - iteration:50 step:9200/10100, NER loss: 0.920371
2019-02-21 19:26:49,161 - log/train6.log - INFO - iteration:50 step:9300/10100, NER loss: 0.858770
2019-02-21 19:26:51,537 - log/train6.log - INFO - iteration:50 step:9400/10100, NER loss: 0.948797
2019-02-21 19:26:53,704 - log/train6.log - INFO - iteration:50 step:9500/10100, NER loss: 1.157695
2019-02-21 19:26:55,938 - log/train6.log - INFO - iteration:50 step:9600/10100, NER loss: 0.790850
2019-02-21 19:26:58,103 - log/train6.log - INFO - iteration:50 step:9700/10100, NER loss: 0.693699
2019-02-21 19:27:00,416 - log/train6.log - INFO - iteration:50 step:9800/10100, NER loss: 0.901730
2019-02-21 19:27:02,800 - log/train6.log - INFO - iteration:50 step:9900/10100, NER loss: 1.235305
2019-02-21 19:27:04,868 - log/train6.log - INFO - iteration:50 step:10000/10100, NER loss: 0.840674
2019-02-21 19:27:06,875 - log/train6.log - INFO - iteration:51 step:0/10100, NER loss: 0.821213
2019-02-21 19:27:06,876 - log/train6.log - INFO - evaluate:dev
2019-02-21 19:27:13,340 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5634 phrases; correct: 4297.

2019-02-21 19:27:13,340 - log/train6.log - INFO - accuracy:  95.07%; precision:  76.27%; recall:  73.49%; FB1:  74.85

2019-02-21 19:27:13,340 - log/train6.log - INFO -                 C: precision:  87.06%; recall:  87.16%; FB1:  87.11  3393

2019-02-21 19:27:13,340 - log/train6.log - INFO -               IND: precision:  46.18%; recall:  29.66%; FB1:  36.12  262

2019-02-21 19:27:13,341 - log/train6.log - INFO -               INS: precision:  66.42%; recall:  72.03%; FB1:  69.11  411

2019-02-21 19:27:13,341 - log/train6.log - INFO -                 L: precision:  52.85%; recall:  51.98%; FB1:  52.41  596

2019-02-21 19:27:13,341 - log/train6.log - INFO -                 P: precision:  86.99%; recall:  91.16%; FB1:  89.03  569

2019-02-21 19:27:13,341 - log/train6.log - INFO -               PRO: precision:  34.49%; recall:  26.63%; FB1:  30.05  403

2019-02-21 19:27:13,344 - log/train6.log - INFO - evaluate:test
2019-02-21 19:27:14,811 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1680 phrases; correct: 1387.

2019-02-21 19:27:14,811 - log/train6.log - INFO - accuracy:  96.75%; precision:  82.56%; recall:  84.21%; FB1:  83.38

2019-02-21 19:27:14,811 - log/train6.log - INFO -                 C: precision:  89.40%; recall:  91.84%; FB1:  90.60  1057

2019-02-21 19:27:14,811 - log/train6.log - INFO -               IND: precision:  51.67%; recall:  65.96%; FB1:  57.94  60

2019-02-21 19:27:14,811 - log/train6.log - INFO -               INS: precision:  67.68%; recall:  70.53%; FB1:  69.07  99

2019-02-21 19:27:14,811 - log/train6.log - INFO -                 L: precision:  56.60%; recall:  58.25%; FB1:  57.42  106

2019-02-21 19:27:14,811 - log/train6.log - INFO -                 P: precision:  89.72%; recall:  94.12%; FB1:  91.87  214

2019-02-21 19:27:14,811 - log/train6.log - INFO -               PRO: precision:  63.89%; recall:  54.44%; FB1:  58.79  144

2019-02-21 19:27:16,770 - log/train6.log - INFO - iteration:51 step:100/10100, NER loss: 1.101186
2019-02-21 19:27:18,521 - log/train6.log - INFO - iteration:51 step:200/10100, NER loss: 0.639219
2019-02-21 19:27:20,848 - log/train6.log - INFO - iteration:51 step:300/10100, NER loss: 1.091120
2019-02-21 19:27:23,235 - log/train6.log - INFO - iteration:51 step:400/10100, NER loss: 0.975611
2019-02-21 19:27:25,538 - log/train6.log - INFO - iteration:51 step:500/10100, NER loss: 0.984651
2019-02-21 19:27:27,717 - log/train6.log - INFO - iteration:51 step:600/10100, NER loss: 0.892868
2019-02-21 19:27:29,938 - log/train6.log - INFO - iteration:51 step:700/10100, NER loss: 0.889579
2019-02-21 19:27:32,276 - log/train6.log - INFO - iteration:51 step:800/10100, NER loss: 1.009567
2019-02-21 19:27:34,526 - log/train6.log - INFO - iteration:51 step:900/10100, NER loss: 0.856750
2019-02-21 19:27:38,506 - log/train6.log - INFO - iteration:51 step:1000/10100, NER loss: 1.133831
2019-02-21 19:27:40,782 - log/train6.log - INFO - iteration:51 step:1100/10100, NER loss: 0.964214
2019-02-21 19:27:42,899 - log/train6.log - INFO - iteration:51 step:1200/10100, NER loss: 0.708656
2019-02-21 19:27:45,182 - log/train6.log - INFO - iteration:51 step:1300/10100, NER loss: 0.917961
2019-02-21 19:27:47,582 - log/train6.log - INFO - iteration:51 step:1400/10100, NER loss: 1.076781
2019-02-21 19:27:49,688 - log/train6.log - INFO - iteration:51 step:1500/10100, NER loss: 0.998026
2019-02-21 19:27:51,835 - log/train6.log - INFO - iteration:51 step:1600/10100, NER loss: 0.712592
2019-02-21 19:27:54,171 - log/train6.log - INFO - iteration:51 step:1700/10100, NER loss: 0.914724
2019-02-21 19:27:56,147 - log/train6.log - INFO - iteration:51 step:1800/10100, NER loss: 0.724465
2019-02-21 19:27:58,423 - log/train6.log - INFO - iteration:51 step:1900/10100, NER loss: 0.845733
2019-02-21 19:28:00,687 - log/train6.log - INFO - iteration:51 step:2000/10100, NER loss: 0.782226
2019-02-21 19:28:02,602 - log/train6.log - INFO - iteration:51 step:2100/10100, NER loss: 0.599755
2019-02-21 19:28:04,643 - log/train6.log - INFO - iteration:51 step:2200/10100, NER loss: 0.924698
2019-02-21 19:28:06,745 - log/train6.log - INFO - iteration:51 step:2300/10100, NER loss: 0.842867
2019-02-21 19:28:09,165 - log/train6.log - INFO - iteration:51 step:2400/10100, NER loss: 0.907435
2019-02-21 19:28:11,342 - log/train6.log - INFO - iteration:51 step:2500/10100, NER loss: 0.886746
2019-02-21 19:28:13,512 - log/train6.log - INFO - iteration:51 step:2600/10100, NER loss: 0.754994
2019-02-21 19:28:15,653 - log/train6.log - INFO - iteration:51 step:2700/10100, NER loss: 0.946367
2019-02-21 19:28:18,015 - log/train6.log - INFO - iteration:51 step:2800/10100, NER loss: 1.312137
2019-02-21 19:28:20,192 - log/train6.log - INFO - iteration:51 step:2900/10100, NER loss: 0.718575
2019-02-21 19:28:22,257 - log/train6.log - INFO - iteration:51 step:3000/10100, NER loss: 0.882283
2019-02-21 19:28:24,352 - log/train6.log - INFO - iteration:51 step:3100/10100, NER loss: 0.888781
2019-02-21 19:28:26,459 - log/train6.log - INFO - iteration:51 step:3200/10100, NER loss: 0.861691
2019-02-21 19:28:28,888 - log/train6.log - INFO - iteration:51 step:3300/10100, NER loss: 1.007974
2019-02-21 19:28:30,955 - log/train6.log - INFO - iteration:51 step:3400/10100, NER loss: 0.805628
2019-02-21 19:28:33,505 - log/train6.log - INFO - iteration:51 step:3500/10100, NER loss: 1.029866
2019-02-21 19:28:35,803 - log/train6.log - INFO - iteration:51 step:3600/10100, NER loss: 0.982638
2019-02-21 19:28:38,062 - log/train6.log - INFO - iteration:51 step:3700/10100, NER loss: 0.917340
2019-02-21 19:28:40,221 - log/train6.log - INFO - iteration:51 step:3800/10100, NER loss: 0.935418
2019-02-21 19:28:42,548 - log/train6.log - INFO - iteration:51 step:3900/10100, NER loss: 0.909808
2019-02-21 19:28:44,686 - log/train6.log - INFO - iteration:51 step:4000/10100, NER loss: 0.897977
2019-02-21 19:28:46,703 - log/train6.log - INFO - iteration:51 step:4100/10100, NER loss: 0.692454
2019-02-21 19:28:48,942 - log/train6.log - INFO - iteration:51 step:4200/10100, NER loss: 0.867344
2019-02-21 19:28:51,056 - log/train6.log - INFO - iteration:51 step:4300/10100, NER loss: 0.970826
2019-02-21 19:28:53,233 - log/train6.log - INFO - iteration:51 step:4400/10100, NER loss: 0.778741
2019-02-21 19:28:55,434 - log/train6.log - INFO - iteration:51 step:4500/10100, NER loss: 0.975149
2019-02-21 19:28:57,529 - log/train6.log - INFO - iteration:51 step:4600/10100, NER loss: 0.905237
2019-02-21 19:28:59,829 - log/train6.log - INFO - iteration:51 step:4700/10100, NER loss: 0.893014
2019-02-21 19:29:01,853 - log/train6.log - INFO - iteration:51 step:4800/10100, NER loss: 0.714330
2019-02-21 19:29:04,010 - log/train6.log - INFO - iteration:51 step:4900/10100, NER loss: 0.838099
2019-02-21 19:29:06,207 - log/train6.log - INFO - iteration:51 step:5000/10100, NER loss: 0.738128
2019-02-21 19:29:08,511 - log/train6.log - INFO - iteration:51 step:5100/10100, NER loss: 0.812400
2019-02-21 19:29:10,599 - log/train6.log - INFO - iteration:51 step:5200/10100, NER loss: 0.824392
2019-02-21 19:29:12,753 - log/train6.log - INFO - iteration:51 step:5300/10100, NER loss: 0.854910
2019-02-21 19:29:15,049 - log/train6.log - INFO - iteration:51 step:5400/10100, NER loss: 0.836366
2019-02-21 19:29:17,587 - log/train6.log - INFO - iteration:51 step:5500/10100, NER loss: 1.031699
2019-02-21 19:29:22,294 - log/train6.log - INFO - iteration:51 step:5600/10100, NER loss: 2.143877
2019-02-21 19:29:24,515 - log/train6.log - INFO - iteration:51 step:5700/10100, NER loss: 1.287648
2019-02-21 19:29:26,866 - log/train6.log - INFO - iteration:51 step:5800/10100, NER loss: 1.107058
2019-02-21 19:29:29,044 - log/train6.log - INFO - iteration:51 step:5900/10100, NER loss: 0.903704
2019-02-21 19:29:31,248 - log/train6.log - INFO - iteration:51 step:6000/10100, NER loss: 0.988654
2019-02-21 19:29:35,839 - log/train6.log - INFO - iteration:51 step:6100/10100, NER loss: 1.980819
2019-02-21 19:29:38,166 - log/train6.log - INFO - iteration:51 step:6200/10100, NER loss: 1.130284
2019-02-21 19:29:40,463 - log/train6.log - INFO - iteration:51 step:6300/10100, NER loss: 0.841159
2019-02-21 19:29:42,614 - log/train6.log - INFO - iteration:51 step:6400/10100, NER loss: 0.980410
2019-02-21 19:29:44,591 - log/train6.log - INFO - iteration:51 step:6500/10100, NER loss: 0.764263
2019-02-21 19:29:47,008 - log/train6.log - INFO - iteration:51 step:6600/10100, NER loss: 1.138763
2019-02-21 19:29:49,109 - log/train6.log - INFO - iteration:51 step:6700/10100, NER loss: 0.861384
2019-02-21 19:29:51,200 - log/train6.log - INFO - iteration:51 step:6800/10100, NER loss: 0.748452
2019-02-21 19:29:53,250 - log/train6.log - INFO - iteration:51 step:6900/10100, NER loss: 0.701068
2019-02-21 19:29:55,552 - log/train6.log - INFO - iteration:51 step:7000/10100, NER loss: 0.849678
2019-02-21 19:29:57,735 - log/train6.log - INFO - iteration:51 step:7100/10100, NER loss: 0.788861
2019-02-21 19:30:00,012 - log/train6.log - INFO - iteration:51 step:7200/10100, NER loss: 1.128170
2019-02-21 19:30:02,438 - log/train6.log - INFO - iteration:51 step:7300/10100, NER loss: 0.896212
2019-02-21 19:30:04,703 - log/train6.log - INFO - iteration:51 step:7400/10100, NER loss: 1.083623
2019-02-21 19:30:06,905 - log/train6.log - INFO - iteration:51 step:7500/10100, NER loss: 1.020754
2019-02-21 19:30:09,003 - log/train6.log - INFO - iteration:51 step:7600/10100, NER loss: 0.718092
2019-02-21 19:30:11,135 - log/train6.log - INFO - iteration:51 step:7700/10100, NER loss: 0.859609
2019-02-21 19:30:13,258 - log/train6.log - INFO - iteration:51 step:7800/10100, NER loss: 0.822864
2019-02-21 19:30:15,634 - log/train6.log - INFO - iteration:51 step:7900/10100, NER loss: 0.963782
2019-02-21 19:30:17,925 - log/train6.log - INFO - iteration:51 step:8000/10100, NER loss: 1.104924
2019-02-21 19:30:20,098 - log/train6.log - INFO - iteration:51 step:8100/10100, NER loss: 0.813728
2019-02-21 19:30:22,142 - log/train6.log - INFO - iteration:51 step:8200/10100, NER loss: 0.720661
2019-02-21 19:30:24,370 - log/train6.log - INFO - iteration:51 step:8300/10100, NER loss: 0.895564
2019-02-21 19:30:26,662 - log/train6.log - INFO - iteration:51 step:8400/10100, NER loss: 0.773528
2019-02-21 19:30:28,733 - log/train6.log - INFO - iteration:51 step:8500/10100, NER loss: 0.768487
2019-02-21 19:30:30,863 - log/train6.log - INFO - iteration:51 step:8600/10100, NER loss: 0.773674
2019-02-21 19:30:33,046 - log/train6.log - INFO - iteration:51 step:8700/10100, NER loss: 0.826880
2019-02-21 19:30:35,411 - log/train6.log - INFO - iteration:51 step:8800/10100, NER loss: 0.973164
2019-02-21 19:30:37,629 - log/train6.log - INFO - iteration:51 step:8900/10100, NER loss: 0.841355
2019-02-21 19:30:39,827 - log/train6.log - INFO - iteration:51 step:9000/10100, NER loss: 0.745506
2019-02-21 19:30:41,979 - log/train6.log - INFO - iteration:51 step:9100/10100, NER loss: 0.830206
2019-02-21 19:30:44,201 - log/train6.log - INFO - iteration:51 step:9200/10100, NER loss: 0.833730
2019-02-21 19:30:46,457 - log/train6.log - INFO - iteration:51 step:9300/10100, NER loss: 0.876486
2019-02-21 19:30:48,595 - log/train6.log - INFO - iteration:51 step:9400/10100, NER loss: 0.859833
2019-02-21 19:30:50,693 - log/train6.log - INFO - iteration:51 step:9500/10100, NER loss: 0.941992
2019-02-21 19:30:52,951 - log/train6.log - INFO - iteration:51 step:9600/10100, NER loss: 0.835696
2019-02-21 19:30:55,359 - log/train6.log - INFO - iteration:51 step:9700/10100, NER loss: 0.968359
2019-02-21 19:30:57,585 - log/train6.log - INFO - iteration:51 step:9800/10100, NER loss: 1.013336
2019-02-21 19:30:59,658 - log/train6.log - INFO - iteration:51 step:9900/10100, NER loss: 0.735268
2019-02-21 19:31:01,864 - log/train6.log - INFO - iteration:51 step:10000/10100, NER loss: 0.992281
2019-02-21 19:31:04,047 - log/train6.log - INFO - iteration:52 step:0/10100, NER loss: 0.816506
2019-02-21 19:31:04,047 - log/train6.log - INFO - evaluate:dev
2019-02-21 19:31:10,521 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5429 phrases; correct: 4249.

2019-02-21 19:31:10,521 - log/train6.log - INFO - accuracy:  95.34%; precision:  78.26%; recall:  72.67%; FB1:  75.36

2019-02-21 19:31:10,522 - log/train6.log - INFO -                 C: precision:  88.43%; recall:  87.05%; FB1:  87.73  3336

2019-02-21 19:31:10,522 - log/train6.log - INFO -               IND: precision:  46.91%; recall:  27.94%; FB1:  35.02  243

2019-02-21 19:31:10,522 - log/train6.log - INFO -               INS: precision:  74.86%; recall:  68.34%; FB1:  71.45  346

2019-02-21 19:31:10,522 - log/train6.log - INFO -                 L: precision:  51.27%; recall:  56.44%; FB1:  53.73  667

2019-02-21 19:31:10,522 - log/train6.log - INFO -                 P: precision:  87.48%; recall:  90.06%; FB1:  88.75  559

2019-02-21 19:31:10,522 - log/train6.log - INFO -               PRO: precision:  34.17%; recall:  18.20%; FB1:  23.75  278

2019-02-21 19:31:10,525 - log/train6.log - INFO - evaluate:test
2019-02-21 19:31:11,990 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1625 phrases; correct: 1373.

2019-02-21 19:31:11,990 - log/train6.log - INFO - accuracy:  97.00%; precision:  84.49%; recall:  83.36%; FB1:  83.92

2019-02-21 19:31:11,990 - log/train6.log - INFO -                 C: precision:  88.72%; recall:  91.74%; FB1:  90.21  1064

2019-02-21 19:31:11,990 - log/train6.log - INFO -               IND: precision:  60.00%; recall:  57.45%; FB1:  58.70  45

2019-02-21 19:31:11,990 - log/train6.log - INFO -               INS: precision:  75.90%; recall:  66.32%; FB1:  70.79  83

2019-02-21 19:31:11,991 - log/train6.log - INFO -                 L: precision:  57.80%; recall:  61.17%; FB1:  59.43  109

2019-02-21 19:31:11,991 - log/train6.log - INFO -                 P: precision:  91.51%; recall:  95.10%; FB1:  93.27  212

2019-02-21 19:31:11,991 - log/train6.log - INFO -               PRO: precision:  73.21%; recall:  48.52%; FB1:  58.36  112

2019-02-21 19:31:13,973 - log/train6.log - INFO - iteration:52 step:100/10100, NER loss: 0.923258
2019-02-21 19:31:15,872 - log/train6.log - INFO - iteration:52 step:200/10100, NER loss: 0.971846
2019-02-21 19:31:18,009 - log/train6.log - INFO - iteration:52 step:300/10100, NER loss: 0.949537
2019-02-21 19:31:20,331 - log/train6.log - INFO - iteration:52 step:400/10100, NER loss: 1.002923
2019-02-21 19:31:24,404 - log/train6.log - INFO - iteration:52 step:500/10100, NER loss: 1.990630
2019-02-21 19:31:26,501 - log/train6.log - INFO - iteration:52 step:600/10100, NER loss: 0.929608
2019-02-21 19:31:28,703 - log/train6.log - INFO - iteration:52 step:700/10100, NER loss: 0.925587
2019-02-21 19:31:30,838 - log/train6.log - INFO - iteration:52 step:800/10100, NER loss: 1.029269
2019-02-21 19:31:32,761 - log/train6.log - INFO - iteration:52 step:900/10100, NER loss: 0.657871
2019-02-21 19:31:34,806 - log/train6.log - INFO - iteration:52 step:1000/10100, NER loss: 0.744772
2019-02-21 19:31:37,098 - log/train6.log - INFO - iteration:52 step:1100/10100, NER loss: 0.929748
2019-02-21 19:31:39,293 - log/train6.log - INFO - iteration:52 step:1200/10100, NER loss: 0.957858
2019-02-21 19:31:41,516 - log/train6.log - INFO - iteration:52 step:1300/10100, NER loss: 0.942644
2019-02-21 19:31:43,724 - log/train6.log - INFO - iteration:52 step:1400/10100, NER loss: 0.907435
2019-02-21 19:31:45,751 - log/train6.log - INFO - iteration:52 step:1500/10100, NER loss: 0.634240
2019-02-21 19:31:47,988 - log/train6.log - INFO - iteration:52 step:1600/10100, NER loss: 0.799186
2019-02-21 19:31:50,358 - log/train6.log - INFO - iteration:52 step:1700/10100, NER loss: 0.899375
2019-02-21 19:31:52,314 - log/train6.log - INFO - iteration:52 step:1800/10100, NER loss: 0.783490
2019-02-21 19:31:54,434 - log/train6.log - INFO - iteration:52 step:1900/10100, NER loss: 0.884578
2019-02-21 19:31:56,839 - log/train6.log - INFO - iteration:52 step:2000/10100, NER loss: 0.916359
2019-02-21 19:31:59,232 - log/train6.log - INFO - iteration:52 step:2100/10100, NER loss: 1.081511
2019-02-21 19:32:01,203 - log/train6.log - INFO - iteration:52 step:2200/10100, NER loss: 0.857295
2019-02-21 19:32:03,448 - log/train6.log - INFO - iteration:52 step:2300/10100, NER loss: 1.004361
2019-02-21 19:32:05,563 - log/train6.log - INFO - iteration:52 step:2400/10100, NER loss: 0.688405
2019-02-21 19:32:07,883 - log/train6.log - INFO - iteration:52 step:2500/10100, NER loss: 0.847539
2019-02-21 19:32:10,099 - log/train6.log - INFO - iteration:52 step:2600/10100, NER loss: 0.889267
2019-02-21 19:32:12,899 - log/train6.log - INFO - iteration:52 step:2700/10100, NER loss: 1.394609
2019-02-21 19:32:15,122 - log/train6.log - INFO - iteration:52 step:2800/10100, NER loss: 1.098705
2019-02-21 19:32:17,456 - log/train6.log - INFO - iteration:52 step:2900/10100, NER loss: 0.919791
2019-02-21 19:32:19,628 - log/train6.log - INFO - iteration:52 step:3000/10100, NER loss: 0.763884
2019-02-21 19:32:21,868 - log/train6.log - INFO - iteration:52 step:3100/10100, NER loss: 0.905328
2019-02-21 19:32:23,963 - log/train6.log - INFO - iteration:52 step:3200/10100, NER loss: 0.905019
2019-02-21 19:32:25,935 - log/train6.log - INFO - iteration:52 step:3300/10100, NER loss: 0.653940
2019-02-21 19:32:28,154 - log/train6.log - INFO - iteration:52 step:3400/10100, NER loss: 0.868483
2019-02-21 19:32:30,781 - log/train6.log - INFO - iteration:52 step:3500/10100, NER loss: 1.088899
2019-02-21 19:32:32,974 - log/train6.log - INFO - iteration:52 step:3600/10100, NER loss: 0.871190
2019-02-21 19:32:35,105 - log/train6.log - INFO - iteration:52 step:3700/10100, NER loss: 0.962355
2019-02-21 19:32:37,374 - log/train6.log - INFO - iteration:52 step:3800/10100, NER loss: 0.929067
2019-02-21 19:32:39,497 - log/train6.log - INFO - iteration:52 step:3900/10100, NER loss: 0.979073
2019-02-21 19:32:41,709 - log/train6.log - INFO - iteration:52 step:4000/10100, NER loss: 0.791845
2019-02-21 19:32:44,028 - log/train6.log - INFO - iteration:52 step:4100/10100, NER loss: 0.964369
2019-02-21 19:32:46,347 - log/train6.log - INFO - iteration:52 step:4200/10100, NER loss: 1.067165
2019-02-21 19:32:50,662 - log/train6.log - INFO - iteration:52 step:4300/10100, NER loss: 1.613858
2019-02-21 19:32:52,994 - log/train6.log - INFO - iteration:52 step:4400/10100, NER loss: 0.816721
2019-02-21 19:32:55,192 - log/train6.log - INFO - iteration:52 step:4500/10100, NER loss: 0.820493
2019-02-21 19:32:57,340 - log/train6.log - INFO - iteration:52 step:4600/10100, NER loss: 0.891089
2019-02-21 19:32:59,475 - log/train6.log - INFO - iteration:52 step:4700/10100, NER loss: 0.840403
2019-02-21 19:33:01,746 - log/train6.log - INFO - iteration:52 step:4800/10100, NER loss: 0.882896
2019-02-21 19:33:03,972 - log/train6.log - INFO - iteration:52 step:4900/10100, NER loss: 0.794526
2019-02-21 19:33:06,081 - log/train6.log - INFO - iteration:52 step:5000/10100, NER loss: 0.775873
2019-02-21 19:33:08,077 - log/train6.log - INFO - iteration:52 step:5100/10100, NER loss: 0.895642
2019-02-21 19:33:10,333 - log/train6.log - INFO - iteration:52 step:5200/10100, NER loss: 1.085832
2019-02-21 19:33:12,657 - log/train6.log - INFO - iteration:52 step:5300/10100, NER loss: 0.941265
2019-02-21 19:33:14,762 - log/train6.log - INFO - iteration:52 step:5400/10100, NER loss: 0.837930
2019-02-21 19:33:16,971 - log/train6.log - INFO - iteration:52 step:5500/10100, NER loss: 0.951435
2019-02-21 19:33:19,272 - log/train6.log - INFO - iteration:52 step:5600/10100, NER loss: 0.972138
2019-02-21 19:33:21,663 - log/train6.log - INFO - iteration:52 step:5700/10100, NER loss: 0.961660
2019-02-21 19:33:23,808 - log/train6.log - INFO - iteration:52 step:5800/10100, NER loss: 0.733164
2019-02-21 19:33:26,026 - log/train6.log - INFO - iteration:52 step:5900/10100, NER loss: 0.738643
2019-02-21 19:33:28,145 - log/train6.log - INFO - iteration:52 step:6000/10100, NER loss: 0.884338
2019-02-21 19:33:30,238 - log/train6.log - INFO - iteration:52 step:6100/10100, NER loss: 0.862689
2019-02-21 19:33:32,403 - log/train6.log - INFO - iteration:52 step:6200/10100, NER loss: 0.822489
2019-02-21 19:33:34,621 - log/train6.log - INFO - iteration:52 step:6300/10100, NER loss: 0.797080
2019-02-21 19:33:38,904 - log/train6.log - INFO - iteration:52 step:6400/10100, NER loss: 1.537929
2019-02-21 19:33:41,145 - log/train6.log - INFO - iteration:52 step:6500/10100, NER loss: 0.985533
2019-02-21 19:33:43,281 - log/train6.log - INFO - iteration:52 step:6600/10100, NER loss: 0.837700
2019-02-21 19:33:45,459 - log/train6.log - INFO - iteration:52 step:6700/10100, NER loss: 0.851638
2019-02-21 19:33:47,708 - log/train6.log - INFO - iteration:52 step:6800/10100, NER loss: 0.946367
2019-02-21 19:33:50,359 - log/train6.log - INFO - iteration:52 step:6900/10100, NER loss: 1.044236
2019-02-21 19:33:52,690 - log/train6.log - INFO - iteration:52 step:7000/10100, NER loss: 0.879146
2019-02-21 19:33:54,820 - log/train6.log - INFO - iteration:52 step:7100/10100, NER loss: 0.795130
2019-02-21 19:33:56,967 - log/train6.log - INFO - iteration:52 step:7200/10100, NER loss: 0.801874
2019-02-21 19:33:58,950 - log/train6.log - INFO - iteration:52 step:7300/10100, NER loss: 0.706896
2019-02-21 19:34:01,228 - log/train6.log - INFO - iteration:52 step:7400/10100, NER loss: 0.880234
2019-02-21 19:34:03,568 - log/train6.log - INFO - iteration:52 step:7500/10100, NER loss: 0.928769
2019-02-21 19:34:05,742 - log/train6.log - INFO - iteration:52 step:7600/10100, NER loss: 0.982661
2019-02-21 19:34:08,210 - log/train6.log - INFO - iteration:52 step:7700/10100, NER loss: 1.093540
2019-02-21 19:34:10,360 - log/train6.log - INFO - iteration:52 step:7800/10100, NER loss: 0.796371
2019-02-21 19:34:12,543 - log/train6.log - INFO - iteration:52 step:7900/10100, NER loss: 1.041606
2019-02-21 19:34:14,748 - log/train6.log - INFO - iteration:52 step:8000/10100, NER loss: 1.019200
2019-02-21 19:34:17,070 - log/train6.log - INFO - iteration:52 step:8100/10100, NER loss: 0.975964
2019-02-21 19:34:19,346 - log/train6.log - INFO - iteration:52 step:8200/10100, NER loss: 0.880800
2019-02-21 19:34:21,721 - log/train6.log - INFO - iteration:52 step:8300/10100, NER loss: 0.944831
2019-02-21 19:34:23,712 - log/train6.log - INFO - iteration:52 step:8400/10100, NER loss: 0.758875
2019-02-21 19:34:25,903 - log/train6.log - INFO - iteration:52 step:8500/10100, NER loss: 1.136437
2019-02-21 19:34:28,298 - log/train6.log - INFO - iteration:52 step:8600/10100, NER loss: 1.015643
2019-02-21 19:34:30,188 - log/train6.log - INFO - iteration:52 step:8700/10100, NER loss: 0.710024
2019-02-21 19:34:32,478 - log/train6.log - INFO - iteration:52 step:8800/10100, NER loss: 0.880293
2019-02-21 19:34:34,626 - log/train6.log - INFO - iteration:52 step:8900/10100, NER loss: 0.840119
2019-02-21 19:34:36,784 - log/train6.log - INFO - iteration:52 step:9000/10100, NER loss: 0.915003
2019-02-21 19:34:39,101 - log/train6.log - INFO - iteration:52 step:9100/10100, NER loss: 1.067980
2019-02-21 19:34:41,353 - log/train6.log - INFO - iteration:52 step:9200/10100, NER loss: 0.828118
2019-02-21 19:34:43,439 - log/train6.log - INFO - iteration:52 step:9300/10100, NER loss: 0.973547
2019-02-21 19:34:45,669 - log/train6.log - INFO - iteration:52 step:9400/10100, NER loss: 0.970685
2019-02-21 19:34:47,806 - log/train6.log - INFO - iteration:52 step:9500/10100, NER loss: 1.003607
2019-02-21 19:34:49,976 - log/train6.log - INFO - iteration:52 step:9600/10100, NER loss: 1.003951
2019-02-21 19:34:52,097 - log/train6.log - INFO - iteration:52 step:9700/10100, NER loss: 0.909373
2019-02-21 19:34:54,148 - log/train6.log - INFO - iteration:52 step:9800/10100, NER loss: 0.776525
2019-02-21 19:34:56,405 - log/train6.log - INFO - iteration:52 step:9900/10100, NER loss: 0.761186
2019-02-21 19:34:58,759 - log/train6.log - INFO - iteration:52 step:10000/10100, NER loss: 1.002772
2019-02-21 19:35:00,977 - log/train6.log - INFO - iteration:53 step:0/10100, NER loss: 1.009915
2019-02-21 19:35:00,977 - log/train6.log - INFO - evaluate:dev
2019-02-21 19:35:07,473 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5585 phrases; correct: 4276.

2019-02-21 19:35:07,474 - log/train6.log - INFO - accuracy:  95.17%; precision:  76.56%; recall:  73.13%; FB1:  74.81

2019-02-21 19:35:07,474 - log/train6.log - INFO -                 C: precision:  87.84%; recall:  86.96%; FB1:  87.40  3355

2019-02-21 19:35:07,474 - log/train6.log - INFO -               IND: precision:  46.09%; recall:  27.45%; FB1:  34.41  243

2019-02-21 19:35:07,474 - log/train6.log - INFO -               INS: precision:  67.41%; recall:  72.03%; FB1:  69.64  405

2019-02-21 19:35:07,474 - log/train6.log - INFO -                 L: precision:  54.01%; recall:  48.84%; FB1:  51.30  548

2019-02-21 19:35:07,474 - log/train6.log - INFO -                 P: precision:  88.21%; recall:  90.98%; FB1:  89.57  560

2019-02-21 19:35:07,474 - log/train6.log - INFO -               PRO: precision:  32.49%; recall:  29.50%; FB1:  30.92  474

2019-02-21 19:35:07,478 - log/train6.log - INFO - evaluate:test
2019-02-21 19:35:08,940 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1668 phrases; correct: 1386.

2019-02-21 19:35:08,940 - log/train6.log - INFO - accuracy:  96.95%; precision:  83.09%; recall:  84.15%; FB1:  83.62

2019-02-21 19:35:08,940 - log/train6.log - INFO -                 C: precision:  88.98%; recall:  91.06%; FB1:  90.01  1053

2019-02-21 19:35:08,940 - log/train6.log - INFO -               IND: precision:  65.96%; recall:  65.96%; FB1:  65.96  47

2019-02-21 19:35:08,940 - log/train6.log - INFO -               INS: precision:  67.03%; recall:  64.21%; FB1:  65.59  91

2019-02-21 19:35:08,940 - log/train6.log - INFO -                 L: precision:  59.18%; recall:  56.31%; FB1:  57.71  98

2019-02-21 19:35:08,940 - log/train6.log - INFO -                 P: precision:  89.77%; recall:  94.61%; FB1:  92.12  215

2019-02-21 19:35:08,940 - log/train6.log - INFO -               PRO: precision:  64.63%; recall:  62.72%; FB1:  63.66  164

2019-02-21 19:35:11,077 - log/train6.log - INFO - iteration:53 step:100/10100, NER loss: 1.075445
2019-02-21 19:35:13,162 - log/train6.log - INFO - iteration:53 step:200/10100, NER loss: 0.972739
2019-02-21 19:35:15,309 - log/train6.log - INFO - iteration:53 step:300/10100, NER loss: 0.758729
2019-02-21 19:35:17,432 - log/train6.log - INFO - iteration:53 step:400/10100, NER loss: 0.732016
2019-02-21 19:35:19,740 - log/train6.log - INFO - iteration:53 step:500/10100, NER loss: 0.884269
2019-02-21 19:35:22,242 - log/train6.log - INFO - iteration:53 step:600/10100, NER loss: 1.093502
2019-02-21 19:35:24,442 - log/train6.log - INFO - iteration:53 step:700/10100, NER loss: 0.982579
2019-02-21 19:35:26,781 - log/train6.log - INFO - iteration:53 step:800/10100, NER loss: 1.081525
2019-02-21 19:35:28,966 - log/train6.log - INFO - iteration:53 step:900/10100, NER loss: 0.759760
2019-02-21 19:35:31,133 - log/train6.log - INFO - iteration:53 step:1000/10100, NER loss: 0.774353
2019-02-21 19:35:33,194 - log/train6.log - INFO - iteration:53 step:1100/10100, NER loss: 0.824727
2019-02-21 19:35:35,275 - log/train6.log - INFO - iteration:53 step:1200/10100, NER loss: 0.734958
2019-02-21 19:35:37,297 - log/train6.log - INFO - iteration:53 step:1300/10100, NER loss: 0.864947
2019-02-21 19:35:39,490 - log/train6.log - INFO - iteration:53 step:1400/10100, NER loss: 0.803957
2019-02-21 19:35:41,806 - log/train6.log - INFO - iteration:53 step:1500/10100, NER loss: 0.863616
2019-02-21 19:35:43,934 - log/train6.log - INFO - iteration:53 step:1600/10100, NER loss: 0.770686
2019-02-21 19:35:46,064 - log/train6.log - INFO - iteration:53 step:1700/10100, NER loss: 0.769098
2019-02-21 19:35:48,181 - log/train6.log - INFO - iteration:53 step:1800/10100, NER loss: 0.854025
2019-02-21 19:35:50,239 - log/train6.log - INFO - iteration:53 step:1900/10100, NER loss: 0.882135
2019-02-21 19:35:52,328 - log/train6.log - INFO - iteration:53 step:2000/10100, NER loss: 0.925250
2019-02-21 19:35:54,733 - log/train6.log - INFO - iteration:53 step:2100/10100, NER loss: 1.050461
2019-02-21 19:35:57,009 - log/train6.log - INFO - iteration:53 step:2200/10100, NER loss: 1.252369
2019-02-21 19:35:59,188 - log/train6.log - INFO - iteration:53 step:2300/10100, NER loss: 0.948495
2019-02-21 19:36:01,543 - log/train6.log - INFO - iteration:53 step:2400/10100, NER loss: 1.067411
2019-02-21 19:36:03,742 - log/train6.log - INFO - iteration:53 step:2500/10100, NER loss: 0.808305
2019-02-21 19:36:06,050 - log/train6.log - INFO - iteration:53 step:2600/10100, NER loss: 0.978255
2019-02-21 19:36:08,248 - log/train6.log - INFO - iteration:53 step:2700/10100, NER loss: 0.833449
2019-02-21 19:36:10,446 - log/train6.log - INFO - iteration:53 step:2800/10100, NER loss: 0.781100
2019-02-21 19:36:12,696 - log/train6.log - INFO - iteration:53 step:2900/10100, NER loss: 0.995411
2019-02-21 19:36:14,785 - log/train6.log - INFO - iteration:53 step:3000/10100, NER loss: 0.822606
2019-02-21 19:36:16,964 - log/train6.log - INFO - iteration:53 step:3100/10100, NER loss: 0.921275
2019-02-21 19:36:19,299 - log/train6.log - INFO - iteration:53 step:3200/10100, NER loss: 0.920175
2019-02-21 19:36:21,408 - log/train6.log - INFO - iteration:53 step:3300/10100, NER loss: 0.827889
2019-02-21 19:36:23,342 - log/train6.log - INFO - iteration:53 step:3400/10100, NER loss: 0.732195
2019-02-21 19:36:25,529 - log/train6.log - INFO - iteration:53 step:3500/10100, NER loss: 0.918106
2019-02-21 19:36:28,121 - log/train6.log - INFO - iteration:53 step:3600/10100, NER loss: 1.148747
2019-02-21 19:36:30,293 - log/train6.log - INFO - iteration:53 step:3700/10100, NER loss: 0.937616
2019-02-21 19:36:32,337 - log/train6.log - INFO - iteration:53 step:3800/10100, NER loss: 0.783365
2019-02-21 19:36:34,615 - log/train6.log - INFO - iteration:53 step:3900/10100, NER loss: 1.029111
2019-02-21 19:36:37,027 - log/train6.log - INFO - iteration:53 step:4000/10100, NER loss: 0.917393
2019-02-21 19:36:39,319 - log/train6.log - INFO - iteration:53 step:4100/10100, NER loss: 0.852203
2019-02-21 19:36:41,446 - log/train6.log - INFO - iteration:53 step:4200/10100, NER loss: 0.748530
2019-02-21 19:36:43,686 - log/train6.log - INFO - iteration:53 step:4300/10100, NER loss: 0.816332
2019-02-21 19:36:45,905 - log/train6.log - INFO - iteration:53 step:4400/10100, NER loss: 0.895692
2019-02-21 19:36:48,071 - log/train6.log - INFO - iteration:53 step:4500/10100, NER loss: 1.012072
2019-02-21 19:36:50,478 - log/train6.log - INFO - iteration:53 step:4600/10100, NER loss: 0.938488
2019-02-21 19:36:52,780 - log/train6.log - INFO - iteration:53 step:4700/10100, NER loss: 0.924880
2019-02-21 19:36:54,997 - log/train6.log - INFO - iteration:53 step:4800/10100, NER loss: 0.952490
2019-02-21 19:36:57,155 - log/train6.log - INFO - iteration:53 step:4900/10100, NER loss: 0.877982
2019-02-21 19:36:59,415 - log/train6.log - INFO - iteration:53 step:5000/10100, NER loss: 0.834017
2019-02-21 19:37:01,388 - log/train6.log - INFO - iteration:53 step:5100/10100, NER loss: 0.662327
2019-02-21 19:37:03,659 - log/train6.log - INFO - iteration:53 step:5200/10100, NER loss: 0.832642
2019-02-21 19:37:05,662 - log/train6.log - INFO - iteration:53 step:5300/10100, NER loss: 0.861011
2019-02-21 19:37:07,925 - log/train6.log - INFO - iteration:53 step:5400/10100, NER loss: 0.936545
2019-02-21 19:37:10,209 - log/train6.log - INFO - iteration:53 step:5500/10100, NER loss: 0.861853
2019-02-21 19:37:12,406 - log/train6.log - INFO - iteration:53 step:5600/10100, NER loss: 0.800820
2019-02-21 19:37:14,681 - log/train6.log - INFO - iteration:53 step:5700/10100, NER loss: 0.836503
2019-02-21 19:37:16,762 - log/train6.log - INFO - iteration:53 step:5800/10100, NER loss: 0.782496
2019-02-21 19:37:19,027 - log/train6.log - INFO - iteration:53 step:5900/10100, NER loss: 1.035848
2019-02-21 19:37:21,412 - log/train6.log - INFO - iteration:53 step:6000/10100, NER loss: 0.958687
2019-02-21 19:37:23,545 - log/train6.log - INFO - iteration:53 step:6100/10100, NER loss: 0.938200
2019-02-21 19:37:25,820 - log/train6.log - INFO - iteration:53 step:6200/10100, NER loss: 0.975187
2019-02-21 19:37:27,923 - log/train6.log - INFO - iteration:53 step:6300/10100, NER loss: 0.779669
2019-02-21 19:37:30,030 - log/train6.log - INFO - iteration:53 step:6400/10100, NER loss: 0.780020
2019-02-21 19:37:32,023 - log/train6.log - INFO - iteration:53 step:6500/10100, NER loss: 0.894663
2019-02-21 19:37:34,040 - log/train6.log - INFO - iteration:53 step:6600/10100, NER loss: 0.811574
2019-02-21 19:37:36,332 - log/train6.log - INFO - iteration:53 step:6700/10100, NER loss: 0.959886
2019-02-21 19:37:38,628 - log/train6.log - INFO - iteration:53 step:6800/10100, NER loss: 0.851290
2019-02-21 19:37:40,982 - log/train6.log - INFO - iteration:53 step:6900/10100, NER loss: 0.941145
2019-02-21 19:37:43,231 - log/train6.log - INFO - iteration:53 step:7000/10100, NER loss: 0.984943
2019-02-21 19:37:45,314 - log/train6.log - INFO - iteration:53 step:7100/10100, NER loss: 0.799743
2019-02-21 19:37:47,374 - log/train6.log - INFO - iteration:53 step:7200/10100, NER loss: 0.757484
2019-02-21 19:37:49,639 - log/train6.log - INFO - iteration:53 step:7300/10100, NER loss: 0.889117
2019-02-21 19:37:51,727 - log/train6.log - INFO - iteration:53 step:7400/10100, NER loss: 0.794865
2019-02-21 19:37:53,847 - log/train6.log - INFO - iteration:53 step:7500/10100, NER loss: 0.804090
2019-02-21 19:37:56,221 - log/train6.log - INFO - iteration:53 step:7600/10100, NER loss: 1.068430
2019-02-21 19:37:58,413 - log/train6.log - INFO - iteration:53 step:7700/10100, NER loss: 0.833102
2019-02-21 19:38:00,472 - log/train6.log - INFO - iteration:53 step:7800/10100, NER loss: 0.763296
2019-02-21 19:38:04,528 - log/train6.log - INFO - iteration:53 step:7900/10100, NER loss: 1.251709
2019-02-21 19:38:06,783 - log/train6.log - INFO - iteration:53 step:8000/10100, NER loss: 0.835557
2019-02-21 19:38:08,881 - log/train6.log - INFO - iteration:53 step:8100/10100, NER loss: 0.784182
2019-02-21 19:38:11,042 - log/train6.log - INFO - iteration:53 step:8200/10100, NER loss: 0.944928
2019-02-21 19:38:13,358 - log/train6.log - INFO - iteration:53 step:8300/10100, NER loss: 0.871775
2019-02-21 19:38:15,589 - log/train6.log - INFO - iteration:53 step:8400/10100, NER loss: 0.822442
2019-02-21 19:38:17,872 - log/train6.log - INFO - iteration:53 step:8500/10100, NER loss: 1.006198
2019-02-21 19:38:20,213 - log/train6.log - INFO - iteration:53 step:8600/10100, NER loss: 0.908391
2019-02-21 19:38:24,649 - log/train6.log - INFO - iteration:53 step:8700/10100, NER loss: 1.772782
2019-02-21 19:38:26,798 - log/train6.log - INFO - iteration:53 step:8800/10100, NER loss: 0.859025
2019-02-21 19:38:29,166 - log/train6.log - INFO - iteration:53 step:8900/10100, NER loss: 1.205613
2019-02-21 19:38:31,453 - log/train6.log - INFO - iteration:53 step:9000/10100, NER loss: 1.071864
2019-02-21 19:38:33,607 - log/train6.log - INFO - iteration:53 step:9100/10100, NER loss: 0.878688
2019-02-21 19:38:35,795 - log/train6.log - INFO - iteration:53 step:9200/10100, NER loss: 0.779210
2019-02-21 19:38:37,975 - log/train6.log - INFO - iteration:53 step:9300/10100, NER loss: 0.843516
2019-02-21 19:38:40,296 - log/train6.log - INFO - iteration:53 step:9400/10100, NER loss: 0.855070
2019-02-21 19:38:42,649 - log/train6.log - INFO - iteration:53 step:9500/10100, NER loss: 1.054271
2019-02-21 19:38:44,968 - log/train6.log - INFO - iteration:53 step:9600/10100, NER loss: 1.050608
2019-02-21 19:38:47,147 - log/train6.log - INFO - iteration:53 step:9700/10100, NER loss: 0.888421
2019-02-21 19:38:51,244 - log/train6.log - INFO - iteration:53 step:9800/10100, NER loss: 2.328728
2019-02-21 19:38:53,819 - log/train6.log - INFO - iteration:53 step:9900/10100, NER loss: 1.284087
2019-02-21 19:38:55,959 - log/train6.log - INFO - iteration:53 step:10000/10100, NER loss: 0.785699
2019-02-21 19:38:58,081 - log/train6.log - INFO - iteration:54 step:0/10100, NER loss: 0.824313
2019-02-21 19:38:58,081 - log/train6.log - INFO - evaluate:dev
2019-02-21 19:39:04,540 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5582 phrases; correct: 4332.

2019-02-21 19:39:04,541 - log/train6.log - INFO - accuracy:  95.42%; precision:  77.61%; recall:  74.09%; FB1:  75.81

2019-02-21 19:39:04,541 - log/train6.log - INFO -                 C: precision:  87.08%; recall:  88.70%; FB1:  87.88  3452

2019-02-21 19:39:04,541 - log/train6.log - INFO -               IND: precision:  50.00%; recall:  25.49%; FB1:  33.77  208

2019-02-21 19:39:04,541 - log/train6.log - INFO -               INS: precision:  69.95%; recall:  71.24%; FB1:  70.59  386

2019-02-21 19:39:04,541 - log/train6.log - INFO -                 L: precision:  53.66%; recall:  51.98%; FB1:  52.81  587

2019-02-21 19:39:04,541 - log/train6.log - INFO -                 P: precision:  87.23%; recall:  89.32%; FB1:  88.26  556

2019-02-21 19:39:04,541 - log/train6.log - INFO -               PRO: precision:  38.68%; recall:  29.12%; FB1:  33.22  393

2019-02-21 19:39:04,544 - log/train6.log - INFO - evaluate:test
2019-02-21 19:39:06,019 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1656 phrases; correct: 1385.

2019-02-21 19:39:06,019 - log/train6.log - INFO - accuracy:  96.83%; precision:  83.64%; recall:  84.09%; FB1:  83.86

2019-02-21 19:39:06,019 - log/train6.log - INFO -                 C: precision:  88.13%; recall:  91.64%; FB1:  89.85  1070

2019-02-21 19:39:06,020 - log/train6.log - INFO -               IND: precision:  65.12%; recall:  59.57%; FB1:  62.22  43

2019-02-21 19:39:06,020 - log/train6.log - INFO -               INS: precision:  70.33%; recall:  67.37%; FB1:  68.82  91

2019-02-21 19:39:06,020 - log/train6.log - INFO -                 L: precision:  59.05%; recall:  60.19%; FB1:  59.62  105

2019-02-21 19:39:06,020 - log/train6.log - INFO -                 P: precision:  91.94%; recall:  95.10%; FB1:  93.49  211

2019-02-21 19:39:06,020 - log/train6.log - INFO -               PRO: precision:  69.12%; recall:  55.62%; FB1:  61.64  136

2019-02-21 19:39:08,068 - log/train6.log - INFO - iteration:54 step:100/10100, NER loss: 0.907363
2019-02-21 19:39:10,140 - log/train6.log - INFO - iteration:54 step:200/10100, NER loss: 0.845164
2019-02-21 19:39:12,363 - log/train6.log - INFO - iteration:54 step:300/10100, NER loss: 0.836739
2019-02-21 19:39:14,669 - log/train6.log - INFO - iteration:54 step:400/10100, NER loss: 0.834445
2019-02-21 19:39:16,686 - log/train6.log - INFO - iteration:54 step:500/10100, NER loss: 0.687862
2019-02-21 19:39:18,817 - log/train6.log - INFO - iteration:54 step:600/10100, NER loss: 0.766887
2019-02-21 19:39:21,128 - log/train6.log - INFO - iteration:54 step:700/10100, NER loss: 0.904075
2019-02-21 19:39:23,453 - log/train6.log - INFO - iteration:54 step:800/10100, NER loss: 0.914408
2019-02-21 19:39:25,688 - log/train6.log - INFO - iteration:54 step:900/10100, NER loss: 0.856668
2019-02-21 19:39:28,391 - log/train6.log - INFO - iteration:54 step:1000/10100, NER loss: 1.335853
2019-02-21 19:39:30,394 - log/train6.log - INFO - iteration:54 step:1100/10100, NER loss: 0.729320
2019-02-21 19:39:32,266 - log/train6.log - INFO - iteration:54 step:1200/10100, NER loss: 0.712787
2019-02-21 19:39:34,428 - log/train6.log - INFO - iteration:54 step:1300/10100, NER loss: 0.864916
2019-02-21 19:39:36,835 - log/train6.log - INFO - iteration:54 step:1400/10100, NER loss: 0.959159
2019-02-21 19:39:38,904 - log/train6.log - INFO - iteration:54 step:1500/10100, NER loss: 0.631205
2019-02-21 19:39:40,967 - log/train6.log - INFO - iteration:54 step:1600/10100, NER loss: 0.736153
2019-02-21 19:39:43,153 - log/train6.log - INFO - iteration:54 step:1700/10100, NER loss: 0.979788
2019-02-21 19:39:45,115 - log/train6.log - INFO - iteration:54 step:1800/10100, NER loss: 0.696702
2019-02-21 19:39:47,113 - log/train6.log - INFO - iteration:54 step:1900/10100, NER loss: 0.766850
2019-02-21 19:39:49,309 - log/train6.log - INFO - iteration:54 step:2000/10100, NER loss: 1.063262
2019-02-21 19:39:51,834 - log/train6.log - INFO - iteration:54 step:2100/10100, NER loss: 1.239401
2019-02-21 19:39:55,744 - log/train6.log - INFO - iteration:54 step:2200/10100, NER loss: 1.797311
2019-02-21 19:39:57,762 - log/train6.log - INFO - iteration:54 step:2300/10100, NER loss: 0.785913
2019-02-21 19:40:00,051 - log/train6.log - INFO - iteration:54 step:2400/10100, NER loss: 0.799210
2019-02-21 19:40:02,357 - log/train6.log - INFO - iteration:54 step:2500/10100, NER loss: 0.964478
2019-02-21 19:40:04,813 - log/train6.log - INFO - iteration:54 step:2600/10100, NER loss: 0.986104
2019-02-21 19:40:07,123 - log/train6.log - INFO - iteration:54 step:2700/10100, NER loss: 0.858699
2019-02-21 19:40:09,492 - log/train6.log - INFO - iteration:54 step:2800/10100, NER loss: 1.053205
2019-02-21 19:40:11,476 - log/train6.log - INFO - iteration:54 step:2900/10100, NER loss: 0.774451
2019-02-21 19:40:13,705 - log/train6.log - INFO - iteration:54 step:3000/10100, NER loss: 0.957868
2019-02-21 19:40:15,820 - log/train6.log - INFO - iteration:54 step:3100/10100, NER loss: 0.785850
2019-02-21 19:40:18,111 - log/train6.log - INFO - iteration:54 step:3200/10100, NER loss: 0.958174
2019-02-21 19:40:20,401 - log/train6.log - INFO - iteration:54 step:3300/10100, NER loss: 0.868188
2019-02-21 19:40:22,750 - log/train6.log - INFO - iteration:54 step:3400/10100, NER loss: 0.980092
2019-02-21 19:40:25,051 - log/train6.log - INFO - iteration:54 step:3500/10100, NER loss: 0.926243
2019-02-21 19:40:27,137 - log/train6.log - INFO - iteration:54 step:3600/10100, NER loss: 0.893752
2019-02-21 19:40:29,212 - log/train6.log - INFO - iteration:54 step:3700/10100, NER loss: 0.929673
2019-02-21 19:40:31,384 - log/train6.log - INFO - iteration:54 step:3800/10100, NER loss: 0.733224
2019-02-21 19:40:33,419 - log/train6.log - INFO - iteration:54 step:3900/10100, NER loss: 0.739747
2019-02-21 19:40:35,498 - log/train6.log - INFO - iteration:54 step:4000/10100, NER loss: 1.032703
2019-02-21 19:40:37,805 - log/train6.log - INFO - iteration:54 step:4100/10100, NER loss: 0.914477
2019-02-21 19:40:39,981 - log/train6.log - INFO - iteration:54 step:4200/10100, NER loss: 0.884590
2019-02-21 19:40:42,403 - log/train6.log - INFO - iteration:54 step:4300/10100, NER loss: 1.404865
2019-02-21 19:40:44,557 - log/train6.log - INFO - iteration:54 step:4400/10100, NER loss: 0.803919
2019-02-21 19:40:49,090 - log/train6.log - INFO - iteration:54 step:4500/10100, NER loss: 2.018329
2019-02-21 19:40:51,498 - log/train6.log - INFO - iteration:54 step:4600/10100, NER loss: 1.294847
2019-02-21 19:40:53,694 - log/train6.log - INFO - iteration:54 step:4700/10100, NER loss: 0.795031
2019-02-21 19:40:55,794 - log/train6.log - INFO - iteration:54 step:4800/10100, NER loss: 0.842012
2019-02-21 19:40:58,094 - log/train6.log - INFO - iteration:54 step:4900/10100, NER loss: 1.091709
2019-02-21 19:41:00,131 - log/train6.log - INFO - iteration:54 step:5000/10100, NER loss: 0.683732
2019-02-21 19:41:02,458 - log/train6.log - INFO - iteration:54 step:5100/10100, NER loss: 0.963847
2019-02-21 19:41:04,926 - log/train6.log - INFO - iteration:54 step:5200/10100, NER loss: 1.149641
2019-02-21 19:41:07,198 - log/train6.log - INFO - iteration:54 step:5300/10100, NER loss: 0.969186
2019-02-21 19:41:09,537 - log/train6.log - INFO - iteration:54 step:5400/10100, NER loss: 1.055627
2019-02-21 19:41:11,673 - log/train6.log - INFO - iteration:54 step:5500/10100, NER loss: 0.907655
2019-02-21 19:41:14,041 - log/train6.log - INFO - iteration:54 step:5600/10100, NER loss: 0.880541
2019-02-21 19:41:16,304 - log/train6.log - INFO - iteration:54 step:5700/10100, NER loss: 0.835496
2019-02-21 19:41:18,449 - log/train6.log - INFO - iteration:54 step:5800/10100, NER loss: 0.760246
2019-02-21 19:41:20,628 - log/train6.log - INFO - iteration:54 step:5900/10100, NER loss: 0.695283
2019-02-21 19:41:22,888 - log/train6.log - INFO - iteration:54 step:6000/10100, NER loss: 1.010543
2019-02-21 19:41:25,081 - log/train6.log - INFO - iteration:54 step:6100/10100, NER loss: 0.791016
2019-02-21 19:41:27,590 - log/train6.log - INFO - iteration:54 step:6200/10100, NER loss: 0.987027
2019-02-21 19:41:29,553 - log/train6.log - INFO - iteration:54 step:6300/10100, NER loss: 0.734291
2019-02-21 19:41:31,880 - log/train6.log - INFO - iteration:54 step:6400/10100, NER loss: 0.870773
2019-02-21 19:41:34,017 - log/train6.log - INFO - iteration:54 step:6500/10100, NER loss: 0.841021
2019-02-21 19:41:36,488 - log/train6.log - INFO - iteration:54 step:6600/10100, NER loss: 0.971676
2019-02-21 19:41:38,715 - log/train6.log - INFO - iteration:54 step:6700/10100, NER loss: 0.772079
2019-02-21 19:41:40,831 - log/train6.log - INFO - iteration:54 step:6800/10100, NER loss: 0.891225
2019-02-21 19:41:42,959 - log/train6.log - INFO - iteration:54 step:6900/10100, NER loss: 1.021461
2019-02-21 19:41:45,118 - log/train6.log - INFO - iteration:54 step:7000/10100, NER loss: 0.798031
2019-02-21 19:41:47,245 - log/train6.log - INFO - iteration:54 step:7100/10100, NER loss: 0.752354
2019-02-21 19:41:49,320 - log/train6.log - INFO - iteration:54 step:7200/10100, NER loss: 0.999475
2019-02-21 19:41:51,582 - log/train6.log - INFO - iteration:54 step:7300/10100, NER loss: 0.834955
2019-02-21 19:41:53,851 - log/train6.log - INFO - iteration:54 step:7400/10100, NER loss: 0.860854
2019-02-21 19:41:56,175 - log/train6.log - INFO - iteration:54 step:7500/10100, NER loss: 1.004515
2019-02-21 19:41:58,710 - log/train6.log - INFO - iteration:54 step:7600/10100, NER loss: 1.005548
2019-02-21 19:42:00,978 - log/train6.log - INFO - iteration:54 step:7700/10100, NER loss: 0.799201
2019-02-21 19:42:03,265 - log/train6.log - INFO - iteration:54 step:7800/10100, NER loss: 1.017817
2019-02-21 19:42:05,327 - log/train6.log - INFO - iteration:54 step:7900/10100, NER loss: 0.897882
2019-02-21 19:42:07,409 - log/train6.log - INFO - iteration:54 step:8000/10100, NER loss: 0.763715
2019-02-21 19:42:09,714 - log/train6.log - INFO - iteration:54 step:8100/10100, NER loss: 0.890504
2019-02-21 19:42:11,936 - log/train6.log - INFO - iteration:54 step:8200/10100, NER loss: 0.938119
2019-02-21 19:42:14,053 - log/train6.log - INFO - iteration:54 step:8300/10100, NER loss: 0.749513
2019-02-21 19:42:16,253 - log/train6.log - INFO - iteration:54 step:8400/10100, NER loss: 0.889205
2019-02-21 19:42:18,501 - log/train6.log - INFO - iteration:54 step:8500/10100, NER loss: 0.735055
2019-02-21 19:42:20,543 - log/train6.log - INFO - iteration:54 step:8600/10100, NER loss: 0.794904
2019-02-21 19:42:22,673 - log/train6.log - INFO - iteration:54 step:8700/10100, NER loss: 0.833742
2019-02-21 19:42:24,744 - log/train6.log - INFO - iteration:54 step:8800/10100, NER loss: 0.696394
2019-02-21 19:42:26,989 - log/train6.log - INFO - iteration:54 step:8900/10100, NER loss: 0.954667
2019-02-21 19:42:29,186 - log/train6.log - INFO - iteration:54 step:9000/10100, NER loss: 0.951743
2019-02-21 19:42:31,380 - log/train6.log - INFO - iteration:54 step:9100/10100, NER loss: 1.084323
2019-02-21 19:42:33,604 - log/train6.log - INFO - iteration:54 step:9200/10100, NER loss: 1.013662
2019-02-21 19:42:35,829 - log/train6.log - INFO - iteration:54 step:9300/10100, NER loss: 0.924229
2019-02-21 19:42:37,843 - log/train6.log - INFO - iteration:54 step:9400/10100, NER loss: 0.737861
2019-02-21 19:42:39,949 - log/train6.log - INFO - iteration:54 step:9500/10100, NER loss: 0.804410
2019-02-21 19:42:42,300 - log/train6.log - INFO - iteration:54 step:9600/10100, NER loss: 0.903961
2019-02-21 19:42:46,382 - log/train6.log - INFO - iteration:54 step:9700/10100, NER loss: 1.308371
2019-02-21 19:42:48,310 - log/train6.log - INFO - iteration:54 step:9800/10100, NER loss: 0.786337
2019-02-21 19:42:50,547 - log/train6.log - INFO - iteration:54 step:9900/10100, NER loss: 0.857008
2019-02-21 19:42:52,721 - log/train6.log - INFO - iteration:54 step:10000/10100, NER loss: 0.980294
2019-02-21 19:42:54,927 - log/train6.log - INFO - iteration:55 step:0/10100, NER loss: 0.811171
2019-02-21 19:42:54,928 - log/train6.log - INFO - evaluate:dev
2019-02-21 19:43:01,445 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5467 phrases; correct: 4234.

2019-02-21 19:43:01,445 - log/train6.log - INFO - accuracy:  95.23%; precision:  77.45%; recall:  72.41%; FB1:  74.85

2019-02-21 19:43:01,445 - log/train6.log - INFO -                 C: precision:  87.72%; recall:  87.05%; FB1:  87.38  3363

2019-02-21 19:43:01,445 - log/train6.log - INFO -               IND: precision:  39.93%; recall:  29.66%; FB1:  34.04  303

2019-02-21 19:43:01,445 - log/train6.log - INFO -               INS: precision:  63.82%; recall:  73.09%; FB1:  68.14  434

2019-02-21 19:43:01,445 - log/train6.log - INFO -                 L: precision:  55.36%; recall:  47.69%; FB1:  51.24  522

2019-02-21 19:43:01,446 - log/train6.log - INFO -                 P: precision:  88.51%; recall:  90.79%; FB1:  89.64  557

2019-02-21 19:43:01,446 - log/train6.log - INFO -               PRO: precision:  36.11%; recall:  19.92%; FB1:  25.68  288

2019-02-21 19:43:01,448 - log/train6.log - INFO - evaluate:test
2019-02-21 19:43:02,914 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1615 phrases; correct: 1368.

2019-02-21 19:43:02,915 - log/train6.log - INFO - accuracy:  96.83%; precision:  84.71%; recall:  83.06%; FB1:  83.87

2019-02-21 19:43:02,915 - log/train6.log - INFO -                 C: precision:  90.09%; recall:  90.96%; FB1:  90.52  1039

2019-02-21 19:43:02,915 - log/train6.log - INFO -               IND: precision:  50.00%; recall:  63.83%; FB1:  56.07  60

2019-02-21 19:43:02,915 - log/train6.log - INFO -               INS: precision:  64.49%; recall:  72.63%; FB1:  68.32  107

2019-02-21 19:43:02,915 - log/train6.log - INFO -                 L: precision:  62.89%; recall:  59.22%; FB1:  61.00  97

2019-02-21 19:43:02,915 - log/train6.log - INFO -                 P: precision:  91.90%; recall:  94.61%; FB1:  93.24  210

2019-02-21 19:43:02,915 - log/train6.log - INFO -               PRO: precision:  77.45%; recall:  46.75%; FB1:  58.30  102

2019-02-21 19:43:04,994 - log/train6.log - INFO - iteration:55 step:100/10100, NER loss: 0.918485
2019-02-21 19:43:06,916 - log/train6.log - INFO - iteration:55 step:200/10100, NER loss: 0.651999
2019-02-21 19:43:09,039 - log/train6.log - INFO - iteration:55 step:300/10100, NER loss: 0.842485
2019-02-21 19:43:11,293 - log/train6.log - INFO - iteration:55 step:400/10100, NER loss: 1.199340
2019-02-21 19:43:13,513 - log/train6.log - INFO - iteration:55 step:500/10100, NER loss: 0.751329
2019-02-21 19:43:15,762 - log/train6.log - INFO - iteration:55 step:600/10100, NER loss: 0.802527
2019-02-21 19:43:17,932 - log/train6.log - INFO - iteration:55 step:700/10100, NER loss: 0.793663
2019-02-21 19:43:20,105 - log/train6.log - INFO - iteration:55 step:800/10100, NER loss: 0.755304
2019-02-21 19:43:22,291 - log/train6.log - INFO - iteration:55 step:900/10100, NER loss: 0.884365
2019-02-21 19:43:24,437 - log/train6.log - INFO - iteration:55 step:1000/10100, NER loss: 0.644251
2019-02-21 19:43:26,759 - log/train6.log - INFO - iteration:55 step:1100/10100, NER loss: 0.966603
2019-02-21 19:43:29,157 - log/train6.log - INFO - iteration:55 step:1200/10100, NER loss: 1.136570
2019-02-21 19:43:31,194 - log/train6.log - INFO - iteration:55 step:1300/10100, NER loss: 0.719126
2019-02-21 19:43:33,287 - log/train6.log - INFO - iteration:55 step:1400/10100, NER loss: 0.822950
2019-02-21 19:43:35,636 - log/train6.log - INFO - iteration:55 step:1500/10100, NER loss: 1.026096
2019-02-21 19:43:37,919 - log/train6.log - INFO - iteration:55 step:1600/10100, NER loss: 0.903351
2019-02-21 19:43:39,844 - log/train6.log - INFO - iteration:55 step:1700/10100, NER loss: 0.802653
2019-02-21 19:43:42,107 - log/train6.log - INFO - iteration:55 step:1800/10100, NER loss: 0.913000
2019-02-21 19:43:44,261 - log/train6.log - INFO - iteration:55 step:1900/10100, NER loss: 0.895606
2019-02-21 19:43:46,644 - log/train6.log - INFO - iteration:55 step:2000/10100, NER loss: 0.973133
2019-02-21 19:43:48,934 - log/train6.log - INFO - iteration:55 step:2100/10100, NER loss: 0.829823
2019-02-21 19:43:50,984 - log/train6.log - INFO - iteration:55 step:2200/10100, NER loss: 0.685457
2019-02-21 19:43:53,256 - log/train6.log - INFO - iteration:55 step:2300/10100, NER loss: 1.008061
2019-02-21 19:43:55,544 - log/train6.log - INFO - iteration:55 step:2400/10100, NER loss: 0.826653
2019-02-21 19:43:57,743 - log/train6.log - INFO - iteration:55 step:2500/10100, NER loss: 0.932881
2019-02-21 19:43:59,905 - log/train6.log - INFO - iteration:55 step:2600/10100, NER loss: 0.807645
2019-02-21 19:44:02,171 - log/train6.log - INFO - iteration:55 step:2700/10100, NER loss: 0.820582
2019-02-21 19:44:04,429 - log/train6.log - INFO - iteration:55 step:2800/10100, NER loss: 0.822345
2019-02-21 19:44:06,873 - log/train6.log - INFO - iteration:55 step:2900/10100, NER loss: 1.157205
2019-02-21 19:44:09,307 - log/train6.log - INFO - iteration:55 step:3000/10100, NER loss: 0.961739
2019-02-21 19:44:11,494 - log/train6.log - INFO - iteration:55 step:3100/10100, NER loss: 0.795597
2019-02-21 19:44:13,694 - log/train6.log - INFO - iteration:55 step:3200/10100, NER loss: 0.799528
2019-02-21 19:44:15,911 - log/train6.log - INFO - iteration:55 step:3300/10100, NER loss: 0.782752
2019-02-21 19:44:18,139 - log/train6.log - INFO - iteration:55 step:3400/10100, NER loss: 0.874501
2019-02-21 19:44:20,489 - log/train6.log - INFO - iteration:55 step:3500/10100, NER loss: 0.874163
2019-02-21 19:44:22,590 - log/train6.log - INFO - iteration:55 step:3600/10100, NER loss: 0.762998
2019-02-21 19:44:24,732 - log/train6.log - INFO - iteration:55 step:3700/10100, NER loss: 0.948254
2019-02-21 19:44:26,965 - log/train6.log - INFO - iteration:55 step:3800/10100, NER loss: 0.844258
2019-02-21 19:44:29,353 - log/train6.log - INFO - iteration:55 step:3900/10100, NER loss: 1.083700
2019-02-21 19:44:31,626 - log/train6.log - INFO - iteration:55 step:4000/10100, NER loss: 0.898373
2019-02-21 19:44:33,753 - log/train6.log - INFO - iteration:55 step:4100/10100, NER loss: 0.808268
2019-02-21 19:44:35,989 - log/train6.log - INFO - iteration:55 step:4200/10100, NER loss: 0.951727
2019-02-21 19:44:38,228 - log/train6.log - INFO - iteration:55 step:4300/10100, NER loss: 0.772239
2019-02-21 19:44:40,412 - log/train6.log - INFO - iteration:55 step:4400/10100, NER loss: 1.034745
2019-02-21 19:44:42,654 - log/train6.log - INFO - iteration:55 step:4500/10100, NER loss: 0.845582
2019-02-21 19:44:45,181 - log/train6.log - INFO - iteration:55 step:4600/10100, NER loss: 1.044130
2019-02-21 19:44:47,305 - log/train6.log - INFO - iteration:55 step:4700/10100, NER loss: 0.809630
2019-02-21 19:44:49,565 - log/train6.log - INFO - iteration:55 step:4800/10100, NER loss: 0.846347
2019-02-21 19:44:51,871 - log/train6.log - INFO - iteration:55 step:4900/10100, NER loss: 0.924002
2019-02-21 19:44:53,925 - log/train6.log - INFO - iteration:55 step:5000/10100, NER loss: 0.898910
2019-02-21 19:44:56,177 - log/train6.log - INFO - iteration:55 step:5100/10100, NER loss: 1.097476
2019-02-21 19:44:58,308 - log/train6.log - INFO - iteration:55 step:5200/10100, NER loss: 0.855795
2019-02-21 19:45:00,694 - log/train6.log - INFO - iteration:55 step:5300/10100, NER loss: 1.086163
2019-02-21 19:45:02,890 - log/train6.log - INFO - iteration:55 step:5400/10100, NER loss: 1.007139
2019-02-21 19:45:05,388 - log/train6.log - INFO - iteration:55 step:5500/10100, NER loss: 0.925391
2019-02-21 19:45:07,910 - log/train6.log - INFO - iteration:55 step:5600/10100, NER loss: 1.101949
2019-02-21 19:45:12,195 - log/train6.log - INFO - iteration:55 step:5700/10100, NER loss: 2.246530
2019-02-21 19:45:14,465 - log/train6.log - INFO - iteration:55 step:5800/10100, NER loss: 0.889727
2019-02-21 19:45:16,456 - log/train6.log - INFO - iteration:55 step:5900/10100, NER loss: 0.849722
2019-02-21 19:45:20,455 - log/train6.log - INFO - iteration:55 step:6000/10100, NER loss: 1.621641
2019-02-21 19:45:22,514 - log/train6.log - INFO - iteration:55 step:6100/10100, NER loss: 0.826627
2019-02-21 19:45:24,795 - log/train6.log - INFO - iteration:55 step:6200/10100, NER loss: 1.038315
2019-02-21 19:45:27,171 - log/train6.log - INFO - iteration:55 step:6300/10100, NER loss: 1.053190
2019-02-21 19:45:29,296 - log/train6.log - INFO - iteration:55 step:6400/10100, NER loss: 0.746905
2019-02-21 19:45:31,603 - log/train6.log - INFO - iteration:55 step:6500/10100, NER loss: 1.013491
2019-02-21 19:45:33,724 - log/train6.log - INFO - iteration:55 step:6600/10100, NER loss: 0.988511
2019-02-21 19:45:35,619 - log/train6.log - INFO - iteration:55 step:6700/10100, NER loss: 0.717560
2019-02-21 19:45:37,837 - log/train6.log - INFO - iteration:55 step:6800/10100, NER loss: 0.858037
2019-02-21 19:45:40,067 - log/train6.log - INFO - iteration:55 step:6900/10100, NER loss: 0.826850
2019-02-21 19:45:42,309 - log/train6.log - INFO - iteration:55 step:7000/10100, NER loss: 0.884389
2019-02-21 19:45:44,545 - log/train6.log - INFO - iteration:55 step:7100/10100, NER loss: 0.753463
2019-02-21 19:45:46,890 - log/train6.log - INFO - iteration:55 step:7200/10100, NER loss: 1.030317
2019-02-21 19:45:48,936 - log/train6.log - INFO - iteration:55 step:7300/10100, NER loss: 0.886278
2019-02-21 19:45:50,962 - log/train6.log - INFO - iteration:55 step:7400/10100, NER loss: 0.971443
2019-02-21 19:45:53,204 - log/train6.log - INFO - iteration:55 step:7500/10100, NER loss: 0.929153
2019-02-21 19:45:55,416 - log/train6.log - INFO - iteration:55 step:7600/10100, NER loss: 0.976604
2019-02-21 19:45:57,651 - log/train6.log - INFO - iteration:55 step:7700/10100, NER loss: 0.865711
2019-02-21 19:45:59,740 - log/train6.log - INFO - iteration:55 step:7800/10100, NER loss: 0.866534
2019-02-21 19:46:02,003 - log/train6.log - INFO - iteration:55 step:7900/10100, NER loss: 0.947258
2019-02-21 19:46:04,163 - log/train6.log - INFO - iteration:55 step:8000/10100, NER loss: 0.849686
2019-02-21 19:46:06,411 - log/train6.log - INFO - iteration:55 step:8100/10100, NER loss: 0.937614
2019-02-21 19:46:08,568 - log/train6.log - INFO - iteration:55 step:8200/10100, NER loss: 0.968727
2019-02-21 19:46:13,003 - log/train6.log - INFO - iteration:55 step:8300/10100, NER loss: 1.290133
2019-02-21 19:46:15,390 - log/train6.log - INFO - iteration:55 step:8400/10100, NER loss: 0.864562
2019-02-21 19:46:17,395 - log/train6.log - INFO - iteration:55 step:8500/10100, NER loss: 0.810692
2019-02-21 19:46:19,633 - log/train6.log - INFO - iteration:55 step:8600/10100, NER loss: 0.811358
2019-02-21 19:46:21,947 - log/train6.log - INFO - iteration:55 step:8700/10100, NER loss: 0.940617
2019-02-21 19:46:23,987 - log/train6.log - INFO - iteration:55 step:8800/10100, NER loss: 0.749743
2019-02-21 19:46:26,172 - log/train6.log - INFO - iteration:55 step:8900/10100, NER loss: 0.959544
2019-02-21 19:46:28,365 - log/train6.log - INFO - iteration:55 step:9000/10100, NER loss: 0.959892
2019-02-21 19:46:30,533 - log/train6.log - INFO - iteration:55 step:9100/10100, NER loss: 0.803238
2019-02-21 19:46:32,897 - log/train6.log - INFO - iteration:55 step:9200/10100, NER loss: 0.876182
2019-02-21 19:46:35,224 - log/train6.log - INFO - iteration:55 step:9300/10100, NER loss: 0.891184
2019-02-21 19:46:37,306 - log/train6.log - INFO - iteration:55 step:9400/10100, NER loss: 0.760306
2019-02-21 19:46:39,311 - log/train6.log - INFO - iteration:55 step:9500/10100, NER loss: 0.826843
2019-02-21 19:46:41,338 - log/train6.log - INFO - iteration:55 step:9600/10100, NER loss: 0.690485
2019-02-21 19:46:43,361 - log/train6.log - INFO - iteration:55 step:9700/10100, NER loss: 0.777556
2019-02-21 19:46:45,375 - log/train6.log - INFO - iteration:55 step:9800/10100, NER loss: 0.810436
2019-02-21 19:46:47,622 - log/train6.log - INFO - iteration:55 step:9900/10100, NER loss: 0.934787
2019-02-21 19:46:49,658 - log/train6.log - INFO - iteration:55 step:10000/10100, NER loss: 0.948112
2019-02-21 19:46:51,841 - log/train6.log - INFO - iteration:56 step:0/10100, NER loss: 0.959722
2019-02-21 19:46:51,842 - log/train6.log - INFO - evaluate:dev
2019-02-21 19:46:58,354 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5782 phrases; correct: 4311.

2019-02-21 19:46:58,354 - log/train6.log - INFO - accuracy:  94.76%; precision:  74.56%; recall:  73.73%; FB1:  74.14

2019-02-21 19:46:58,354 - log/train6.log - INFO -                 C: precision:  80.98%; recall:  89.82%; FB1:  85.17  3759

2019-02-21 19:46:58,354 - log/train6.log - INFO -               IND: precision:  43.45%; recall:  30.88%; FB1:  36.10  290

2019-02-21 19:46:58,354 - log/train6.log - INFO -               INS: precision:  70.24%; recall:  69.13%; FB1:  69.68  373

2019-02-21 19:46:58,354 - log/train6.log - INFO -                 L: precision:  54.96%; recall:  42.08%; FB1:  47.66  464

2019-02-21 19:46:58,354 - log/train6.log - INFO -                 P: precision:  88.39%; recall:  91.16%; FB1:  89.76  560

2019-02-21 19:46:58,354 - log/train6.log - INFO -               PRO: precision:  38.39%; recall:  24.71%; FB1:  30.07  336

2019-02-21 19:46:58,357 - log/train6.log - INFO - evaluate:test
2019-02-21 19:46:59,821 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1710 phrases; correct: 1371.

2019-02-21 19:46:59,821 - log/train6.log - INFO - accuracy:  96.33%; precision:  80.18%; recall:  83.24%; FB1:  81.68

2019-02-21 19:46:59,821 - log/train6.log - INFO -                 C: precision:  83.80%; recall:  92.52%; FB1:  87.94  1136

2019-02-21 19:46:59,821 - log/train6.log - INFO -               IND: precision:  52.63%; recall:  63.83%; FB1:  57.69  57

2019-02-21 19:46:59,821 - log/train6.log - INFO -               INS: precision:  74.12%; recall:  66.32%; FB1:  70.00  85

2019-02-21 19:46:59,821 - log/train6.log - INFO -                 L: precision:  55.00%; recall:  53.40%; FB1:  54.19  100

2019-02-21 19:46:59,821 - log/train6.log - INFO -                 P: precision:  89.77%; recall:  94.61%; FB1:  92.12  215

2019-02-21 19:46:59,821 - log/train6.log - INFO -               PRO: precision:  66.67%; recall:  46.15%; FB1:  54.55  117

2019-02-21 19:47:01,786 - log/train6.log - INFO - iteration:56 step:100/10100, NER loss: 0.828942
2019-02-21 19:47:03,871 - log/train6.log - INFO - iteration:56 step:200/10100, NER loss: 0.964674
2019-02-21 19:47:06,027 - log/train6.log - INFO - iteration:56 step:300/10100, NER loss: 1.006013
2019-02-21 19:47:07,984 - log/train6.log - INFO - iteration:56 step:400/10100, NER loss: 0.774905
2019-02-21 19:47:10,209 - log/train6.log - INFO - iteration:56 step:500/10100, NER loss: 0.949247
2019-02-21 19:47:14,118 - log/train6.log - INFO - iteration:56 step:600/10100, NER loss: 1.251692
2019-02-21 19:47:16,454 - log/train6.log - INFO - iteration:56 step:700/10100, NER loss: 0.906883
2019-02-21 19:47:18,684 - log/train6.log - INFO - iteration:56 step:800/10100, NER loss: 0.970368
2019-02-21 19:47:20,992 - log/train6.log - INFO - iteration:56 step:900/10100, NER loss: 0.806218
2019-02-21 19:47:23,148 - log/train6.log - INFO - iteration:56 step:1000/10100, NER loss: 0.889996
2019-02-21 19:47:25,541 - log/train6.log - INFO - iteration:56 step:1100/10100, NER loss: 1.008435
2019-02-21 19:47:27,751 - log/train6.log - INFO - iteration:56 step:1200/10100, NER loss: 1.002457
2019-02-21 19:47:29,895 - log/train6.log - INFO - iteration:56 step:1300/10100, NER loss: 0.836810
2019-02-21 19:47:32,180 - log/train6.log - INFO - iteration:56 step:1400/10100, NER loss: 1.030480
2019-02-21 19:47:34,603 - log/train6.log - INFO - iteration:56 step:1500/10100, NER loss: 1.181919
2019-02-21 19:47:36,606 - log/train6.log - INFO - iteration:56 step:1600/10100, NER loss: 0.762530
2019-02-21 19:47:40,981 - log/train6.log - INFO - iteration:56 step:1700/10100, NER loss: 1.117643
2019-02-21 19:47:43,261 - log/train6.log - INFO - iteration:56 step:1800/10100, NER loss: 0.943036
2019-02-21 19:47:45,477 - log/train6.log - INFO - iteration:56 step:1900/10100, NER loss: 0.837778
2019-02-21 19:47:47,826 - log/train6.log - INFO - iteration:56 step:2000/10100, NER loss: 1.035920
2019-02-21 19:47:49,936 - log/train6.log - INFO - iteration:56 step:2100/10100, NER loss: 0.670284
2019-02-21 19:47:52,165 - log/train6.log - INFO - iteration:56 step:2200/10100, NER loss: 0.857347
2019-02-21 19:47:54,247 - log/train6.log - INFO - iteration:56 step:2300/10100, NER loss: 0.842773
2019-02-21 19:47:56,395 - log/train6.log - INFO - iteration:56 step:2400/10100, NER loss: 0.868213
2019-02-21 19:47:58,486 - log/train6.log - INFO - iteration:56 step:2500/10100, NER loss: 0.855962
2019-02-21 19:48:00,815 - log/train6.log - INFO - iteration:56 step:2600/10100, NER loss: 0.990626
2019-02-21 19:48:03,055 - log/train6.log - INFO - iteration:56 step:2700/10100, NER loss: 0.754317
2019-02-21 19:48:05,300 - log/train6.log - INFO - iteration:56 step:2800/10100, NER loss: 0.875676
2019-02-21 19:48:07,438 - log/train6.log - INFO - iteration:56 step:2900/10100, NER loss: 0.914304
2019-02-21 19:48:09,668 - log/train6.log - INFO - iteration:56 step:3000/10100, NER loss: 0.837690
2019-02-21 19:48:11,778 - log/train6.log - INFO - iteration:56 step:3100/10100, NER loss: 0.684232
2019-02-21 19:48:13,970 - log/train6.log - INFO - iteration:56 step:3200/10100, NER loss: 0.795064
2019-02-21 19:48:16,181 - log/train6.log - INFO - iteration:56 step:3300/10100, NER loss: 1.012219
2019-02-21 19:48:18,399 - log/train6.log - INFO - iteration:56 step:3400/10100, NER loss: 0.821571
2019-02-21 19:48:20,625 - log/train6.log - INFO - iteration:56 step:3500/10100, NER loss: 0.867838
2019-02-21 19:48:22,888 - log/train6.log - INFO - iteration:56 step:3600/10100, NER loss: 0.777652
2019-02-21 19:48:25,205 - log/train6.log - INFO - iteration:56 step:3700/10100, NER loss: 0.920001
2019-02-21 19:48:27,387 - log/train6.log - INFO - iteration:56 step:3800/10100, NER loss: 0.859389
2019-02-21 19:48:29,492 - log/train6.log - INFO - iteration:56 step:3900/10100, NER loss: 0.818530
2019-02-21 19:48:31,879 - log/train6.log - INFO - iteration:56 step:4000/10100, NER loss: 0.957338
2019-02-21 19:48:34,001 - log/train6.log - INFO - iteration:56 step:4100/10100, NER loss: 0.714348
2019-02-21 19:48:36,203 - log/train6.log - INFO - iteration:56 step:4200/10100, NER loss: 0.898309
2019-02-21 19:48:38,256 - log/train6.log - INFO - iteration:56 step:4300/10100, NER loss: 0.814781
2019-02-21 19:48:40,480 - log/train6.log - INFO - iteration:56 step:4400/10100, NER loss: 0.827424
2019-02-21 19:48:42,570 - log/train6.log - INFO - iteration:56 step:4500/10100, NER loss: 0.784227
2019-02-21 19:48:44,721 - log/train6.log - INFO - iteration:56 step:4600/10100, NER loss: 0.898667
2019-02-21 19:48:46,878 - log/train6.log - INFO - iteration:56 step:4700/10100, NER loss: 0.938106
2019-02-21 19:48:48,966 - log/train6.log - INFO - iteration:56 step:4800/10100, NER loss: 0.803916
2019-02-21 19:48:51,103 - log/train6.log - INFO - iteration:56 step:4900/10100, NER loss: 0.748695
2019-02-21 19:48:53,121 - log/train6.log - INFO - iteration:56 step:5000/10100, NER loss: 0.754957
2019-02-21 19:48:55,311 - log/train6.log - INFO - iteration:56 step:5100/10100, NER loss: 0.895041
2019-02-21 19:48:57,598 - log/train6.log - INFO - iteration:56 step:5200/10100, NER loss: 0.871636
2019-02-21 19:48:59,996 - log/train6.log - INFO - iteration:56 step:5300/10100, NER loss: 1.070828
2019-02-21 19:49:02,096 - log/train6.log - INFO - iteration:56 step:5400/10100, NER loss: 0.785939
2019-02-21 19:49:04,508 - log/train6.log - INFO - iteration:56 step:5500/10100, NER loss: 0.964309
2019-02-21 19:49:06,794 - log/train6.log - INFO - iteration:56 step:5600/10100, NER loss: 0.904804
2019-02-21 19:49:09,117 - log/train6.log - INFO - iteration:56 step:5700/10100, NER loss: 0.920449
2019-02-21 19:49:11,174 - log/train6.log - INFO - iteration:56 step:5800/10100, NER loss: 0.694021
2019-02-21 19:49:13,270 - log/train6.log - INFO - iteration:56 step:5900/10100, NER loss: 0.973625
2019-02-21 19:49:15,166 - log/train6.log - INFO - iteration:56 step:6000/10100, NER loss: 0.568929
2019-02-21 19:49:17,463 - log/train6.log - INFO - iteration:56 step:6100/10100, NER loss: 0.966753
2019-02-21 19:49:19,649 - log/train6.log - INFO - iteration:56 step:6200/10100, NER loss: 0.855824
2019-02-21 19:49:21,962 - log/train6.log - INFO - iteration:56 step:6300/10100, NER loss: 0.939173
2019-02-21 19:49:24,103 - log/train6.log - INFO - iteration:56 step:6400/10100, NER loss: 0.791244
2019-02-21 19:49:26,255 - log/train6.log - INFO - iteration:56 step:6500/10100, NER loss: 0.857515
2019-02-21 19:49:28,333 - log/train6.log - INFO - iteration:56 step:6600/10100, NER loss: 0.831354
2019-02-21 19:49:30,864 - log/train6.log - INFO - iteration:56 step:6700/10100, NER loss: 1.070095
2019-02-21 19:49:33,172 - log/train6.log - INFO - iteration:56 step:6800/10100, NER loss: 1.067186
2019-02-21 19:49:35,331 - log/train6.log - INFO - iteration:56 step:6900/10100, NER loss: 0.831568
2019-02-21 19:49:37,731 - log/train6.log - INFO - iteration:56 step:7000/10100, NER loss: 1.029621
2019-02-21 19:49:39,884 - log/train6.log - INFO - iteration:56 step:7100/10100, NER loss: 0.854700
2019-02-21 19:49:42,054 - log/train6.log - INFO - iteration:56 step:7200/10100, NER loss: 0.768864
2019-02-21 19:49:44,337 - log/train6.log - INFO - iteration:56 step:7300/10100, NER loss: 0.897767
2019-02-21 19:49:47,151 - log/train6.log - INFO - iteration:56 step:7400/10100, NER loss: 1.323417
2019-02-21 19:49:49,167 - log/train6.log - INFO - iteration:56 step:7500/10100, NER loss: 0.792703
2019-02-21 19:49:51,226 - log/train6.log - INFO - iteration:56 step:7600/10100, NER loss: 0.793237
2019-02-21 19:49:53,560 - log/train6.log - INFO - iteration:56 step:7700/10100, NER loss: 1.126420
2019-02-21 19:49:55,527 - log/train6.log - INFO - iteration:56 step:7800/10100, NER loss: 0.679731
2019-02-21 19:49:57,923 - log/train6.log - INFO - iteration:56 step:7900/10100, NER loss: 0.966983
2019-02-21 19:50:00,026 - log/train6.log - INFO - iteration:56 step:8000/10100, NER loss: 0.848733
2019-02-21 19:50:02,239 - log/train6.log - INFO - iteration:56 step:8100/10100, NER loss: 0.873690
2019-02-21 19:50:04,319 - log/train6.log - INFO - iteration:56 step:8200/10100, NER loss: 0.878842
2019-02-21 19:50:06,583 - log/train6.log - INFO - iteration:56 step:8300/10100, NER loss: 0.977493
2019-02-21 19:50:08,646 - log/train6.log - INFO - iteration:56 step:8400/10100, NER loss: 0.743590
2019-02-21 19:50:11,458 - log/train6.log - INFO - iteration:56 step:8500/10100, NER loss: 0.955775
2019-02-21 19:50:13,653 - log/train6.log - INFO - iteration:56 step:8600/10100, NER loss: 0.827479
2019-02-21 19:50:15,911 - log/train6.log - INFO - iteration:56 step:8700/10100, NER loss: 0.813853
2019-02-21 19:50:18,226 - log/train6.log - INFO - iteration:56 step:8800/10100, NER loss: 1.071724
2019-02-21 19:50:20,367 - log/train6.log - INFO - iteration:56 step:8900/10100, NER loss: 0.886776
2019-02-21 19:50:22,632 - log/train6.log - INFO - iteration:56 step:9000/10100, NER loss: 0.859289
2019-02-21 19:50:24,671 - log/train6.log - INFO - iteration:56 step:9100/10100, NER loss: 0.808501
2019-02-21 19:50:27,001 - log/train6.log - INFO - iteration:56 step:9200/10100, NER loss: 1.018206
2019-02-21 19:50:29,276 - log/train6.log - INFO - iteration:56 step:9300/10100, NER loss: 0.999702
2019-02-21 19:50:31,850 - log/train6.log - INFO - iteration:56 step:9400/10100, NER loss: 1.244694
2019-02-21 19:50:36,023 - log/train6.log - INFO - iteration:56 step:9500/10100, NER loss: 1.384617
2019-02-21 19:50:38,237 - log/train6.log - INFO - iteration:56 step:9600/10100, NER loss: 0.917916
2019-02-21 19:50:40,513 - log/train6.log - INFO - iteration:56 step:9700/10100, NER loss: 0.905330
2019-02-21 19:50:42,967 - log/train6.log - INFO - iteration:56 step:9800/10100, NER loss: 1.041059
2019-02-21 19:50:45,404 - log/train6.log - INFO - iteration:56 step:9900/10100, NER loss: 1.051163
2019-02-21 19:50:47,641 - log/train6.log - INFO - iteration:56 step:10000/10100, NER loss: 0.907765
2019-02-21 19:50:49,689 - log/train6.log - INFO - iteration:57 step:0/10100, NER loss: 1.155009
2019-02-21 19:50:49,689 - log/train6.log - INFO - evaluate:dev
2019-02-21 19:50:56,092 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 6133 phrases; correct: 4460.

2019-02-21 19:50:56,092 - log/train6.log - INFO - accuracy:  94.85%; precision:  72.72%; recall:  76.28%; FB1:  74.46

2019-02-21 19:50:56,092 - log/train6.log - INFO -                 C: precision:  81.35%; recall:  90.09%; FB1:  85.49  3753

2019-02-21 19:50:56,092 - log/train6.log - INFO -               IND: precision:  31.98%; recall:  42.40%; FB1:  36.46  541

2019-02-21 19:50:56,092 - log/train6.log - INFO -               INS: precision:  74.85%; recall:  65.17%; FB1:  69.68  330

2019-02-21 19:50:56,092 - log/train6.log - INFO -                 L: precision:  58.37%; recall:  59.24%; FB1:  58.80  615

2019-02-21 19:50:56,092 - log/train6.log - INFO -                 P: precision:  89.69%; recall:  91.34%; FB1:  90.51  553

2019-02-21 19:50:56,092 - log/train6.log - INFO -               PRO: precision:  38.71%; recall:  25.29%; FB1:  30.59  341

2019-02-21 19:50:56,095 - log/train6.log - INFO - evaluate:test
2019-02-21 19:50:57,565 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1761 phrases; correct: 1384.

2019-02-21 19:50:57,565 - log/train6.log - INFO - accuracy:  95.83%; precision:  78.59%; recall:  84.03%; FB1:  81.22

2019-02-21 19:50:57,565 - log/train6.log - INFO -                 C: precision:  85.05%; recall:  91.74%; FB1:  88.27  1110

2019-02-21 19:50:57,565 - log/train6.log - INFO -               IND: precision:  29.46%; recall:  70.21%; FB1:  41.51  112

2019-02-21 19:50:57,565 - log/train6.log - INFO -               INS: precision:  69.88%; recall:  61.05%; FB1:  65.17  83

2019-02-21 19:50:57,565 - log/train6.log - INFO -                 L: precision:  55.45%; recall:  59.22%; FB1:  57.28  110

2019-02-21 19:50:57,565 - log/train6.log - INFO -                 P: precision:  91.00%; recall:  94.12%; FB1:  92.53  211

2019-02-21 19:50:57,565 - log/train6.log - INFO -               PRO: precision:  71.11%; recall:  56.80%; FB1:  63.16  135

2019-02-21 19:50:59,739 - log/train6.log - INFO - iteration:57 step:100/10100, NER loss: 0.941144
2019-02-21 19:51:01,679 - log/train6.log - INFO - iteration:57 step:200/10100, NER loss: 0.870713
2019-02-21 19:51:03,783 - log/train6.log - INFO - iteration:57 step:300/10100, NER loss: 0.748541
2019-02-21 19:51:06,085 - log/train6.log - INFO - iteration:57 step:400/10100, NER loss: 0.831192
2019-02-21 19:51:08,439 - log/train6.log - INFO - iteration:57 step:500/10100, NER loss: 1.038461
2019-02-21 19:51:10,531 - log/train6.log - INFO - iteration:57 step:600/10100, NER loss: 0.772083
2019-02-21 19:51:13,128 - log/train6.log - INFO - iteration:57 step:700/10100, NER loss: 1.036914
2019-02-21 19:51:15,210 - log/train6.log - INFO - iteration:57 step:800/10100, NER loss: 0.784332
2019-02-21 19:51:17,210 - log/train6.log - INFO - iteration:57 step:900/10100, NER loss: 0.773187
2019-02-21 19:51:19,260 - log/train6.log - INFO - iteration:57 step:1000/10100, NER loss: 0.854951
2019-02-21 19:51:21,482 - log/train6.log - INFO - iteration:57 step:1100/10100, NER loss: 0.908655
2019-02-21 19:51:23,694 - log/train6.log - INFO - iteration:57 step:1200/10100, NER loss: 0.874756
2019-02-21 19:51:26,062 - log/train6.log - INFO - iteration:57 step:1300/10100, NER loss: 1.020734
2019-02-21 19:51:28,385 - log/train6.log - INFO - iteration:57 step:1400/10100, NER loss: 0.966842
2019-02-21 19:51:30,529 - log/train6.log - INFO - iteration:57 step:1500/10100, NER loss: 1.000955
2019-02-21 19:51:32,820 - log/train6.log - INFO - iteration:57 step:1600/10100, NER loss: 0.861862
2019-02-21 19:51:35,016 - log/train6.log - INFO - iteration:57 step:1700/10100, NER loss: 0.987177
2019-02-21 19:51:37,235 - log/train6.log - INFO - iteration:57 step:1800/10100, NER loss: 0.990042
2019-02-21 19:51:39,609 - log/train6.log - INFO - iteration:57 step:1900/10100, NER loss: 1.129147
2019-02-21 19:51:42,026 - log/train6.log - INFO - iteration:57 step:2000/10100, NER loss: 1.155145
2019-02-21 19:51:44,166 - log/train6.log - INFO - iteration:57 step:2100/10100, NER loss: 0.806469
2019-02-21 19:51:46,318 - log/train6.log - INFO - iteration:57 step:2200/10100, NER loss: 0.958230
2019-02-21 19:51:48,543 - log/train6.log - INFO - iteration:57 step:2300/10100, NER loss: 1.043513
2019-02-21 19:51:52,724 - log/train6.log - INFO - iteration:57 step:2400/10100, NER loss: 1.376200
2019-02-21 19:51:54,768 - log/train6.log - INFO - iteration:57 step:2500/10100, NER loss: 0.826066
2019-02-21 19:51:57,092 - log/train6.log - INFO - iteration:57 step:2600/10100, NER loss: 0.934318
2019-02-21 19:51:59,133 - log/train6.log - INFO - iteration:57 step:2700/10100, NER loss: 0.719873
2019-02-21 19:52:01,319 - log/train6.log - INFO - iteration:57 step:2800/10100, NER loss: 1.135386
2019-02-21 19:52:03,459 - log/train6.log - INFO - iteration:57 step:2900/10100, NER loss: 0.827257
2019-02-21 19:52:05,766 - log/train6.log - INFO - iteration:57 step:3000/10100, NER loss: 0.963704
2019-02-21 19:52:08,114 - log/train6.log - INFO - iteration:57 step:3100/10100, NER loss: 1.059376
2019-02-21 19:52:10,505 - log/train6.log - INFO - iteration:57 step:3200/10100, NER loss: 1.051113
2019-02-21 19:52:12,716 - log/train6.log - INFO - iteration:57 step:3300/10100, NER loss: 0.881500
2019-02-21 19:52:15,094 - log/train6.log - INFO - iteration:57 step:3400/10100, NER loss: 0.988880
2019-02-21 19:52:17,212 - log/train6.log - INFO - iteration:57 step:3500/10100, NER loss: 0.827918
2019-02-21 19:52:19,512 - log/train6.log - INFO - iteration:57 step:3600/10100, NER loss: 0.919227
2019-02-21 19:52:21,722 - log/train6.log - INFO - iteration:57 step:3700/10100, NER loss: 1.020763
2019-02-21 19:52:23,714 - log/train6.log - INFO - iteration:57 step:3800/10100, NER loss: 0.688594
2019-02-21 19:52:25,866 - log/train6.log - INFO - iteration:57 step:3900/10100, NER loss: 0.932331
2019-02-21 19:52:28,179 - log/train6.log - INFO - iteration:57 step:4000/10100, NER loss: 0.777473
2019-02-21 19:52:30,268 - log/train6.log - INFO - iteration:57 step:4100/10100, NER loss: 0.843938
2019-02-21 19:52:32,501 - log/train6.log - INFO - iteration:57 step:4200/10100, NER loss: 0.992123
2019-02-21 19:52:34,732 - log/train6.log - INFO - iteration:57 step:4300/10100, NER loss: 0.988357
2019-02-21 19:52:36,984 - log/train6.log - INFO - iteration:57 step:4400/10100, NER loss: 0.799657
2019-02-21 19:52:39,091 - log/train6.log - INFO - iteration:57 step:4500/10100, NER loss: 0.948581
2019-02-21 19:52:41,199 - log/train6.log - INFO - iteration:57 step:4600/10100, NER loss: 0.757766
2019-02-21 19:52:45,537 - log/train6.log - INFO - iteration:57 step:4700/10100, NER loss: 1.037957
2019-02-21 19:52:47,791 - log/train6.log - INFO - iteration:57 step:4800/10100, NER loss: 0.930087
2019-02-21 19:52:50,005 - log/train6.log - INFO - iteration:57 step:4900/10100, NER loss: 0.755738
2019-02-21 19:52:52,240 - log/train6.log - INFO - iteration:57 step:5000/10100, NER loss: 0.928745
2019-02-21 19:52:54,538 - log/train6.log - INFO - iteration:57 step:5100/10100, NER loss: 0.934139
2019-02-21 19:52:56,607 - log/train6.log - INFO - iteration:57 step:5200/10100, NER loss: 0.681788
2019-02-21 19:52:58,863 - log/train6.log - INFO - iteration:57 step:5300/10100, NER loss: 0.926480
2019-02-21 19:53:01,153 - log/train6.log - INFO - iteration:57 step:5400/10100, NER loss: 1.019607
2019-02-21 19:53:03,437 - log/train6.log - INFO - iteration:57 step:5500/10100, NER loss: 1.398595
2019-02-21 19:53:05,746 - log/train6.log - INFO - iteration:57 step:5600/10100, NER loss: 1.166223
2019-02-21 19:53:07,899 - log/train6.log - INFO - iteration:57 step:5700/10100, NER loss: 0.776548
2019-02-21 19:53:10,057 - log/train6.log - INFO - iteration:57 step:5800/10100, NER loss: 0.793117
2019-02-21 19:53:12,319 - log/train6.log - INFO - iteration:57 step:5900/10100, NER loss: 0.916264
2019-02-21 19:53:14,463 - log/train6.log - INFO - iteration:57 step:6000/10100, NER loss: 0.874499
2019-02-21 19:53:17,044 - log/train6.log - INFO - iteration:57 step:6100/10100, NER loss: 1.204950
2019-02-21 19:53:19,118 - log/train6.log - INFO - iteration:57 step:6200/10100, NER loss: 0.748624
2019-02-21 19:53:21,380 - log/train6.log - INFO - iteration:57 step:6300/10100, NER loss: 0.976727
2019-02-21 19:53:23,459 - log/train6.log - INFO - iteration:57 step:6400/10100, NER loss: 0.764866
2019-02-21 19:53:25,638 - log/train6.log - INFO - iteration:57 step:6500/10100, NER loss: 0.695544
2019-02-21 19:53:27,577 - log/train6.log - INFO - iteration:57 step:6600/10100, NER loss: 0.790985
2019-02-21 19:53:29,774 - log/train6.log - INFO - iteration:57 step:6700/10100, NER loss: 0.742171
2019-02-21 19:53:32,108 - log/train6.log - INFO - iteration:57 step:6800/10100, NER loss: 0.902605
2019-02-21 19:53:34,093 - log/train6.log - INFO - iteration:57 step:6900/10100, NER loss: 0.685723
2019-02-21 19:53:36,296 - log/train6.log - INFO - iteration:57 step:7000/10100, NER loss: 1.005041
2019-02-21 19:53:38,665 - log/train6.log - INFO - iteration:57 step:7100/10100, NER loss: 0.825551
2019-02-21 19:53:41,190 - log/train6.log - INFO - iteration:57 step:7200/10100, NER loss: 1.167763
2019-02-21 19:53:43,535 - log/train6.log - INFO - iteration:57 step:7300/10100, NER loss: 0.901435
2019-02-21 19:53:45,664 - log/train6.log - INFO - iteration:57 step:7400/10100, NER loss: 0.798476
2019-02-21 19:53:47,763 - log/train6.log - INFO - iteration:57 step:7500/10100, NER loss: 0.776132
2019-02-21 19:53:49,799 - log/train6.log - INFO - iteration:57 step:7600/10100, NER loss: 0.767229
2019-02-21 19:53:54,160 - log/train6.log - INFO - iteration:57 step:7700/10100, NER loss: 1.673681
2019-02-21 19:53:56,353 - log/train6.log - INFO - iteration:57 step:7800/10100, NER loss: 0.819764
2019-02-21 19:53:58,699 - log/train6.log - INFO - iteration:57 step:7900/10100, NER loss: 1.017034
2019-02-21 19:54:00,987 - log/train6.log - INFO - iteration:57 step:8000/10100, NER loss: 0.900810
2019-02-21 19:54:03,218 - log/train6.log - INFO - iteration:57 step:8100/10100, NER loss: 0.933219
2019-02-21 19:54:05,692 - log/train6.log - INFO - iteration:57 step:8200/10100, NER loss: 0.986940
2019-02-21 19:54:07,963 - log/train6.log - INFO - iteration:57 step:8300/10100, NER loss: 1.087009
2019-02-21 19:54:10,098 - log/train6.log - INFO - iteration:57 step:8400/10100, NER loss: 0.865650
2019-02-21 19:54:12,275 - log/train6.log - INFO - iteration:57 step:8500/10100, NER loss: 0.740152
2019-02-21 19:54:14,353 - log/train6.log - INFO - iteration:57 step:8600/10100, NER loss: 0.930893
2019-02-21 19:54:16,604 - log/train6.log - INFO - iteration:57 step:8700/10100, NER loss: 0.814427
2019-02-21 19:54:18,786 - log/train6.log - INFO - iteration:57 step:8800/10100, NER loss: 0.900458
2019-02-21 19:54:20,949 - log/train6.log - INFO - iteration:57 step:8900/10100, NER loss: 0.879220
2019-02-21 19:54:22,996 - log/train6.log - INFO - iteration:57 step:9000/10100, NER loss: 0.625588
2019-02-21 19:54:25,012 - log/train6.log - INFO - iteration:57 step:9100/10100, NER loss: 0.750111
2019-02-21 19:54:27,416 - log/train6.log - INFO - iteration:57 step:9200/10100, NER loss: 0.915482
2019-02-21 19:54:29,831 - log/train6.log - INFO - iteration:57 step:9300/10100, NER loss: 0.950800
2019-02-21 19:54:31,776 - log/train6.log - INFO - iteration:57 step:9400/10100, NER loss: 0.669957
2019-02-21 19:54:34,052 - log/train6.log - INFO - iteration:57 step:9500/10100, NER loss: 0.975406
2019-02-21 19:54:36,219 - log/train6.log - INFO - iteration:57 step:9600/10100, NER loss: 0.738065
2019-02-21 19:54:38,139 - log/train6.log - INFO - iteration:57 step:9700/10100, NER loss: 0.731914
2019-02-21 19:54:40,168 - log/train6.log - INFO - iteration:57 step:9800/10100, NER loss: 0.780241
2019-02-21 19:54:42,329 - log/train6.log - INFO - iteration:57 step:9900/10100, NER loss: 0.813995
2019-02-21 19:54:44,628 - log/train6.log - INFO - iteration:57 step:10000/10100, NER loss: 0.958039
2019-02-21 19:54:46,690 - log/train6.log - INFO - iteration:58 step:0/10100, NER loss: 0.694135
2019-02-21 19:54:46,690 - log/train6.log - INFO - evaluate:dev
2019-02-21 19:54:53,154 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5514 phrases; correct: 4313.

2019-02-21 19:54:53,154 - log/train6.log - INFO - accuracy:  95.50%; precision:  78.22%; recall:  73.76%; FB1:  75.93

2019-02-21 19:54:53,154 - log/train6.log - INFO -                 C: precision:  88.05%; recall:  86.78%; FB1:  87.41  3340

2019-02-21 19:54:53,154 - log/train6.log - INFO -               IND: precision:  49.01%; recall:  24.26%; FB1:  32.46  202

2019-02-21 19:54:53,154 - log/train6.log - INFO -               INS: precision:  70.70%; recall:  69.39%; FB1:  70.04  372

2019-02-21 19:54:53,154 - log/train6.log - INFO -                 L: precision:  55.60%; recall:  62.21%; FB1:  58.72  678

2019-02-21 19:54:53,154 - log/train6.log - INFO -                 P: precision:  87.87%; recall:  92.08%; FB1:  89.93  569

2019-02-21 19:54:53,154 - log/train6.log - INFO -               PRO: precision:  37.68%; recall:  25.48%; FB1:  30.40  353

2019-02-21 19:54:53,157 - log/train6.log - INFO - evaluate:test
2019-02-21 19:54:54,616 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1636 phrases; correct: 1391.

2019-02-21 19:54:54,617 - log/train6.log - INFO - accuracy:  97.06%; precision:  85.02%; recall:  84.46%; FB1:  84.74

2019-02-21 19:54:54,617 - log/train6.log - INFO -                 C: precision:  90.04%; recall:  91.35%; FB1:  90.69  1044

2019-02-21 19:54:54,617 - log/train6.log - INFO -               IND: precision:  65.12%; recall:  59.57%; FB1:  62.22  43

2019-02-21 19:54:54,617 - log/train6.log - INFO -               INS: precision:  73.03%; recall:  68.42%; FB1:  70.65  89

2019-02-21 19:54:54,617 - log/train6.log - INFO -                 L: precision:  56.14%; recall:  62.14%; FB1:  58.99  114

2019-02-21 19:54:54,617 - log/train6.log - INFO -                 P: precision:  91.47%; recall:  94.61%; FB1:  93.01  211

2019-02-21 19:54:54,617 - log/train6.log - INFO -               PRO: precision:  74.81%; recall:  59.76%; FB1:  66.45  135

2019-02-21 19:54:56,754 - log/train6.log - INFO - iteration:58 step:100/10100, NER loss: 0.935144
2019-02-21 19:54:58,773 - log/train6.log - INFO - iteration:58 step:200/10100, NER loss: 0.836832
2019-02-21 19:55:00,982 - log/train6.log - INFO - iteration:58 step:300/10100, NER loss: 0.913552
2019-02-21 19:55:02,934 - log/train6.log - INFO - iteration:58 step:400/10100, NER loss: 0.794831
2019-02-21 19:55:05,157 - log/train6.log - INFO - iteration:58 step:500/10100, NER loss: 0.972007
2019-02-21 19:55:07,149 - log/train6.log - INFO - iteration:58 step:600/10100, NER loss: 0.704615
2019-02-21 19:55:09,510 - log/train6.log - INFO - iteration:58 step:700/10100, NER loss: 1.069520
2019-02-21 19:55:11,659 - log/train6.log - INFO - iteration:58 step:800/10100, NER loss: 0.879635
2019-02-21 19:55:13,767 - log/train6.log - INFO - iteration:58 step:900/10100, NER loss: 0.751732
2019-02-21 19:55:16,023 - log/train6.log - INFO - iteration:58 step:1000/10100, NER loss: 0.925641
2019-02-21 19:55:18,377 - log/train6.log - INFO - iteration:58 step:1100/10100, NER loss: 0.866514
2019-02-21 19:55:20,480 - log/train6.log - INFO - iteration:58 step:1200/10100, NER loss: 1.035644
2019-02-21 19:55:22,699 - log/train6.log - INFO - iteration:58 step:1300/10100, NER loss: 0.880300
2019-02-21 19:55:24,754 - log/train6.log - INFO - iteration:58 step:1400/10100, NER loss: 0.798499
2019-02-21 19:55:27,014 - log/train6.log - INFO - iteration:58 step:1500/10100, NER loss: 0.931977
2019-02-21 19:55:29,263 - log/train6.log - INFO - iteration:58 step:1600/10100, NER loss: 0.973004
2019-02-21 19:55:31,391 - log/train6.log - INFO - iteration:58 step:1700/10100, NER loss: 0.814283
2019-02-21 19:55:33,686 - log/train6.log - INFO - iteration:58 step:1800/10100, NER loss: 0.876390
2019-02-21 19:55:35,849 - log/train6.log - INFO - iteration:58 step:1900/10100, NER loss: 0.850657
2019-02-21 19:55:38,047 - log/train6.log - INFO - iteration:58 step:2000/10100, NER loss: 0.801216
2019-02-21 19:55:40,305 - log/train6.log - INFO - iteration:58 step:2100/10100, NER loss: 0.924049
2019-02-21 19:55:42,851 - log/train6.log - INFO - iteration:58 step:2200/10100, NER loss: 1.148576
2019-02-21 19:55:44,884 - log/train6.log - INFO - iteration:58 step:2300/10100, NER loss: 0.786189
2019-02-21 19:55:47,057 - log/train6.log - INFO - iteration:58 step:2400/10100, NER loss: 0.854055
2019-02-21 19:55:49,244 - log/train6.log - INFO - iteration:58 step:2500/10100, NER loss: 0.809309
2019-02-21 19:55:51,606 - log/train6.log - INFO - iteration:58 step:2600/10100, NER loss: 1.081113
2019-02-21 19:55:53,868 - log/train6.log - INFO - iteration:58 step:2700/10100, NER loss: 0.843668
2019-02-21 19:55:56,130 - log/train6.log - INFO - iteration:58 step:2800/10100, NER loss: 0.946760
2019-02-21 19:55:58,437 - log/train6.log - INFO - iteration:58 step:2900/10100, NER loss: 1.047601
2019-02-21 19:56:00,673 - log/train6.log - INFO - iteration:58 step:3000/10100, NER loss: 0.893916
2019-02-21 19:56:03,173 - log/train6.log - INFO - iteration:58 step:3100/10100, NER loss: 1.277639
2019-02-21 19:56:05,163 - log/train6.log - INFO - iteration:58 step:3200/10100, NER loss: 0.807228
2019-02-21 19:56:07,284 - log/train6.log - INFO - iteration:58 step:3300/10100, NER loss: 0.769874
2019-02-21 19:56:09,559 - log/train6.log - INFO - iteration:58 step:3400/10100, NER loss: 0.967709
2019-02-21 19:56:11,599 - log/train6.log - INFO - iteration:58 step:3500/10100, NER loss: 0.707869
2019-02-21 19:56:13,717 - log/train6.log - INFO - iteration:58 step:3600/10100, NER loss: 0.855963
2019-02-21 19:56:15,819 - log/train6.log - INFO - iteration:58 step:3700/10100, NER loss: 0.794620
2019-02-21 19:56:18,052 - log/train6.log - INFO - iteration:58 step:3800/10100, NER loss: 0.834598
2019-02-21 19:56:20,298 - log/train6.log - INFO - iteration:58 step:3900/10100, NER loss: 0.941376
2019-02-21 19:56:22,459 - log/train6.log - INFO - iteration:58 step:4000/10100, NER loss: 0.845598
2019-02-21 19:56:24,876 - log/train6.log - INFO - iteration:58 step:4100/10100, NER loss: 0.959729
2019-02-21 19:56:27,113 - log/train6.log - INFO - iteration:58 step:4200/10100, NER loss: 1.012743
2019-02-21 19:56:29,246 - log/train6.log - INFO - iteration:58 step:4300/10100, NER loss: 0.698600
2019-02-21 19:56:31,614 - log/train6.log - INFO - iteration:58 step:4400/10100, NER loss: 1.076524
2019-02-21 19:56:33,585 - log/train6.log - INFO - iteration:58 step:4500/10100, NER loss: 0.690353
2019-02-21 19:56:35,629 - log/train6.log - INFO - iteration:58 step:4600/10100, NER loss: 0.876587
2019-02-21 19:56:38,510 - log/train6.log - INFO - iteration:58 step:4700/10100, NER loss: 1.273020
2019-02-21 19:56:40,799 - log/train6.log - INFO - iteration:58 step:4800/10100, NER loss: 0.883199
2019-02-21 19:56:43,050 - log/train6.log - INFO - iteration:58 step:4900/10100, NER loss: 1.027219
2019-02-21 19:56:45,356 - log/train6.log - INFO - iteration:58 step:5000/10100, NER loss: 0.892363
2019-02-21 19:56:47,626 - log/train6.log - INFO - iteration:58 step:5100/10100, NER loss: 1.057683
2019-02-21 19:56:51,867 - log/train6.log - INFO - iteration:58 step:5200/10100, NER loss: 2.435478
2019-02-21 19:56:53,974 - log/train6.log - INFO - iteration:58 step:5300/10100, NER loss: 0.825740
2019-02-21 19:56:56,430 - log/train6.log - INFO - iteration:58 step:5400/10100, NER loss: 1.015317
2019-02-21 19:56:58,554 - log/train6.log - INFO - iteration:58 step:5500/10100, NER loss: 0.727687
2019-02-21 19:57:00,669 - log/train6.log - INFO - iteration:58 step:5600/10100, NER loss: 0.843058
2019-02-21 19:57:02,805 - log/train6.log - INFO - iteration:58 step:5700/10100, NER loss: 0.765941
2019-02-21 19:57:05,060 - log/train6.log - INFO - iteration:58 step:5800/10100, NER loss: 0.918309
2019-02-21 19:57:07,209 - log/train6.log - INFO - iteration:58 step:5900/10100, NER loss: 0.944051
2019-02-21 19:57:09,186 - log/train6.log - INFO - iteration:58 step:6000/10100, NER loss: 0.692253
2019-02-21 19:57:13,259 - log/train6.log - INFO - iteration:58 step:6100/10100, NER loss: 1.439017
2019-02-21 19:57:15,576 - log/train6.log - INFO - iteration:58 step:6200/10100, NER loss: 1.094595
2019-02-21 19:57:17,770 - log/train6.log - INFO - iteration:58 step:6300/10100, NER loss: 0.881215
2019-02-21 19:57:20,014 - log/train6.log - INFO - iteration:58 step:6400/10100, NER loss: 0.815596
2019-02-21 19:57:22,328 - log/train6.log - INFO - iteration:58 step:6500/10100, NER loss: 1.135455
2019-02-21 19:57:24,408 - log/train6.log - INFO - iteration:58 step:6600/10100, NER loss: 0.923288
2019-02-21 19:57:26,583 - log/train6.log - INFO - iteration:58 step:6700/10100, NER loss: 0.838141
2019-02-21 19:57:28,785 - log/train6.log - INFO - iteration:58 step:6800/10100, NER loss: 0.736314
2019-02-21 19:57:30,802 - log/train6.log - INFO - iteration:58 step:6900/10100, NER loss: 0.817816
2019-02-21 19:57:33,106 - log/train6.log - INFO - iteration:58 step:7000/10100, NER loss: 0.874426
2019-02-21 19:57:35,195 - log/train6.log - INFO - iteration:58 step:7100/10100, NER loss: 0.835226
2019-02-21 19:57:37,394 - log/train6.log - INFO - iteration:58 step:7200/10100, NER loss: 0.876825
2019-02-21 19:57:39,602 - log/train6.log - INFO - iteration:58 step:7300/10100, NER loss: 1.051564
2019-02-21 19:57:41,722 - log/train6.log - INFO - iteration:58 step:7400/10100, NER loss: 0.938187
2019-02-21 19:57:44,006 - log/train6.log - INFO - iteration:58 step:7500/10100, NER loss: 0.890871
2019-02-21 19:57:48,574 - log/train6.log - INFO - iteration:58 step:7600/10100, NER loss: 1.377900
2019-02-21 19:57:50,681 - log/train6.log - INFO - iteration:58 step:7700/10100, NER loss: 0.909906
2019-02-21 19:57:52,942 - log/train6.log - INFO - iteration:58 step:7800/10100, NER loss: 0.993154
2019-02-21 19:57:55,067 - log/train6.log - INFO - iteration:58 step:7900/10100, NER loss: 0.809052
2019-02-21 19:57:57,350 - log/train6.log - INFO - iteration:58 step:8000/10100, NER loss: 1.049677
2019-02-21 19:57:59,789 - log/train6.log - INFO - iteration:58 step:8100/10100, NER loss: 0.917274
2019-02-21 19:58:02,134 - log/train6.log - INFO - iteration:58 step:8200/10100, NER loss: 0.942175
2019-02-21 19:58:04,119 - log/train6.log - INFO - iteration:58 step:8300/10100, NER loss: 0.793009
2019-02-21 19:58:06,311 - log/train6.log - INFO - iteration:58 step:8400/10100, NER loss: 0.736322
2019-02-21 19:58:08,452 - log/train6.log - INFO - iteration:58 step:8500/10100, NER loss: 0.743409
2019-02-21 19:58:10,586 - log/train6.log - INFO - iteration:58 step:8600/10100, NER loss: 0.814345
2019-02-21 19:58:12,661 - log/train6.log - INFO - iteration:58 step:8700/10100, NER loss: 0.908057
2019-02-21 19:58:14,862 - log/train6.log - INFO - iteration:58 step:8800/10100, NER loss: 0.913173
2019-02-21 19:58:16,986 - log/train6.log - INFO - iteration:58 step:8900/10100, NER loss: 0.874715
2019-02-21 19:58:19,149 - log/train6.log - INFO - iteration:58 step:9000/10100, NER loss: 0.807112
2019-02-21 19:58:21,242 - log/train6.log - INFO - iteration:58 step:9100/10100, NER loss: 0.744566
2019-02-21 19:58:23,637 - log/train6.log - INFO - iteration:58 step:9200/10100, NER loss: 1.330697
2019-02-21 19:58:25,910 - log/train6.log - INFO - iteration:58 step:9300/10100, NER loss: 0.909573
2019-02-21 19:58:28,023 - log/train6.log - INFO - iteration:58 step:9400/10100, NER loss: 1.019139
2019-02-21 19:58:30,318 - log/train6.log - INFO - iteration:58 step:9500/10100, NER loss: 0.834594
2019-02-21 19:58:32,657 - log/train6.log - INFO - iteration:58 step:9600/10100, NER loss: 1.163024
2019-02-21 19:58:35,076 - log/train6.log - INFO - iteration:58 step:9700/10100, NER loss: 0.960644
2019-02-21 19:58:37,245 - log/train6.log - INFO - iteration:58 step:9800/10100, NER loss: 0.891143
2019-02-21 19:58:39,145 - log/train6.log - INFO - iteration:58 step:9900/10100, NER loss: 0.658458
2019-02-21 19:58:41,350 - log/train6.log - INFO - iteration:58 step:10000/10100, NER loss: 0.877095
2019-02-21 19:58:43,582 - log/train6.log - INFO - iteration:59 step:0/10100, NER loss: 0.948739
2019-02-21 19:58:43,582 - log/train6.log - INFO - evaluate:dev
2019-02-21 19:58:50,083 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5432 phrases; correct: 4244.

2019-02-21 19:58:50,083 - log/train6.log - INFO - accuracy:  95.32%; precision:  78.13%; recall:  72.58%; FB1:  75.25

2019-02-21 19:58:50,083 - log/train6.log - INFO -                 C: precision:  86.60%; recall:  87.90%; FB1:  87.25  3440

2019-02-21 19:58:50,083 - log/train6.log - INFO -               IND: precision:  48.52%; recall:  20.10%; FB1:  28.42  169

2019-02-21 19:58:50,083 - log/train6.log - INFO -               INS: precision:  72.91%; recall:  68.87%; FB1:  70.83  358

2019-02-21 19:58:50,083 - log/train6.log - INFO -                 L: precision:  54.59%; recall:  50.00%; FB1:  52.20  555

2019-02-21 19:58:50,083 - log/train6.log - INFO -                 P: precision:  86.09%; recall:  91.16%; FB1:  88.55  575

2019-02-21 19:58:50,083 - log/train6.log - INFO -               PRO: precision:  37.01%; recall:  23.75%; FB1:  28.94  335

2019-02-21 19:58:50,086 - log/train6.log - INFO - evaluate:test
2019-02-21 19:58:51,541 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1629 phrases; correct: 1378.

2019-02-21 19:58:51,541 - log/train6.log - INFO - accuracy:  96.99%; precision:  84.59%; recall:  83.67%; FB1:  84.13

2019-02-21 19:58:51,541 - log/train6.log - INFO -                 C: precision:  88.58%; recall:  91.25%; FB1:  89.90  1060

2019-02-21 19:58:51,541 - log/train6.log - INFO -               IND: precision:  65.00%; recall:  55.32%; FB1:  59.77  40

2019-02-21 19:58:51,541 - log/train6.log - INFO -               INS: precision:  71.08%; recall:  62.11%; FB1:  66.29  83

2019-02-21 19:58:51,541 - log/train6.log - INFO -                 L: precision:  61.46%; recall:  57.28%; FB1:  59.30  96

2019-02-21 19:58:51,542 - log/train6.log - INFO -                 P: precision:  90.57%; recall:  94.12%; FB1:  92.31  212

2019-02-21 19:58:51,542 - log/train6.log - INFO -               PRO: precision:  74.64%; recall:  60.95%; FB1:  67.10  138

2019-02-21 19:58:53,688 - log/train6.log - INFO - iteration:59 step:100/10100, NER loss: 0.950783
2019-02-21 19:58:55,762 - log/train6.log - INFO - iteration:59 step:200/10100, NER loss: 0.719541
2019-02-21 19:58:57,774 - log/train6.log - INFO - iteration:59 step:300/10100, NER loss: 0.750025
2019-02-21 19:59:02,134 - log/train6.log - INFO - iteration:59 step:400/10100, NER loss: 1.395622
2019-02-21 19:59:04,522 - log/train6.log - INFO - iteration:59 step:500/10100, NER loss: 1.115912
2019-02-21 19:59:06,905 - log/train6.log - INFO - iteration:59 step:600/10100, NER loss: 1.069627
2019-02-21 19:59:08,874 - log/train6.log - INFO - iteration:59 step:700/10100, NER loss: 0.797568
2019-02-21 19:59:11,081 - log/train6.log - INFO - iteration:59 step:800/10100, NER loss: 0.779760
2019-02-21 19:59:13,134 - log/train6.log - INFO - iteration:59 step:900/10100, NER loss: 0.732492
2019-02-21 19:59:15,259 - log/train6.log - INFO - iteration:59 step:1000/10100, NER loss: 0.825988
2019-02-21 19:59:17,436 - log/train6.log - INFO - iteration:59 step:1100/10100, NER loss: 0.817986
2019-02-21 19:59:19,846 - log/train6.log - INFO - iteration:59 step:1200/10100, NER loss: 1.092520
2019-02-21 19:59:22,082 - log/train6.log - INFO - iteration:59 step:1300/10100, NER loss: 0.808145
2019-02-21 19:59:24,044 - log/train6.log - INFO - iteration:59 step:1400/10100, NER loss: 0.708044
2019-02-21 19:59:26,135 - log/train6.log - INFO - iteration:59 step:1500/10100, NER loss: 0.751184
2019-02-21 19:59:28,484 - log/train6.log - INFO - iteration:59 step:1600/10100, NER loss: 0.881874
2019-02-21 19:59:30,555 - log/train6.log - INFO - iteration:59 step:1700/10100, NER loss: 0.829988
2019-02-21 19:59:32,986 - log/train6.log - INFO - iteration:59 step:1800/10100, NER loss: 1.103814
2019-02-21 19:59:35,200 - log/train6.log - INFO - iteration:59 step:1900/10100, NER loss: 0.979996
2019-02-21 19:59:37,443 - log/train6.log - INFO - iteration:59 step:2000/10100, NER loss: 0.908876
2019-02-21 19:59:41,729 - log/train6.log - INFO - iteration:59 step:2100/10100, NER loss: 1.125835
2019-02-21 19:59:43,915 - log/train6.log - INFO - iteration:59 step:2200/10100, NER loss: 0.841790
2019-02-21 19:59:45,873 - log/train6.log - INFO - iteration:59 step:2300/10100, NER loss: 0.812361
2019-02-21 19:59:47,902 - log/train6.log - INFO - iteration:59 step:2400/10100, NER loss: 0.791602
2019-02-21 19:59:50,069 - log/train6.log - INFO - iteration:59 step:2500/10100, NER loss: 0.959610
2019-02-21 19:59:52,343 - log/train6.log - INFO - iteration:59 step:2600/10100, NER loss: 0.906873
2019-02-21 19:59:54,411 - log/train6.log - INFO - iteration:59 step:2700/10100, NER loss: 0.954203
2019-02-21 19:59:56,903 - log/train6.log - INFO - iteration:59 step:2800/10100, NER loss: 1.031284
2019-02-21 19:59:59,154 - log/train6.log - INFO - iteration:59 step:2900/10100, NER loss: 1.122637
2019-02-21 20:00:01,630 - log/train6.log - INFO - iteration:59 step:3000/10100, NER loss: 1.025862
2019-02-21 20:00:03,924 - log/train6.log - INFO - iteration:59 step:3100/10100, NER loss: 0.814493
2019-02-21 20:00:06,118 - log/train6.log - INFO - iteration:59 step:3200/10100, NER loss: 0.837812
2019-02-21 20:00:08,336 - log/train6.log - INFO - iteration:59 step:3300/10100, NER loss: 0.816130
2019-02-21 20:00:10,298 - log/train6.log - INFO - iteration:59 step:3400/10100, NER loss: 0.679376
2019-02-21 20:00:12,456 - log/train6.log - INFO - iteration:59 step:3500/10100, NER loss: 0.979033
2019-02-21 20:00:14,735 - log/train6.log - INFO - iteration:59 step:3600/10100, NER loss: 0.903295
2019-02-21 20:00:16,969 - log/train6.log - INFO - iteration:59 step:3700/10100, NER loss: 0.911419
2019-02-21 20:00:18,934 - log/train6.log - INFO - iteration:59 step:3800/10100, NER loss: 0.741808
2019-02-21 20:00:21,313 - log/train6.log - INFO - iteration:59 step:3900/10100, NER loss: 1.006203
2019-02-21 20:00:23,446 - log/train6.log - INFO - iteration:59 step:4000/10100, NER loss: 0.737150
2019-02-21 20:00:25,713 - log/train6.log - INFO - iteration:59 step:4100/10100, NER loss: 0.932324
2019-02-21 20:00:28,090 - log/train6.log - INFO - iteration:59 step:4200/10100, NER loss: 0.907636
2019-02-21 20:00:30,409 - log/train6.log - INFO - iteration:59 step:4300/10100, NER loss: 0.923844
2019-02-21 20:00:32,586 - log/train6.log - INFO - iteration:59 step:4400/10100, NER loss: 0.806055
2019-02-21 20:00:34,547 - log/train6.log - INFO - iteration:59 step:4500/10100, NER loss: 0.704002
2019-02-21 20:00:36,755 - log/train6.log - INFO - iteration:59 step:4600/10100, NER loss: 0.881401
2019-02-21 20:00:39,004 - log/train6.log - INFO - iteration:59 step:4700/10100, NER loss: 0.994726
2019-02-21 20:00:41,216 - log/train6.log - INFO - iteration:59 step:4800/10100, NER loss: 0.860261
2019-02-21 20:00:43,355 - log/train6.log - INFO - iteration:59 step:4900/10100, NER loss: 0.857442
2019-02-21 20:00:45,352 - log/train6.log - INFO - iteration:59 step:5000/10100, NER loss: 0.839290
2019-02-21 20:00:47,576 - log/train6.log - INFO - iteration:59 step:5100/10100, NER loss: 0.955155
2019-02-21 20:00:49,688 - log/train6.log - INFO - iteration:59 step:5200/10100, NER loss: 0.732364
2019-02-21 20:00:51,977 - log/train6.log - INFO - iteration:59 step:5300/10100, NER loss: 0.815358
2019-02-21 20:00:54,175 - log/train6.log - INFO - iteration:59 step:5400/10100, NER loss: 1.040983
2019-02-21 20:00:56,266 - log/train6.log - INFO - iteration:59 step:5500/10100, NER loss: 0.784478
2019-02-21 20:00:58,620 - log/train6.log - INFO - iteration:59 step:5600/10100, NER loss: 1.017255
2019-02-21 20:01:01,018 - log/train6.log - INFO - iteration:59 step:5700/10100, NER loss: 1.111742
2019-02-21 20:01:03,270 - log/train6.log - INFO - iteration:59 step:5800/10100, NER loss: 0.846346
2019-02-21 20:01:05,512 - log/train6.log - INFO - iteration:59 step:5900/10100, NER loss: 0.850777
2019-02-21 20:01:07,588 - log/train6.log - INFO - iteration:59 step:6000/10100, NER loss: 0.801318
2019-02-21 20:01:09,634 - log/train6.log - INFO - iteration:59 step:6100/10100, NER loss: 0.841309
2019-02-21 20:01:11,744 - log/train6.log - INFO - iteration:59 step:6200/10100, NER loss: 0.804941
2019-02-21 20:01:13,882 - log/train6.log - INFO - iteration:59 step:6300/10100, NER loss: 0.857106
2019-02-21 20:01:16,230 - log/train6.log - INFO - iteration:59 step:6400/10100, NER loss: 0.970112
2019-02-21 20:01:18,522 - log/train6.log - INFO - iteration:59 step:6500/10100, NER loss: 0.962440
2019-02-21 20:01:20,641 - log/train6.log - INFO - iteration:59 step:6600/10100, NER loss: 0.797694
2019-02-21 20:01:22,798 - log/train6.log - INFO - iteration:59 step:6700/10100, NER loss: 0.932526
2019-02-21 20:01:25,273 - log/train6.log - INFO - iteration:59 step:6800/10100, NER loss: 1.039698
2019-02-21 20:01:27,287 - log/train6.log - INFO - iteration:59 step:6900/10100, NER loss: 0.749958
2019-02-21 20:01:29,429 - log/train6.log - INFO - iteration:59 step:7000/10100, NER loss: 0.773894
2019-02-21 20:01:31,647 - log/train6.log - INFO - iteration:59 step:7100/10100, NER loss: 0.978313
2019-02-21 20:01:33,794 - log/train6.log - INFO - iteration:59 step:7200/10100, NER loss: 0.970929
2019-02-21 20:01:35,876 - log/train6.log - INFO - iteration:59 step:7300/10100, NER loss: 1.016801
2019-02-21 20:01:38,137 - log/train6.log - INFO - iteration:59 step:7400/10100, NER loss: 1.064048
2019-02-21 20:01:40,473 - log/train6.log - INFO - iteration:59 step:7500/10100, NER loss: 1.013700
2019-02-21 20:01:42,938 - log/train6.log - INFO - iteration:59 step:7600/10100, NER loss: 1.229217
2019-02-21 20:01:45,184 - log/train6.log - INFO - iteration:59 step:7700/10100, NER loss: 0.840439
2019-02-21 20:01:47,453 - log/train6.log - INFO - iteration:59 step:7800/10100, NER loss: 0.883606
2019-02-21 20:01:51,510 - log/train6.log - INFO - iteration:59 step:7900/10100, NER loss: 1.592447
2019-02-21 20:01:53,644 - log/train6.log - INFO - iteration:59 step:8000/10100, NER loss: 0.955881
2019-02-21 20:01:55,744 - log/train6.log - INFO - iteration:59 step:8100/10100, NER loss: 0.842015
2019-02-21 20:01:58,082 - log/train6.log - INFO - iteration:59 step:8200/10100, NER loss: 0.862328
2019-02-21 20:02:00,347 - log/train6.log - INFO - iteration:59 step:8300/10100, NER loss: 0.978120
2019-02-21 20:02:03,106 - log/train6.log - INFO - iteration:59 step:8400/10100, NER loss: 1.191087
2019-02-21 20:02:05,371 - log/train6.log - INFO - iteration:59 step:8500/10100, NER loss: 0.813573
2019-02-21 20:02:07,578 - log/train6.log - INFO - iteration:59 step:8600/10100, NER loss: 0.847678
2019-02-21 20:02:09,905 - log/train6.log - INFO - iteration:59 step:8700/10100, NER loss: 1.029732
2019-02-21 20:02:12,138 - log/train6.log - INFO - iteration:59 step:8800/10100, NER loss: 0.846053
2019-02-21 20:02:14,455 - log/train6.log - INFO - iteration:59 step:8900/10100, NER loss: 1.006603
2019-02-21 20:02:16,912 - log/train6.log - INFO - iteration:59 step:9000/10100, NER loss: 1.230351
2019-02-21 20:02:19,071 - log/train6.log - INFO - iteration:59 step:9100/10100, NER loss: 0.828020
2019-02-21 20:02:21,472 - log/train6.log - INFO - iteration:59 step:9200/10100, NER loss: 0.958768
2019-02-21 20:02:23,719 - log/train6.log - INFO - iteration:59 step:9300/10100, NER loss: 0.895671
2019-02-21 20:02:25,875 - log/train6.log - INFO - iteration:59 step:9400/10100, NER loss: 0.879641
2019-02-21 20:02:27,942 - log/train6.log - INFO - iteration:59 step:9500/10100, NER loss: 0.896721
2019-02-21 20:02:30,191 - log/train6.log - INFO - iteration:59 step:9600/10100, NER loss: 0.914828
2019-02-21 20:02:32,393 - log/train6.log - INFO - iteration:59 step:9700/10100, NER loss: 0.852638
2019-02-21 20:02:34,758 - log/train6.log - INFO - iteration:59 step:9800/10100, NER loss: 1.042543
2019-02-21 20:02:36,791 - log/train6.log - INFO - iteration:59 step:9900/10100, NER loss: 0.782332
2019-02-21 20:02:38,776 - log/train6.log - INFO - iteration:59 step:10000/10100, NER loss: 0.764030
2019-02-21 20:02:40,831 - log/train6.log - INFO - iteration:60 step:0/10100, NER loss: 1.005180
2019-02-21 20:02:40,831 - log/train6.log - INFO - evaluate:dev
2019-02-21 20:02:47,310 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5577 phrases; correct: 4323.

2019-02-21 20:02:47,311 - log/train6.log - INFO - accuracy:  95.42%; precision:  77.51%; recall:  73.94%; FB1:  75.68

2019-02-21 20:02:47,311 - log/train6.log - INFO -                 C: precision:  84.42%; recall:  88.43%; FB1:  86.38  3550

2019-02-21 20:02:47,311 - log/train6.log - INFO -               IND: precision:  46.96%; recall:  26.47%; FB1:  33.86  230

2019-02-21 20:02:47,311 - log/train6.log - INFO -               INS: precision:  77.48%; recall:  68.07%; FB1:  72.47  333

2019-02-21 20:02:47,311 - log/train6.log - INFO -                 L: precision:  59.06%; recall:  61.88%; FB1:  60.44  635

2019-02-21 20:02:47,311 - log/train6.log - INFO -                 P: precision:  90.63%; recall:  87.29%; FB1:  88.93  523

2019-02-21 20:02:47,311 - log/train6.log - INFO -               PRO: precision:  36.27%; recall:  21.26%; FB1:  26.81  306

2019-02-21 20:02:47,314 - log/train6.log - INFO - evaluate:test
2019-02-21 20:02:48,772 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1643 phrases; correct: 1363.

2019-02-21 20:02:48,772 - log/train6.log - INFO - accuracy:  96.82%; precision:  82.96%; recall:  82.76%; FB1:  82.86

2019-02-21 20:02:48,773 - log/train6.log - INFO -                 C: precision:  86.61%; recall:  91.74%; FB1:  89.10  1090

2019-02-21 20:02:48,773 - log/train6.log - INFO -               IND: precision:  54.90%; recall:  59.57%; FB1:  57.14  51

2019-02-21 20:02:48,773 - log/train6.log - INFO -               INS: precision:  74.36%; recall:  61.05%; FB1:  67.05  78

2019-02-21 20:02:48,773 - log/train6.log - INFO -                 L: precision:  54.64%; recall:  51.46%; FB1:  53.00  97

2019-02-21 20:02:48,773 - log/train6.log - INFO -                 P: precision:  92.57%; recall:  91.67%; FB1:  92.12  202

2019-02-21 20:02:48,773 - log/train6.log - INFO -               PRO: precision:  74.40%; recall:  55.03%; FB1:  63.27  125

2019-02-21 20:02:50,877 - log/train6.log - INFO - iteration:60 step:100/10100, NER loss: 0.947038
2019-02-21 20:02:52,859 - log/train6.log - INFO - iteration:60 step:200/10100, NER loss: 0.870180
2019-02-21 20:02:54,786 - log/train6.log - INFO - iteration:60 step:300/10100, NER loss: 0.869913
2019-02-21 20:02:56,999 - log/train6.log - INFO - iteration:60 step:400/10100, NER loss: 0.897528
2019-02-21 20:02:59,464 - log/train6.log - INFO - iteration:60 step:500/10100, NER loss: 1.128682
2019-02-21 20:03:01,638 - log/train6.log - INFO - iteration:60 step:600/10100, NER loss: 0.899424
2019-02-21 20:03:03,948 - log/train6.log - INFO - iteration:60 step:700/10100, NER loss: 0.999183
2019-02-21 20:03:06,168 - log/train6.log - INFO - iteration:60 step:800/10100, NER loss: 0.853787
2019-02-21 20:03:08,342 - log/train6.log - INFO - iteration:60 step:900/10100, NER loss: 0.605053
2019-02-21 20:03:10,609 - log/train6.log - INFO - iteration:60 step:1000/10100, NER loss: 0.883951
2019-02-21 20:03:12,753 - log/train6.log - INFO - iteration:60 step:1100/10100, NER loss: 0.867880
2019-02-21 20:03:14,988 - log/train6.log - INFO - iteration:60 step:1200/10100, NER loss: 0.859738
2019-02-21 20:03:17,101 - log/train6.log - INFO - iteration:60 step:1300/10100, NER loss: 0.923719
2019-02-21 20:03:19,111 - log/train6.log - INFO - iteration:60 step:1400/10100, NER loss: 0.843340
2019-02-21 20:03:21,196 - log/train6.log - INFO - iteration:60 step:1500/10100, NER loss: 0.799816
2019-02-21 20:03:23,343 - log/train6.log - INFO - iteration:60 step:1600/10100, NER loss: 0.833128
2019-02-21 20:03:25,680 - log/train6.log - INFO - iteration:60 step:1700/10100, NER loss: 0.931152
2019-02-21 20:03:27,804 - log/train6.log - INFO - iteration:60 step:1800/10100, NER loss: 0.880142
2019-02-21 20:03:30,296 - log/train6.log - INFO - iteration:60 step:1900/10100, NER loss: 0.992331
2019-02-21 20:03:32,661 - log/train6.log - INFO - iteration:60 step:2000/10100, NER loss: 1.075671
2019-02-21 20:03:35,046 - log/train6.log - INFO - iteration:60 step:2100/10100, NER loss: 1.071485
2019-02-21 20:03:37,197 - log/train6.log - INFO - iteration:60 step:2200/10100, NER loss: 0.844425
2019-02-21 20:03:39,442 - log/train6.log - INFO - iteration:60 step:2300/10100, NER loss: 0.890571
2019-02-21 20:03:41,468 - log/train6.log - INFO - iteration:60 step:2400/10100, NER loss: 0.729631
2019-02-21 20:03:43,647 - log/train6.log - INFO - iteration:60 step:2500/10100, NER loss: 0.895607
2019-02-21 20:03:45,490 - log/train6.log - INFO - iteration:60 step:2600/10100, NER loss: 0.673185
2019-02-21 20:03:47,713 - log/train6.log - INFO - iteration:60 step:2700/10100, NER loss: 0.946392
2019-02-21 20:03:49,805 - log/train6.log - INFO - iteration:60 step:2800/10100, NER loss: 0.877957
2019-02-21 20:03:52,078 - log/train6.log - INFO - iteration:60 step:2900/10100, NER loss: 0.889907
2019-02-21 20:03:54,095 - log/train6.log - INFO - iteration:60 step:3000/10100, NER loss: 0.712936
2019-02-21 20:03:56,345 - log/train6.log - INFO - iteration:60 step:3100/10100, NER loss: 1.045972
2019-02-21 20:03:58,455 - log/train6.log - INFO - iteration:60 step:3200/10100, NER loss: 0.879495
2019-02-21 20:04:00,561 - log/train6.log - INFO - iteration:60 step:3300/10100, NER loss: 0.873176
2019-02-21 20:04:02,851 - log/train6.log - INFO - iteration:60 step:3400/10100, NER loss: 0.831666
2019-02-21 20:04:04,980 - log/train6.log - INFO - iteration:60 step:3500/10100, NER loss: 0.813558
2019-02-21 20:04:07,587 - log/train6.log - INFO - iteration:60 step:3600/10100, NER loss: 1.147020
2019-02-21 20:04:09,735 - log/train6.log - INFO - iteration:60 step:3700/10100, NER loss: 1.074690
2019-02-21 20:04:11,721 - log/train6.log - INFO - iteration:60 step:3800/10100, NER loss: 0.755825
2019-02-21 20:04:14,126 - log/train6.log - INFO - iteration:60 step:3900/10100, NER loss: 1.036568
2019-02-21 20:04:16,602 - log/train6.log - INFO - iteration:60 step:4000/10100, NER loss: 0.980785
2019-02-21 20:04:18,920 - log/train6.log - INFO - iteration:60 step:4100/10100, NER loss: 1.095508
2019-02-21 20:04:23,427 - log/train6.log - INFO - iteration:60 step:4200/10100, NER loss: 1.803862
2019-02-21 20:04:27,562 - log/train6.log - INFO - iteration:60 step:4300/10100, NER loss: 1.397080
2019-02-21 20:04:29,583 - log/train6.log - INFO - iteration:60 step:4400/10100, NER loss: 0.719688
2019-02-21 20:04:31,767 - log/train6.log - INFO - iteration:60 step:4500/10100, NER loss: 1.038085
2019-02-21 20:04:34,188 - log/train6.log - INFO - iteration:60 step:4600/10100, NER loss: 0.957484
2019-02-21 20:04:36,295 - log/train6.log - INFO - iteration:60 step:4700/10100, NER loss: 0.780064
2019-02-21 20:04:38,571 - log/train6.log - INFO - iteration:60 step:4800/10100, NER loss: 0.916968
2019-02-21 20:04:40,764 - log/train6.log - INFO - iteration:60 step:4900/10100, NER loss: 0.831475
2019-02-21 20:04:42,953 - log/train6.log - INFO - iteration:60 step:5000/10100, NER loss: 0.920689
2019-02-21 20:04:45,219 - log/train6.log - INFO - iteration:60 step:5100/10100, NER loss: 1.045625
2019-02-21 20:04:47,472 - log/train6.log - INFO - iteration:60 step:5200/10100, NER loss: 0.794525
2019-02-21 20:04:49,724 - log/train6.log - INFO - iteration:60 step:5300/10100, NER loss: 1.124069
2019-02-21 20:04:52,299 - log/train6.log - INFO - iteration:60 step:5400/10100, NER loss: 0.980534
2019-02-21 20:04:54,376 - log/train6.log - INFO - iteration:60 step:5500/10100, NER loss: 0.947066
2019-02-21 20:04:56,661 - log/train6.log - INFO - iteration:60 step:5600/10100, NER loss: 0.962747
2019-02-21 20:04:58,960 - log/train6.log - INFO - iteration:60 step:5700/10100, NER loss: 0.882022
2019-02-21 20:05:01,235 - log/train6.log - INFO - iteration:60 step:5800/10100, NER loss: 0.854066
2019-02-21 20:05:03,418 - log/train6.log - INFO - iteration:60 step:5900/10100, NER loss: 0.838524
2019-02-21 20:05:05,557 - log/train6.log - INFO - iteration:60 step:6000/10100, NER loss: 0.736295
2019-02-21 20:05:07,762 - log/train6.log - INFO - iteration:60 step:6100/10100, NER loss: 0.912489
2019-02-21 20:05:10,122 - log/train6.log - INFO - iteration:60 step:6200/10100, NER loss: 1.079750
2019-02-21 20:05:12,341 - log/train6.log - INFO - iteration:60 step:6300/10100, NER loss: 0.914261
2019-02-21 20:05:14,310 - log/train6.log - INFO - iteration:60 step:6400/10100, NER loss: 0.725765
2019-02-21 20:05:16,683 - log/train6.log - INFO - iteration:60 step:6500/10100, NER loss: 0.954253
2019-02-21 20:05:18,855 - log/train6.log - INFO - iteration:60 step:6600/10100, NER loss: 0.860784
2019-02-21 20:05:21,159 - log/train6.log - INFO - iteration:60 step:6700/10100, NER loss: 0.870776
2019-02-21 20:05:23,289 - log/train6.log - INFO - iteration:60 step:6800/10100, NER loss: 0.900313
2019-02-21 20:05:25,546 - log/train6.log - INFO - iteration:60 step:6900/10100, NER loss: 0.995898
2019-02-21 20:05:27,660 - log/train6.log - INFO - iteration:60 step:7000/10100, NER loss: 0.794095
2019-02-21 20:05:29,884 - log/train6.log - INFO - iteration:60 step:7100/10100, NER loss: 0.966171
2019-02-21 20:05:32,014 - log/train6.log - INFO - iteration:60 step:7200/10100, NER loss: 0.931678
2019-02-21 20:05:34,325 - log/train6.log - INFO - iteration:60 step:7300/10100, NER loss: 1.058950
2019-02-21 20:05:36,366 - log/train6.log - INFO - iteration:60 step:7400/10100, NER loss: 0.816422
2019-02-21 20:05:38,499 - log/train6.log - INFO - iteration:60 step:7500/10100, NER loss: 0.801005
2019-02-21 20:05:41,078 - log/train6.log - INFO - iteration:60 step:7600/10100, NER loss: 1.183379
2019-02-21 20:05:43,315 - log/train6.log - INFO - iteration:60 step:7700/10100, NER loss: 0.885566
2019-02-21 20:05:45,309 - log/train6.log - INFO - iteration:60 step:7800/10100, NER loss: 0.689254
2019-02-21 20:05:47,670 - log/train6.log - INFO - iteration:60 step:7900/10100, NER loss: 0.993668
2019-02-21 20:05:49,996 - log/train6.log - INFO - iteration:60 step:8000/10100, NER loss: 0.960848
2019-02-21 20:05:52,378 - log/train6.log - INFO - iteration:60 step:8100/10100, NER loss: 1.035109
2019-02-21 20:05:54,659 - log/train6.log - INFO - iteration:60 step:8200/10100, NER loss: 0.933115
2019-02-21 20:05:56,850 - log/train6.log - INFO - iteration:60 step:8300/10100, NER loss: 0.786257
2019-02-21 20:05:59,223 - log/train6.log - INFO - iteration:60 step:8400/10100, NER loss: 1.066282
2019-02-21 20:06:01,369 - log/train6.log - INFO - iteration:60 step:8500/10100, NER loss: 0.861252
2019-02-21 20:06:03,532 - log/train6.log - INFO - iteration:60 step:8600/10100, NER loss: 0.893829
2019-02-21 20:06:05,689 - log/train6.log - INFO - iteration:60 step:8700/10100, NER loss: 0.835884
2019-02-21 20:06:07,900 - log/train6.log - INFO - iteration:60 step:8800/10100, NER loss: 0.896288
2019-02-21 20:06:09,976 - log/train6.log - INFO - iteration:60 step:8900/10100, NER loss: 0.831440
2019-02-21 20:06:12,097 - log/train6.log - INFO - iteration:60 step:9000/10100, NER loss: 0.956348
2019-02-21 20:06:14,168 - log/train6.log - INFO - iteration:60 step:9100/10100, NER loss: 0.763068
2019-02-21 20:06:16,277 - log/train6.log - INFO - iteration:60 step:9200/10100, NER loss: 0.846209
2019-02-21 20:06:18,529 - log/train6.log - INFO - iteration:60 step:9300/10100, NER loss: 1.332140
2019-02-21 20:06:20,504 - log/train6.log - INFO - iteration:60 step:9400/10100, NER loss: 0.600347
2019-02-21 20:06:22,571 - log/train6.log - INFO - iteration:60 step:9500/10100, NER loss: 0.781478
2019-02-21 20:06:24,939 - log/train6.log - INFO - iteration:60 step:9600/10100, NER loss: 1.113811
2019-02-21 20:06:29,052 - log/train6.log - INFO - iteration:60 step:9700/10100, NER loss: 1.590318
2019-02-21 20:06:31,116 - log/train6.log - INFO - iteration:60 step:9800/10100, NER loss: 0.802793
2019-02-21 20:06:33,270 - log/train6.log - INFO - iteration:60 step:9900/10100, NER loss: 0.868120
2019-02-21 20:06:35,509 - log/train6.log - INFO - iteration:60 step:10000/10100, NER loss: 0.847669
2019-02-21 20:06:37,706 - log/train6.log - INFO - iteration:61 step:0/10100, NER loss: 1.018349
2019-02-21 20:06:37,707 - log/train6.log - INFO - evaluate:dev
2019-02-21 20:06:44,174 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5229 phrases; correct: 4163.

2019-02-21 20:06:44,174 - log/train6.log - INFO - accuracy:  95.21%; precision:  79.61%; recall:  71.20%; FB1:  75.17

2019-02-21 20:06:44,174 - log/train6.log - INFO -                 C: precision:  87.90%; recall:  85.13%; FB1:  86.49  3282

2019-02-21 20:06:44,174 - log/train6.log - INFO -               IND: precision:  38.83%; recall:  25.98%; FB1:  31.13  273

2019-02-21 20:06:44,174 - log/train6.log - INFO -               INS: precision:  71.58%; recall:  70.45%; FB1:  71.01  373

2019-02-21 20:06:44,174 - log/train6.log - INFO -                 L: precision:  58.04%; recall:  62.54%; FB1:  60.21  653

2019-02-21 20:06:44,174 - log/train6.log - INFO -                 P: precision:  87.92%; recall:  91.16%; FB1:  89.51  563

2019-02-21 20:06:44,174 - log/train6.log - INFO -               PRO: precision:  36.47%; recall:   5.94%; FB1:  10.21  85

2019-02-21 20:06:44,177 - log/train6.log - INFO - evaluate:test
2019-02-21 20:06:45,639 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1549 phrases; correct: 1312.

2019-02-21 20:06:45,639 - log/train6.log - INFO - accuracy:  96.38%; precision:  84.70%; recall:  79.66%; FB1:  82.10

2019-02-21 20:06:45,639 - log/train6.log - INFO -                 C: precision:  88.84%; recall:  89.70%; FB1:  89.26  1039

2019-02-21 20:06:45,639 - log/train6.log - INFO -               IND: precision:  50.00%; recall:  63.83%; FB1:  56.07  60

2019-02-21 20:06:45,639 - log/train6.log - INFO -               INS: precision:  70.11%; recall:  64.21%; FB1:  67.03  87

2019-02-21 20:06:45,639 - log/train6.log - INFO -                 L: precision:  58.10%; recall:  59.22%; FB1:  58.65  105

2019-02-21 20:06:45,639 - log/train6.log - INFO -                 P: precision:  92.82%; recall:  95.10%; FB1:  93.95  209

2019-02-21 20:06:45,639 - log/train6.log - INFO -               PRO: precision:  87.76%; recall:  25.44%; FB1:  39.45  49

2019-02-21 20:06:47,781 - log/train6.log - INFO - iteration:61 step:100/10100, NER loss: 0.889790
2019-02-21 20:06:49,997 - log/train6.log - INFO - iteration:61 step:200/10100, NER loss: 1.057313
2019-02-21 20:06:52,161 - log/train6.log - INFO - iteration:61 step:300/10100, NER loss: 0.875227
2019-02-21 20:06:54,401 - log/train6.log - INFO - iteration:61 step:400/10100, NER loss: 0.880547
2019-02-21 20:06:56,833 - log/train6.log - INFO - iteration:61 step:500/10100, NER loss: 1.053178
2019-02-21 20:06:59,056 - log/train6.log - INFO - iteration:61 step:600/10100, NER loss: 0.854141
2019-02-21 20:07:01,122 - log/train6.log - INFO - iteration:61 step:700/10100, NER loss: 0.732979
2019-02-21 20:07:03,302 - log/train6.log - INFO - iteration:61 step:800/10100, NER loss: 0.815257
2019-02-21 20:07:05,482 - log/train6.log - INFO - iteration:61 step:900/10100, NER loss: 0.942837
2019-02-21 20:07:07,434 - log/train6.log - INFO - iteration:61 step:1000/10100, NER loss: 0.884977
2019-02-21 20:07:09,420 - log/train6.log - INFO - iteration:61 step:1100/10100, NER loss: 0.752791
2019-02-21 20:07:11,643 - log/train6.log - INFO - iteration:61 step:1200/10100, NER loss: 0.895309
2019-02-21 20:07:13,832 - log/train6.log - INFO - iteration:61 step:1300/10100, NER loss: 0.906306
2019-02-21 20:07:15,943 - log/train6.log - INFO - iteration:61 step:1400/10100, NER loss: 0.861436
2019-02-21 20:07:18,027 - log/train6.log - INFO - iteration:61 step:1500/10100, NER loss: 0.784579
2019-02-21 20:07:20,356 - log/train6.log - INFO - iteration:61 step:1600/10100, NER loss: 0.985764
2019-02-21 20:07:22,535 - log/train6.log - INFO - iteration:61 step:1700/10100, NER loss: 0.795323
2019-02-21 20:07:24,700 - log/train6.log - INFO - iteration:61 step:1800/10100, NER loss: 0.852852
2019-02-21 20:07:27,005 - log/train6.log - INFO - iteration:61 step:1900/10100, NER loss: 0.869818
2019-02-21 20:07:29,519 - log/train6.log - INFO - iteration:61 step:2000/10100, NER loss: 1.263666
2019-02-21 20:07:31,727 - log/train6.log - INFO - iteration:61 step:2100/10100, NER loss: 0.896111
2019-02-21 20:07:33,614 - log/train6.log - INFO - iteration:61 step:2200/10100, NER loss: 0.691499
2019-02-21 20:07:35,598 - log/train6.log - INFO - iteration:61 step:2300/10100, NER loss: 0.829686
2019-02-21 20:07:37,767 - log/train6.log - INFO - iteration:61 step:2400/10100, NER loss: 0.990703
2019-02-21 20:07:39,828 - log/train6.log - INFO - iteration:61 step:2500/10100, NER loss: 0.714192
2019-02-21 20:07:42,091 - log/train6.log - INFO - iteration:61 step:2600/10100, NER loss: 0.963833
2019-02-21 20:07:44,269 - log/train6.log - INFO - iteration:61 step:2700/10100, NER loss: 0.811488
2019-02-21 20:07:46,259 - log/train6.log - INFO - iteration:61 step:2800/10100, NER loss: 0.716548
2019-02-21 20:07:48,767 - log/train6.log - INFO - iteration:61 step:2900/10100, NER loss: 1.372684
2019-02-21 20:07:50,873 - log/train6.log - INFO - iteration:61 step:3000/10100, NER loss: 0.904969
2019-02-21 20:07:55,111 - log/train6.log - INFO - iteration:61 step:3100/10100, NER loss: 1.545215
2019-02-21 20:07:57,293 - log/train6.log - INFO - iteration:61 step:3200/10100, NER loss: 0.910198
2019-02-21 20:07:59,459 - log/train6.log - INFO - iteration:61 step:3300/10100, NER loss: 0.958627
2019-02-21 20:08:01,691 - log/train6.log - INFO - iteration:61 step:3400/10100, NER loss: 0.890368
2019-02-21 20:08:04,032 - log/train6.log - INFO - iteration:61 step:3500/10100, NER loss: 0.936374
2019-02-21 20:08:06,377 - log/train6.log - INFO - iteration:61 step:3600/10100, NER loss: 1.046785
2019-02-21 20:08:08,909 - log/train6.log - INFO - iteration:61 step:3700/10100, NER loss: 0.988595
2019-02-21 20:08:10,946 - log/train6.log - INFO - iteration:61 step:3800/10100, NER loss: 0.828933
2019-02-21 20:08:13,111 - log/train6.log - INFO - iteration:61 step:3900/10100, NER loss: 0.951564
2019-02-21 20:08:15,412 - log/train6.log - INFO - iteration:61 step:4000/10100, NER loss: 0.963538
2019-02-21 20:08:17,408 - log/train6.log - INFO - iteration:61 step:4100/10100, NER loss: 0.779180
2019-02-21 20:08:19,756 - log/train6.log - INFO - iteration:61 step:4200/10100, NER loss: 1.271119
2019-02-21 20:08:22,008 - log/train6.log - INFO - iteration:61 step:4300/10100, NER loss: 1.016674
2019-02-21 20:08:24,287 - log/train6.log - INFO - iteration:61 step:4400/10100, NER loss: 0.831254
2019-02-21 20:08:28,890 - log/train6.log - INFO - iteration:61 step:4500/10100, NER loss: 2.427932
2019-02-21 20:08:31,058 - log/train6.log - INFO - iteration:61 step:4600/10100, NER loss: 1.057778
2019-02-21 20:08:33,093 - log/train6.log - INFO - iteration:61 step:4700/10100, NER loss: 0.862509
2019-02-21 20:08:35,145 - log/train6.log - INFO - iteration:61 step:4800/10100, NER loss: 0.849447
2019-02-21 20:08:37,234 - log/train6.log - INFO - iteration:61 step:4900/10100, NER loss: 0.920903
2019-02-21 20:08:39,616 - log/train6.log - INFO - iteration:61 step:5000/10100, NER loss: 0.851948
2019-02-21 20:08:41,854 - log/train6.log - INFO - iteration:61 step:5100/10100, NER loss: 1.047136
2019-02-21 20:08:44,557 - log/train6.log - INFO - iteration:61 step:5200/10100, NER loss: 1.230725
2019-02-21 20:08:46,640 - log/train6.log - INFO - iteration:61 step:5300/10100, NER loss: 0.794792
2019-02-21 20:08:48,954 - log/train6.log - INFO - iteration:61 step:5400/10100, NER loss: 0.869335
2019-02-21 20:08:51,059 - log/train6.log - INFO - iteration:61 step:5500/10100, NER loss: 0.800064
2019-02-21 20:08:53,174 - log/train6.log - INFO - iteration:61 step:5600/10100, NER loss: 0.848947
2019-02-21 20:08:55,425 - log/train6.log - INFO - iteration:61 step:5700/10100, NER loss: 0.922298
2019-02-21 20:08:57,525 - log/train6.log - INFO - iteration:61 step:5800/10100, NER loss: 0.798602
2019-02-21 20:08:59,834 - log/train6.log - INFO - iteration:61 step:5900/10100, NER loss: 1.015869
2019-02-21 20:09:01,869 - log/train6.log - INFO - iteration:61 step:6000/10100, NER loss: 0.855007
2019-02-21 20:09:04,174 - log/train6.log - INFO - iteration:61 step:6100/10100, NER loss: 0.951592
2019-02-21 20:09:06,304 - log/train6.log - INFO - iteration:61 step:6200/10100, NER loss: 0.769385
2019-02-21 20:09:08,608 - log/train6.log - INFO - iteration:61 step:6300/10100, NER loss: 0.971772
2019-02-21 20:09:10,670 - log/train6.log - INFO - iteration:61 step:6400/10100, NER loss: 0.759481
2019-02-21 20:09:12,941 - log/train6.log - INFO - iteration:61 step:6500/10100, NER loss: 0.930306
2019-02-21 20:09:15,465 - log/train6.log - INFO - iteration:61 step:6600/10100, NER loss: 1.042126
2019-02-21 20:09:17,713 - log/train6.log - INFO - iteration:61 step:6700/10100, NER loss: 0.868025
2019-02-21 20:09:19,771 - log/train6.log - INFO - iteration:61 step:6800/10100, NER loss: 0.760087
2019-02-21 20:09:22,037 - log/train6.log - INFO - iteration:61 step:6900/10100, NER loss: 0.911302
2019-02-21 20:09:24,357 - log/train6.log - INFO - iteration:61 step:7000/10100, NER loss: 0.944702
2019-02-21 20:09:26,539 - log/train6.log - INFO - iteration:61 step:7100/10100, NER loss: 0.834521
2019-02-21 20:09:28,650 - log/train6.log - INFO - iteration:61 step:7200/10100, NER loss: 0.773582
2019-02-21 20:09:30,747 - log/train6.log - INFO - iteration:61 step:7300/10100, NER loss: 0.898886
2019-02-21 20:09:32,973 - log/train6.log - INFO - iteration:61 step:7400/10100, NER loss: 0.885010
2019-02-21 20:09:37,157 - log/train6.log - INFO - iteration:61 step:7500/10100, NER loss: 2.115868
2019-02-21 20:09:39,258 - log/train6.log - INFO - iteration:61 step:7600/10100, NER loss: 0.825145
2019-02-21 20:09:41,305 - log/train6.log - INFO - iteration:61 step:7700/10100, NER loss: 0.809275
2019-02-21 20:09:43,667 - log/train6.log - INFO - iteration:61 step:7800/10100, NER loss: 0.907949
2019-02-21 20:09:45,663 - log/train6.log - INFO - iteration:61 step:7900/10100, NER loss: 0.790292
2019-02-21 20:09:48,118 - log/train6.log - INFO - iteration:61 step:8000/10100, NER loss: 1.137622
2019-02-21 20:09:50,259 - log/train6.log - INFO - iteration:61 step:8100/10100, NER loss: 0.882290
2019-02-21 20:09:52,824 - log/train6.log - INFO - iteration:61 step:8200/10100, NER loss: 0.985257
2019-02-21 20:09:54,986 - log/train6.log - INFO - iteration:61 step:8300/10100, NER loss: 0.876513
2019-02-21 20:09:57,035 - log/train6.log - INFO - iteration:61 step:8400/10100, NER loss: 0.791618
2019-02-21 20:09:59,504 - log/train6.log - INFO - iteration:61 step:8500/10100, NER loss: 1.032856
2019-02-21 20:10:01,697 - log/train6.log - INFO - iteration:61 step:8600/10100, NER loss: 0.819823
2019-02-21 20:10:03,867 - log/train6.log - INFO - iteration:61 step:8700/10100, NER loss: 0.824188
2019-02-21 20:10:06,010 - log/train6.log - INFO - iteration:61 step:8800/10100, NER loss: 0.833503
2019-02-21 20:10:08,139 - log/train6.log - INFO - iteration:61 step:8900/10100, NER loss: 0.900059
2019-02-21 20:10:10,164 - log/train6.log - INFO - iteration:61 step:9000/10100, NER loss: 1.060482
2019-02-21 20:10:12,189 - log/train6.log - INFO - iteration:61 step:9100/10100, NER loss: 0.780367
2019-02-21 20:10:14,211 - log/train6.log - INFO - iteration:61 step:9200/10100, NER loss: 0.813330
2019-02-21 20:10:16,451 - log/train6.log - INFO - iteration:61 step:9300/10100, NER loss: 0.812391
2019-02-21 20:10:18,737 - log/train6.log - INFO - iteration:61 step:9400/10100, NER loss: 0.826091
2019-02-21 20:10:20,809 - log/train6.log - INFO - iteration:61 step:9500/10100, NER loss: 0.780406
2019-02-21 20:10:23,119 - log/train6.log - INFO - iteration:61 step:9600/10100, NER loss: 1.062087
2019-02-21 20:10:25,250 - log/train6.log - INFO - iteration:61 step:9700/10100, NER loss: 0.924894
2019-02-21 20:10:27,565 - log/train6.log - INFO - iteration:61 step:9800/10100, NER loss: 0.990100
2019-02-21 20:10:29,655 - log/train6.log - INFO - iteration:61 step:9900/10100, NER loss: 0.815752
2019-02-21 20:10:31,949 - log/train6.log - INFO - iteration:61 step:10000/10100, NER loss: 1.024266
2019-02-21 20:10:33,926 - log/train6.log - INFO - iteration:62 step:0/10100, NER loss: 0.672248
2019-02-21 20:10:33,926 - log/train6.log - INFO - evaluate:dev
2019-02-21 20:10:40,475 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5612 phrases; correct: 4315.

2019-02-21 20:10:40,475 - log/train6.log - INFO - accuracy:  95.24%; precision:  76.89%; recall:  73.80%; FB1:  75.31

2019-02-21 20:10:40,475 - log/train6.log - INFO -                 C: precision:  84.19%; recall:  89.08%; FB1:  86.57  3586

2019-02-21 20:10:40,475 - log/train6.log - INFO -               IND: precision:  34.53%; recall:  25.98%; FB1:  29.65  307

2019-02-21 20:10:40,475 - log/train6.log - INFO -               INS: precision:  78.16%; recall:  65.17%; FB1:  71.08  316

2019-02-21 20:10:40,475 - log/train6.log - INFO -                 L: precision:  57.42%; recall:  63.20%; FB1:  60.17  667

2019-02-21 20:10:40,475 - log/train6.log - INFO -                 P: precision:  90.64%; recall:  90.98%; FB1:  90.81  545

2019-02-21 20:10:40,475 - log/train6.log - INFO -               PRO: precision:  34.55%; recall:  12.64%; FB1:  18.51  191

2019-02-21 20:10:40,478 - log/train6.log - INFO - evaluate:test
2019-02-21 20:10:41,934 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1639 phrases; correct: 1336.

2019-02-21 20:10:41,934 - log/train6.log - INFO - accuracy:  96.47%; precision:  81.51%; recall:  81.12%; FB1:  81.31

2019-02-21 20:10:41,934 - log/train6.log - INFO -                 C: precision:  85.55%; recall:  91.45%; FB1:  88.40  1100

2019-02-21 20:10:41,934 - log/train6.log - INFO -               IND: precision:  45.45%; recall:  63.83%; FB1:  53.10  66

2019-02-21 20:10:41,934 - log/train6.log - INFO -               INS: precision:  73.33%; recall:  57.89%; FB1:  64.71  75

2019-02-21 20:10:41,935 - log/train6.log - INFO -                 L: precision:  50.00%; recall:  52.43%; FB1:  51.18  108

2019-02-21 20:10:41,935 - log/train6.log - INFO -                 P: precision:  90.87%; recall:  92.65%; FB1:  91.75  208

2019-02-21 20:10:41,935 - log/train6.log - INFO -               PRO: precision:  81.71%; recall:  39.64%; FB1:  53.39  82

2019-02-21 20:10:43,926 - log/train6.log - INFO - iteration:62 step:100/10100, NER loss: 0.922510
2019-02-21 20:10:46,011 - log/train6.log - INFO - iteration:62 step:200/10100, NER loss: 0.977399
2019-02-21 20:10:48,173 - log/train6.log - INFO - iteration:62 step:300/10100, NER loss: 1.102943
2019-02-21 20:10:50,433 - log/train6.log - INFO - iteration:62 step:400/10100, NER loss: 0.881597
2019-02-21 20:10:52,864 - log/train6.log - INFO - iteration:62 step:500/10100, NER loss: 1.031513
2019-02-21 20:10:55,118 - log/train6.log - INFO - iteration:62 step:600/10100, NER loss: 0.846824
2019-02-21 20:10:56,957 - log/train6.log - INFO - iteration:62 step:700/10100, NER loss: 0.748077
2019-02-21 20:10:58,988 - log/train6.log - INFO - iteration:62 step:800/10100, NER loss: 0.840930
2019-02-21 20:11:01,227 - log/train6.log - INFO - iteration:62 step:900/10100, NER loss: 0.864904
2019-02-21 20:11:05,785 - log/train6.log - INFO - iteration:62 step:1000/10100, NER loss: 2.184475
2019-02-21 20:11:08,221 - log/train6.log - INFO - iteration:62 step:1100/10100, NER loss: 1.200066
2019-02-21 20:11:10,520 - log/train6.log - INFO - iteration:62 step:1200/10100, NER loss: 1.008576
2019-02-21 20:11:12,591 - log/train6.log - INFO - iteration:62 step:1300/10100, NER loss: 0.704331
2019-02-21 20:11:14,751 - log/train6.log - INFO - iteration:62 step:1400/10100, NER loss: 0.871587
2019-02-21 20:11:16,897 - log/train6.log - INFO - iteration:62 step:1500/10100, NER loss: 0.974835
2019-02-21 20:11:19,115 - log/train6.log - INFO - iteration:62 step:1600/10100, NER loss: 0.897450
2019-02-21 20:11:21,443 - log/train6.log - INFO - iteration:62 step:1700/10100, NER loss: 1.077272
2019-02-21 20:11:23,782 - log/train6.log - INFO - iteration:62 step:1800/10100, NER loss: 0.934515
2019-02-21 20:11:26,040 - log/train6.log - INFO - iteration:62 step:1900/10100, NER loss: 0.992838
2019-02-21 20:11:28,134 - log/train6.log - INFO - iteration:62 step:2000/10100, NER loss: 0.855747
2019-02-21 20:11:30,297 - log/train6.log - INFO - iteration:62 step:2100/10100, NER loss: 0.943910
2019-02-21 20:11:32,471 - log/train6.log - INFO - iteration:62 step:2200/10100, NER loss: 0.790809
2019-02-21 20:11:34,849 - log/train6.log - INFO - iteration:62 step:2300/10100, NER loss: 1.175314
2019-02-21 20:11:36,967 - log/train6.log - INFO - iteration:62 step:2400/10100, NER loss: 0.798890
2019-02-21 20:11:39,109 - log/train6.log - INFO - iteration:62 step:2500/10100, NER loss: 0.920800
2019-02-21 20:11:41,144 - log/train6.log - INFO - iteration:62 step:2600/10100, NER loss: 0.928569
2019-02-21 20:11:43,165 - log/train6.log - INFO - iteration:62 step:2700/10100, NER loss: 0.891611
2019-02-21 20:11:45,467 - log/train6.log - INFO - iteration:62 step:2800/10100, NER loss: 0.969701
2019-02-21 20:11:47,772 - log/train6.log - INFO - iteration:62 step:2900/10100, NER loss: 0.926079
2019-02-21 20:11:49,975 - log/train6.log - INFO - iteration:62 step:3000/10100, NER loss: 0.903537
2019-02-21 20:11:52,026 - log/train6.log - INFO - iteration:62 step:3100/10100, NER loss: 0.709768
2019-02-21 20:11:54,027 - log/train6.log - INFO - iteration:62 step:3200/10100, NER loss: 0.843398
2019-02-21 20:11:56,188 - log/train6.log - INFO - iteration:62 step:3300/10100, NER loss: 0.819157
2019-02-21 20:11:58,276 - log/train6.log - INFO - iteration:62 step:3400/10100, NER loss: 0.804812
2019-02-21 20:12:00,616 - log/train6.log - INFO - iteration:62 step:3500/10100, NER loss: 0.965517
2019-02-21 20:12:02,658 - log/train6.log - INFO - iteration:62 step:3600/10100, NER loss: 0.769806
2019-02-21 20:12:04,797 - log/train6.log - INFO - iteration:62 step:3700/10100, NER loss: 0.972431
2019-02-21 20:12:07,119 - log/train6.log - INFO - iteration:62 step:3800/10100, NER loss: 0.895210
2019-02-21 20:12:09,472 - log/train6.log - INFO - iteration:62 step:3900/10100, NER loss: 0.855708
2019-02-21 20:12:11,540 - log/train6.log - INFO - iteration:62 step:4000/10100, NER loss: 0.724862
2019-02-21 20:12:13,785 - log/train6.log - INFO - iteration:62 step:4100/10100, NER loss: 0.990192
2019-02-21 20:12:16,486 - log/train6.log - INFO - iteration:62 step:4200/10100, NER loss: 1.468685
2019-02-21 20:12:18,894 - log/train6.log - INFO - iteration:62 step:4300/10100, NER loss: 0.963228
2019-02-21 20:12:21,191 - log/train6.log - INFO - iteration:62 step:4400/10100, NER loss: 1.068802
2019-02-21 20:12:23,244 - log/train6.log - INFO - iteration:62 step:4500/10100, NER loss: 0.778003
2019-02-21 20:12:25,469 - log/train6.log - INFO - iteration:62 step:4600/10100, NER loss: 0.967232
2019-02-21 20:12:27,920 - log/train6.log - INFO - iteration:62 step:4700/10100, NER loss: 0.993630
2019-02-21 20:12:29,946 - log/train6.log - INFO - iteration:62 step:4800/10100, NER loss: 0.786274
2019-02-21 20:12:32,039 - log/train6.log - INFO - iteration:62 step:4900/10100, NER loss: 0.865555
2019-02-21 20:12:34,389 - log/train6.log - INFO - iteration:62 step:5000/10100, NER loss: 1.053810
2019-02-21 20:12:36,320 - log/train6.log - INFO - iteration:62 step:5100/10100, NER loss: 0.791670
2019-02-21 20:12:38,431 - log/train6.log - INFO - iteration:62 step:5200/10100, NER loss: 0.793387
2019-02-21 20:12:40,646 - log/train6.log - INFO - iteration:62 step:5300/10100, NER loss: 0.796709
2019-02-21 20:12:42,810 - log/train6.log - INFO - iteration:62 step:5400/10100, NER loss: 0.872956
2019-02-21 20:12:44,877 - log/train6.log - INFO - iteration:62 step:5500/10100, NER loss: 0.818493
2019-02-21 20:12:47,172 - log/train6.log - INFO - iteration:62 step:5600/10100, NER loss: 0.845001
2019-02-21 20:12:49,327 - log/train6.log - INFO - iteration:62 step:5700/10100, NER loss: 0.861552
2019-02-21 20:12:51,492 - log/train6.log - INFO - iteration:62 step:5800/10100, NER loss: 0.890942
2019-02-21 20:12:53,439 - log/train6.log - INFO - iteration:62 step:5900/10100, NER loss: 0.559834
2019-02-21 20:12:55,494 - log/train6.log - INFO - iteration:62 step:6000/10100, NER loss: 0.871645
2019-02-21 20:12:57,662 - log/train6.log - INFO - iteration:62 step:6100/10100, NER loss: 0.784933
2019-02-21 20:12:59,894 - log/train6.log - INFO - iteration:62 step:6200/10100, NER loss: 1.022145
2019-02-21 20:13:02,079 - log/train6.log - INFO - iteration:62 step:6300/10100, NER loss: 0.851905
2019-02-21 20:13:04,401 - log/train6.log - INFO - iteration:62 step:6400/10100, NER loss: 1.007639
2019-02-21 20:13:06,537 - log/train6.log - INFO - iteration:62 step:6500/10100, NER loss: 0.792243
2019-02-21 20:13:08,970 - log/train6.log - INFO - iteration:62 step:6600/10100, NER loss: 1.143541
2019-02-21 20:13:11,217 - log/train6.log - INFO - iteration:62 step:6700/10100, NER loss: 0.988460
2019-02-21 20:13:13,559 - log/train6.log - INFO - iteration:62 step:6800/10100, NER loss: 1.013498
2019-02-21 20:13:15,638 - log/train6.log - INFO - iteration:62 step:6900/10100, NER loss: 0.737189
2019-02-21 20:13:19,683 - log/train6.log - INFO - iteration:62 step:7000/10100, NER loss: 2.384782
2019-02-21 20:13:21,874 - log/train6.log - INFO - iteration:62 step:7100/10100, NER loss: 0.870875
2019-02-21 20:13:24,035 - log/train6.log - INFO - iteration:62 step:7200/10100, NER loss: 1.014479
2019-02-21 20:13:26,351 - log/train6.log - INFO - iteration:62 step:7300/10100, NER loss: 0.999638
2019-02-21 20:13:28,392 - log/train6.log - INFO - iteration:62 step:7400/10100, NER loss: 0.778834
2019-02-21 20:13:30,557 - log/train6.log - INFO - iteration:62 step:7500/10100, NER loss: 0.929224
2019-02-21 20:13:32,852 - log/train6.log - INFO - iteration:62 step:7600/10100, NER loss: 0.963195
2019-02-21 20:13:34,978 - log/train6.log - INFO - iteration:62 step:7700/10100, NER loss: 0.792916
2019-02-21 20:13:37,490 - log/train6.log - INFO - iteration:62 step:7800/10100, NER loss: 1.109602
2019-02-21 20:13:39,650 - log/train6.log - INFO - iteration:62 step:7900/10100, NER loss: 0.984398
2019-02-21 20:13:41,814 - log/train6.log - INFO - iteration:62 step:8000/10100, NER loss: 0.943699
2019-02-21 20:13:43,885 - log/train6.log - INFO - iteration:62 step:8100/10100, NER loss: 0.829606
2019-02-21 20:13:46,138 - log/train6.log - INFO - iteration:62 step:8200/10100, NER loss: 0.958934
2019-02-21 20:13:48,442 - log/train6.log - INFO - iteration:62 step:8300/10100, NER loss: 0.913150
2019-02-21 20:13:50,694 - log/train6.log - INFO - iteration:62 step:8400/10100, NER loss: 1.067956
2019-02-21 20:13:52,921 - log/train6.log - INFO - iteration:62 step:8500/10100, NER loss: 0.959589
2019-02-21 20:13:55,047 - log/train6.log - INFO - iteration:62 step:8600/10100, NER loss: 0.878823
2019-02-21 20:13:57,524 - log/train6.log - INFO - iteration:62 step:8700/10100, NER loss: 1.140347
2019-02-21 20:13:59,606 - log/train6.log - INFO - iteration:62 step:8800/10100, NER loss: 0.828615
2019-02-21 20:14:01,767 - log/train6.log - INFO - iteration:62 step:8900/10100, NER loss: 0.764000
2019-02-21 20:14:05,766 - log/train6.log - INFO - iteration:62 step:9000/10100, NER loss: 1.103256
2019-02-21 20:14:08,006 - log/train6.log - INFO - iteration:62 step:9100/10100, NER loss: 0.936762
2019-02-21 20:14:09,902 - log/train6.log - INFO - iteration:62 step:9200/10100, NER loss: 0.772126
2019-02-21 20:14:12,202 - log/train6.log - INFO - iteration:62 step:9300/10100, NER loss: 0.936435
2019-02-21 20:14:14,501 - log/train6.log - INFO - iteration:62 step:9400/10100, NER loss: 1.166251
2019-02-21 20:14:16,680 - log/train6.log - INFO - iteration:62 step:9500/10100, NER loss: 0.832176
2019-02-21 20:14:18,930 - log/train6.log - INFO - iteration:62 step:9600/10100, NER loss: 0.801441
2019-02-21 20:14:21,235 - log/train6.log - INFO - iteration:62 step:9700/10100, NER loss: 0.903008
2019-02-21 20:14:23,456 - log/train6.log - INFO - iteration:62 step:9800/10100, NER loss: 0.946167
2019-02-21 20:14:25,802 - log/train6.log - INFO - iteration:62 step:9900/10100, NER loss: 1.098623
2019-02-21 20:14:27,886 - log/train6.log - INFO - iteration:62 step:10000/10100, NER loss: 0.938743
2019-02-21 20:14:30,355 - log/train6.log - INFO - iteration:63 step:0/10100, NER loss: 0.991886
2019-02-21 20:14:30,355 - log/train6.log - INFO - evaluate:dev
2019-02-21 20:14:36,839 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5784 phrases; correct: 4316.

2019-02-21 20:14:36,839 - log/train6.log - INFO - accuracy:  95.08%; precision:  74.62%; recall:  73.82%; FB1:  74.22

2019-02-21 20:14:36,839 - log/train6.log - INFO -                 C: precision:  82.38%; recall:  89.64%; FB1:  85.86  3688

2019-02-21 20:14:36,839 - log/train6.log - INFO -               IND: precision:  34.47%; recall:  32.11%; FB1:  33.25  380

2019-02-21 20:14:36,839 - log/train6.log - INFO -               INS: precision:  78.69%; recall:  63.32%; FB1:  70.18  305

2019-02-21 20:14:36,839 - log/train6.log - INFO -                 L: precision:  54.75%; recall:  56.11%; FB1:  55.42  621

2019-02-21 20:14:36,839 - log/train6.log - INFO -                 P: precision:  88.02%; recall:  89.32%; FB1:  88.67  551

2019-02-21 20:14:36,839 - log/train6.log - INFO -               PRO: precision:  34.31%; recall:  15.71%; FB1:  21.55  239

2019-02-21 20:14:36,843 - log/train6.log - INFO - evaluate:test
2019-02-21 20:14:38,305 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1679 phrases; correct: 1345.

2019-02-21 20:14:38,305 - log/train6.log - INFO - accuracy:  96.09%; precision:  80.11%; recall:  81.66%; FB1:  80.88

2019-02-21 20:14:38,306 - log/train6.log - INFO -                 C: precision:  84.53%; recall:  91.84%; FB1:  88.03  1118

2019-02-21 20:14:38,306 - log/train6.log - INFO -               IND: precision:  35.29%; recall:  63.83%; FB1:  45.45  85

2019-02-21 20:14:38,306 - log/train6.log - INFO -               INS: precision:  76.62%; recall:  62.11%; FB1:  68.60  77

2019-02-21 20:14:38,306 - log/train6.log - INFO -                 L: precision:  56.00%; recall:  54.37%; FB1:  55.17  100

2019-02-21 20:14:38,306 - log/train6.log - INFO -                 P: precision:  91.47%; recall:  94.61%; FB1:  93.01  211

2019-02-21 20:14:38,306 - log/train6.log - INFO -               PRO: precision:  70.45%; recall:  36.69%; FB1:  48.25  88

2019-02-21 20:14:40,281 - log/train6.log - INFO - iteration:63 step:100/10100, NER loss: 0.919265
2019-02-21 20:14:42,586 - log/train6.log - INFO - iteration:63 step:200/10100, NER loss: 1.120661
2019-02-21 20:14:44,544 - log/train6.log - INFO - iteration:63 step:300/10100, NER loss: 0.976302
2019-02-21 20:14:46,730 - log/train6.log - INFO - iteration:63 step:400/10100, NER loss: 0.825846
2019-02-21 20:14:49,021 - log/train6.log - INFO - iteration:63 step:500/10100, NER loss: 1.080553
2019-02-21 20:14:51,247 - log/train6.log - INFO - iteration:63 step:600/10100, NER loss: 0.867813
2019-02-21 20:14:53,337 - log/train6.log - INFO - iteration:63 step:700/10100, NER loss: 0.679055
2019-02-21 20:14:55,418 - log/train6.log - INFO - iteration:63 step:800/10100, NER loss: 0.684318
2019-02-21 20:14:57,494 - log/train6.log - INFO - iteration:63 step:900/10100, NER loss: 0.755557
2019-02-21 20:14:59,430 - log/train6.log - INFO - iteration:63 step:1000/10100, NER loss: 0.605308
2019-02-21 20:15:01,567 - log/train6.log - INFO - iteration:63 step:1100/10100, NER loss: 0.775411
2019-02-21 20:15:03,675 - log/train6.log - INFO - iteration:63 step:1200/10100, NER loss: 0.785179
2019-02-21 20:15:05,794 - log/train6.log - INFO - iteration:63 step:1300/10100, NER loss: 0.873472
2019-02-21 20:15:08,076 - log/train6.log - INFO - iteration:63 step:1400/10100, NER loss: 1.054795
2019-02-21 20:15:10,163 - log/train6.log - INFO - iteration:63 step:1500/10100, NER loss: 0.716362
2019-02-21 20:15:12,418 - log/train6.log - INFO - iteration:63 step:1600/10100, NER loss: 0.871462
2019-02-21 20:15:14,574 - log/train6.log - INFO - iteration:63 step:1700/10100, NER loss: 1.104429
2019-02-21 20:15:16,910 - log/train6.log - INFO - iteration:63 step:1800/10100, NER loss: 1.059991
2019-02-21 20:15:19,103 - log/train6.log - INFO - iteration:63 step:1900/10100, NER loss: 0.840225
2019-02-21 20:15:21,389 - log/train6.log - INFO - iteration:63 step:2000/10100, NER loss: 0.932886
2019-02-21 20:15:25,846 - log/train6.log - INFO - iteration:63 step:2100/10100, NER loss: 2.042169
2019-02-21 20:15:27,898 - log/train6.log - INFO - iteration:63 step:2200/10100, NER loss: 0.928188
2019-02-21 20:15:30,252 - log/train6.log - INFO - iteration:63 step:2300/10100, NER loss: 1.188969
2019-02-21 20:15:32,597 - log/train6.log - INFO - iteration:63 step:2400/10100, NER loss: 0.931836
2019-02-21 20:15:34,658 - log/train6.log - INFO - iteration:63 step:2500/10100, NER loss: 0.866224
2019-02-21 20:15:36,760 - log/train6.log - INFO - iteration:63 step:2600/10100, NER loss: 0.984881
2019-02-21 20:15:38,864 - log/train6.log - INFO - iteration:63 step:2700/10100, NER loss: 0.860453
2019-02-21 20:15:41,060 - log/train6.log - INFO - iteration:63 step:2800/10100, NER loss: 0.948362
2019-02-21 20:15:43,435 - log/train6.log - INFO - iteration:63 step:2900/10100, NER loss: 0.943435
2019-02-21 20:15:45,586 - log/train6.log - INFO - iteration:63 step:3000/10100, NER loss: 1.042275
2019-02-21 20:15:48,114 - log/train6.log - INFO - iteration:63 step:3100/10100, NER loss: 1.263433
2019-02-21 20:15:50,237 - log/train6.log - INFO - iteration:63 step:3200/10100, NER loss: 0.760449
2019-02-21 20:15:52,409 - log/train6.log - INFO - iteration:63 step:3300/10100, NER loss: 0.874913
2019-02-21 20:15:54,660 - log/train6.log - INFO - iteration:63 step:3400/10100, NER loss: 0.987948
2019-02-21 20:15:56,786 - log/train6.log - INFO - iteration:63 step:3500/10100, NER loss: 0.972579
2019-02-21 20:15:59,100 - log/train6.log - INFO - iteration:63 step:3600/10100, NER loss: 0.995842
2019-02-21 20:16:01,413 - log/train6.log - INFO - iteration:63 step:3700/10100, NER loss: 1.004730
2019-02-21 20:16:03,692 - log/train6.log - INFO - iteration:63 step:3800/10100, NER loss: 0.887613
2019-02-21 20:16:06,074 - log/train6.log - INFO - iteration:63 step:3900/10100, NER loss: 1.257791
2019-02-21 20:16:08,094 - log/train6.log - INFO - iteration:63 step:4000/10100, NER loss: 0.831836
2019-02-21 20:16:10,482 - log/train6.log - INFO - iteration:63 step:4100/10100, NER loss: 1.123924
2019-02-21 20:16:12,646 - log/train6.log - INFO - iteration:63 step:4200/10100, NER loss: 0.992418
2019-02-21 20:16:14,730 - log/train6.log - INFO - iteration:63 step:4300/10100, NER loss: 0.631715
2019-02-21 20:16:16,839 - log/train6.log - INFO - iteration:63 step:4400/10100, NER loss: 1.014055
2019-02-21 20:16:19,206 - log/train6.log - INFO - iteration:63 step:4500/10100, NER loss: 0.973961
2019-02-21 20:16:21,406 - log/train6.log - INFO - iteration:63 step:4600/10100, NER loss: 1.043640
2019-02-21 20:16:23,602 - log/train6.log - INFO - iteration:63 step:4700/10100, NER loss: 0.832237
2019-02-21 20:16:25,671 - log/train6.log - INFO - iteration:63 step:4800/10100, NER loss: 0.708098
2019-02-21 20:16:27,792 - log/train6.log - INFO - iteration:63 step:4900/10100, NER loss: 0.818326
2019-02-21 20:16:29,905 - log/train6.log - INFO - iteration:63 step:5000/10100, NER loss: 0.861357
2019-02-21 20:16:32,119 - log/train6.log - INFO - iteration:63 step:5100/10100, NER loss: 0.866698
2019-02-21 20:16:34,518 - log/train6.log - INFO - iteration:63 step:5200/10100, NER loss: 0.977676
2019-02-21 20:16:38,575 - log/train6.log - INFO - iteration:63 step:5300/10100, NER loss: 1.902376
2019-02-21 20:16:40,749 - log/train6.log - INFO - iteration:63 step:5400/10100, NER loss: 0.787351
2019-02-21 20:16:43,224 - log/train6.log - INFO - iteration:63 step:5500/10100, NER loss: 1.050133
2019-02-21 20:16:45,266 - log/train6.log - INFO - iteration:63 step:5600/10100, NER loss: 0.808603
2019-02-21 20:16:47,543 - log/train6.log - INFO - iteration:63 step:5700/10100, NER loss: 1.003447
2019-02-21 20:16:49,820 - log/train6.log - INFO - iteration:63 step:5800/10100, NER loss: 0.894286
2019-02-21 20:16:51,931 - log/train6.log - INFO - iteration:63 step:5900/10100, NER loss: 0.799554
2019-02-21 20:16:54,081 - log/train6.log - INFO - iteration:63 step:6000/10100, NER loss: 0.865419
2019-02-21 20:16:56,449 - log/train6.log - INFO - iteration:63 step:6100/10100, NER loss: 1.052931
2019-02-21 20:16:58,599 - log/train6.log - INFO - iteration:63 step:6200/10100, NER loss: 1.011556
2019-02-21 20:17:00,780 - log/train6.log - INFO - iteration:63 step:6300/10100, NER loss: 0.883592
2019-02-21 20:17:03,157 - log/train6.log - INFO - iteration:63 step:6400/10100, NER loss: 1.003925
2019-02-21 20:17:05,314 - log/train6.log - INFO - iteration:63 step:6500/10100, NER loss: 0.899613
2019-02-21 20:17:09,398 - log/train6.log - INFO - iteration:63 step:6600/10100, NER loss: 1.602680
2019-02-21 20:17:11,762 - log/train6.log - INFO - iteration:63 step:6700/10100, NER loss: 0.936366
2019-02-21 20:17:14,064 - log/train6.log - INFO - iteration:63 step:6800/10100, NER loss: 1.034578
2019-02-21 20:17:16,371 - log/train6.log - INFO - iteration:63 step:6900/10100, NER loss: 0.916172
2019-02-21 20:17:18,671 - log/train6.log - INFO - iteration:63 step:7000/10100, NER loss: 0.878968
2019-02-21 20:17:21,057 - log/train6.log - INFO - iteration:63 step:7100/10100, NER loss: 0.957006
2019-02-21 20:17:23,118 - log/train6.log - INFO - iteration:63 step:7200/10100, NER loss: 0.745025
2019-02-21 20:17:25,571 - log/train6.log - INFO - iteration:63 step:7300/10100, NER loss: 1.018467
2019-02-21 20:17:27,926 - log/train6.log - INFO - iteration:63 step:7400/10100, NER loss: 1.099344
2019-02-21 20:17:30,235 - log/train6.log - INFO - iteration:63 step:7500/10100, NER loss: 1.063390
2019-02-21 20:17:32,507 - log/train6.log - INFO - iteration:63 step:7600/10100, NER loss: 0.875777
2019-02-21 20:17:34,847 - log/train6.log - INFO - iteration:63 step:7700/10100, NER loss: 1.059629
2019-02-21 20:17:36,922 - log/train6.log - INFO - iteration:63 step:7800/10100, NER loss: 0.866239
2019-02-21 20:17:39,359 - log/train6.log - INFO - iteration:63 step:7900/10100, NER loss: 1.042099
2019-02-21 20:17:41,315 - log/train6.log - INFO - iteration:63 step:8000/10100, NER loss: 0.675895
2019-02-21 20:17:43,624 - log/train6.log - INFO - iteration:63 step:8100/10100, NER loss: 0.868101
2019-02-21 20:17:45,841 - log/train6.log - INFO - iteration:63 step:8200/10100, NER loss: 1.100572
2019-02-21 20:17:47,963 - log/train6.log - INFO - iteration:63 step:8300/10100, NER loss: 0.962504
2019-02-21 20:17:50,287 - log/train6.log - INFO - iteration:63 step:8400/10100, NER loss: 0.844718
2019-02-21 20:17:52,396 - log/train6.log - INFO - iteration:63 step:8500/10100, NER loss: 0.980538
2019-02-21 20:17:54,675 - log/train6.log - INFO - iteration:63 step:8600/10100, NER loss: 0.904101
2019-02-21 20:17:56,829 - log/train6.log - INFO - iteration:63 step:8700/10100, NER loss: 0.897922
2019-02-21 20:17:59,252 - log/train6.log - INFO - iteration:63 step:8800/10100, NER loss: 1.135478
2019-02-21 20:18:01,462 - log/train6.log - INFO - iteration:63 step:8900/10100, NER loss: 0.864898
2019-02-21 20:18:03,623 - log/train6.log - INFO - iteration:63 step:9000/10100, NER loss: 0.830211
2019-02-21 20:18:05,655 - log/train6.log - INFO - iteration:63 step:9100/10100, NER loss: 0.645125
2019-02-21 20:18:07,859 - log/train6.log - INFO - iteration:63 step:9200/10100, NER loss: 0.975608
2019-02-21 20:18:10,025 - log/train6.log - INFO - iteration:63 step:9300/10100, NER loss: 0.897296
2019-02-21 20:18:12,147 - log/train6.log - INFO - iteration:63 step:9400/10100, NER loss: 0.815599
2019-02-21 20:18:14,216 - log/train6.log - INFO - iteration:63 step:9500/10100, NER loss: 0.715887
2019-02-21 20:18:16,316 - log/train6.log - INFO - iteration:63 step:9600/10100, NER loss: 0.769951
2019-02-21 20:18:18,399 - log/train6.log - INFO - iteration:63 step:9700/10100, NER loss: 0.753538
2019-02-21 20:18:20,609 - log/train6.log - INFO - iteration:63 step:9800/10100, NER loss: 0.802353
2019-02-21 20:18:22,685 - log/train6.log - INFO - iteration:63 step:9900/10100, NER loss: 0.842915
2019-02-21 20:18:24,805 - log/train6.log - INFO - iteration:63 step:10000/10100, NER loss: 1.149540
2019-02-21 20:18:26,855 - log/train6.log - INFO - iteration:64 step:0/10100, NER loss: 0.795044
2019-02-21 20:18:26,855 - log/train6.log - INFO - evaluate:dev
2019-02-21 20:18:33,337 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5843 phrases; correct: 4282.

2019-02-21 20:18:33,337 - log/train6.log - INFO - accuracy:  91.34%; precision:  73.28%; recall:  73.23%; FB1:  73.26

2019-02-21 20:18:33,337 - log/train6.log - INFO -                 C: precision:  86.18%; recall:  87.19%; FB1:  86.68  3429

2019-02-21 20:18:33,337 - log/train6.log - INFO -               IND: precision:  48.91%; recall:  16.42%; FB1:  24.59  137

2019-02-21 20:18:33,337 - log/train6.log - INFO -               INS: precision:  63.96%; recall:  70.71%; FB1:  67.17  419

2019-02-21 20:18:33,337 - log/train6.log - INFO -                 L: precision:  58.06%; recall:  58.25%; FB1:  58.15  608

2019-02-21 20:18:33,337 - log/train6.log - INFO -                 P: precision:  86.89%; recall:  89.13%; FB1:  88.00  557

2019-02-21 20:18:33,337 - log/train6.log - INFO -               PRO: precision:  22.37%; recall:  29.69%; FB1:  25.51  693

2019-02-21 20:18:33,340 - log/train6.log - INFO - evaluate:test
2019-02-21 20:18:34,804 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1696 phrases; correct: 1373.

2019-02-21 20:18:34,804 - log/train6.log - INFO - accuracy:  95.75%; precision:  80.96%; recall:  83.36%; FB1:  82.14

2019-02-21 20:18:34,804 - log/train6.log - INFO -                 C: precision:  88.58%; recall:  91.25%; FB1:  89.90  1060

2019-02-21 20:18:34,804 - log/train6.log - INFO -               IND: precision:  71.88%; recall:  48.94%; FB1:  58.23  32

2019-02-21 20:18:34,804 - log/train6.log - INFO -               INS: precision:  57.84%; recall:  62.11%; FB1:  59.90  102

2019-02-21 20:18:34,804 - log/train6.log - INFO -                 L: precision:  54.46%; recall:  53.40%; FB1:  53.92  101

2019-02-21 20:18:34,804 - log/train6.log - INFO -                 P: precision:  90.65%; recall:  95.10%; FB1:  92.82  214

2019-02-21 20:18:34,804 - log/train6.log - INFO -               PRO: precision:  55.08%; recall:  60.95%; FB1:  57.87  187

2019-02-21 20:18:36,941 - log/train6.log - INFO - iteration:64 step:100/10100, NER loss: 1.055131
2019-02-21 20:18:38,922 - log/train6.log - INFO - iteration:64 step:200/10100, NER loss: 0.814245
2019-02-21 20:18:41,056 - log/train6.log - INFO - iteration:64 step:300/10100, NER loss: 0.905533
2019-02-21 20:18:43,471 - log/train6.log - INFO - iteration:64 step:400/10100, NER loss: 1.073762
2019-02-21 20:18:45,739 - log/train6.log - INFO - iteration:64 step:500/10100, NER loss: 0.899675
2019-02-21 20:18:47,899 - log/train6.log - INFO - iteration:64 step:600/10100, NER loss: 0.858239
2019-02-21 20:18:50,024 - log/train6.log - INFO - iteration:64 step:700/10100, NER loss: 0.857257
2019-02-21 20:18:52,406 - log/train6.log - INFO - iteration:64 step:800/10100, NER loss: 0.929254
2019-02-21 20:18:54,751 - log/train6.log - INFO - iteration:64 step:900/10100, NER loss: 1.158839
2019-02-21 20:18:57,033 - log/train6.log - INFO - iteration:64 step:1000/10100, NER loss: 0.920569
2019-02-21 20:18:59,450 - log/train6.log - INFO - iteration:64 step:1100/10100, NER loss: 0.886742
2019-02-21 20:19:01,410 - log/train6.log - INFO - iteration:64 step:1200/10100, NER loss: 0.749537
2019-02-21 20:19:05,180 - log/train6.log - INFO - iteration:64 step:1300/10100, NER loss: 2.224482
2019-02-21 20:19:07,157 - log/train6.log - INFO - iteration:64 step:1400/10100, NER loss: 0.831736
2019-02-21 20:19:09,345 - log/train6.log - INFO - iteration:64 step:1500/10100, NER loss: 0.909070
2019-02-21 20:19:11,465 - log/train6.log - INFO - iteration:64 step:1600/10100, NER loss: 0.878095
2019-02-21 20:19:13,866 - log/train6.log - INFO - iteration:64 step:1700/10100, NER loss: 0.992343
2019-02-21 20:19:16,063 - log/train6.log - INFO - iteration:64 step:1800/10100, NER loss: 1.125642
2019-02-21 20:19:18,175 - log/train6.log - INFO - iteration:64 step:1900/10100, NER loss: 0.954068
2019-02-21 20:19:20,273 - log/train6.log - INFO - iteration:64 step:2000/10100, NER loss: 0.777047
2019-02-21 20:19:22,481 - log/train6.log - INFO - iteration:64 step:2100/10100, NER loss: 1.013571
2019-02-21 20:19:24,601 - log/train6.log - INFO - iteration:64 step:2200/10100, NER loss: 0.774124
2019-02-21 20:19:26,961 - log/train6.log - INFO - iteration:64 step:2300/10100, NER loss: 0.912005
2019-02-21 20:19:29,085 - log/train6.log - INFO - iteration:64 step:2400/10100, NER loss: 1.045750
2019-02-21 20:19:30,986 - log/train6.log - INFO - iteration:64 step:2500/10100, NER loss: 0.752854
2019-02-21 20:19:33,121 - log/train6.log - INFO - iteration:64 step:2600/10100, NER loss: 0.885666
2019-02-21 20:19:35,175 - log/train6.log - INFO - iteration:64 step:2700/10100, NER loss: 0.871324
2019-02-21 20:19:37,483 - log/train6.log - INFO - iteration:64 step:2800/10100, NER loss: 0.934594
2019-02-21 20:19:39,775 - log/train6.log - INFO - iteration:64 step:2900/10100, NER loss: 0.971676
2019-02-21 20:19:42,027 - log/train6.log - INFO - iteration:64 step:3000/10100, NER loss: 0.950143
2019-02-21 20:19:44,154 - log/train6.log - INFO - iteration:64 step:3100/10100, NER loss: 0.787466
2019-02-21 20:19:46,076 - log/train6.log - INFO - iteration:64 step:3200/10100, NER loss: 0.736508
2019-02-21 20:19:48,063 - log/train6.log - INFO - iteration:64 step:3300/10100, NER loss: 0.899372
2019-02-21 20:19:50,009 - log/train6.log - INFO - iteration:64 step:3400/10100, NER loss: 0.761045
2019-02-21 20:19:52,195 - log/train6.log - INFO - iteration:64 step:3500/10100, NER loss: 0.852204
2019-02-21 20:19:54,386 - log/train6.log - INFO - iteration:64 step:3600/10100, NER loss: 0.971550
2019-02-21 20:19:56,533 - log/train6.log - INFO - iteration:64 step:3700/10100, NER loss: 0.823797
2019-02-21 20:19:58,768 - log/train6.log - INFO - iteration:64 step:3800/10100, NER loss: 0.924587
2019-02-21 20:20:01,033 - log/train6.log - INFO - iteration:64 step:3900/10100, NER loss: 1.157554
2019-02-21 20:20:03,039 - log/train6.log - INFO - iteration:64 step:4000/10100, NER loss: 0.864733
2019-02-21 20:20:05,215 - log/train6.log - INFO - iteration:64 step:4100/10100, NER loss: 0.820124
2019-02-21 20:20:07,412 - log/train6.log - INFO - iteration:64 step:4200/10100, NER loss: 0.970594
2019-02-21 20:20:09,486 - log/train6.log - INFO - iteration:64 step:4300/10100, NER loss: 0.944301
2019-02-21 20:20:11,905 - log/train6.log - INFO - iteration:64 step:4400/10100, NER loss: 1.210026
2019-02-21 20:20:14,027 - log/train6.log - INFO - iteration:64 step:4500/10100, NER loss: 0.773962
2019-02-21 20:20:16,226 - log/train6.log - INFO - iteration:64 step:4600/10100, NER loss: 0.880802
2019-02-21 20:20:18,834 - log/train6.log - INFO - iteration:64 step:4700/10100, NER loss: 1.010300
2019-02-21 20:20:21,057 - log/train6.log - INFO - iteration:64 step:4800/10100, NER loss: 0.921368
2019-02-21 20:20:23,179 - log/train6.log - INFO - iteration:64 step:4900/10100, NER loss: 0.845467
2019-02-21 20:20:25,547 - log/train6.log - INFO - iteration:64 step:5000/10100, NER loss: 0.976209
2019-02-21 20:20:27,612 - log/train6.log - INFO - iteration:64 step:5100/10100, NER loss: 0.888785
2019-02-21 20:20:29,646 - log/train6.log - INFO - iteration:64 step:5200/10100, NER loss: 0.786389
2019-02-21 20:20:31,816 - log/train6.log - INFO - iteration:64 step:5300/10100, NER loss: 0.788052
2019-02-21 20:20:34,520 - log/train6.log - INFO - iteration:64 step:5400/10100, NER loss: 1.253212
2019-02-21 20:20:36,560 - log/train6.log - INFO - iteration:64 step:5500/10100, NER loss: 0.757525
2019-02-21 20:20:38,777 - log/train6.log - INFO - iteration:64 step:5600/10100, NER loss: 0.853318
2019-02-21 20:20:40,982 - log/train6.log - INFO - iteration:64 step:5700/10100, NER loss: 0.862627
2019-02-21 20:20:43,363 - log/train6.log - INFO - iteration:64 step:5800/10100, NER loss: 0.904040
2019-02-21 20:20:45,822 - log/train6.log - INFO - iteration:64 step:5900/10100, NER loss: 1.197221
2019-02-21 20:20:50,335 - log/train6.log - INFO - iteration:64 step:6000/10100, NER loss: 2.380691
2019-02-21 20:20:52,691 - log/train6.log - INFO - iteration:64 step:6100/10100, NER loss: 0.984783
2019-02-21 20:20:55,094 - log/train6.log - INFO - iteration:64 step:6200/10100, NER loss: 0.971000
2019-02-21 20:20:57,149 - log/train6.log - INFO - iteration:64 step:6300/10100, NER loss: 0.705989
2019-02-21 20:20:59,470 - log/train6.log - INFO - iteration:64 step:6400/10100, NER loss: 0.907885
2019-02-21 20:21:01,678 - log/train6.log - INFO - iteration:64 step:6500/10100, NER loss: 0.940204
2019-02-21 20:21:03,788 - log/train6.log - INFO - iteration:64 step:6600/10100, NER loss: 0.992284
2019-02-21 20:21:05,772 - log/train6.log - INFO - iteration:64 step:6700/10100, NER loss: 0.650305
2019-02-21 20:21:07,965 - log/train6.log - INFO - iteration:64 step:6800/10100, NER loss: 0.965019
2019-02-21 20:21:10,281 - log/train6.log - INFO - iteration:64 step:6900/10100, NER loss: 1.008989
2019-02-21 20:21:12,632 - log/train6.log - INFO - iteration:64 step:7000/10100, NER loss: 1.250117
2019-02-21 20:21:14,923 - log/train6.log - INFO - iteration:64 step:7100/10100, NER loss: 0.913642
2019-02-21 20:21:17,401 - log/train6.log - INFO - iteration:64 step:7200/10100, NER loss: 1.104074
2019-02-21 20:21:19,576 - log/train6.log - INFO - iteration:64 step:7300/10100, NER loss: 0.971458
2019-02-21 20:21:21,491 - log/train6.log - INFO - iteration:64 step:7400/10100, NER loss: 0.664292
2019-02-21 20:21:23,728 - log/train6.log - INFO - iteration:64 step:7500/10100, NER loss: 0.879813
2019-02-21 20:21:27,894 - log/train6.log - INFO - iteration:64 step:7600/10100, NER loss: 1.512574
2019-02-21 20:21:29,840 - log/train6.log - INFO - iteration:64 step:7700/10100, NER loss: 0.855513
2019-02-21 20:21:32,014 - log/train6.log - INFO - iteration:64 step:7800/10100, NER loss: 0.784840
2019-02-21 20:21:34,009 - log/train6.log - INFO - iteration:64 step:7900/10100, NER loss: 0.849133
2019-02-21 20:21:36,181 - log/train6.log - INFO - iteration:64 step:8000/10100, NER loss: 0.952901
2019-02-21 20:21:38,550 - log/train6.log - INFO - iteration:64 step:8100/10100, NER loss: 1.071907
2019-02-21 20:21:40,639 - log/train6.log - INFO - iteration:64 step:8200/10100, NER loss: 0.839733
2019-02-21 20:21:42,774 - log/train6.log - INFO - iteration:64 step:8300/10100, NER loss: 0.928715
2019-02-21 20:21:44,790 - log/train6.log - INFO - iteration:64 step:8400/10100, NER loss: 0.751761
2019-02-21 20:21:46,994 - log/train6.log - INFO - iteration:64 step:8500/10100, NER loss: 0.961753
2019-02-21 20:21:49,414 - log/train6.log - INFO - iteration:64 step:8600/10100, NER loss: 1.128235
2019-02-21 20:21:51,472 - log/train6.log - INFO - iteration:64 step:8700/10100, NER loss: 0.792006
2019-02-21 20:21:54,004 - log/train6.log - INFO - iteration:64 step:8800/10100, NER loss: 1.185824
2019-02-21 20:21:56,257 - log/train6.log - INFO - iteration:64 step:8900/10100, NER loss: 0.885591
2019-02-21 20:21:58,651 - log/train6.log - INFO - iteration:64 step:9000/10100, NER loss: 1.222206
2019-02-21 20:22:00,774 - log/train6.log - INFO - iteration:64 step:9100/10100, NER loss: 0.916209
2019-02-21 20:22:02,987 - log/train6.log - INFO - iteration:64 step:9200/10100, NER loss: 0.879357
2019-02-21 20:22:05,052 - log/train6.log - INFO - iteration:64 step:9300/10100, NER loss: 0.800489
2019-02-21 20:22:07,249 - log/train6.log - INFO - iteration:64 step:9400/10100, NER loss: 1.042035
2019-02-21 20:22:09,347 - log/train6.log - INFO - iteration:64 step:9500/10100, NER loss: 0.840806
2019-02-21 20:22:11,399 - log/train6.log - INFO - iteration:64 step:9600/10100, NER loss: 0.873071
2019-02-21 20:22:13,574 - log/train6.log - INFO - iteration:64 step:9700/10100, NER loss: 0.863331
2019-02-21 20:22:15,833 - log/train6.log - INFO - iteration:64 step:9800/10100, NER loss: 0.942102
2019-02-21 20:22:18,001 - log/train6.log - INFO - iteration:64 step:9900/10100, NER loss: 0.939230
2019-02-21 20:22:20,123 - log/train6.log - INFO - iteration:64 step:10000/10100, NER loss: 0.894689
2019-02-21 20:22:22,244 - log/train6.log - INFO - iteration:65 step:0/10100, NER loss: 0.907712
2019-02-21 20:22:22,245 - log/train6.log - INFO - evaluate:dev
2019-02-21 20:22:28,705 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5304 phrases; correct: 4189.

2019-02-21 20:22:28,705 - log/train6.log - INFO - accuracy:  95.32%; precision:  78.98%; recall:  71.64%; FB1:  75.13

2019-02-21 20:22:28,705 - log/train6.log - INFO -                 C: precision:  86.63%; recall:  86.22%; FB1:  86.42  3373

2019-02-21 20:22:28,705 - log/train6.log - INFO -               IND: precision:  48.47%; recall:  19.36%; FB1:  27.67  163

2019-02-21 20:22:28,705 - log/train6.log - INFO -               INS: precision:  69.21%; recall:  69.39%; FB1:  69.30  380

2019-02-21 20:22:28,705 - log/train6.log - INFO -                 L: precision:  62.70%; recall:  59.08%; FB1:  60.83  571

2019-02-21 20:22:28,705 - log/train6.log - INFO -                 P: precision:  82.55%; recall:  90.61%; FB1:  86.39  596

2019-02-21 20:22:28,705 - log/train6.log - INFO -               PRO: precision:  33.94%; recall:  14.37%; FB1:  20.19  221

2019-02-21 20:22:28,708 - log/train6.log - INFO - evaluate:test
2019-02-21 20:22:30,169 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1573 phrases; correct: 1330.

2019-02-21 20:22:30,169 - log/train6.log - INFO - accuracy:  96.67%; precision:  84.55%; recall:  80.75%; FB1:  82.61

2019-02-21 20:22:30,169 - log/train6.log - INFO -                 C: precision:  88.21%; recall:  90.18%; FB1:  89.19  1052

2019-02-21 20:22:30,169 - log/train6.log - INFO -               IND: precision:  73.68%; recall:  59.57%; FB1:  65.88  38

2019-02-21 20:22:30,169 - log/train6.log - INFO -               INS: precision:  69.77%; recall:  63.16%; FB1:  66.30  86

2019-02-21 20:22:30,169 - log/train6.log - INFO -                 L: precision:  57.29%; recall:  53.40%; FB1:  55.28  96

2019-02-21 20:22:30,169 - log/train6.log - INFO -                 P: precision:  88.99%; recall:  95.10%; FB1:  91.94  218

2019-02-21 20:22:30,169 - log/train6.log - INFO -               PRO: precision:  78.31%; recall:  38.46%; FB1:  51.59  83

2019-02-21 20:22:31,986 - log/train6.log - INFO - iteration:65 step:100/10100, NER loss: 0.700371
2019-02-21 20:22:33,945 - log/train6.log - INFO - iteration:65 step:200/10100, NER loss: 0.892377
2019-02-21 20:22:36,130 - log/train6.log - INFO - iteration:65 step:300/10100, NER loss: 1.116822
2019-02-21 20:22:38,299 - log/train6.log - INFO - iteration:65 step:400/10100, NER loss: 0.803216
2019-02-21 20:22:40,456 - log/train6.log - INFO - iteration:65 step:500/10100, NER loss: 0.732447
2019-02-21 20:22:42,678 - log/train6.log - INFO - iteration:65 step:600/10100, NER loss: 0.911644
2019-02-21 20:22:44,700 - log/train6.log - INFO - iteration:65 step:700/10100, NER loss: 0.849370
2019-02-21 20:22:46,971 - log/train6.log - INFO - iteration:65 step:800/10100, NER loss: 0.972217
2019-02-21 20:22:49,204 - log/train6.log - INFO - iteration:65 step:900/10100, NER loss: 0.866506
2019-02-21 20:22:51,332 - log/train6.log - INFO - iteration:65 step:1000/10100, NER loss: 0.797477
2019-02-21 20:22:53,678 - log/train6.log - INFO - iteration:65 step:1100/10100, NER loss: 0.990922
2019-02-21 20:22:55,987 - log/train6.log - INFO - iteration:65 step:1200/10100, NER loss: 1.127314
2019-02-21 20:22:57,931 - log/train6.log - INFO - iteration:65 step:1300/10100, NER loss: 0.738676
2019-02-21 20:23:00,148 - log/train6.log - INFO - iteration:65 step:1400/10100, NER loss: 0.906672
2019-02-21 20:23:02,509 - log/train6.log - INFO - iteration:65 step:1500/10100, NER loss: 1.006303
2019-02-21 20:23:04,708 - log/train6.log - INFO - iteration:65 step:1600/10100, NER loss: 0.963835
2019-02-21 20:23:06,983 - log/train6.log - INFO - iteration:65 step:1700/10100, NER loss: 0.896912
2019-02-21 20:23:09,146 - log/train6.log - INFO - iteration:65 step:1800/10100, NER loss: 0.818370
2019-02-21 20:23:11,134 - log/train6.log - INFO - iteration:65 step:1900/10100, NER loss: 0.741450
2019-02-21 20:23:13,317 - log/train6.log - INFO - iteration:65 step:2000/10100, NER loss: 0.982291
2019-02-21 20:23:15,390 - log/train6.log - INFO - iteration:65 step:2100/10100, NER loss: 0.831269
2019-02-21 20:23:17,448 - log/train6.log - INFO - iteration:65 step:2200/10100, NER loss: 0.847180
2019-02-21 20:23:19,701 - log/train6.log - INFO - iteration:65 step:2300/10100, NER loss: 1.053891
2019-02-21 20:23:21,952 - log/train6.log - INFO - iteration:65 step:2400/10100, NER loss: 1.019971
2019-02-21 20:23:24,187 - log/train6.log - INFO - iteration:65 step:2500/10100, NER loss: 0.863219
2019-02-21 20:23:26,519 - log/train6.log - INFO - iteration:65 step:2600/10100, NER loss: 0.868386
2019-02-21 20:23:28,796 - log/train6.log - INFO - iteration:65 step:2700/10100, NER loss: 1.029449
2019-02-21 20:23:31,061 - log/train6.log - INFO - iteration:65 step:2800/10100, NER loss: 0.875269
2019-02-21 20:23:33,356 - log/train6.log - INFO - iteration:65 step:2900/10100, NER loss: 0.850867
2019-02-21 20:23:35,426 - log/train6.log - INFO - iteration:65 step:3000/10100, NER loss: 0.815545
2019-02-21 20:23:37,601 - log/train6.log - INFO - iteration:65 step:3100/10100, NER loss: 0.976666
2019-02-21 20:23:39,998 - log/train6.log - INFO - iteration:65 step:3200/10100, NER loss: 1.154218
2019-02-21 20:23:42,157 - log/train6.log - INFO - iteration:65 step:3300/10100, NER loss: 1.040191
2019-02-21 20:23:44,362 - log/train6.log - INFO - iteration:65 step:3400/10100, NER loss: 0.990471
2019-02-21 20:23:46,614 - log/train6.log - INFO - iteration:65 step:3500/10100, NER loss: 1.155950
2019-02-21 20:23:48,849 - log/train6.log - INFO - iteration:65 step:3600/10100, NER loss: 1.004396
2019-02-21 20:23:50,819 - log/train6.log - INFO - iteration:65 step:3700/10100, NER loss: 0.739838
2019-02-21 20:23:53,099 - log/train6.log - INFO - iteration:65 step:3800/10100, NER loss: 0.916023
2019-02-21 20:23:55,101 - log/train6.log - INFO - iteration:65 step:3900/10100, NER loss: 0.717613
2019-02-21 20:23:57,350 - log/train6.log - INFO - iteration:65 step:4000/10100, NER loss: 0.995549
2019-02-21 20:23:59,496 - log/train6.log - INFO - iteration:65 step:4100/10100, NER loss: 0.940726
2019-02-21 20:24:01,764 - log/train6.log - INFO - iteration:65 step:4200/10100, NER loss: 0.813550
2019-02-21 20:24:04,078 - log/train6.log - INFO - iteration:65 step:4300/10100, NER loss: 0.915808
2019-02-21 20:24:06,591 - log/train6.log - INFO - iteration:65 step:4400/10100, NER loss: 1.103243
2019-02-21 20:24:09,052 - log/train6.log - INFO - iteration:65 step:4500/10100, NER loss: 1.055846
2019-02-21 20:24:11,407 - log/train6.log - INFO - iteration:65 step:4600/10100, NER loss: 0.875074
2019-02-21 20:24:13,551 - log/train6.log - INFO - iteration:65 step:4700/10100, NER loss: 0.998999
2019-02-21 20:24:15,695 - log/train6.log - INFO - iteration:65 step:4800/10100, NER loss: 0.978119
2019-02-21 20:24:18,006 - log/train6.log - INFO - iteration:65 step:4900/10100, NER loss: 1.075198
2019-02-21 20:24:20,206 - log/train6.log - INFO - iteration:65 step:5000/10100, NER loss: 0.868193
2019-02-21 20:24:22,379 - log/train6.log - INFO - iteration:65 step:5100/10100, NER loss: 0.963432
2019-02-21 20:24:24,879 - log/train6.log - INFO - iteration:65 step:5200/10100, NER loss: 0.974889
2019-02-21 20:24:29,323 - log/train6.log - INFO - iteration:65 step:5300/10100, NER loss: 2.285687
2019-02-21 20:24:31,345 - log/train6.log - INFO - iteration:65 step:5400/10100, NER loss: 0.954745
2019-02-21 20:24:33,443 - log/train6.log - INFO - iteration:65 step:5500/10100, NER loss: 0.836491
2019-02-21 20:24:35,703 - log/train6.log - INFO - iteration:65 step:5600/10100, NER loss: 0.913249
2019-02-21 20:24:37,840 - log/train6.log - INFO - iteration:65 step:5700/10100, NER loss: 0.749628
2019-02-21 20:24:40,116 - log/train6.log - INFO - iteration:65 step:5800/10100, NER loss: 0.913958
2019-02-21 20:24:42,349 - log/train6.log - INFO - iteration:65 step:5900/10100, NER loss: 1.038583
2019-02-21 20:24:44,406 - log/train6.log - INFO - iteration:65 step:6000/10100, NER loss: 0.736868
2019-02-21 20:24:46,831 - log/train6.log - INFO - iteration:65 step:6100/10100, NER loss: 1.038617
2019-02-21 20:24:48,867 - log/train6.log - INFO - iteration:65 step:6200/10100, NER loss: 0.772209
2019-02-21 20:24:51,012 - log/train6.log - INFO - iteration:65 step:6300/10100, NER loss: 0.844275
2019-02-21 20:24:53,299 - log/train6.log - INFO - iteration:65 step:6400/10100, NER loss: 0.993212
2019-02-21 20:24:55,600 - log/train6.log - INFO - iteration:65 step:6500/10100, NER loss: 0.932537
2019-02-21 20:24:57,803 - log/train6.log - INFO - iteration:65 step:6600/10100, NER loss: 0.823565
2019-02-21 20:25:01,956 - log/train6.log - INFO - iteration:65 step:6700/10100, NER loss: 1.674678
2019-02-21 20:25:04,345 - log/train6.log - INFO - iteration:65 step:6800/10100, NER loss: 1.049496
2019-02-21 20:25:06,699 - log/train6.log - INFO - iteration:65 step:6900/10100, NER loss: 1.074021
2019-02-21 20:25:08,911 - log/train6.log - INFO - iteration:65 step:7000/10100, NER loss: 0.882823
2019-02-21 20:25:11,325 - log/train6.log - INFO - iteration:65 step:7100/10100, NER loss: 1.132767
2019-02-21 20:25:13,399 - log/train6.log - INFO - iteration:65 step:7200/10100, NER loss: 0.660956
2019-02-21 20:25:15,654 - log/train6.log - INFO - iteration:65 step:7300/10100, NER loss: 0.918984
2019-02-21 20:25:17,950 - log/train6.log - INFO - iteration:65 step:7400/10100, NER loss: 0.980742
2019-02-21 20:25:20,070 - log/train6.log - INFO - iteration:65 step:7500/10100, NER loss: 0.814384
2019-02-21 20:25:22,294 - log/train6.log - INFO - iteration:65 step:7600/10100, NER loss: 0.905660
2019-02-21 20:25:24,649 - log/train6.log - INFO - iteration:65 step:7700/10100, NER loss: 1.011756
2019-02-21 20:25:26,720 - log/train6.log - INFO - iteration:65 step:7800/10100, NER loss: 0.895302
2019-02-21 20:25:29,260 - log/train6.log - INFO - iteration:65 step:7900/10100, NER loss: 1.090249
2019-02-21 20:25:33,300 - log/train6.log - INFO - iteration:65 step:8000/10100, NER loss: 1.773382
2019-02-21 20:25:35,517 - log/train6.log - INFO - iteration:65 step:8100/10100, NER loss: 0.896029
2019-02-21 20:25:37,590 - log/train6.log - INFO - iteration:65 step:8200/10100, NER loss: 0.794884
2019-02-21 20:25:39,886 - log/train6.log - INFO - iteration:65 step:8300/10100, NER loss: 0.916969
2019-02-21 20:25:41,957 - log/train6.log - INFO - iteration:65 step:8400/10100, NER loss: 0.773249
2019-02-21 20:25:44,014 - log/train6.log - INFO - iteration:65 step:8500/10100, NER loss: 0.789919
2019-02-21 20:25:46,122 - log/train6.log - INFO - iteration:65 step:8600/10100, NER loss: 0.842619
2019-02-21 20:25:48,037 - log/train6.log - INFO - iteration:65 step:8700/10100, NER loss: 0.858490
2019-02-21 20:25:50,348 - log/train6.log - INFO - iteration:65 step:8800/10100, NER loss: 0.850275
2019-02-21 20:25:52,311 - log/train6.log - INFO - iteration:65 step:8900/10100, NER loss: 0.688251
2019-02-21 20:25:54,516 - log/train6.log - INFO - iteration:65 step:9000/10100, NER loss: 0.866176
2019-02-21 20:25:56,725 - log/train6.log - INFO - iteration:65 step:9100/10100, NER loss: 0.765526
2019-02-21 20:25:58,892 - log/train6.log - INFO - iteration:65 step:9200/10100, NER loss: 0.898039
2019-02-21 20:26:00,880 - log/train6.log - INFO - iteration:65 step:9300/10100, NER loss: 0.860166
2019-02-21 20:26:02,900 - log/train6.log - INFO - iteration:65 step:9400/10100, NER loss: 0.894612
2019-02-21 20:26:04,971 - log/train6.log - INFO - iteration:65 step:9500/10100, NER loss: 0.766891
2019-02-21 20:26:07,159 - log/train6.log - INFO - iteration:65 step:9600/10100, NER loss: 0.952711
2019-02-21 20:26:09,355 - log/train6.log - INFO - iteration:65 step:9700/10100, NER loss: 0.940459
2019-02-21 20:26:11,704 - log/train6.log - INFO - iteration:65 step:9800/10100, NER loss: 1.215943
2019-02-21 20:26:14,109 - log/train6.log - INFO - iteration:65 step:9900/10100, NER loss: 1.102350
2019-02-21 20:26:16,428 - log/train6.log - INFO - iteration:65 step:10000/10100, NER loss: 1.016721
2019-02-21 20:26:19,143 - log/train6.log - INFO - iteration:66 step:0/10100, NER loss: 1.488024
2019-02-21 20:26:19,143 - log/train6.log - INFO - evaluate:dev
2019-02-21 20:26:25,653 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5778 phrases; correct: 4333.

2019-02-21 20:26:25,653 - log/train6.log - INFO - accuracy:  95.09%; precision:  74.99%; recall:  74.11%; FB1:  74.55

2019-02-21 20:26:25,653 - log/train6.log - INFO -                 C: precision:  84.25%; recall:  87.90%; FB1:  86.04  3536

2019-02-21 20:26:25,653 - log/train6.log - INFO -               IND: precision:  36.62%; recall:  35.54%; FB1:  36.07  396

2019-02-21 20:26:25,653 - log/train6.log - INFO -               INS: precision:  67.24%; recall:  72.03%; FB1:  69.55  406

2019-02-21 20:26:25,653 - log/train6.log - INFO -                 L: precision:  56.52%; recall:  61.55%; FB1:  58.93  660

2019-02-21 20:26:25,653 - log/train6.log - INFO -                 P: precision:  86.14%; recall:  90.42%; FB1:  88.23  570

2019-02-21 20:26:25,654 - log/train6.log - INFO -               PRO: precision:  34.29%; recall:  13.79%; FB1:  19.67  210

2019-02-21 20:26:25,657 - log/train6.log - INFO - evaluate:test
2019-02-21 20:26:27,126 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1643 phrases; correct: 1341.

2019-02-21 20:26:27,126 - log/train6.log - INFO - accuracy:  96.33%; precision:  81.62%; recall:  81.42%; FB1:  81.52

2019-02-21 20:26:27,126 - log/train6.log - INFO -                 C: precision:  87.29%; recall:  91.45%; FB1:  89.32  1078

2019-02-21 20:26:27,126 - log/train6.log - INFO -               IND: precision:  38.82%; recall:  70.21%; FB1:  50.00  85

2019-02-21 20:26:27,126 - log/train6.log - INFO -               INS: precision:  66.67%; recall:  63.16%; FB1:  64.86  90

2019-02-21 20:26:27,126 - log/train6.log - INFO -                 L: precision:  57.28%; recall:  57.28%; FB1:  57.28  103

2019-02-21 20:26:27,127 - log/train6.log - INFO -                 P: precision:  90.48%; recall:  93.14%; FB1:  91.79  210

2019-02-21 20:26:27,127 - log/train6.log - INFO -               PRO: precision:  75.32%; recall:  34.32%; FB1:  47.15  77

2019-02-21 20:26:29,444 - log/train6.log - INFO - iteration:66 step:100/10100, NER loss: 1.031605
2019-02-21 20:26:31,282 - log/train6.log - INFO - iteration:66 step:200/10100, NER loss: 0.829438
2019-02-21 20:26:33,491 - log/train6.log - INFO - iteration:66 step:300/10100, NER loss: 1.029832
2019-02-21 20:26:35,639 - log/train6.log - INFO - iteration:66 step:400/10100, NER loss: 0.941413
2019-02-21 20:26:39,757 - log/train6.log - INFO - iteration:66 step:500/10100, NER loss: 1.677382
2019-02-21 20:26:41,597 - log/train6.log - INFO - iteration:66 step:600/10100, NER loss: 0.726624
2019-02-21 20:26:43,777 - log/train6.log - INFO - iteration:66 step:700/10100, NER loss: 1.068687
2019-02-21 20:26:45,999 - log/train6.log - INFO - iteration:66 step:800/10100, NER loss: 0.934965
2019-02-21 20:26:48,013 - log/train6.log - INFO - iteration:66 step:900/10100, NER loss: 0.794843
2019-02-21 20:26:50,181 - log/train6.log - INFO - iteration:66 step:1000/10100, NER loss: 0.880999
2019-02-21 20:26:52,416 - log/train6.log - INFO - iteration:66 step:1100/10100, NER loss: 0.932626
2019-02-21 20:26:54,424 - log/train6.log - INFO - iteration:66 step:1200/10100, NER loss: 0.730462
2019-02-21 20:26:56,533 - log/train6.log - INFO - iteration:66 step:1300/10100, NER loss: 0.738046
2019-02-21 20:26:58,766 - log/train6.log - INFO - iteration:66 step:1400/10100, NER loss: 1.009292
2019-02-21 20:27:00,874 - log/train6.log - INFO - iteration:66 step:1500/10100, NER loss: 0.840753
2019-02-21 20:27:03,470 - log/train6.log - INFO - iteration:66 step:1600/10100, NER loss: 1.199723
2019-02-21 20:27:05,788 - log/train6.log - INFO - iteration:66 step:1700/10100, NER loss: 0.983744
2019-02-21 20:27:08,089 - log/train6.log - INFO - iteration:66 step:1800/10100, NER loss: 1.073054
2019-02-21 20:27:10,278 - log/train6.log - INFO - iteration:66 step:1900/10100, NER loss: 0.875164
2019-02-21 20:27:12,364 - log/train6.log - INFO - iteration:66 step:2000/10100, NER loss: 0.879828
2019-02-21 20:27:14,606 - log/train6.log - INFO - iteration:66 step:2100/10100, NER loss: 1.053840
2019-02-21 20:27:16,994 - log/train6.log - INFO - iteration:66 step:2200/10100, NER loss: 0.922480
2019-02-21 20:27:19,207 - log/train6.log - INFO - iteration:66 step:2300/10100, NER loss: 0.823199
2019-02-21 20:27:21,384 - log/train6.log - INFO - iteration:66 step:2400/10100, NER loss: 0.832234
2019-02-21 20:27:23,443 - log/train6.log - INFO - iteration:66 step:2500/10100, NER loss: 0.908799
2019-02-21 20:27:25,723 - log/train6.log - INFO - iteration:66 step:2600/10100, NER loss: 1.033220
2019-02-21 20:27:28,033 - log/train6.log - INFO - iteration:66 step:2700/10100, NER loss: 1.014941
2019-02-21 20:27:30,236 - log/train6.log - INFO - iteration:66 step:2800/10100, NER loss: 0.982741
2019-02-21 20:27:32,489 - log/train6.log - INFO - iteration:66 step:2900/10100, NER loss: 0.723114
2019-02-21 20:27:34,586 - log/train6.log - INFO - iteration:66 step:3000/10100, NER loss: 0.840699
2019-02-21 20:27:36,817 - log/train6.log - INFO - iteration:66 step:3100/10100, NER loss: 0.896542
2019-02-21 20:27:39,063 - log/train6.log - INFO - iteration:66 step:3200/10100, NER loss: 0.877052
2019-02-21 20:27:41,400 - log/train6.log - INFO - iteration:66 step:3300/10100, NER loss: 1.019857
2019-02-21 20:27:45,839 - log/train6.log - INFO - iteration:66 step:3400/10100, NER loss: 1.907905
2019-02-21 20:27:48,090 - log/train6.log - INFO - iteration:66 step:3500/10100, NER loss: 1.341708
2019-02-21 20:27:50,270 - log/train6.log - INFO - iteration:66 step:3600/10100, NER loss: 0.861303
2019-02-21 20:27:52,493 - log/train6.log - INFO - iteration:66 step:3700/10100, NER loss: 1.011269
2019-02-21 20:27:54,586 - log/train6.log - INFO - iteration:66 step:3800/10100, NER loss: 0.790891
2019-02-21 20:27:56,737 - log/train6.log - INFO - iteration:66 step:3900/10100, NER loss: 0.871230
2019-02-21 20:27:58,916 - log/train6.log - INFO - iteration:66 step:4000/10100, NER loss: 0.882554
2019-02-21 20:28:01,088 - log/train6.log - INFO - iteration:66 step:4100/10100, NER loss: 0.936102
2019-02-21 20:28:03,445 - log/train6.log - INFO - iteration:66 step:4200/10100, NER loss: 0.983755
2019-02-21 20:28:05,832 - log/train6.log - INFO - iteration:66 step:4300/10100, NER loss: 1.034145
2019-02-21 20:28:08,184 - log/train6.log - INFO - iteration:66 step:4400/10100, NER loss: 1.000237
2019-02-21 20:28:10,408 - log/train6.log - INFO - iteration:66 step:4500/10100, NER loss: 1.029327
2019-02-21 20:28:12,476 - log/train6.log - INFO - iteration:66 step:4600/10100, NER loss: 0.837366
2019-02-21 20:28:14,840 - log/train6.log - INFO - iteration:66 step:4700/10100, NER loss: 0.906324
2019-02-21 20:28:17,074 - log/train6.log - INFO - iteration:66 step:4800/10100, NER loss: 0.911470
2019-02-21 20:28:19,305 - log/train6.log - INFO - iteration:66 step:4900/10100, NER loss: 0.985665
2019-02-21 20:28:21,654 - log/train6.log - INFO - iteration:66 step:5000/10100, NER loss: 0.901264
2019-02-21 20:28:23,723 - log/train6.log - INFO - iteration:66 step:5100/10100, NER loss: 0.849870
2019-02-21 20:28:27,874 - log/train6.log - INFO - iteration:66 step:5200/10100, NER loss: 1.363102
2019-02-21 20:28:29,956 - log/train6.log - INFO - iteration:66 step:5300/10100, NER loss: 0.834833
2019-02-21 20:28:32,298 - log/train6.log - INFO - iteration:66 step:5400/10100, NER loss: 0.844385
2019-02-21 20:28:34,439 - log/train6.log - INFO - iteration:66 step:5500/10100, NER loss: 0.814047
2019-02-21 20:28:36,589 - log/train6.log - INFO - iteration:66 step:5600/10100, NER loss: 0.932375
2019-02-21 20:28:38,812 - log/train6.log - INFO - iteration:66 step:5700/10100, NER loss: 0.726730
2019-02-21 20:28:41,137 - log/train6.log - INFO - iteration:66 step:5800/10100, NER loss: 0.975430
2019-02-21 20:28:43,465 - log/train6.log - INFO - iteration:66 step:5900/10100, NER loss: 0.931310
2019-02-21 20:28:45,491 - log/train6.log - INFO - iteration:66 step:6000/10100, NER loss: 0.855134
2019-02-21 20:28:47,761 - log/train6.log - INFO - iteration:66 step:6100/10100, NER loss: 1.002249
2019-02-21 20:28:49,955 - log/train6.log - INFO - iteration:66 step:6200/10100, NER loss: 0.833685
2019-02-21 20:28:52,164 - log/train6.log - INFO - iteration:66 step:6300/10100, NER loss: 0.985310
2019-02-21 20:28:54,257 - log/train6.log - INFO - iteration:66 step:6400/10100, NER loss: 0.848734
2019-02-21 20:28:56,263 - log/train6.log - INFO - iteration:66 step:6500/10100, NER loss: 0.781573
2019-02-21 20:28:58,595 - log/train6.log - INFO - iteration:66 step:6600/10100, NER loss: 0.951582
2019-02-21 20:29:00,886 - log/train6.log - INFO - iteration:66 step:6700/10100, NER loss: 0.972817
2019-02-21 20:29:03,099 - log/train6.log - INFO - iteration:66 step:6800/10100, NER loss: 0.952309
2019-02-21 20:29:05,385 - log/train6.log - INFO - iteration:66 step:6900/10100, NER loss: 0.960305
2019-02-21 20:29:07,702 - log/train6.log - INFO - iteration:66 step:7000/10100, NER loss: 1.138166
2019-02-21 20:29:09,965 - log/train6.log - INFO - iteration:66 step:7100/10100, NER loss: 1.102008
2019-02-21 20:29:12,218 - log/train6.log - INFO - iteration:66 step:7200/10100, NER loss: 0.856339
2019-02-21 20:29:14,599 - log/train6.log - INFO - iteration:66 step:7300/10100, NER loss: 0.960393
2019-02-21 20:29:16,779 - log/train6.log - INFO - iteration:66 step:7400/10100, NER loss: 1.298515
2019-02-21 20:29:18,887 - log/train6.log - INFO - iteration:66 step:7500/10100, NER loss: 0.882587
2019-02-21 20:29:20,918 - log/train6.log - INFO - iteration:66 step:7600/10100, NER loss: 0.839916
2019-02-21 20:29:23,004 - log/train6.log - INFO - iteration:66 step:7700/10100, NER loss: 0.787301
2019-02-21 20:29:25,200 - log/train6.log - INFO - iteration:66 step:7800/10100, NER loss: 0.867713
2019-02-21 20:29:27,612 - log/train6.log - INFO - iteration:66 step:7900/10100, NER loss: 1.084029
2019-02-21 20:29:29,659 - log/train6.log - INFO - iteration:66 step:8000/10100, NER loss: 1.044785
2019-02-21 20:29:31,985 - log/train6.log - INFO - iteration:66 step:8100/10100, NER loss: 0.952253
2019-02-21 20:29:34,310 - log/train6.log - INFO - iteration:66 step:8200/10100, NER loss: 1.077886
2019-02-21 20:29:37,247 - log/train6.log - INFO - iteration:66 step:8300/10100, NER loss: 1.285381
2019-02-21 20:29:39,426 - log/train6.log - INFO - iteration:66 step:8400/10100, NER loss: 0.802743
2019-02-21 20:29:41,472 - log/train6.log - INFO - iteration:66 step:8500/10100, NER loss: 1.032438
2019-02-21 20:29:43,589 - log/train6.log - INFO - iteration:66 step:8600/10100, NER loss: 0.932848
2019-02-21 20:29:45,749 - log/train6.log - INFO - iteration:66 step:8700/10100, NER loss: 0.850148
2019-02-21 20:29:47,805 - log/train6.log - INFO - iteration:66 step:8800/10100, NER loss: 0.724084
2019-02-21 20:29:50,142 - log/train6.log - INFO - iteration:66 step:8900/10100, NER loss: 1.107654
2019-02-21 20:29:52,228 - log/train6.log - INFO - iteration:66 step:9000/10100, NER loss: 0.733972
2019-02-21 20:29:54,578 - log/train6.log - INFO - iteration:66 step:9100/10100, NER loss: 0.921297
2019-02-21 20:29:56,622 - log/train6.log - INFO - iteration:66 step:9200/10100, NER loss: 0.764459
2019-02-21 20:29:58,916 - log/train6.log - INFO - iteration:66 step:9300/10100, NER loss: 1.072426
2019-02-21 20:30:00,820 - log/train6.log - INFO - iteration:66 step:9400/10100, NER loss: 0.710145
2019-02-21 20:30:03,110 - log/train6.log - INFO - iteration:66 step:9500/10100, NER loss: 1.021308
2019-02-21 20:30:05,304 - log/train6.log - INFO - iteration:66 step:9600/10100, NER loss: 0.898390
2019-02-21 20:30:07,523 - log/train6.log - INFO - iteration:66 step:9700/10100, NER loss: 0.982467
2019-02-21 20:30:09,969 - log/train6.log - INFO - iteration:66 step:9800/10100, NER loss: 1.071500
2019-02-21 20:30:12,029 - log/train6.log - INFO - iteration:66 step:9900/10100, NER loss: 1.047434
2019-02-21 20:30:14,071 - log/train6.log - INFO - iteration:66 step:10000/10100, NER loss: 0.645673
2019-02-21 20:30:16,401 - log/train6.log - INFO - iteration:67 step:0/10100, NER loss: 1.125107
2019-02-21 20:30:16,401 - log/train6.log - INFO - evaluate:dev
2019-02-21 20:30:22,939 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5389 phrases; correct: 4131.

2019-02-21 20:30:22,939 - log/train6.log - INFO - accuracy:  91.70%; precision:  76.66%; recall:  70.65%; FB1:  73.53

2019-02-21 20:30:22,940 - log/train6.log - INFO -                 C: precision:  85.93%; recall:  86.16%; FB1:  86.05  3398

2019-02-21 20:30:22,940 - log/train6.log - INFO -               IND: precision:  55.41%; recall:  20.10%; FB1:  29.50  148

2019-02-21 20:30:22,940 - log/train6.log - INFO -               INS: precision:  51.39%; recall:  73.35%; FB1:  60.43  541

2019-02-21 20:30:22,940 - log/train6.log - INFO -                 L: precision:  52.61%; recall:  51.65%; FB1:  52.12  595

2019-02-21 20:30:22,940 - log/train6.log - INFO -                 P: precision:  88.93%; recall:  87.29%; FB1:  88.10  533

2019-02-21 20:30:22,940 - log/train6.log - INFO -               PRO: precision:  36.78%; recall:  12.26%; FB1:  18.39  174

2019-02-21 20:30:22,943 - log/train6.log - INFO - evaluate:test
2019-02-21 20:30:24,400 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1585 phrases; correct: 1329.

2019-02-21 20:30:24,400 - log/train6.log - INFO - accuracy:  96.31%; precision:  83.85%; recall:  80.69%; FB1:  82.24

2019-02-21 20:30:24,400 - log/train6.log - INFO -                 C: precision:  87.56%; recall:  91.64%; FB1:  89.55  1077

2019-02-21 20:30:24,400 - log/train6.log - INFO -               IND: precision:  73.53%; recall:  53.19%; FB1:  61.73  34

2019-02-21 20:30:24,400 - log/train6.log - INFO -               INS: precision:  56.07%; recall:  63.16%; FB1:  59.41  107

2019-02-21 20:30:24,400 - log/train6.log - INFO -                 L: precision:  60.40%; recall:  59.22%; FB1:  59.80  101

2019-02-21 20:30:24,400 - log/train6.log - INFO -                 P: precision:  93.97%; recall:  91.67%; FB1:  92.80  199

2019-02-21 20:30:24,401 - log/train6.log - INFO -               PRO: precision:  79.10%; recall:  31.36%; FB1:  44.92  67

2019-02-21 20:30:26,472 - log/train6.log - INFO - iteration:67 step:100/10100, NER loss: 1.033140
2019-02-21 20:30:28,700 - log/train6.log - INFO - iteration:67 step:200/10100, NER loss: 1.171273
2019-02-21 20:30:30,546 - log/train6.log - INFO - iteration:67 step:300/10100, NER loss: 0.742118
2019-02-21 20:30:32,751 - log/train6.log - INFO - iteration:67 step:400/10100, NER loss: 1.012102
2019-02-21 20:30:34,781 - log/train6.log - INFO - iteration:67 step:500/10100, NER loss: 0.807622
2019-02-21 20:30:37,105 - log/train6.log - INFO - iteration:67 step:600/10100, NER loss: 0.935288
2019-02-21 20:30:39,133 - log/train6.log - INFO - iteration:67 step:700/10100, NER loss: 0.796019
2019-02-21 20:30:41,237 - log/train6.log - INFO - iteration:67 step:800/10100, NER loss: 0.830896
2019-02-21 20:30:43,421 - log/train6.log - INFO - iteration:67 step:900/10100, NER loss: 1.048962
2019-02-21 20:30:45,805 - log/train6.log - INFO - iteration:67 step:1000/10100, NER loss: 0.993695
2019-02-21 20:30:47,902 - log/train6.log - INFO - iteration:67 step:1100/10100, NER loss: 0.859738
2019-02-21 20:30:49,994 - log/train6.log - INFO - iteration:67 step:1200/10100, NER loss: 0.832618
2019-02-21 20:30:52,065 - log/train6.log - INFO - iteration:67 step:1300/10100, NER loss: 0.927058
2019-02-21 20:30:54,136 - log/train6.log - INFO - iteration:67 step:1400/10100, NER loss: 0.805507
2019-02-21 20:30:56,470 - log/train6.log - INFO - iteration:67 step:1500/10100, NER loss: 1.175727
2019-02-21 20:30:58,419 - log/train6.log - INFO - iteration:67 step:1600/10100, NER loss: 0.813730
2019-02-21 20:31:00,685 - log/train6.log - INFO - iteration:67 step:1700/10100, NER loss: 0.934938
2019-02-21 20:31:02,742 - log/train6.log - INFO - iteration:67 step:1800/10100, NER loss: 0.724537
2019-02-21 20:31:05,045 - log/train6.log - INFO - iteration:67 step:1900/10100, NER loss: 0.935707
2019-02-21 20:31:07,070 - log/train6.log - INFO - iteration:67 step:2000/10100, NER loss: 0.725816
2019-02-21 20:31:09,299 - log/train6.log - INFO - iteration:67 step:2100/10100, NER loss: 0.852400
2019-02-21 20:31:11,470 - log/train6.log - INFO - iteration:67 step:2200/10100, NER loss: 0.936062
2019-02-21 20:31:13,696 - log/train6.log - INFO - iteration:67 step:2300/10100, NER loss: 0.986161
2019-02-21 20:31:15,934 - log/train6.log - INFO - iteration:67 step:2400/10100, NER loss: 0.979959
2019-02-21 20:31:18,212 - log/train6.log - INFO - iteration:67 step:2500/10100, NER loss: 0.896647
2019-02-21 20:31:20,554 - log/train6.log - INFO - iteration:67 step:2600/10100, NER loss: 1.209587
2019-02-21 20:31:22,825 - log/train6.log - INFO - iteration:67 step:2700/10100, NER loss: 0.972782
2019-02-21 20:31:24,916 - log/train6.log - INFO - iteration:67 step:2800/10100, NER loss: 0.820741
2019-02-21 20:31:26,987 - log/train6.log - INFO - iteration:67 step:2900/10100, NER loss: 0.751715
2019-02-21 20:31:28,927 - log/train6.log - INFO - iteration:67 step:3000/10100, NER loss: 0.720175
2019-02-21 20:31:31,088 - log/train6.log - INFO - iteration:67 step:3100/10100, NER loss: 0.874726
2019-02-21 20:31:33,191 - log/train6.log - INFO - iteration:67 step:3200/10100, NER loss: 0.855652
2019-02-21 20:31:35,445 - log/train6.log - INFO - iteration:67 step:3300/10100, NER loss: 1.108605
2019-02-21 20:31:37,495 - log/train6.log - INFO - iteration:67 step:3400/10100, NER loss: 0.703315
2019-02-21 20:31:39,834 - log/train6.log - INFO - iteration:67 step:3500/10100, NER loss: 0.956693
2019-02-21 20:31:42,516 - log/train6.log - INFO - iteration:67 step:3600/10100, NER loss: 1.130772
2019-02-21 20:31:44,843 - log/train6.log - INFO - iteration:67 step:3700/10100, NER loss: 0.974720
2019-02-21 20:31:47,164 - log/train6.log - INFO - iteration:67 step:3800/10100, NER loss: 0.861537
2019-02-21 20:31:49,264 - log/train6.log - INFO - iteration:67 step:3900/10100, NER loss: 0.886279
2019-02-21 20:31:51,567 - log/train6.log - INFO - iteration:67 step:4000/10100, NER loss: 0.880492
2019-02-21 20:31:53,708 - log/train6.log - INFO - iteration:67 step:4100/10100, NER loss: 0.753057
2019-02-21 20:31:55,884 - log/train6.log - INFO - iteration:67 step:4200/10100, NER loss: 0.855645
2019-02-21 20:31:58,001 - log/train6.log - INFO - iteration:67 step:4300/10100, NER loss: 0.994783
2019-02-21 20:32:00,193 - log/train6.log - INFO - iteration:67 step:4400/10100, NER loss: 0.887341
2019-02-21 20:32:02,448 - log/train6.log - INFO - iteration:67 step:4500/10100, NER loss: 0.770835
2019-02-21 20:32:04,660 - log/train6.log - INFO - iteration:67 step:4600/10100, NER loss: 0.827319
2019-02-21 20:32:06,702 - log/train6.log - INFO - iteration:67 step:4700/10100, NER loss: 0.830078
2019-02-21 20:32:09,064 - log/train6.log - INFO - iteration:67 step:4800/10100, NER loss: 0.991242
2019-02-21 20:32:11,144 - log/train6.log - INFO - iteration:67 step:4900/10100, NER loss: 0.828202
2019-02-21 20:32:13,323 - log/train6.log - INFO - iteration:67 step:5000/10100, NER loss: 1.081667
2019-02-21 20:32:15,537 - log/train6.log - INFO - iteration:67 step:5100/10100, NER loss: 1.011477
2019-02-21 20:32:17,835 - log/train6.log - INFO - iteration:67 step:5200/10100, NER loss: 1.101419
2019-02-21 20:32:20,094 - log/train6.log - INFO - iteration:67 step:5300/10100, NER loss: 0.943984
2019-02-21 20:32:22,303 - log/train6.log - INFO - iteration:67 step:5400/10100, NER loss: 0.920725
2019-02-21 20:32:24,674 - log/train6.log - INFO - iteration:67 step:5500/10100, NER loss: 1.109352
2019-02-21 20:32:26,861 - log/train6.log - INFO - iteration:67 step:5600/10100, NER loss: 0.990217
2019-02-21 20:32:29,056 - log/train6.log - INFO - iteration:67 step:5700/10100, NER loss: 0.844516
2019-02-21 20:32:31,308 - log/train6.log - INFO - iteration:67 step:5800/10100, NER loss: 0.878135
2019-02-21 20:32:33,615 - log/train6.log - INFO - iteration:67 step:5900/10100, NER loss: 1.261290
2019-02-21 20:32:36,078 - log/train6.log - INFO - iteration:67 step:6000/10100, NER loss: 1.249283
2019-02-21 20:32:38,419 - log/train6.log - INFO - iteration:67 step:6100/10100, NER loss: 0.977931
2019-02-21 20:32:40,589 - log/train6.log - INFO - iteration:67 step:6200/10100, NER loss: 0.892016
2019-02-21 20:32:42,749 - log/train6.log - INFO - iteration:67 step:6300/10100, NER loss: 0.774514
2019-02-21 20:32:44,859 - log/train6.log - INFO - iteration:67 step:6400/10100, NER loss: 0.857757
2019-02-21 20:32:47,049 - log/train6.log - INFO - iteration:67 step:6500/10100, NER loss: 0.802851
2019-02-21 21:07:48,570 - log/train6.log - INFO - iteration:67 step:6600/10100, NER loss: 1.254572
2019-02-21 21:07:51,194 - log/train6.log - INFO - iteration:67 step:6700/10100, NER loss: 0.841536
2019-02-21 21:07:53,258 - log/train6.log - INFO - iteration:67 step:6800/10100, NER loss: 1.027045
2019-02-21 21:07:55,199 - log/train6.log - INFO - iteration:67 step:6900/10100, NER loss: 0.732728
2019-02-21 21:07:57,646 - log/train6.log - INFO - iteration:67 step:7000/10100, NER loss: 0.945180
2019-02-21 21:08:06,409 - log/train6.log - INFO - iteration:67 step:7100/10100, NER loss: 0.805476
2019-02-21 21:08:25,711 - log/train6.log - INFO - iteration:67 step:7200/10100, NER loss: 2.149627
2019-02-21 21:08:34,953 - log/train6.log - INFO - iteration:67 step:7300/10100, NER loss: 1.058644
2019-02-21 21:08:45,327 - log/train6.log - INFO - iteration:67 step:7400/10100, NER loss: 1.051370
2019-02-21 21:08:54,806 - log/train6.log - INFO - iteration:67 step:7500/10100, NER loss: 1.026457
2019-02-21 21:09:03,331 - log/train6.log - INFO - iteration:67 step:7600/10100, NER loss: 0.776463
2019-02-21 21:09:12,662 - log/train6.log - INFO - iteration:67 step:7700/10100, NER loss: 0.910722
2019-02-21 21:09:22,236 - log/train6.log - INFO - iteration:67 step:7800/10100, NER loss: 0.953756
2019-02-21 21:09:31,200 - log/train6.log - INFO - iteration:67 step:7900/10100, NER loss: 0.955782
2019-02-21 21:09:40,509 - log/train6.log - INFO - iteration:67 step:8000/10100, NER loss: 0.875764
2019-02-21 21:09:52,168 - log/train6.log - INFO - iteration:67 step:8100/10100, NER loss: 1.337905
2019-02-21 21:10:01,292 - log/train6.log - INFO - iteration:67 step:8200/10100, NER loss: 0.891272
2019-02-21 21:10:10,518 - log/train6.log - INFO - iteration:67 step:8300/10100, NER loss: 0.800661
2019-02-21 21:10:20,467 - log/train6.log - INFO - iteration:67 step:8400/10100, NER loss: 1.101653
2019-02-21 21:10:28,708 - log/train6.log - INFO - iteration:67 step:8500/10100, NER loss: 0.729193
2019-02-21 21:10:38,663 - log/train6.log - INFO - iteration:67 step:8600/10100, NER loss: 1.029756
2019-02-21 21:10:48,010 - log/train6.log - INFO - iteration:67 step:8700/10100, NER loss: 0.936304
2019-02-21 21:10:57,641 - log/train6.log - INFO - iteration:67 step:8800/10100, NER loss: 0.829326
2019-02-21 21:11:07,926 - log/train6.log - INFO - iteration:67 step:8900/10100, NER loss: 1.187200
2019-02-21 21:11:17,104 - log/train6.log - INFO - iteration:67 step:9000/10100, NER loss: 1.034560
2019-02-21 21:11:25,753 - log/train6.log - INFO - iteration:67 step:9100/10100, NER loss: 0.835389
2019-02-21 21:11:35,347 - log/train6.log - INFO - iteration:67 step:9200/10100, NER loss: 1.085065
2019-02-21 21:11:44,391 - log/train6.log - INFO - iteration:67 step:9300/10100, NER loss: 0.804183
2019-02-21 21:11:53,688 - log/train6.log - INFO - iteration:67 step:9400/10100, NER loss: 0.844481
2019-02-21 21:12:11,274 - log/train6.log - INFO - iteration:67 step:9500/10100, NER loss: 2.284274
2019-02-21 21:12:20,056 - log/train6.log - INFO - iteration:67 step:9600/10100, NER loss: 0.807693
2019-02-21 21:12:30,463 - log/train6.log - INFO - iteration:67 step:9700/10100, NER loss: 1.364882
2019-02-21 21:12:39,440 - log/train6.log - INFO - iteration:67 step:9800/10100, NER loss: 0.708806
2019-02-21 21:12:56,142 - log/train6.log - INFO - iteration:67 step:9900/10100, NER loss: 1.525046
2019-02-21 21:13:06,143 - log/train6.log - INFO - iteration:67 step:10000/10100, NER loss: 0.948462
2019-02-21 21:13:14,915 - log/train6.log - INFO - iteration:68 step:0/10100, NER loss: 0.798912
2019-02-21 21:13:14,915 - log/train6.log - INFO - evaluate:dev
2019-02-21 21:13:43,542 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5822 phrases; correct: 4329.

2019-02-21 21:13:43,544 - log/train6.log - INFO - accuracy:  95.02%; precision:  74.36%; recall:  74.04%; FB1:  74.20

2019-02-21 21:13:43,544 - log/train6.log - INFO -                 C: precision:  83.19%; recall:  88.46%; FB1:  85.74  3604

2019-02-21 21:13:43,544 - log/train6.log - INFO -               IND: precision:  38.56%; recall:  28.92%; FB1:  33.05  306

2019-02-21 21:13:43,545 - log/train6.log - INFO -               INS: precision:  73.16%; recall:  65.44%; FB1:  69.08  339

2019-02-21 21:13:43,545 - log/train6.log - INFO -                 L: precision:  53.78%; recall:  57.59%; FB1:  55.62  649

2019-02-21 21:13:43,545 - log/train6.log - INFO -                 P: precision:  85.99%; recall:  90.42%; FB1:  88.15  571

2019-02-21 21:13:43,546 - log/train6.log - INFO -               PRO: precision:  35.41%; recall:  23.95%; FB1:  28.57  353

2019-02-21 21:13:43,556 - log/train6.log - INFO - evaluate:test
2019-02-21 21:13:50,107 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1678 phrases; correct: 1353.

2019-02-21 21:13:50,107 - log/train6.log - INFO - accuracy:  96.39%; precision:  80.63%; recall:  82.15%; FB1:  81.38

2019-02-21 21:13:50,108 - log/train6.log - INFO -                 C: precision:  85.53%; recall:  91.35%; FB1:  88.35  1099

2019-02-21 21:13:50,108 - log/train6.log - INFO -               IND: precision:  45.90%; recall:  59.57%; FB1:  51.85  61

2019-02-21 21:13:50,108 - log/train6.log - INFO -               INS: precision:  73.08%; recall:  60.00%; FB1:  65.90  78

2019-02-21 21:13:50,109 - log/train6.log - INFO -                 L: precision:  52.34%; recall:  54.37%; FB1:  53.33  107

2019-02-21 21:13:50,109 - log/train6.log - INFO -                 P: precision:  89.30%; recall:  94.12%; FB1:  91.65  215

2019-02-21 21:13:50,109 - log/train6.log - INFO -               PRO: precision:  67.80%; recall:  47.34%; FB1:  55.75  118

2019-02-21 21:13:59,413 - log/train6.log - INFO - iteration:68 step:100/10100, NER loss: 0.854350
2019-02-21 21:14:08,754 - log/train6.log - INFO - iteration:68 step:200/10100, NER loss: 0.921152
2019-02-21 21:14:18,143 - log/train6.log - INFO - iteration:68 step:300/10100, NER loss: 1.021991
2019-02-21 21:14:26,964 - log/train6.log - INFO - iteration:68 step:400/10100, NER loss: 0.925775
2019-02-21 21:14:36,938 - log/train6.log - INFO - iteration:68 step:500/10100, NER loss: 0.980999
2019-02-21 21:14:46,688 - log/train6.log - INFO - iteration:68 step:600/10100, NER loss: 1.024399
2019-02-21 21:14:56,241 - log/train6.log - INFO - iteration:68 step:700/10100, NER loss: 0.890556
2019-02-21 21:15:05,664 - log/train6.log - INFO - iteration:68 step:800/10100, NER loss: 0.964197
2019-02-21 21:15:14,646 - log/train6.log - INFO - iteration:68 step:900/10100, NER loss: 0.889147
2019-02-21 21:15:24,929 - log/train6.log - INFO - iteration:68 step:1000/10100, NER loss: 1.281348
2019-02-21 21:15:34,606 - log/train6.log - INFO - iteration:68 step:1100/10100, NER loss: 0.980468
2019-02-21 21:15:44,313 - log/train6.log - INFO - iteration:68 step:1200/10100, NER loss: 0.899545
2019-02-21 21:15:53,412 - log/train6.log - INFO - iteration:68 step:1300/10100, NER loss: 0.864567
2019-02-21 21:16:02,823 - log/train6.log - INFO - iteration:68 step:1400/10100, NER loss: 0.820528
2019-02-21 21:16:11,726 - log/train6.log - INFO - iteration:68 step:1500/10100, NER loss: 0.956571
2019-02-21 21:16:21,977 - log/train6.log - INFO - iteration:68 step:1600/10100, NER loss: 0.963118
2019-02-21 21:16:38,890 - log/train6.log - INFO - iteration:68 step:1700/10100, NER loss: 2.137882
2019-02-21 21:16:49,285 - log/train6.log - INFO - iteration:68 step:1800/10100, NER loss: 1.304707
2019-02-21 21:16:58,785 - log/train6.log - INFO - iteration:68 step:1900/10100, NER loss: 0.797229
2019-02-21 21:17:08,897 - log/train6.log - INFO - iteration:68 step:2000/10100, NER loss: 1.038986
2019-02-21 21:17:18,362 - log/train6.log - INFO - iteration:68 step:2100/10100, NER loss: 0.924987
2019-02-21 21:17:28,937 - log/train6.log - INFO - iteration:68 step:2200/10100, NER loss: 1.070423
2019-02-21 21:17:37,912 - log/train6.log - INFO - iteration:68 step:2300/10100, NER loss: 0.851237
2019-02-21 21:17:47,935 - log/train6.log - INFO - iteration:68 step:2400/10100, NER loss: 1.023706
2019-02-21 21:17:56,753 - log/train6.log - INFO - iteration:68 step:2500/10100, NER loss: 0.881330
2019-02-21 21:18:06,396 - log/train6.log - INFO - iteration:68 step:2600/10100, NER loss: 1.011595
2019-02-21 21:18:15,346 - log/train6.log - INFO - iteration:68 step:2700/10100, NER loss: 0.800575
2019-02-21 21:18:24,479 - log/train6.log - INFO - iteration:68 step:2800/10100, NER loss: 0.887686
2019-02-21 21:18:34,215 - log/train6.log - INFO - iteration:68 step:2900/10100, NER loss: 1.153522
2019-02-21 21:18:43,688 - log/train6.log - INFO - iteration:68 step:3000/10100, NER loss: 1.142912
2019-02-21 21:18:52,329 - log/train6.log - INFO - iteration:68 step:3100/10100, NER loss: 0.895044
2019-02-21 21:19:01,410 - log/train6.log - INFO - iteration:68 step:3200/10100, NER loss: 0.857444
2019-02-21 21:19:10,234 - log/train6.log - INFO - iteration:68 step:3300/10100, NER loss: 0.779911
2019-02-21 21:19:19,294 - log/train6.log - INFO - iteration:68 step:3400/10100, NER loss: 0.729284
2019-02-21 21:19:27,652 - log/train6.log - INFO - iteration:68 step:3500/10100, NER loss: 0.812012
2019-02-21 21:19:37,405 - log/train6.log - INFO - iteration:68 step:3600/10100, NER loss: 0.969195
2019-02-21 21:19:46,931 - log/train6.log - INFO - iteration:68 step:3700/10100, NER loss: 0.938335
2019-02-21 21:19:56,353 - log/train6.log - INFO - iteration:68 step:3800/10100, NER loss: 1.122976
2019-02-21 21:20:05,388 - log/train6.log - INFO - iteration:68 step:3900/10100, NER loss: 0.785146
2019-02-21 21:20:22,101 - log/train6.log - INFO - iteration:68 step:4000/10100, NER loss: 1.579144
2019-02-21 21:20:30,855 - log/train6.log - INFO - iteration:68 step:4100/10100, NER loss: 0.831425
2019-02-21 21:20:42,450 - log/train6.log - INFO - iteration:68 step:4200/10100, NER loss: 1.296865
2019-02-21 21:20:51,586 - log/train6.log - INFO - iteration:68 step:4300/10100, NER loss: 0.832913
2019-02-21 21:20:59,705 - log/train6.log - INFO - iteration:68 step:4400/10100, NER loss: 0.823425
2019-02-21 21:21:08,699 - log/train6.log - INFO - iteration:68 step:4500/10100, NER loss: 0.966826
2019-02-21 21:21:17,859 - log/train6.log - INFO - iteration:68 step:4600/10100, NER loss: 0.843097
2019-02-21 21:21:26,982 - log/train6.log - INFO - iteration:68 step:4700/10100, NER loss: 0.888441
2019-02-21 21:21:36,825 - log/train6.log - INFO - iteration:68 step:4800/10100, NER loss: 0.992272
2019-02-21 21:21:45,841 - log/train6.log - INFO - iteration:68 step:4900/10100, NER loss: 0.989624
2019-02-21 21:21:54,785 - log/train6.log - INFO - iteration:68 step:5000/10100, NER loss: 0.834994
2019-02-21 21:22:03,154 - log/train6.log - INFO - iteration:68 step:5100/10100, NER loss: 0.868685
2019-02-21 21:22:12,748 - log/train6.log - INFO - iteration:68 step:5200/10100, NER loss: 1.155687
2019-02-21 21:22:20,814 - log/train6.log - INFO - iteration:68 step:5300/10100, NER loss: 0.716139
2019-02-21 21:22:29,340 - log/train6.log - INFO - iteration:68 step:5400/10100, NER loss: 0.787862
2019-02-21 21:22:38,980 - log/train6.log - INFO - iteration:68 step:5500/10100, NER loss: 0.963933
2019-02-21 21:22:48,790 - log/train6.log - INFO - iteration:68 step:5600/10100, NER loss: 1.032734
2019-02-21 21:22:58,683 - log/train6.log - INFO - iteration:68 step:5700/10100, NER loss: 1.097160
2019-02-21 21:23:08,785 - log/train6.log - INFO - iteration:68 step:5800/10100, NER loss: 1.165732
2019-02-21 21:23:18,859 - log/train6.log - INFO - iteration:68 step:5900/10100, NER loss: 0.942251
2019-02-21 21:23:28,894 - log/train6.log - INFO - iteration:68 step:6000/10100, NER loss: 0.990011
2019-02-21 21:23:38,243 - log/train6.log - INFO - iteration:68 step:6100/10100, NER loss: 0.905253
2019-02-21 21:23:47,211 - log/train6.log - INFO - iteration:68 step:6200/10100, NER loss: 0.782006
2019-02-21 21:23:57,004 - log/train6.log - INFO - iteration:68 step:6300/10100, NER loss: 0.995600
2019-02-21 21:24:07,007 - log/train6.log - INFO - iteration:68 step:6400/10100, NER loss: 1.053655
2019-02-21 21:24:16,585 - log/train6.log - INFO - iteration:68 step:6500/10100, NER loss: 1.022840
2019-02-21 21:24:26,038 - log/train6.log - INFO - iteration:68 step:6600/10100, NER loss: 1.039692
2019-02-21 21:24:35,733 - log/train6.log - INFO - iteration:68 step:6700/10100, NER loss: 0.946843
2019-02-21 21:24:45,016 - log/train6.log - INFO - iteration:68 step:6800/10100, NER loss: 0.882857
2019-02-21 21:24:54,429 - log/train6.log - INFO - iteration:68 step:6900/10100, NER loss: 0.993591
2019-02-21 21:25:03,250 - log/train6.log - INFO - iteration:68 step:7000/10100, NER loss: 0.873234
2019-02-21 21:25:13,459 - log/train6.log - INFO - iteration:68 step:7100/10100, NER loss: 1.158805
2019-02-21 21:25:22,832 - log/train6.log - INFO - iteration:68 step:7200/10100, NER loss: 0.991781
2019-02-21 21:25:32,865 - log/train6.log - INFO - iteration:68 step:7300/10100, NER loss: 1.075434
2019-02-21 21:25:42,553 - log/train6.log - INFO - iteration:68 step:7400/10100, NER loss: 1.090274
2019-02-21 21:25:51,922 - log/train6.log - INFO - iteration:68 step:7500/10100, NER loss: 1.006580
2019-02-21 21:26:01,389 - log/train6.log - INFO - iteration:68 step:7600/10100, NER loss: 0.987517
2019-02-21 21:26:10,416 - log/train6.log - INFO - iteration:68 step:7700/10100, NER loss: 0.878369
2019-02-21 21:26:19,506 - log/train6.log - INFO - iteration:68 step:7800/10100, NER loss: 0.837330
2019-02-21 21:26:29,029 - log/train6.log - INFO - iteration:68 step:7900/10100, NER loss: 0.982537
2019-02-21 21:26:38,956 - log/train6.log - INFO - iteration:68 step:8000/10100, NER loss: 1.050762
2019-02-21 21:26:48,827 - log/train6.log - INFO - iteration:68 step:8100/10100, NER loss: 0.972758
2019-02-21 21:26:57,978 - log/train6.log - INFO - iteration:68 step:8200/10100, NER loss: 1.028579
2019-02-21 21:27:07,560 - log/train6.log - INFO - iteration:68 step:8300/10100, NER loss: 1.019192
2019-02-21 21:27:26,127 - log/train6.log - INFO - iteration:68 step:8400/10100, NER loss: 1.984169
2019-02-21 21:27:35,261 - log/train6.log - INFO - iteration:68 step:8500/10100, NER loss: 0.930281
2019-02-21 21:27:43,904 - log/train6.log - INFO - iteration:68 step:8600/10100, NER loss: 0.720564
2019-02-21 21:27:53,040 - log/train6.log - INFO - iteration:68 step:8700/10100, NER loss: 0.924524
2019-02-21 21:28:02,917 - log/train6.log - INFO - iteration:68 step:8800/10100, NER loss: 1.006248
2019-02-21 21:28:11,636 - log/train6.log - INFO - iteration:68 step:8900/10100, NER loss: 0.873712
2019-02-21 21:28:20,042 - log/train6.log - INFO - iteration:68 step:9000/10100, NER loss: 0.975243
2019-02-21 21:28:28,512 - log/train6.log - INFO - iteration:68 step:9100/10100, NER loss: 0.814840
2019-02-21 21:28:37,678 - log/train6.log - INFO - iteration:68 step:9200/10100, NER loss: 0.961822
2019-02-21 21:28:47,511 - log/train6.log - INFO - iteration:68 step:9300/10100, NER loss: 1.013826
2019-02-21 21:28:57,954 - log/train6.log - INFO - iteration:68 step:9400/10100, NER loss: 1.168539
2019-02-21 21:29:08,018 - log/train6.log - INFO - iteration:68 step:9500/10100, NER loss: 1.008557
2019-02-21 21:29:18,611 - log/train6.log - INFO - iteration:68 step:9600/10100, NER loss: 1.161096
2019-02-21 21:29:27,513 - log/train6.log - INFO - iteration:68 step:9700/10100, NER loss: 0.773427
2019-02-21 21:29:36,452 - log/train6.log - INFO - iteration:68 step:9800/10100, NER loss: 0.894631
2019-02-21 21:29:45,637 - log/train6.log - INFO - iteration:68 step:9900/10100, NER loss: 0.883235
2019-02-21 21:29:55,909 - log/train6.log - INFO - iteration:68 step:10000/10100, NER loss: 1.109635
2019-02-21 21:30:04,878 - log/train6.log - INFO - iteration:69 step:0/10100, NER loss: 0.970497
2019-02-21 21:30:04,879 - log/train6.log - INFO - evaluate:dev
2019-02-21 21:30:33,490 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5799 phrases; correct: 4250.

2019-02-21 21:30:33,491 - log/train6.log - INFO - accuracy:  94.84%; precision:  73.29%; recall:  72.69%; FB1:  72.99

2019-02-21 21:30:33,491 - log/train6.log - INFO -                 C: precision:  84.56%; recall:  87.46%; FB1:  85.99  3505

2019-02-21 21:30:33,491 - log/train6.log - INFO -               IND: precision:  28.84%; recall:  29.90%; FB1:  29.36  423

2019-02-21 21:30:33,492 - log/train6.log - INFO -               INS: precision:  58.48%; recall:  70.98%; FB1:  64.12  460

2019-02-21 21:30:33,492 - log/train6.log - INFO -                 L: precision:  57.22%; recall:  52.31%; FB1:  54.66  554

2019-02-21 21:30:33,492 - log/train6.log - INFO -                 P: precision:  86.19%; recall:  89.69%; FB1:  87.91  565

2019-02-21 21:30:33,493 - log/train6.log - INFO -               PRO: precision:  31.16%; recall:  17.43%; FB1:  22.36  292

2019-02-21 21:30:33,503 - log/train6.log - INFO - evaluate:test
2019-02-21 21:30:40,077 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1672 phrases; correct: 1350.

2019-02-21 21:30:40,078 - log/train6.log - INFO - accuracy:  96.17%; precision:  80.74%; recall:  81.97%; FB1:  81.35

2019-02-21 21:30:40,078 - log/train6.log - INFO -                 C: precision:  87.00%; recall:  91.06%; FB1:  88.98  1077

2019-02-21 21:30:40,079 - log/train6.log - INFO -               IND: precision:  38.27%; recall:  65.96%; FB1:  48.44  81

2019-02-21 21:30:40,079 - log/train6.log - INFO -               INS: precision:  56.88%; recall:  65.26%; FB1:  60.78  109

2019-02-21 21:30:40,079 - log/train6.log - INFO -                 L: precision:  62.92%; recall:  54.37%; FB1:  58.33  89

2019-02-21 21:30:40,079 - log/train6.log - INFO -                 P: precision:  89.40%; recall:  95.10%; FB1:  92.16  217

2019-02-21 21:30:40,080 - log/train6.log - INFO -               PRO: precision:  70.71%; recall:  41.42%; FB1:  52.24  99

2019-02-21 21:30:48,885 - log/train6.log - INFO - iteration:69 step:100/10100, NER loss: 0.887846
2019-02-21 21:30:59,014 - log/train6.log - INFO - iteration:69 step:200/10100, NER loss: 1.092280
2019-02-21 21:31:08,207 - log/train6.log - INFO - iteration:69 step:300/10100, NER loss: 1.174438
2019-02-21 21:31:16,605 - log/train6.log - INFO - iteration:69 step:400/10100, NER loss: 0.732568
2019-02-21 21:31:25,956 - log/train6.log - INFO - iteration:69 step:500/10100, NER loss: 0.866475
2019-02-21 21:31:34,467 - log/train6.log - INFO - iteration:69 step:600/10100, NER loss: 0.711012
2019-02-21 21:31:43,520 - log/train6.log - INFO - iteration:69 step:700/10100, NER loss: 0.704362
2019-02-21 21:31:54,096 - log/train6.log - INFO - iteration:69 step:800/10100, NER loss: 1.221520
2019-02-21 21:32:02,989 - log/train6.log - INFO - iteration:69 step:900/10100, NER loss: 0.857758
2019-02-21 21:32:20,262 - log/train6.log - INFO - iteration:69 step:1000/10100, NER loss: 2.131634
2019-02-21 21:32:30,512 - log/train6.log - INFO - iteration:69 step:1100/10100, NER loss: 0.997987
2019-02-21 21:32:40,316 - log/train6.log - INFO - iteration:69 step:1200/10100, NER loss: 1.048104
2019-02-21 21:32:49,985 - log/train6.log - INFO - iteration:69 step:1300/10100, NER loss: 1.095733
2019-02-21 21:32:59,956 - log/train6.log - INFO - iteration:69 step:1400/10100, NER loss: 0.940015
2019-02-21 21:33:09,202 - log/train6.log - INFO - iteration:69 step:1500/10100, NER loss: 0.845541
2019-02-21 21:33:19,015 - log/train6.log - INFO - iteration:69 step:1600/10100, NER loss: 1.014908
2019-02-21 21:33:28,348 - log/train6.log - INFO - iteration:69 step:1700/10100, NER loss: 0.939312
2019-02-21 21:33:37,036 - log/train6.log - INFO - iteration:69 step:1800/10100, NER loss: 0.833454
2019-02-21 21:33:47,453 - log/train6.log - INFO - iteration:69 step:1900/10100, NER loss: 1.283553
2019-02-21 23:33:51,427 - log/train6.log - INFO - iteration:69 step:2000/10100, NER loss: 0.768534
2019-02-21 23:33:53,477 - log/train6.log - INFO - iteration:69 step:2100/10100, NER loss: 0.862316
2019-02-21 23:33:55,396 - log/train6.log - INFO - iteration:69 step:2200/10100, NER loss: 0.842550
2019-02-21 23:33:57,314 - log/train6.log - INFO - iteration:69 step:2300/10100, NER loss: 0.855542
2019-02-21 23:33:59,257 - log/train6.log - INFO - iteration:69 step:2400/10100, NER loss: 1.010500
2019-02-21 23:34:08,277 - log/train6.log - INFO - iteration:69 step:2500/10100, NER loss: 0.945836
2019-02-21 23:34:18,481 - log/train6.log - INFO - iteration:69 step:2600/10100, NER loss: 0.985629
2019-02-21 23:34:26,873 - log/train6.log - INFO - iteration:69 step:2700/10100, NER loss: 0.797225
2019-02-21 23:34:35,589 - log/train6.log - INFO - iteration:69 step:2800/10100, NER loss: 0.848808
2019-02-21 23:34:44,555 - log/train6.log - INFO - iteration:69 step:2900/10100, NER loss: 0.922033
2019-02-21 23:34:53,747 - log/train6.log - INFO - iteration:69 step:3000/10100, NER loss: 0.917361
2019-02-21 23:35:02,681 - log/train6.log - INFO - iteration:69 step:3100/10100, NER loss: 0.839669
2019-02-21 23:35:12,501 - log/train6.log - INFO - iteration:69 step:3200/10100, NER loss: 0.937623
2019-02-21 23:35:21,979 - log/train6.log - INFO - iteration:69 step:3300/10100, NER loss: 0.947803
2019-02-21 23:35:31,546 - log/train6.log - INFO - iteration:69 step:3400/10100, NER loss: 0.934227
2019-02-21 23:35:41,981 - log/train6.log - INFO - iteration:69 step:3500/10100, NER loss: 1.275793
2019-02-21 23:35:50,335 - log/train6.log - INFO - iteration:69 step:3600/10100, NER loss: 0.760882
2019-02-21 23:36:00,331 - log/train6.log - INFO - iteration:69 step:3700/10100, NER loss: 0.985848
2019-02-21 23:36:10,042 - log/train6.log - INFO - iteration:69 step:3800/10100, NER loss: 0.974819
2019-02-21 23:36:19,298 - log/train6.log - INFO - iteration:69 step:3900/10100, NER loss: 0.836379
2019-02-21 23:36:29,242 - log/train6.log - INFO - iteration:69 step:4000/10100, NER loss: 1.016113
2019-02-21 23:36:38,744 - log/train6.log - INFO - iteration:69 step:4100/10100, NER loss: 1.037751
2019-02-21 23:36:47,988 - log/train6.log - INFO - iteration:69 step:4200/10100, NER loss: 0.923843
2019-02-21 23:36:57,360 - log/train6.log - INFO - iteration:69 step:4300/10100, NER loss: 0.937753
2019-02-21 23:37:07,179 - log/train6.log - INFO - iteration:69 step:4400/10100, NER loss: 0.935593
2019-02-21 23:37:15,806 - log/train6.log - INFO - iteration:69 step:4500/10100, NER loss: 0.763335
2019-02-21 23:37:25,982 - log/train6.log - INFO - iteration:69 step:4600/10100, NER loss: 1.012736
2019-02-21 23:37:35,428 - log/train6.log - INFO - iteration:69 step:4700/10100, NER loss: 0.912935
2019-02-21 23:37:44,699 - log/train6.log - INFO - iteration:69 step:4800/10100, NER loss: 0.950481
2019-02-21 23:37:54,224 - log/train6.log - INFO - iteration:69 step:4900/10100, NER loss: 0.835224
2019-02-21 23:38:04,674 - log/train6.log - INFO - iteration:69 step:5000/10100, NER loss: 1.029787
2019-02-21 23:38:13,061 - log/train6.log - INFO - iteration:69 step:5100/10100, NER loss: 0.747235
2019-02-21 23:38:22,305 - log/train6.log - INFO - iteration:69 step:5200/10100, NER loss: 0.968561
2019-02-21 23:38:31,209 - log/train6.log - INFO - iteration:69 step:5300/10100, NER loss: 0.974070
2019-02-21 23:38:39,903 - log/train6.log - INFO - iteration:69 step:5400/10100, NER loss: 0.741459
2019-02-21 23:38:48,950 - log/train6.log - INFO - iteration:69 step:5500/10100, NER loss: 0.872138
2019-02-21 23:38:59,184 - log/train6.log - INFO - iteration:69 step:5600/10100, NER loss: 1.099350
2019-02-21 23:39:08,458 - log/train6.log - INFO - iteration:69 step:5700/10100, NER loss: 1.321481
2019-02-21 23:39:18,064 - log/train6.log - INFO - iteration:69 step:5800/10100, NER loss: 0.911408
2019-02-21 23:39:27,652 - log/train6.log - INFO - iteration:69 step:5900/10100, NER loss: 0.922435
2019-02-21 23:39:37,108 - log/train6.log - INFO - iteration:69 step:6000/10100, NER loss: 0.893097
2019-02-21 23:39:46,582 - log/train6.log - INFO - iteration:69 step:6100/10100, NER loss: 0.801680
2019-02-21 23:39:57,084 - log/train6.log - INFO - iteration:69 step:6200/10100, NER loss: 1.251439
2019-02-21 23:40:06,461 - log/train6.log - INFO - iteration:69 step:6300/10100, NER loss: 1.013812
2019-02-21 23:40:16,027 - log/train6.log - INFO - iteration:69 step:6400/10100, NER loss: 0.915770
2019-02-21 23:40:35,308 - log/train6.log - INFO - iteration:69 step:6500/10100, NER loss: 3.336589
2019-02-21 23:40:44,608 - log/train6.log - INFO - iteration:69 step:6600/10100, NER loss: 1.065033
2019-02-21 23:40:52,973 - log/train6.log - INFO - iteration:69 step:6700/10100, NER loss: 0.945804
2019-02-21 23:41:03,075 - log/train6.log - INFO - iteration:69 step:6800/10100, NER loss: 1.153141
2019-02-21 23:41:11,932 - log/train6.log - INFO - iteration:69 step:6900/10100, NER loss: 0.834265
2019-02-21 23:41:21,596 - log/train6.log - INFO - iteration:69 step:7000/10100, NER loss: 0.998937
2019-02-21 23:41:29,866 - log/train6.log - INFO - iteration:69 step:7100/10100, NER loss: 0.803831
2019-02-21 23:41:39,391 - log/train6.log - INFO - iteration:69 step:7200/10100, NER loss: 0.888430
2019-02-21 23:41:48,753 - log/train6.log - INFO - iteration:69 step:7300/10100, NER loss: 0.949763
2019-02-21 23:41:57,246 - log/train6.log - INFO - iteration:69 step:7400/10100, NER loss: 0.844661
2019-02-21 23:42:07,342 - log/train6.log - INFO - iteration:69 step:7500/10100, NER loss: 1.095195
2019-02-21 23:42:16,392 - log/train6.log - INFO - iteration:69 step:7600/10100, NER loss: 0.835604
2019-02-21 23:42:25,199 - log/train6.log - INFO - iteration:69 step:7700/10100, NER loss: 0.749572
2019-02-21 23:42:34,597 - log/train6.log - INFO - iteration:69 step:7800/10100, NER loss: 1.047487
2019-02-21 23:42:43,331 - log/train6.log - INFO - iteration:69 step:7900/10100, NER loss: 0.844988
2019-02-21 23:42:52,522 - log/train6.log - INFO - iteration:69 step:8000/10100, NER loss: 0.769833
2019-02-21 23:43:01,722 - log/train6.log - INFO - iteration:69 step:8100/10100, NER loss: 0.910961
2019-02-21 23:43:10,715 - log/train6.log - INFO - iteration:69 step:8200/10100, NER loss: 0.906149
2019-02-21 23:43:19,225 - log/train6.log - INFO - iteration:69 step:8300/10100, NER loss: 0.906349
2019-02-21 23:43:28,091 - log/train6.log - INFO - iteration:69 step:8400/10100, NER loss: 0.834266
2019-02-21 23:43:37,490 - log/train6.log - INFO - iteration:69 step:8500/10100, NER loss: 1.040622
2019-02-21 23:43:55,534 - log/train6.log - INFO - iteration:69 step:8600/10100, NER loss: 1.686602
2019-02-21 23:44:04,701 - log/train6.log - INFO - iteration:69 step:8700/10100, NER loss: 1.035104
2019-02-21 23:44:14,411 - log/train6.log - INFO - iteration:69 step:8800/10100, NER loss: 1.012957
2019-02-21 23:44:24,032 - log/train6.log - INFO - iteration:69 step:8900/10100, NER loss: 1.034958
2019-02-21 23:44:32,860 - log/train6.log - INFO - iteration:69 step:9000/10100, NER loss: 0.806647
2019-02-21 23:44:42,008 - log/train6.log - INFO - iteration:69 step:9100/10100, NER loss: 0.940610
2019-02-21 23:44:51,735 - log/train6.log - INFO - iteration:69 step:9200/10100, NER loss: 1.060880
2019-02-21 23:45:01,042 - log/train6.log - INFO - iteration:69 step:9300/10100, NER loss: 1.001718
2019-02-21 23:45:09,984 - log/train6.log - INFO - iteration:69 step:9400/10100, NER loss: 0.756181
2019-02-21 23:45:19,766 - log/train6.log - INFO - iteration:69 step:9500/10100, NER loss: 0.949474
2019-02-21 23:45:30,011 - log/train6.log - INFO - iteration:69 step:9600/10100, NER loss: 1.110067
2019-02-21 23:45:40,126 - log/train6.log - INFO - iteration:69 step:9700/10100, NER loss: 1.056570
2019-02-21 23:45:51,330 - log/train6.log - INFO - iteration:69 step:9800/10100, NER loss: 1.309191
2019-02-21 23:46:00,370 - log/train6.log - INFO - iteration:69 step:9900/10100, NER loss: 0.947550
2019-02-21 23:46:10,275 - log/train6.log - INFO - iteration:69 step:10000/10100, NER loss: 0.991707
2019-02-21 23:46:19,735 - log/train6.log - INFO - iteration:70 step:0/10100, NER loss: 1.003949
2019-02-21 23:46:19,735 - log/train6.log - INFO - evaluate:dev
2019-02-21 23:46:48,226 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5871 phrases; correct: 4292.

2019-02-21 23:46:48,226 - log/train6.log - INFO - accuracy:  94.34%; precision:  73.11%; recall:  73.41%; FB1:  73.25

2019-02-21 23:46:48,227 - log/train6.log - INFO -                 C: precision:  83.72%; recall:  87.58%; FB1:  85.61  3545

2019-02-21 23:46:48,227 - log/train6.log - INFO -               IND: precision:  38.96%; recall:  23.77%; FB1:  29.53  249

2019-02-21 23:46:48,227 - log/train6.log - INFO -               INS: precision:  57.59%; recall:  73.09%; FB1:  64.42  481

2019-02-21 23:46:48,227 - log/train6.log - INFO -                 L: precision:  57.96%; recall:  48.68%; FB1:  52.91  509

2019-02-21 23:46:48,228 - log/train6.log - INFO -                 P: precision:  87.84%; recall:  90.42%; FB1:  89.11  559

2019-02-21 23:46:48,228 - log/train6.log - INFO -               PRO: precision:  31.06%; recall:  31.42%; FB1:  31.24  528

2019-02-21 23:46:48,238 - log/train6.log - INFO - evaluate:test
2019-02-21 23:46:54,759 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1717 phrases; correct: 1373.

2019-02-21 23:46:54,760 - log/train6.log - INFO - accuracy:  95.88%; precision:  79.97%; recall:  83.36%; FB1:  81.63

2019-02-21 23:46:54,760 - log/train6.log - INFO -                 C: precision:  86.58%; recall:  91.55%; FB1:  88.99  1088

2019-02-21 23:46:54,760 - log/train6.log - INFO -               IND: precision:  55.36%; recall:  65.96%; FB1:  60.19  56

2019-02-21 23:46:54,760 - log/train6.log - INFO -               INS: precision:  57.80%; recall:  66.32%; FB1:  61.76  109

2019-02-21 23:46:54,761 - log/train6.log - INFO -                 L: precision:  59.14%; recall:  53.40%; FB1:  56.12  93

2019-02-21 23:46:54,761 - log/train6.log - INFO -                 P: precision:  91.00%; recall:  94.12%; FB1:  92.53  211

2019-02-21 23:46:54,761 - log/train6.log - INFO -               PRO: precision:  56.25%; recall:  53.25%; FB1:  54.71  160

2019-02-21 23:47:04,410 - log/train6.log - INFO - iteration:70 step:100/10100, NER loss: 0.893238
2019-02-21 23:47:13,953 - log/train6.log - INFO - iteration:70 step:200/10100, NER loss: 0.991663
2019-02-21 23:47:23,228 - log/train6.log - INFO - iteration:70 step:300/10100, NER loss: 1.015317
2019-02-21 23:47:32,936 - log/train6.log - INFO - iteration:70 step:400/10100, NER loss: 0.965578
2019-02-21 23:47:42,744 - log/train6.log - INFO - iteration:70 step:500/10100, NER loss: 1.181604
2019-02-21 23:47:52,665 - log/train6.log - INFO - iteration:70 step:600/10100, NER loss: 1.067461
2019-02-21 23:48:02,811 - log/train6.log - INFO - iteration:70 step:700/10100, NER loss: 1.119926
2019-02-21 23:48:12,112 - log/train6.log - INFO - iteration:70 step:800/10100, NER loss: 0.873999
2019-02-21 23:48:21,643 - log/train6.log - INFO - iteration:70 step:900/10100, NER loss: 0.989238
2019-02-21 23:48:30,645 - log/train6.log - INFO - iteration:70 step:1000/10100, NER loss: 0.915219
2019-02-21 23:48:40,643 - log/train6.log - INFO - iteration:70 step:1100/10100, NER loss: 1.132094
2019-02-21 23:48:49,814 - log/train6.log - INFO - iteration:70 step:1200/10100, NER loss: 0.915844
2019-02-21 23:48:59,460 - log/train6.log - INFO - iteration:70 step:1300/10100, NER loss: 0.947623
2019-02-21 23:49:08,539 - log/train6.log - INFO - iteration:70 step:1400/10100, NER loss: 0.792464
2019-02-21 23:49:20,793 - log/train6.log - INFO - iteration:70 step:1500/10100, NER loss: 1.243550
2019-02-21 23:49:30,240 - log/train6.log - INFO - iteration:70 step:1600/10100, NER loss: 1.068125
2019-02-21 23:49:38,993 - log/train6.log - INFO - iteration:70 step:1700/10100, NER loss: 0.748731
2019-02-21 23:49:48,219 - log/train6.log - INFO - iteration:70 step:1800/10100, NER loss: 1.029353
2019-02-21 23:49:57,112 - log/train6.log - INFO - iteration:70 step:1900/10100, NER loss: 0.915198
2019-02-21 23:50:07,176 - log/train6.log - INFO - iteration:70 step:2000/10100, NER loss: 0.976498
2019-02-21 23:50:15,683 - log/train6.log - INFO - iteration:70 step:2100/10100, NER loss: 0.893086
2019-02-21 23:50:24,789 - log/train6.log - INFO - iteration:70 step:2200/10100, NER loss: 0.850084
2019-02-21 23:50:33,992 - log/train6.log - INFO - iteration:70 step:2300/10100, NER loss: 0.865968
2019-02-21 23:50:43,126 - log/train6.log - INFO - iteration:70 step:2400/10100, NER loss: 0.853893
2019-02-21 23:50:59,809 - log/train6.log - INFO - iteration:70 step:2500/10100, NER loss: 1.538036
2019-02-21 23:51:08,795 - log/train6.log - INFO - iteration:70 step:2600/10100, NER loss: 0.944155
2019-02-21 23:51:18,739 - log/train6.log - INFO - iteration:70 step:2700/10100, NER loss: 1.041698
2019-02-21 23:51:28,895 - log/train6.log - INFO - iteration:70 step:2800/10100, NER loss: 1.187914
2019-02-21 23:51:37,732 - log/train6.log - INFO - iteration:70 step:2900/10100, NER loss: 0.759125
2019-02-21 23:51:47,063 - log/train6.log - INFO - iteration:70 step:3000/10100, NER loss: 0.935334
2019-02-21 23:51:56,577 - log/train6.log - INFO - iteration:70 step:3100/10100, NER loss: 0.909958
2019-02-21 23:52:06,510 - log/train6.log - INFO - iteration:70 step:3200/10100, NER loss: 1.067868
2019-02-21 23:52:14,968 - log/train6.log - INFO - iteration:70 step:3300/10100, NER loss: 0.692971
2019-02-21 23:52:24,656 - log/train6.log - INFO - iteration:70 step:3400/10100, NER loss: 1.001920
2019-02-21 23:52:34,999 - log/train6.log - INFO - iteration:70 step:3500/10100, NER loss: 1.084717
2019-02-21 23:52:44,715 - log/train6.log - INFO - iteration:70 step:3600/10100, NER loss: 1.006271
2019-02-21 23:52:53,329 - log/train6.log - INFO - iteration:70 step:3700/10100, NER loss: 0.787345
2019-02-21 23:53:02,542 - log/train6.log - INFO - iteration:70 step:3800/10100, NER loss: 1.125044
2019-02-21 23:53:11,840 - log/train6.log - INFO - iteration:70 step:3900/10100, NER loss: 0.935342
2019-02-21 23:53:30,837 - log/train6.log - INFO - iteration:70 step:4000/10100, NER loss: 1.659279
2019-02-21 23:53:40,151 - log/train6.log - INFO - iteration:70 step:4100/10100, NER loss: 1.041959
2019-02-21 23:53:49,876 - log/train6.log - INFO - iteration:70 step:4200/10100, NER loss: 1.042952
2019-02-21 23:53:59,116 - log/train6.log - INFO - iteration:70 step:4300/10100, NER loss: 0.828029
2019-02-21 23:54:08,076 - log/train6.log - INFO - iteration:70 step:4400/10100, NER loss: 1.039116
2019-02-21 23:54:17,617 - log/train6.log - INFO - iteration:70 step:4500/10100, NER loss: 1.163862
2019-02-21 23:54:26,222 - log/train6.log - INFO - iteration:70 step:4600/10100, NER loss: 0.863450
2019-02-21 23:54:35,624 - log/train6.log - INFO - iteration:70 step:4700/10100, NER loss: 1.079865
2019-02-21 23:54:45,295 - log/train6.log - INFO - iteration:70 step:4800/10100, NER loss: 0.968092
2019-02-21 23:54:55,025 - log/train6.log - INFO - iteration:70 step:4900/10100, NER loss: 1.188390
2019-02-21 23:55:04,388 - log/train6.log - INFO - iteration:70 step:5000/10100, NER loss: 0.864616
2019-02-21 23:55:13,840 - log/train6.log - INFO - iteration:70 step:5100/10100, NER loss: 0.937311
2019-02-21 23:55:22,775 - log/train6.log - INFO - iteration:70 step:5200/10100, NER loss: 0.782908
2019-02-21 23:55:31,979 - log/train6.log - INFO - iteration:70 step:5300/10100, NER loss: 0.953810
2019-02-21 23:55:40,764 - log/train6.log - INFO - iteration:70 step:5400/10100, NER loss: 0.972125
2019-02-21 23:55:50,066 - log/train6.log - INFO - iteration:70 step:5500/10100, NER loss: 0.865750
2019-02-21 23:55:59,614 - log/train6.log - INFO - iteration:70 step:5600/10100, NER loss: 1.053536
2019-02-21 23:56:09,388 - log/train6.log - INFO - iteration:70 step:5700/10100, NER loss: 1.160258
2019-02-21 23:56:18,349 - log/train6.log - INFO - iteration:70 step:5800/10100, NER loss: 0.882349
2019-02-21 23:56:27,568 - log/train6.log - INFO - iteration:70 step:5900/10100, NER loss: 0.813930
2019-02-21 23:56:36,398 - log/train6.log - INFO - iteration:70 step:6000/10100, NER loss: 0.982065
2019-02-21 23:56:44,802 - log/train6.log - INFO - iteration:70 step:6100/10100, NER loss: 0.740984
2019-02-21 23:56:54,465 - log/train6.log - INFO - iteration:70 step:6200/10100, NER loss: 1.556058
2019-02-21 23:57:04,216 - log/train6.log - INFO - iteration:70 step:6300/10100, NER loss: 0.921887
2019-02-21 23:57:14,239 - log/train6.log - INFO - iteration:70 step:6400/10100, NER loss: 0.977977
2019-02-21 23:57:23,556 - log/train6.log - INFO - iteration:70 step:6500/10100, NER loss: 0.969897
2019-02-21 23:57:34,850 - log/train6.log - INFO - iteration:70 step:6600/10100, NER loss: 1.156960
2019-02-21 23:57:45,250 - log/train6.log - INFO - iteration:70 step:6700/10100, NER loss: 1.147489
2019-02-21 23:57:54,298 - log/train6.log - INFO - iteration:70 step:6800/10100, NER loss: 0.884948
2019-02-21 23:58:03,596 - log/train6.log - INFO - iteration:70 step:6900/10100, NER loss: 0.832868
2019-02-21 23:58:12,234 - log/train6.log - INFO - iteration:70 step:7000/10100, NER loss: 0.768572
2019-02-21 23:58:21,856 - log/train6.log - INFO - iteration:70 step:7100/10100, NER loss: 1.007270
2019-02-21 23:58:31,430 - log/train6.log - INFO - iteration:70 step:7200/10100, NER loss: 0.856492
2019-02-21 23:58:49,270 - log/train6.log - INFO - iteration:70 step:7300/10100, NER loss: 1.662684
2019-02-21 23:58:58,191 - log/train6.log - INFO - iteration:70 step:7400/10100, NER loss: 0.956400
2019-02-21 23:59:07,129 - log/train6.log - INFO - iteration:70 step:7500/10100, NER loss: 0.936199
2019-02-21 23:59:17,123 - log/train6.log - INFO - iteration:70 step:7600/10100, NER loss: 1.222494
2019-02-21 23:59:26,215 - log/train6.log - INFO - iteration:70 step:7700/10100, NER loss: 1.014946
2019-02-21 23:59:35,354 - log/train6.log - INFO - iteration:70 step:7800/10100, NER loss: 0.865193
2019-02-21 23:59:44,765 - log/train6.log - INFO - iteration:70 step:7900/10100, NER loss: 1.135869
2019-02-21 23:59:54,187 - log/train6.log - INFO - iteration:70 step:8000/10100, NER loss: 0.908861
2019-02-22 00:00:03,196 - log/train6.log - INFO - iteration:70 step:8100/10100, NER loss: 0.824626
2019-02-22 00:00:12,733 - log/train6.log - INFO - iteration:70 step:8200/10100, NER loss: 0.831874
2019-02-22 00:00:21,857 - log/train6.log - INFO - iteration:70 step:8300/10100, NER loss: 1.028876
2019-02-22 00:00:30,998 - log/train6.log - INFO - iteration:70 step:8400/10100, NER loss: 0.894456
2019-02-22 00:00:40,322 - log/train6.log - INFO - iteration:70 step:8500/10100, NER loss: 0.944205
2019-02-22 00:00:49,122 - log/train6.log - INFO - iteration:70 step:8600/10100, NER loss: 0.893229
2019-02-22 00:00:58,326 - log/train6.log - INFO - iteration:70 step:8700/10100, NER loss: 0.996566
2019-02-22 00:01:06,812 - log/train6.log - INFO - iteration:70 step:8800/10100, NER loss: 0.838833
2019-02-22 00:01:16,167 - log/train6.log - INFO - iteration:70 step:8900/10100, NER loss: 1.033948
2019-02-22 00:01:25,469 - log/train6.log - INFO - iteration:70 step:9000/10100, NER loss: 1.015657
2019-02-22 00:01:34,791 - log/train6.log - INFO - iteration:70 step:9100/10100, NER loss: 0.864445
2019-02-22 00:01:44,035 - log/train6.log - INFO - iteration:70 step:9200/10100, NER loss: 0.912565
2019-02-22 00:01:53,881 - log/train6.log - INFO - iteration:70 step:9300/10100, NER loss: 1.022062
2019-02-22 00:02:03,057 - log/train6.log - INFO - iteration:70 step:9400/10100, NER loss: 0.978574
2019-02-22 00:02:13,158 - log/train6.log - INFO - iteration:70 step:9500/10100, NER loss: 0.891912
2019-02-22 00:02:22,074 - log/train6.log - INFO - iteration:70 step:9600/10100, NER loss: 0.739182
2019-02-22 00:02:31,251 - log/train6.log - INFO - iteration:70 step:9700/10100, NER loss: 0.858256
2019-02-22 00:02:40,867 - log/train6.log - INFO - iteration:70 step:9800/10100, NER loss: 1.028908
2019-02-22 00:02:50,564 - log/train6.log - INFO - iteration:70 step:9900/10100, NER loss: 1.079170
2019-02-22 00:02:59,318 - log/train6.log - INFO - iteration:70 step:10000/10100, NER loss: 0.819095
2019-02-22 00:03:09,611 - log/train6.log - INFO - iteration:71 step:0/10100, NER loss: 1.110026
2019-02-22 00:03:09,613 - log/train6.log - INFO - evaluate:dev
2019-02-22 00:03:38,184 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5861 phrases; correct: 4314.

2019-02-22 00:03:38,184 - log/train6.log - INFO - accuracy:  94.62%; precision:  73.61%; recall:  73.78%; FB1:  73.69

2019-02-22 00:03:38,185 - log/train6.log - INFO -                 C: precision:  83.32%; recall:  87.55%; FB1:  85.38  3561

2019-02-22 00:03:38,185 - log/train6.log - INFO -               IND: precision:  34.17%; recall:  26.72%; FB1:  29.99  319

2019-02-22 00:03:38,185 - log/train6.log - INFO -               INS: precision:  66.84%; recall:  69.66%; FB1:  68.22  395

2019-02-22 00:03:38,186 - log/train6.log - INFO -                 L: precision:  58.80%; recall:  56.77%; FB1:  57.77  585

2019-02-22 00:03:38,186 - log/train6.log - INFO -                 P: precision:  87.52%; recall:  90.42%; FB1:  88.95  561

2019-02-22 00:03:38,186 - log/train6.log - INFO -               PRO: precision:  31.59%; recall:  26.63%; FB1:  28.90  440

2019-02-22 00:03:38,196 - log/train6.log - INFO - evaluate:test
2019-02-22 00:03:44,772 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1702 phrases; correct: 1361.

2019-02-22 00:03:44,772 - log/train6.log - INFO - accuracy:  96.28%; precision:  79.96%; recall:  82.64%; FB1:  81.28

2019-02-22 00:03:44,773 - log/train6.log - INFO -                 C: precision:  84.99%; recall:  90.77%; FB1:  87.78  1099

2019-02-22 00:03:44,773 - log/train6.log - INFO -               IND: precision:  43.84%; recall:  68.09%; FB1:  53.33  73

2019-02-22 00:03:44,773 - log/train6.log - INFO -               INS: precision:  67.05%; recall:  62.11%; FB1:  64.48  88

2019-02-22 00:03:44,774 - log/train6.log - INFO -                 L: precision:  62.37%; recall:  56.31%; FB1:  59.18  93

2019-02-22 00:03:44,774 - log/train6.log - INFO -                 P: precision:  88.79%; recall:  93.14%; FB1:  90.91  214

2019-02-22 00:03:44,774 - log/train6.log - INFO -               PRO: precision:  65.19%; recall:  52.07%; FB1:  57.89  135

2019-02-22 00:03:53,128 - log/train6.log - INFO - iteration:71 step:100/10100, NER loss: 0.841543
2019-02-22 01:01:20,868 - log/train6.log - INFO - iteration:71 step:200/10100, NER loss: 0.867139
2019-02-22 01:01:23,139 - log/train6.log - INFO - iteration:71 step:300/10100, NER loss: 1.175817
2019-02-22 01:01:25,097 - log/train6.log - INFO - iteration:71 step:400/10100, NER loss: 0.804457
2019-02-22 01:01:26,940 - log/train6.log - INFO - iteration:71 step:500/10100, NER loss: 0.827172
2019-02-22 01:01:28,793 - log/train6.log - INFO - iteration:71 step:600/10100, NER loss: 0.979675
2019-02-22 01:01:35,932 - log/train6.log - INFO - iteration:71 step:700/10100, NER loss: 0.942588
2019-02-22 01:01:45,801 - log/train6.log - INFO - iteration:71 step:800/10100, NER loss: 1.214031
2019-02-22 01:01:55,730 - log/train6.log - INFO - iteration:71 step:900/10100, NER loss: 1.005015
2019-02-22 01:02:03,892 - log/train6.log - INFO - iteration:71 step:1000/10100, NER loss: 0.817139
2019-02-22 01:02:13,833 - log/train6.log - INFO - iteration:71 step:1100/10100, NER loss: 0.976755
2019-02-22 01:02:24,318 - log/train6.log - INFO - iteration:71 step:1200/10100, NER loss: 1.137734
2019-02-22 01:02:33,807 - log/train6.log - INFO - iteration:71 step:1300/10100, NER loss: 1.046381
2019-02-22 01:02:43,054 - log/train6.log - INFO - iteration:71 step:1400/10100, NER loss: 0.797260
2019-02-22 01:02:51,569 - log/train6.log - INFO - iteration:71 step:1500/10100, NER loss: 0.862777
2019-02-22 01:03:03,721 - log/train6.log - INFO - iteration:71 step:1600/10100, NER loss: 1.385374
2019-02-22 01:03:12,880 - log/train6.log - INFO - iteration:71 step:1700/10100, NER loss: 0.923134
2019-02-22 01:03:30,361 - log/train6.log - INFO - iteration:71 step:1800/10100, NER loss: 1.684139
2019-02-22 01:03:38,539 - log/train6.log - INFO - iteration:71 step:1900/10100, NER loss: 0.861554
2019-02-22 01:03:47,942 - log/train6.log - INFO - iteration:71 step:2000/10100, NER loss: 1.030829
2019-02-22 01:03:56,384 - log/train6.log - INFO - iteration:71 step:2100/10100, NER loss: 0.764154
2019-02-22 01:04:06,529 - log/train6.log - INFO - iteration:71 step:2200/10100, NER loss: 0.956256
2019-02-22 01:04:15,289 - log/train6.log - INFO - iteration:71 step:2300/10100, NER loss: 0.974888
2019-02-22 01:04:24,590 - log/train6.log - INFO - iteration:71 step:2400/10100, NER loss: 0.821108
2019-02-22 01:04:34,271 - log/train6.log - INFO - iteration:71 step:2500/10100, NER loss: 0.904756
2019-02-22 01:04:43,237 - log/train6.log - INFO - iteration:71 step:2600/10100, NER loss: 0.865690
2019-02-22 01:04:53,439 - log/train6.log - INFO - iteration:71 step:2700/10100, NER loss: 1.282990
2019-02-22 01:05:02,924 - log/train6.log - INFO - iteration:71 step:2800/10100, NER loss: 0.843808
2019-02-22 01:05:12,824 - log/train6.log - INFO - iteration:71 step:2900/10100, NER loss: 1.072509
2019-02-22 01:05:21,360 - log/train6.log - INFO - iteration:71 step:3000/10100, NER loss: 0.904079
2019-02-22 01:05:30,734 - log/train6.log - INFO - iteration:71 step:3100/10100, NER loss: 0.967569
2019-02-22 01:05:39,965 - log/train6.log - INFO - iteration:71 step:3200/10100, NER loss: 0.886779
2019-02-22 01:05:49,477 - log/train6.log - INFO - iteration:71 step:3300/10100, NER loss: 1.105014
2019-02-22 01:05:58,764 - log/train6.log - INFO - iteration:71 step:3400/10100, NER loss: 0.831401
2019-02-22 01:06:08,671 - log/train6.log - INFO - iteration:71 step:3500/10100, NER loss: 1.150755
2019-02-22 01:06:17,195 - log/train6.log - INFO - iteration:71 step:3600/10100, NER loss: 0.737071
2019-02-22 01:06:25,846 - log/train6.log - INFO - iteration:71 step:3700/10100, NER loss: 0.768048
2019-02-22 01:06:34,711 - log/train6.log - INFO - iteration:71 step:3800/10100, NER loss: 0.819252
2019-02-22 01:06:44,661 - log/train6.log - INFO - iteration:71 step:3900/10100, NER loss: 1.063856
2019-02-22 01:06:54,351 - log/train6.log - INFO - iteration:71 step:4000/10100, NER loss: 0.965660
2019-02-22 01:07:03,209 - log/train6.log - INFO - iteration:71 step:4100/10100, NER loss: 0.846217
2019-02-22 01:07:12,041 - log/train6.log - INFO - iteration:71 step:4200/10100, NER loss: 0.873797
2019-02-22 01:07:21,035 - log/train6.log - INFO - iteration:71 step:4300/10100, NER loss: 0.795475
2019-02-22 01:07:30,210 - log/train6.log - INFO - iteration:71 step:4400/10100, NER loss: 0.962703
2019-02-22 01:07:40,280 - log/train6.log - INFO - iteration:71 step:4500/10100, NER loss: 1.233743
2019-02-22 01:07:50,375 - log/train6.log - INFO - iteration:71 step:4600/10100, NER loss: 1.019117
2019-02-22 01:07:59,439 - log/train6.log - INFO - iteration:71 step:4700/10100, NER loss: 0.864405
2019-02-22 01:08:09,280 - log/train6.log - INFO - iteration:71 step:4800/10100, NER loss: 1.205746
2019-02-22 01:08:19,801 - log/train6.log - INFO - iteration:71 step:4900/10100, NER loss: 1.272272
2019-02-22 01:08:28,798 - log/train6.log - INFO - iteration:71 step:5000/10100, NER loss: 1.134395
2019-02-22 01:08:37,729 - log/train6.log - INFO - iteration:71 step:5100/10100, NER loss: 0.758328
2019-02-22 01:08:47,032 - log/train6.log - INFO - iteration:71 step:5200/10100, NER loss: 1.126395
2019-02-22 01:08:56,935 - log/train6.log - INFO - iteration:71 step:5300/10100, NER loss: 1.049430
2019-02-22 01:09:07,313 - log/train6.log - INFO - iteration:71 step:5400/10100, NER loss: 1.083246
2019-02-22 01:09:16,551 - log/train6.log - INFO - iteration:71 step:5500/10100, NER loss: 0.922807
2019-02-22 01:09:25,744 - log/train6.log - INFO - iteration:71 step:5600/10100, NER loss: 0.820568
2019-02-22 01:09:33,945 - log/train6.log - INFO - iteration:71 step:5700/10100, NER loss: 0.860923
2019-02-22 01:09:44,046 - log/train6.log - INFO - iteration:71 step:5800/10100, NER loss: 1.131042
2019-02-22 01:09:53,605 - log/train6.log - INFO - iteration:71 step:5900/10100, NER loss: 0.927914
2019-02-22 01:10:02,434 - log/train6.log - INFO - iteration:71 step:6000/10100, NER loss: 0.899329
2019-02-22 01:10:11,183 - log/train6.log - INFO - iteration:71 step:6100/10100, NER loss: 0.755096
2019-02-22 01:10:20,846 - log/train6.log - INFO - iteration:71 step:6200/10100, NER loss: 1.065291
2019-02-22 01:10:30,273 - log/train6.log - INFO - iteration:71 step:6300/10100, NER loss: 0.896528
2019-02-22 01:10:41,152 - log/train6.log - INFO - iteration:71 step:6400/10100, NER loss: 1.451025
2019-02-22 01:10:50,485 - log/train6.log - INFO - iteration:71 step:6500/10100, NER loss: 0.914518
2019-02-22 01:11:00,285 - log/train6.log - INFO - iteration:71 step:6600/10100, NER loss: 0.920366
2019-02-22 01:11:09,635 - log/train6.log - INFO - iteration:71 step:6700/10100, NER loss: 1.116305
2019-02-22 01:11:19,795 - log/train6.log - INFO - iteration:71 step:6800/10100, NER loss: 1.033312
2019-02-22 01:11:28,987 - log/train6.log - INFO - iteration:71 step:6900/10100, NER loss: 0.813558
2019-02-22 01:11:38,730 - log/train6.log - INFO - iteration:71 step:7000/10100, NER loss: 0.889127
2019-02-22 01:11:47,920 - log/train6.log - INFO - iteration:71 step:7100/10100, NER loss: 0.980525
2019-02-22 01:11:57,663 - log/train6.log - INFO - iteration:71 step:7200/10100, NER loss: 0.928021
2019-02-22 01:12:06,150 - log/train6.log - INFO - iteration:71 step:7300/10100, NER loss: 0.831015
2019-02-22 01:12:15,539 - log/train6.log - INFO - iteration:71 step:7400/10100, NER loss: 0.898748
2019-02-22 01:12:24,495 - log/train6.log - INFO - iteration:71 step:7500/10100, NER loss: 1.032925
2019-02-22 01:12:33,498 - log/train6.log - INFO - iteration:71 step:7600/10100, NER loss: 0.938157
2019-02-22 01:12:43,974 - log/train6.log - INFO - iteration:71 step:7700/10100, NER loss: 1.117301
2019-02-22 01:12:52,978 - log/train6.log - INFO - iteration:71 step:7800/10100, NER loss: 0.994337
2019-02-22 01:13:11,011 - log/train6.log - INFO - iteration:71 step:7900/10100, NER loss: 2.442711
2019-02-22 01:13:20,718 - log/train6.log - INFO - iteration:71 step:8000/10100, NER loss: 1.173757
2019-02-22 01:13:29,715 - log/train6.log - INFO - iteration:71 step:8100/10100, NER loss: 0.958196
2019-02-22 01:13:39,068 - log/train6.log - INFO - iteration:71 step:8200/10100, NER loss: 1.003287
2019-02-22 01:13:48,981 - log/train6.log - INFO - iteration:71 step:8300/10100, NER loss: 0.917349
2019-02-22 01:13:58,662 - log/train6.log - INFO - iteration:71 step:8400/10100, NER loss: 0.943301
2019-02-22 01:14:09,110 - log/train6.log - INFO - iteration:71 step:8500/10100, NER loss: 1.060597
2019-02-22 01:14:18,768 - log/train6.log - INFO - iteration:71 step:8600/10100, NER loss: 1.055792
2019-02-22 01:14:28,995 - log/train6.log - INFO - iteration:71 step:8700/10100, NER loss: 1.124935
2019-02-22 01:14:37,783 - log/train6.log - INFO - iteration:71 step:8800/10100, NER loss: 0.831688
2019-02-22 01:14:47,056 - log/train6.log - INFO - iteration:71 step:8900/10100, NER loss: 1.040726
2019-02-22 01:14:55,615 - log/train6.log - INFO - iteration:71 step:9000/10100, NER loss: 0.829968
2019-02-22 01:15:05,472 - log/train6.log - INFO - iteration:71 step:9100/10100, NER loss: 1.036197
2019-02-22 01:15:13,961 - log/train6.log - INFO - iteration:71 step:9200/10100, NER loss: 0.784421
2019-02-22 01:15:24,158 - log/train6.log - INFO - iteration:71 step:9300/10100, NER loss: 1.024421
2019-02-22 01:15:33,539 - log/train6.log - INFO - iteration:71 step:9400/10100, NER loss: 0.857536
2019-02-22 01:15:42,857 - log/train6.log - INFO - iteration:71 step:9500/10100, NER loss: 0.882137
2019-02-22 01:15:52,038 - log/train6.log - INFO - iteration:71 step:9600/10100, NER loss: 0.955961
2019-02-22 01:16:00,812 - log/train6.log - INFO - iteration:71 step:9700/10100, NER loss: 0.816092
2019-02-22 01:16:18,804 - log/train6.log - INFO - iteration:71 step:9800/10100, NER loss: 2.803838
2019-02-22 01:16:28,024 - log/train6.log - INFO - iteration:71 step:9900/10100, NER loss: 1.051687
2019-02-22 01:16:37,444 - log/train6.log - INFO - iteration:71 step:10000/10100, NER loss: 0.959228
2019-02-22 01:16:47,278 - log/train6.log - INFO - iteration:72 step:0/10100, NER loss: 1.043916
2019-02-22 01:16:47,279 - log/train6.log - INFO - evaluate:dev
2019-02-22 01:17:15,870 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 4743 phrases; correct: 3683.

2019-02-22 01:17:15,872 - log/train6.log - INFO - accuracy:  93.32%; precision:  77.65%; recall:  62.99%; FB1:  69.56

2019-02-22 01:17:15,872 - log/train6.log - INFO -                 C: precision:  89.14%; recall:  73.65%; FB1:  80.66  2800

2019-02-22 01:17:15,873 - log/train6.log - INFO -               IND: precision:  42.00%; recall:  25.74%; FB1:  31.91  250

2019-02-22 01:17:15,873 - log/train6.log - INFO -               INS: precision:  74.62%; recall:  64.38%; FB1:  69.12  327

2019-02-22 01:17:15,873 - log/train6.log - INFO -                 L: precision:  51.76%; recall:  43.73%; FB1:  47.41  512

2019-02-22 01:17:15,873 - log/train6.log - INFO -                 P: precision:  89.54%; recall:  86.74%; FB1:  88.12  526

2019-02-22 01:17:15,874 - log/train6.log - INFO -               PRO: precision:  31.10%; recall:  19.54%; FB1:  24.00  328

2019-02-22 01:17:15,884 - log/train6.log - INFO - evaluate:test
2019-02-22 01:17:22,445 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1450 phrases; correct: 1212.

2019-02-22 01:17:22,446 - log/train6.log - INFO - accuracy:  95.38%; precision:  83.59%; recall:  73.59%; FB1:  78.27

2019-02-22 01:17:22,446 - log/train6.log - INFO -                 C: precision:  90.21%; recall:  78.81%; FB1:  84.13  899

2019-02-22 01:17:22,447 - log/train6.log - INFO -               IND: precision:  53.45%; recall:  65.96%; FB1:  59.05  58

2019-02-22 01:17:22,447 - log/train6.log - INFO -               INS: precision:  70.89%; recall:  58.95%; FB1:  64.37  79

2019-02-22 01:17:22,447 - log/train6.log - INFO -                 L: precision:  60.87%; recall:  54.37%; FB1:  57.44  92

2019-02-22 01:17:22,447 - log/train6.log - INFO -                 P: precision:  90.87%; recall:  92.65%; FB1:  91.75  208

2019-02-22 01:17:22,448 - log/train6.log - INFO -               PRO: precision:  60.53%; recall:  40.83%; FB1:  48.76  114

2019-02-22 01:17:33,866 - log/train6.log - INFO - iteration:72 step:100/10100, NER loss: 1.169820
2019-02-22 01:17:42,739 - log/train6.log - INFO - iteration:72 step:200/10100, NER loss: 1.078991
2019-02-22 01:17:52,303 - log/train6.log - INFO - iteration:72 step:300/10100, NER loss: 1.079961
2019-02-22 01:18:01,631 - log/train6.log - INFO - iteration:72 step:400/10100, NER loss: 0.928322
2019-02-22 01:18:10,950 - log/train6.log - INFO - iteration:72 step:500/10100, NER loss: 0.905347
2019-02-22 01:18:20,231 - log/train6.log - INFO - iteration:72 step:600/10100, NER loss: 0.856270
2019-02-22 01:18:29,371 - log/train6.log - INFO - iteration:72 step:700/10100, NER loss: 0.918398
2019-02-22 01:18:37,604 - log/train6.log - INFO - iteration:72 step:800/10100, NER loss: 0.683191
2019-02-22 01:18:47,175 - log/train6.log - INFO - iteration:72 step:900/10100, NER loss: 0.993069
2019-02-22 01:18:56,510 - log/train6.log - INFO - iteration:72 step:1000/10100, NER loss: 0.931543
2019-02-22 01:19:05,866 - log/train6.log - INFO - iteration:72 step:1100/10100, NER loss: 0.888821
2019-02-22 01:19:15,024 - log/train6.log - INFO - iteration:72 step:1200/10100, NER loss: 0.803977
2019-02-22 01:19:33,660 - log/train6.log - INFO - iteration:72 step:1300/10100, NER loss: 2.615529
2019-02-22 01:19:43,067 - log/train6.log - INFO - iteration:72 step:1400/10100, NER loss: 1.003252
2019-02-22 01:19:53,256 - log/train6.log - INFO - iteration:72 step:1500/10100, NER loss: 1.098608
2019-02-22 01:20:03,144 - log/train6.log - INFO - iteration:72 step:1600/10100, NER loss: 1.060066
2019-02-22 01:20:11,781 - log/train6.log - INFO - iteration:72 step:1700/10100, NER loss: 0.850973
2019-02-22 01:20:22,202 - log/train6.log - INFO - iteration:72 step:1800/10100, NER loss: 1.063368
2019-02-22 01:20:32,446 - log/train6.log - INFO - iteration:72 step:1900/10100, NER loss: 1.079221
2019-02-22 01:20:41,509 - log/train6.log - INFO - iteration:72 step:2000/10100, NER loss: 0.848100
2019-02-22 01:20:51,573 - log/train6.log - INFO - iteration:72 step:2100/10100, NER loss: 1.007498
2019-02-22 01:20:59,985 - log/train6.log - INFO - iteration:72 step:2200/10100, NER loss: 0.673456
2019-02-22 01:21:09,457 - log/train6.log - INFO - iteration:72 step:2300/10100, NER loss: 0.962422
2019-02-22 01:21:18,767 - log/train6.log - INFO - iteration:72 step:2400/10100, NER loss: 0.909818
2019-02-22 01:21:28,010 - log/train6.log - INFO - iteration:72 step:2500/10100, NER loss: 0.920518
2019-02-22 01:21:37,292 - log/train6.log - INFO - iteration:72 step:2600/10100, NER loss: 0.916673
2019-02-22 01:21:48,063 - log/train6.log - INFO - iteration:72 step:2700/10100, NER loss: 1.260990
2019-02-22 01:21:57,434 - log/train6.log - INFO - iteration:72 step:2800/10100, NER loss: 0.945038
2019-02-22 01:22:06,584 - log/train6.log - INFO - iteration:72 step:2900/10100, NER loss: 0.882495
2019-02-22 01:22:15,484 - log/train6.log - INFO - iteration:72 step:3000/10100, NER loss: 1.108951
2019-02-22 01:22:24,156 - log/train6.log - INFO - iteration:72 step:3100/10100, NER loss: 0.904655
2019-02-22 01:22:33,782 - log/train6.log - INFO - iteration:72 step:3200/10100, NER loss: 1.053440
2019-02-22 01:22:43,703 - log/train6.log - INFO - iteration:72 step:3300/10100, NER loss: 1.018362
2019-02-22 01:22:52,985 - log/train6.log - INFO - iteration:72 step:3400/10100, NER loss: 1.031559
2019-02-22 01:23:02,775 - log/train6.log - INFO - iteration:72 step:3500/10100, NER loss: 1.246352
2019-02-22 01:23:11,400 - log/train6.log - INFO - iteration:72 step:3600/10100, NER loss: 1.085835
2019-02-22 01:23:20,531 - log/train6.log - INFO - iteration:72 step:3700/10100, NER loss: 0.924056
2019-02-22 01:23:29,239 - log/train6.log - INFO - iteration:72 step:3800/10100, NER loss: 0.933126
2019-02-22 01:23:38,791 - log/train6.log - INFO - iteration:72 step:3900/10100, NER loss: 1.018859
2019-02-22 01:23:48,053 - log/train6.log - INFO - iteration:72 step:4000/10100, NER loss: 0.899694
2019-02-22 01:23:57,716 - log/train6.log - INFO - iteration:72 step:4100/10100, NER loss: 0.907665
2019-02-22 01:24:06,890 - log/train6.log - INFO - iteration:72 step:4200/10100, NER loss: 1.042729
2019-02-22 01:24:16,766 - log/train6.log - INFO - iteration:72 step:4300/10100, NER loss: 0.938667
2019-02-22 01:24:25,613 - log/train6.log - INFO - iteration:72 step:4400/10100, NER loss: 0.971955
2019-02-22 01:24:35,043 - log/train6.log - INFO - iteration:72 step:4500/10100, NER loss: 0.908100
2019-02-22 01:24:44,726 - log/train6.log - INFO - iteration:72 step:4600/10100, NER loss: 1.116073
2019-02-22 01:24:54,211 - log/train6.log - INFO - iteration:72 step:4700/10100, NER loss: 0.997948
2019-02-22 01:25:03,941 - log/train6.log - INFO - iteration:72 step:4800/10100, NER loss: 0.987155
2019-02-22 01:25:12,844 - log/train6.log - INFO - iteration:72 step:4900/10100, NER loss: 0.935134
2019-02-22 01:25:22,202 - log/train6.log - INFO - iteration:72 step:5000/10100, NER loss: 1.007872
2019-02-22 01:25:31,837 - log/train6.log - INFO - iteration:72 step:5100/10100, NER loss: 0.997913
2019-02-22 01:25:40,863 - log/train6.log - INFO - iteration:72 step:5200/10100, NER loss: 0.912576
2019-02-22 01:25:51,230 - log/train6.log - INFO - iteration:72 step:5300/10100, NER loss: 1.025977
2019-02-22 01:26:00,761 - log/train6.log - INFO - iteration:72 step:5400/10100, NER loss: 0.970579
2019-02-22 01:26:09,669 - log/train6.log - INFO - iteration:72 step:5500/10100, NER loss: 0.829370
2019-02-22 01:26:19,162 - log/train6.log - INFO - iteration:72 step:5600/10100, NER loss: 1.016812
2019-02-22 01:26:29,256 - log/train6.log - INFO - iteration:72 step:5700/10100, NER loss: 1.073072
2019-02-22 01:26:38,742 - log/train6.log - INFO - iteration:72 step:5800/10100, NER loss: 1.019462
2019-02-22 01:26:48,178 - log/train6.log - INFO - iteration:72 step:5900/10100, NER loss: 1.002711
2019-02-22 01:26:56,318 - log/train6.log - INFO - iteration:72 step:6000/10100, NER loss: 0.710360
2019-02-22 01:27:06,446 - log/train6.log - INFO - iteration:72 step:6100/10100, NER loss: 1.137290
2019-02-22 01:27:23,925 - log/train6.log - INFO - iteration:72 step:6200/10100, NER loss: 2.378657
2019-02-22 01:27:33,696 - log/train6.log - INFO - iteration:72 step:6300/10100, NER loss: 0.951382
2019-02-22 01:27:44,148 - log/train6.log - INFO - iteration:72 step:6400/10100, NER loss: 1.091689
2019-02-22 01:27:52,739 - log/train6.log - INFO - iteration:72 step:6500/10100, NER loss: 0.874831
2019-02-22 01:28:01,970 - log/train6.log - INFO - iteration:72 step:6600/10100, NER loss: 1.089307
2019-02-22 01:28:10,393 - log/train6.log - INFO - iteration:72 step:6700/10100, NER loss: 0.813506
2019-02-22 01:28:20,071 - log/train6.log - INFO - iteration:72 step:6800/10100, NER loss: 0.854283
2019-02-22 01:28:29,657 - log/train6.log - INFO - iteration:72 step:6900/10100, NER loss: 1.066455
2019-02-22 01:28:39,244 - log/train6.log - INFO - iteration:72 step:7000/10100, NER loss: 0.972557
2019-02-22 01:28:48,521 - log/train6.log - INFO - iteration:72 step:7100/10100, NER loss: 0.943971
2019-02-22 01:28:57,252 - log/train6.log - INFO - iteration:72 step:7200/10100, NER loss: 1.085833
2019-02-22 01:29:06,476 - log/train6.log - INFO - iteration:72 step:7300/10100, NER loss: 0.881305
2019-02-22 01:29:16,257 - log/train6.log - INFO - iteration:72 step:7400/10100, NER loss: 1.038559
2019-02-22 01:29:25,691 - log/train6.log - INFO - iteration:72 step:7500/10100, NER loss: 1.128825
2019-02-22 01:29:35,426 - log/train6.log - INFO - iteration:72 step:7600/10100, NER loss: 1.031720
2019-02-22 01:29:44,412 - log/train6.log - INFO - iteration:72 step:7700/10100, NER loss: 0.880006
2019-02-22 01:29:53,124 - log/train6.log - INFO - iteration:72 step:7800/10100, NER loss: 0.876194
2019-02-22 01:30:01,546 - log/train6.log - INFO - iteration:72 step:7900/10100, NER loss: 0.880605
2019-02-22 01:30:11,024 - log/train6.log - INFO - iteration:72 step:8000/10100, NER loss: 1.094502
2019-02-22 01:30:20,297 - log/train6.log - INFO - iteration:72 step:8100/10100, NER loss: 0.892702
2019-02-22 01:30:30,157 - log/train6.log - INFO - iteration:72 step:8200/10100, NER loss: 0.977814
2019-02-22 01:30:39,473 - log/train6.log - INFO - iteration:72 step:8300/10100, NER loss: 1.016925
2019-02-22 01:30:48,828 - log/train6.log - INFO - iteration:72 step:8400/10100, NER loss: 1.013790
2019-02-22 01:30:58,239 - log/train6.log - INFO - iteration:72 step:8500/10100, NER loss: 0.875381
2019-02-22 01:31:15,450 - log/train6.log - INFO - iteration:72 step:8600/10100, NER loss: 1.685840
2019-02-22 01:31:25,390 - log/train6.log - INFO - iteration:72 step:8700/10100, NER loss: 1.240055
2019-02-22 03:31:29,696 - log/train6.log - INFO - iteration:72 step:8800/10100, NER loss: 0.838119
2019-02-22 03:31:31,887 - log/train6.log - INFO - iteration:72 step:8900/10100, NER loss: 1.145982
2019-02-22 03:31:33,797 - log/train6.log - INFO - iteration:72 step:9000/10100, NER loss: 0.903800
2019-02-22 03:31:36,079 - log/train6.log - INFO - iteration:72 step:9100/10100, NER loss: 1.218643
2019-02-22 03:31:40,234 - log/train6.log - INFO - iteration:72 step:9200/10100, NER loss: 0.899305
2019-02-22 03:31:50,449 - log/train6.log - INFO - iteration:72 step:9300/10100, NER loss: 1.068389
2019-02-22 03:31:58,938 - log/train6.log - INFO - iteration:72 step:9400/10100, NER loss: 0.694027
2019-02-22 03:32:07,608 - log/train6.log - INFO - iteration:72 step:9500/10100, NER loss: 0.852886
2019-02-22 03:32:17,313 - log/train6.log - INFO - iteration:72 step:9600/10100, NER loss: 0.882610
2019-02-22 03:32:26,756 - log/train6.log - INFO - iteration:72 step:9700/10100, NER loss: 0.888823
2019-02-22 03:32:34,969 - log/train6.log - INFO - iteration:72 step:9800/10100, NER loss: 0.732656
2019-02-22 03:32:43,648 - log/train6.log - INFO - iteration:72 step:9900/10100, NER loss: 0.870691
2019-02-22 03:32:53,476 - log/train6.log - INFO - iteration:72 step:10000/10100, NER loss: 1.119637
2019-02-22 03:33:02,895 - log/train6.log - INFO - iteration:73 step:0/10100, NER loss: 1.096056
2019-02-22 03:33:02,896 - log/train6.log - INFO - evaluate:dev
2019-02-22 03:33:31,482 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5890 phrases; correct: 4298.

2019-02-22 03:33:31,483 - log/train6.log - INFO - accuracy:  94.61%; precision:  72.97%; recall:  73.51%; FB1:  73.24

2019-02-22 03:33:31,483 - log/train6.log - INFO -                 C: precision:  83.42%; recall:  88.02%; FB1:  85.66  3576

2019-02-22 03:33:31,484 - log/train6.log - INFO -               IND: precision:  36.08%; recall:  34.31%; FB1:  35.18  388

2019-02-22 03:33:31,484 - log/train6.log - INFO -               INS: precision:  62.68%; recall:  70.45%; FB1:  66.34  426

2019-02-22 03:33:31,484 - log/train6.log - INFO -                 L: precision:  52.79%; recall:  53.14%; FB1:  52.96  610

2019-02-22 03:33:31,484 - log/train6.log - INFO -                 P: precision:  84.44%; recall:  90.98%; FB1:  87.59  585

2019-02-22 03:33:31,485 - log/train6.log - INFO -               PRO: precision:  30.16%; recall:  17.62%; FB1:  22.25  305

2019-02-22 03:33:31,495 - log/train6.log - INFO - evaluate:test
2019-02-22 03:33:38,041 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1697 phrases; correct: 1346.

2019-02-22 03:33:38,041 - log/train6.log - INFO - accuracy:  96.01%; precision:  79.32%; recall:  81.72%; FB1:  80.50

2019-02-22 03:33:38,042 - log/train6.log - INFO -                 C: precision:  86.56%; recall:  91.35%; FB1:  88.89  1086

2019-02-22 03:33:38,042 - log/train6.log - INFO -               IND: precision:  39.51%; recall:  68.09%; FB1:  50.00  81

2019-02-22 03:33:38,042 - log/train6.log - INFO -               INS: precision:  64.52%; recall:  63.16%; FB1:  63.83  93

2019-02-22 03:33:38,043 - log/train6.log - INFO -                 L: precision:  53.21%; recall:  56.31%; FB1:  54.72  109

2019-02-22 03:33:38,043 - log/train6.log - INFO -                 P: precision:  87.61%; recall:  93.63%; FB1:  90.52  218

2019-02-22 03:33:38,043 - log/train6.log - INFO -               PRO: precision:  59.09%; recall:  38.46%; FB1:  46.59  110

2019-02-22 03:33:49,494 - log/train6.log - INFO - iteration:73 step:100/10100, NER loss: 1.113558
2019-02-22 03:33:58,687 - log/train6.log - INFO - iteration:73 step:200/10100, NER loss: 1.123502
2019-02-22 03:34:08,139 - log/train6.log - INFO - iteration:73 step:300/10100, NER loss: 0.869665
2019-02-22 03:34:16,943 - log/train6.log - INFO - iteration:73 step:400/10100, NER loss: 1.000966
2019-02-22 03:34:25,376 - log/train6.log - INFO - iteration:73 step:500/10100, NER loss: 0.768761
2019-02-22 03:34:34,471 - log/train6.log - INFO - iteration:73 step:600/10100, NER loss: 1.115433
2019-02-22 03:34:43,707 - log/train6.log - INFO - iteration:73 step:700/10100, NER loss: 0.868484
2019-02-22 03:34:53,887 - log/train6.log - INFO - iteration:73 step:800/10100, NER loss: 1.135654
2019-02-22 03:35:02,927 - log/train6.log - INFO - iteration:73 step:900/10100, NER loss: 0.799361
2019-02-22 03:35:12,801 - log/train6.log - INFO - iteration:73 step:1000/10100, NER loss: 0.990792
2019-02-22 03:35:21,811 - log/train6.log - INFO - iteration:73 step:1100/10100, NER loss: 0.776857
2019-02-22 03:35:31,489 - log/train6.log - INFO - iteration:73 step:1200/10100, NER loss: 1.033767
2019-02-22 03:35:40,624 - log/train6.log - INFO - iteration:73 step:1300/10100, NER loss: 0.939445
2019-02-22 03:35:49,801 - log/train6.log - INFO - iteration:73 step:1400/10100, NER loss: 0.888565
2019-02-22 03:35:59,183 - log/train6.log - INFO - iteration:73 step:1500/10100, NER loss: 1.019714
2019-02-22 03:36:07,949 - log/train6.log - INFO - iteration:73 step:1600/10100, NER loss: 0.769634
2019-02-22 03:36:27,791 - log/train6.log - INFO - iteration:73 step:1700/10100, NER loss: 2.491871
2019-02-22 03:36:36,546 - log/train6.log - INFO - iteration:73 step:1800/10100, NER loss: 0.894349
2019-02-22 03:36:45,810 - log/train6.log - INFO - iteration:73 step:1900/10100, NER loss: 0.904724
2019-02-22 03:36:55,447 - log/train6.log - INFO - iteration:73 step:2000/10100, NER loss: 1.113129
2019-02-22 03:37:05,136 - log/train6.log - INFO - iteration:73 step:2100/10100, NER loss: 0.910130
2019-02-22 03:37:14,825 - log/train6.log - INFO - iteration:73 step:2200/10100, NER loss: 1.132266
2019-02-22 03:37:24,916 - log/train6.log - INFO - iteration:73 step:2300/10100, NER loss: 1.035029
2019-02-22 03:37:34,062 - log/train6.log - INFO - iteration:73 step:2400/10100, NER loss: 0.890428
2019-02-22 03:37:44,111 - log/train6.log - INFO - iteration:73 step:2500/10100, NER loss: 0.999301
2019-02-22 03:37:53,947 - log/train6.log - INFO - iteration:73 step:2600/10100, NER loss: 0.999113
2019-02-22 03:38:03,835 - log/train6.log - INFO - iteration:73 step:2700/10100, NER loss: 0.921893
2019-02-22 03:38:21,600 - log/train6.log - INFO - iteration:73 step:2800/10100, NER loss: 1.771106
2019-02-22 03:38:31,723 - log/train6.log - INFO - iteration:73 step:2900/10100, NER loss: 0.992026
2019-02-22 03:38:41,428 - log/train6.log - INFO - iteration:73 step:3000/10100, NER loss: 1.048219
2019-02-22 03:38:50,732 - log/train6.log - INFO - iteration:73 step:3100/10100, NER loss: 1.007259
2019-02-22 03:39:00,844 - log/train6.log - INFO - iteration:73 step:3200/10100, NER loss: 1.082098
2019-02-22 03:39:10,751 - log/train6.log - INFO - iteration:73 step:3300/10100, NER loss: 0.992755
2019-02-22 03:39:19,618 - log/train6.log - INFO - iteration:73 step:3400/10100, NER loss: 0.797123
2019-02-22 03:39:35,935 - log/train6.log - INFO - iteration:73 step:3500/10100, NER loss: 1.806793
2019-02-22 03:39:45,264 - log/train6.log - INFO - iteration:73 step:3600/10100, NER loss: 0.953868
2019-02-22 03:39:55,059 - log/train6.log - INFO - iteration:73 step:3700/10100, NER loss: 1.015772
2019-02-22 03:40:04,156 - log/train6.log - INFO - iteration:73 step:3800/10100, NER loss: 0.856906
2019-02-22 03:40:13,799 - log/train6.log - INFO - iteration:73 step:3900/10100, NER loss: 1.076144
2019-02-22 03:40:22,330 - log/train6.log - INFO - iteration:73 step:4000/10100, NER loss: 0.743628
2019-02-22 03:40:31,668 - log/train6.log - INFO - iteration:73 step:4100/10100, NER loss: 1.264461
2019-02-22 03:40:42,097 - log/train6.log - INFO - iteration:73 step:4200/10100, NER loss: 1.196751
2019-02-22 03:40:50,728 - log/train6.log - INFO - iteration:73 step:4300/10100, NER loss: 0.840509
2019-02-22 03:41:00,918 - log/train6.log - INFO - iteration:73 step:4400/10100, NER loss: 1.306032
2019-02-22 03:41:09,842 - log/train6.log - INFO - iteration:73 step:4500/10100, NER loss: 0.952134
2019-02-22 03:41:19,419 - log/train6.log - INFO - iteration:73 step:4600/10100, NER loss: 1.022032
2019-02-22 03:41:28,188 - log/train6.log - INFO - iteration:73 step:4700/10100, NER loss: 0.886852
2019-02-22 03:41:37,549 - log/train6.log - INFO - iteration:73 step:4800/10100, NER loss: 0.893077
2019-02-22 03:41:46,357 - log/train6.log - INFO - iteration:73 step:4900/10100, NER loss: 0.802686
2019-02-22 03:41:55,845 - log/train6.log - INFO - iteration:73 step:5000/10100, NER loss: 1.008901
2019-02-22 03:42:04,623 - log/train6.log - INFO - iteration:73 step:5100/10100, NER loss: 0.870139
2019-02-22 03:42:13,622 - log/train6.log - INFO - iteration:73 step:5200/10100, NER loss: 0.924693
2019-02-22 03:42:23,319 - log/train6.log - INFO - iteration:73 step:5300/10100, NER loss: 1.108483
2019-02-22 03:42:32,246 - log/train6.log - INFO - iteration:73 step:5400/10100, NER loss: 0.860954
2019-02-22 03:42:41,597 - log/train6.log - INFO - iteration:73 step:5500/10100, NER loss: 0.999559
2019-02-22 03:42:51,585 - log/train6.log - INFO - iteration:73 step:5600/10100, NER loss: 1.072999
2019-02-22 03:43:01,748 - log/train6.log - INFO - iteration:73 step:5700/10100, NER loss: 1.071183
2019-02-22 03:43:11,475 - log/train6.log - INFO - iteration:73 step:5800/10100, NER loss: 1.219472
2019-02-22 03:43:20,530 - log/train6.log - INFO - iteration:73 step:5900/10100, NER loss: 0.948093
2019-02-22 03:43:29,940 - log/train6.log - INFO - iteration:73 step:6000/10100, NER loss: 0.877414
2019-02-22 03:43:39,799 - log/train6.log - INFO - iteration:73 step:6100/10100, NER loss: 1.030011
2019-02-22 03:43:49,004 - log/train6.log - INFO - iteration:73 step:6200/10100, NER loss: 1.089443
2019-02-22 03:43:57,463 - log/train6.log - INFO - iteration:73 step:6300/10100, NER loss: 0.920872
2019-02-22 03:44:06,463 - log/train6.log - INFO - iteration:73 step:6400/10100, NER loss: 0.921065
2019-02-22 03:44:15,719 - log/train6.log - INFO - iteration:73 step:6500/10100, NER loss: 0.833466
2019-02-22 03:44:25,308 - log/train6.log - INFO - iteration:73 step:6600/10100, NER loss: 0.996730
2019-02-22 03:44:35,392 - log/train6.log - INFO - iteration:73 step:6700/10100, NER loss: 1.011546
2019-02-22 03:44:44,880 - log/train6.log - INFO - iteration:73 step:6800/10100, NER loss: 1.093551
2019-02-22 03:44:54,335 - log/train6.log - INFO - iteration:73 step:6900/10100, NER loss: 1.023787
2019-02-22 03:45:03,747 - log/train6.log - INFO - iteration:73 step:7000/10100, NER loss: 0.885519
2019-02-22 03:45:13,458 - log/train6.log - INFO - iteration:73 step:7100/10100, NER loss: 0.933431
2019-02-22 03:45:23,205 - log/train6.log - INFO - iteration:73 step:7200/10100, NER loss: 1.041512
2019-02-22 03:45:32,247 - log/train6.log - INFO - iteration:73 step:7300/10100, NER loss: 0.959536
2019-02-22 03:45:41,958 - log/train6.log - INFO - iteration:73 step:7400/10100, NER loss: 1.039552
2019-02-22 03:45:50,615 - log/train6.log - INFO - iteration:73 step:7500/10100, NER loss: 0.774815
2019-02-22 03:46:00,792 - log/train6.log - INFO - iteration:73 step:7600/10100, NER loss: 1.208588
2019-02-22 03:46:10,823 - log/train6.log - INFO - iteration:73 step:7700/10100, NER loss: 1.172730
2019-02-22 03:46:20,110 - log/train6.log - INFO - iteration:73 step:7800/10100, NER loss: 0.976799
2019-02-22 03:46:29,897 - log/train6.log - INFO - iteration:73 step:7900/10100, NER loss: 1.023216
2019-02-22 03:46:39,346 - log/train6.log - INFO - iteration:73 step:8000/10100, NER loss: 1.027872
2019-02-22 03:46:47,788 - log/train6.log - INFO - iteration:73 step:8100/10100, NER loss: 1.001482
2019-02-22 03:46:57,235 - log/train6.log - INFO - iteration:73 step:8200/10100, NER loss: 0.971312
2019-02-22 03:47:06,834 - log/train6.log - INFO - iteration:73 step:8300/10100, NER loss: 0.972918
2019-02-22 03:47:15,594 - log/train6.log - INFO - iteration:73 step:8400/10100, NER loss: 0.837287
2019-02-22 03:47:25,624 - log/train6.log - INFO - iteration:73 step:8500/10100, NER loss: 1.069688
2019-02-22 03:47:35,238 - log/train6.log - INFO - iteration:73 step:8600/10100, NER loss: 0.972926
2019-02-22 03:47:44,319 - log/train6.log - INFO - iteration:73 step:8700/10100, NER loss: 0.856705
2019-02-22 03:47:54,695 - log/train6.log - INFO - iteration:73 step:8800/10100, NER loss: 1.045960
2019-02-22 03:48:03,756 - log/train6.log - INFO - iteration:73 step:8900/10100, NER loss: 0.950815
2019-02-22 03:48:13,997 - log/train6.log - INFO - iteration:73 step:9000/10100, NER loss: 1.180598
2019-02-22 03:48:23,712 - log/train6.log - INFO - iteration:73 step:9100/10100, NER loss: 0.950745
2019-02-22 03:48:33,253 - log/train6.log - INFO - iteration:73 step:9200/10100, NER loss: 1.125129
2019-02-22 03:48:41,573 - log/train6.log - INFO - iteration:73 step:9300/10100, NER loss: 0.937208
2019-02-22 03:48:50,266 - log/train6.log - INFO - iteration:73 step:9400/10100, NER loss: 0.865155
2019-02-22 03:48:58,406 - log/train6.log - INFO - iteration:73 step:9500/10100, NER loss: 0.943857
2019-02-22 03:49:07,275 - log/train6.log - INFO - iteration:73 step:9600/10100, NER loss: 0.739917
2019-02-22 03:49:16,449 - log/train6.log - INFO - iteration:73 step:9700/10100, NER loss: 1.014084
2019-02-22 03:49:26,038 - log/train6.log - INFO - iteration:73 step:9800/10100, NER loss: 1.117152
2019-02-22 03:49:35,134 - log/train6.log - INFO - iteration:73 step:9900/10100, NER loss: 0.894346
2019-02-22 03:49:44,733 - log/train6.log - INFO - iteration:73 step:10000/10100, NER loss: 0.839619
2019-02-22 03:49:53,992 - log/train6.log - INFO - iteration:74 step:0/10100, NER loss: 0.889154
2019-02-22 03:49:53,993 - log/train6.log - INFO - evaluate:dev
2019-02-22 03:50:22,428 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 5826 phrases; correct: 4318.

2019-02-22 03:50:22,429 - log/train6.log - INFO - accuracy:  94.82%; precision:  74.12%; recall:  73.85%; FB1:  73.98

2019-02-22 03:50:22,429 - log/train6.log - INFO -                 C: precision:  82.90%; recall:  88.40%; FB1:  85.56  3614

2019-02-22 03:50:22,430 - log/train6.log - INFO -               IND: precision:  39.45%; recall:  27.94%; FB1:  32.71  289

2019-02-22 03:50:22,430 - log/train6.log - INFO -               INS: precision:  65.75%; recall:  69.39%; FB1:  67.52  400

2019-02-22 03:50:22,430 - log/train6.log - INFO -                 L: precision:  51.75%; recall:  56.11%; FB1:  53.84  657

2019-02-22 03:50:22,430 - log/train6.log - INFO -                 P: precision:  91.19%; recall:  87.66%; FB1:  89.39  522

2019-02-22 03:50:22,431 - log/train6.log - INFO -               PRO: precision:  37.50%; recall:  24.71%; FB1:  29.79  344

2019-02-22 03:50:22,441 - log/train6.log - INFO - evaluate:test
2019-02-22 03:50:28,993 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 1683 phrases; correct: 1360.

2019-02-22 03:50:28,993 - log/train6.log - INFO - accuracy:  96.30%; precision:  80.81%; recall:  82.57%; FB1:  81.68

2019-02-22 03:50:28,994 - log/train6.log - INFO -                 C: precision:  86.67%; recall:  91.64%; FB1:  89.09  1088

2019-02-22 03:50:28,994 - log/train6.log - INFO -               IND: precision:  44.93%; recall:  65.96%; FB1:  53.45  69

2019-02-22 03:50:28,994 - log/train6.log - INFO -               INS: precision:  67.03%; recall:  64.21%; FB1:  65.59  91

2019-02-22 03:50:28,995 - log/train6.log - INFO -                 L: precision:  52.29%; recall:  55.34%; FB1:  53.77  109

2019-02-22 03:50:28,995 - log/train6.log - INFO -                 P: precision:  93.53%; recall:  92.16%; FB1:  92.84  201

2019-02-22 03:50:28,995 - log/train6.log - INFO -               PRO: precision:  64.00%; recall:  47.34%; FB1:  54.42  125

2019-02-22 03:50:38,727 - log/train6.log - INFO - iteration:74 step:100/10100, NER loss: 1.230906
2019-02-22 03:50:48,331 - log/train6.log - INFO - iteration:74 step:200/10100, NER loss: 0.961435
2019-02-22 03:50:57,880 - log/train6.log - INFO - iteration:74 step:300/10100, NER loss: 1.209429
2019-02-22 03:51:07,195 - log/train6.log - INFO - iteration:74 step:400/10100, NER loss: 1.058292
2019-02-22 03:51:16,971 - log/train6.log - INFO - iteration:74 step:500/10100, NER loss: 1.036391
2019-02-22 03:51:25,582 - log/train6.log - INFO - iteration:74 step:600/10100, NER loss: 0.941922
2019-02-22 03:51:35,179 - log/train6.log - INFO - iteration:74 step:700/10100, NER loss: 1.009399
2019-02-22 03:51:44,768 - log/train6.log - INFO - iteration:74 step:800/10100, NER loss: 0.912924
2019-02-22 03:51:52,887 - log/train6.log - INFO - iteration:74 step:900/10100, NER loss: 0.800060
2019-02-22 03:52:01,483 - log/train6.log - INFO - iteration:74 step:1000/10100, NER loss: 0.928289
2019-02-22 03:52:11,381 - log/train6.log - INFO - iteration:74 step:1100/10100, NER loss: 0.770841
2019-02-22 03:52:21,369 - log/train6.log - INFO - iteration:74 step:1200/10100, NER loss: 1.097195
2019-02-22 03:52:30,727 - log/train6.log - INFO - iteration:74 step:1300/10100, NER loss: 0.958418
2019-02-22 03:52:40,012 - log/train6.log - INFO - iteration:74 step:1400/10100, NER loss: 0.895538
2019-02-22 03:52:49,274 - log/train6.log - INFO - iteration:74 step:1500/10100, NER loss: 0.992682
2019-02-22 03:52:58,138 - log/train6.log - INFO - iteration:74 step:1600/10100, NER loss: 0.960619
2019-02-22 03:53:06,758 - log/train6.log - INFO - iteration:74 step:1700/10100, NER loss: 0.899750
2019-02-22 03:53:16,189 - log/train6.log - INFO - iteration:74 step:1800/10100, NER loss: 0.905897
2019-02-22 03:53:26,580 - log/train6.log - INFO - iteration:74 step:1900/10100, NER loss: 1.083958
2019-02-22 03:53:36,054 - log/train6.log - INFO - iteration:74 step:2000/10100, NER loss: 0.865493
2019-02-22 03:53:45,505 - log/train6.log - INFO - iteration:74 step:2100/10100, NER loss: 0.865787
2019-02-22 03:53:54,868 - log/train6.log - INFO - iteration:74 step:2200/10100, NER loss: 1.024861
2019-02-22 03:54:05,019 - log/train6.log - INFO - iteration:74 step:2300/10100, NER loss: 1.236889
2019-02-22 03:54:14,343 - log/train6.log - INFO - iteration:74 step:2400/10100, NER loss: 0.961705
2019-02-22 03:54:22,989 - log/train6.log - INFO - iteration:74 step:2500/10100, NER loss: 0.994193
2019-02-22 03:54:32,148 - log/train6.log - INFO - iteration:74 step:2600/10100, NER loss: 0.958991
2019-02-22 03:54:40,766 - log/train6.log - INFO - iteration:74 step:2700/10100, NER loss: 0.761036
2019-02-22 03:54:49,624 - log/train6.log - INFO - iteration:74 step:2800/10100, NER loss: 0.768404
2019-02-22 03:55:00,112 - log/train6.log - INFO - iteration:74 step:2900/10100, NER loss: 1.080657
2019-02-22 03:55:09,091 - log/train6.log - INFO - iteration:74 step:3000/10100, NER loss: 0.817816
2019-02-22 03:55:18,936 - log/train6.log - INFO - iteration:74 step:3100/10100, NER loss: 0.938355
2019-02-22 03:55:28,932 - log/train6.log - INFO - iteration:74 step:3200/10100, NER loss: 1.136019
2019-02-22 03:55:47,241 - log/train6.log - INFO - iteration:74 step:3300/10100, NER loss: 1.737519
2019-02-22 03:55:57,533 - log/train6.log - INFO - iteration:74 step:3400/10100, NER loss: 1.033829
2019-02-22 03:56:07,293 - log/train6.log - INFO - iteration:74 step:3500/10100, NER loss: 1.268108
2019-02-22 03:56:17,352 - log/train6.log - INFO - iteration:74 step:3600/10100, NER loss: 1.013039
2019-02-22 03:56:27,687 - log/train6.log - INFO - iteration:74 step:3700/10100, NER loss: 1.181374
2019-02-22 03:56:37,419 - log/train6.log - INFO - iteration:74 step:3800/10100, NER loss: 1.025203
2019-02-22 03:56:47,033 - log/train6.log - INFO - iteration:74 step:3900/10100, NER loss: 0.927028
2019-02-22 03:56:55,960 - log/train6.log - INFO - iteration:74 step:4000/10100, NER loss: 0.858954
2019-02-22 03:57:05,721 - log/train6.log - INFO - iteration:74 step:4100/10100, NER loss: 1.007980
2019-02-22 03:57:15,147 - log/train6.log - INFO - iteration:74 step:4200/10100, NER loss: 0.938163
2019-02-22 03:57:24,094 - log/train6.log - INFO - iteration:74 step:4300/10100, NER loss: 0.869536
2019-02-22 03:57:34,657 - log/train6.log - INFO - iteration:74 step:4400/10100, NER loss: 1.232376
2019-02-22 03:57:43,458 - log/train6.log - INFO - iteration:74 step:4500/10100, NER loss: 0.849071
2019-02-22 03:58:00,515 - log/train6.log - INFO - iteration:74 step:4600/10100, NER loss:      nan
2019-02-22 03:58:09,891 - log/train6.log - INFO - iteration:74 step:4700/10100, NER loss:      nan
2019-02-22 03:58:19,757 - log/train6.log - INFO - iteration:74 step:4800/10100, NER loss:      nan
2019-02-22 03:58:29,258 - log/train6.log - INFO - iteration:74 step:4900/10100, NER loss:      nan
2019-02-22 03:58:38,130 - log/train6.log - INFO - iteration:74 step:5000/10100, NER loss:      nan
2019-02-22 03:58:45,971 - log/train6.log - INFO - iteration:74 step:5100/10100, NER loss:      nan
2019-02-22 03:58:55,418 - log/train6.log - INFO - iteration:74 step:5200/10100, NER loss:      nan
2019-02-22 03:59:04,378 - log/train6.log - INFO - iteration:74 step:5300/10100, NER loss:      nan
2019-02-22 03:59:13,385 - log/train6.log - INFO - iteration:74 step:5400/10100, NER loss:      nan
2019-02-22 03:59:23,012 - log/train6.log - INFO - iteration:74 step:5500/10100, NER loss:      nan
2019-02-22 03:59:30,986 - log/train6.log - INFO - iteration:74 step:5600/10100, NER loss:      nan
2019-02-22 03:59:40,527 - log/train6.log - INFO - iteration:74 step:5700/10100, NER loss:      nan
2019-02-22 03:59:50,432 - log/train6.log - INFO - iteration:74 step:5800/10100, NER loss:      nan
2019-02-22 03:59:59,578 - log/train6.log - INFO - iteration:74 step:5900/10100, NER loss:      nan
2019-02-22 04:00:09,209 - log/train6.log - INFO - iteration:74 step:6000/10100, NER loss:      nan
2019-02-22 04:00:18,493 - log/train6.log - INFO - iteration:74 step:6100/10100, NER loss:      nan
2019-02-22 04:00:28,354 - log/train6.log - INFO - iteration:74 step:6200/10100, NER loss:      nan
2019-02-22 04:00:37,619 - log/train6.log - INFO - iteration:74 step:6300/10100, NER loss:      nan
2019-02-22 04:00:46,493 - log/train6.log - INFO - iteration:74 step:6400/10100, NER loss:      nan
2019-02-22 04:00:54,852 - log/train6.log - INFO - iteration:74 step:6500/10100, NER loss:      nan
2019-02-22 04:01:04,096 - log/train6.log - INFO - iteration:74 step:6600/10100, NER loss:      nan
2019-02-22 04:01:13,365 - log/train6.log - INFO - iteration:74 step:6700/10100, NER loss:      nan
2019-02-22 04:01:22,819 - log/train6.log - INFO - iteration:74 step:6800/10100, NER loss:      nan
2019-02-22 04:01:32,335 - log/train6.log - INFO - iteration:74 step:6900/10100, NER loss:      nan
2019-02-22 06:01:37,457 - log/train6.log - INFO - iteration:74 step:7000/10100, NER loss:      nan
2019-02-22 06:01:39,463 - log/train6.log - INFO - iteration:74 step:7100/10100, NER loss:      nan
2019-02-22 06:01:41,331 - log/train6.log - INFO - iteration:74 step:7200/10100, NER loss:      nan
2019-02-22 06:01:43,327 - log/train6.log - INFO - iteration:74 step:7300/10100, NER loss:      nan
2019-02-22 06:01:45,357 - log/train6.log - INFO - iteration:74 step:7400/10100, NER loss:      nan
2019-02-22 06:01:54,452 - log/train6.log - INFO - iteration:74 step:7500/10100, NER loss:      nan
2019-02-22 06:02:03,998 - log/train6.log - INFO - iteration:74 step:7600/10100, NER loss:      nan
2019-02-22 06:02:15,980 - log/train6.log - INFO - iteration:74 step:7700/10100, NER loss:      nan
2019-02-22 06:02:25,190 - log/train6.log - INFO - iteration:74 step:7800/10100, NER loss:      nan
2019-02-22 06:02:34,643 - log/train6.log - INFO - iteration:74 step:7900/10100, NER loss:      nan
2019-02-22 06:02:44,159 - log/train6.log - INFO - iteration:74 step:8000/10100, NER loss:      nan
2019-02-22 06:02:53,603 - log/train6.log - INFO - iteration:74 step:8100/10100, NER loss:      nan
2019-02-22 06:03:01,930 - log/train6.log - INFO - iteration:74 step:8200/10100, NER loss:      nan
2019-02-22 06:03:10,965 - log/train6.log - INFO - iteration:74 step:8300/10100, NER loss:      nan
2019-02-22 06:03:20,071 - log/train6.log - INFO - iteration:74 step:8400/10100, NER loss:      nan
2019-02-22 06:03:29,202 - log/train6.log - INFO - iteration:74 step:8500/10100, NER loss:      nan
2019-02-22 06:03:39,088 - log/train6.log - INFO - iteration:74 step:8600/10100, NER loss:      nan
2019-02-22 06:03:48,569 - log/train6.log - INFO - iteration:74 step:8700/10100, NER loss:      nan
2019-02-22 06:03:57,911 - log/train6.log - INFO - iteration:74 step:8800/10100, NER loss:      nan
2019-02-22 06:04:06,760 - log/train6.log - INFO - iteration:74 step:8900/10100, NER loss:      nan
2019-02-22 06:04:16,725 - log/train6.log - INFO - iteration:74 step:9000/10100, NER loss:      nan
2019-02-22 06:04:25,653 - log/train6.log - INFO - iteration:74 step:9100/10100, NER loss:      nan
2019-02-22 06:04:44,169 - log/train6.log - INFO - iteration:74 step:9200/10100, NER loss:      nan
2019-02-22 06:04:53,972 - log/train6.log - INFO - iteration:74 step:9300/10100, NER loss:      nan
2019-02-22 06:05:03,045 - log/train6.log - INFO - iteration:74 step:9400/10100, NER loss:      nan
2019-02-22 06:05:12,694 - log/train6.log - INFO - iteration:74 step:9500/10100, NER loss:      nan
2019-02-22 06:05:22,574 - log/train6.log - INFO - iteration:74 step:9600/10100, NER loss:      nan
2019-02-22 06:05:31,995 - log/train6.log - INFO - iteration:74 step:9700/10100, NER loss:      nan
2019-02-22 06:05:41,274 - log/train6.log - INFO - iteration:74 step:9800/10100, NER loss:      nan
2019-02-22 06:05:50,362 - log/train6.log - INFO - iteration:74 step:9900/10100, NER loss:      nan
2019-02-22 06:05:59,716 - log/train6.log - INFO - iteration:74 step:10000/10100, NER loss:      nan
2019-02-22 06:06:08,743 - log/train6.log - INFO - iteration:75 step:0/10100, NER loss:      nan
2019-02-22 06:06:08,743 - log/train6.log - INFO - evaluate:dev
2019-02-22 06:06:37,122 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 06:06:37,122 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 06:06:37,123 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:06:37,123 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:06:37,123 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:06:37,124 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:06:37,124 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:06:37,124 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:06:37,134 - log/train6.log - INFO - evaluate:test
2019-02-22 06:06:43,666 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 06:06:43,666 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 06:06:43,666 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:06:43,667 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:06:43,667 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:06:43,668 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:06:43,668 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:06:43,668 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:06:52,468 - log/train6.log - INFO - iteration:75 step:100/10100, NER loss:      nan
2019-02-22 06:07:01,946 - log/train6.log - INFO - iteration:75 step:200/10100, NER loss:      nan
2019-02-22 06:07:11,589 - log/train6.log - INFO - iteration:75 step:300/10100, NER loss:      nan
2019-02-22 06:07:20,170 - log/train6.log - INFO - iteration:75 step:400/10100, NER loss:      nan
2019-02-22 06:07:37,024 - log/train6.log - INFO - iteration:75 step:500/10100, NER loss:      nan
2019-02-22 06:07:48,470 - log/train6.log - INFO - iteration:75 step:600/10100, NER loss:      nan
2019-02-22 06:07:58,580 - log/train6.log - INFO - iteration:75 step:700/10100, NER loss:      nan
2019-02-22 06:08:07,742 - log/train6.log - INFO - iteration:75 step:800/10100, NER loss:      nan
2019-02-22 06:08:16,986 - log/train6.log - INFO - iteration:75 step:900/10100, NER loss:      nan
2019-02-22 06:08:26,362 - log/train6.log - INFO - iteration:75 step:1000/10100, NER loss:      nan
2019-02-22 06:08:35,658 - log/train6.log - INFO - iteration:75 step:1100/10100, NER loss:      nan
2019-02-22 06:08:44,974 - log/train6.log - INFO - iteration:75 step:1200/10100, NER loss:      nan
2019-02-22 06:08:55,330 - log/train6.log - INFO - iteration:75 step:1300/10100, NER loss:      nan
2019-02-22 06:09:05,013 - log/train6.log - INFO - iteration:75 step:1400/10100, NER loss:      nan
2019-02-22 06:09:15,112 - log/train6.log - INFO - iteration:75 step:1500/10100, NER loss:      nan
2019-02-22 06:09:24,262 - log/train6.log - INFO - iteration:75 step:1600/10100, NER loss:      nan
2019-02-22 06:09:33,652 - log/train6.log - INFO - iteration:75 step:1700/10100, NER loss:      nan
2019-02-22 06:09:42,501 - log/train6.log - INFO - iteration:75 step:1800/10100, NER loss:      nan
2019-02-22 06:09:52,147 - log/train6.log - INFO - iteration:75 step:1900/10100, NER loss:      nan
2019-02-22 06:10:01,350 - log/train6.log - INFO - iteration:75 step:2000/10100, NER loss:      nan
2019-02-22 06:10:11,332 - log/train6.log - INFO - iteration:75 step:2100/10100, NER loss:      nan
2019-02-22 06:10:21,226 - log/train6.log - INFO - iteration:75 step:2200/10100, NER loss:      nan
2019-02-22 06:10:30,033 - log/train6.log - INFO - iteration:75 step:2300/10100, NER loss:      nan
2019-02-22 06:10:39,697 - log/train6.log - INFO - iteration:75 step:2400/10100, NER loss:      nan
2019-02-22 06:10:49,114 - log/train6.log - INFO - iteration:75 step:2500/10100, NER loss:      nan
2019-02-22 06:10:58,477 - log/train6.log - INFO - iteration:75 step:2600/10100, NER loss:      nan
2019-02-22 06:11:06,928 - log/train6.log - INFO - iteration:75 step:2700/10100, NER loss:      nan
2019-02-22 06:11:16,311 - log/train6.log - INFO - iteration:75 step:2800/10100, NER loss:      nan
2019-02-22 06:11:25,701 - log/train6.log - INFO - iteration:75 step:2900/10100, NER loss:      nan
2019-02-22 06:11:35,012 - log/train6.log - INFO - iteration:75 step:3000/10100, NER loss:      nan
2019-02-22 06:11:53,119 - log/train6.log - INFO - iteration:75 step:3100/10100, NER loss:      nan
2019-02-22 06:12:02,627 - log/train6.log - INFO - iteration:75 step:3200/10100, NER loss:      nan
2019-02-22 06:12:11,467 - log/train6.log - INFO - iteration:75 step:3300/10100, NER loss:      nan
2019-02-22 06:12:20,708 - log/train6.log - INFO - iteration:75 step:3400/10100, NER loss:      nan
2019-02-22 06:12:29,543 - log/train6.log - INFO - iteration:75 step:3500/10100, NER loss:      nan
2019-02-22 06:12:38,267 - log/train6.log - INFO - iteration:75 step:3600/10100, NER loss:      nan
2019-02-22 06:12:46,880 - log/train6.log - INFO - iteration:75 step:3700/10100, NER loss:      nan
2019-02-22 06:12:56,750 - log/train6.log - INFO - iteration:75 step:3800/10100, NER loss:      nan
2019-02-22 06:13:06,084 - log/train6.log - INFO - iteration:75 step:3900/10100, NER loss:      nan
2019-02-22 06:13:15,189 - log/train6.log - INFO - iteration:75 step:4000/10100, NER loss:      nan
2019-02-22 06:13:24,982 - log/train6.log - INFO - iteration:75 step:4100/10100, NER loss:      nan
2019-02-22 06:13:35,237 - log/train6.log - INFO - iteration:75 step:4200/10100, NER loss:      nan
2019-02-22 06:13:44,151 - log/train6.log - INFO - iteration:75 step:4300/10100, NER loss:      nan
2019-02-22 06:13:54,147 - log/train6.log - INFO - iteration:75 step:4400/10100, NER loss:      nan
2019-02-22 06:14:03,983 - log/train6.log - INFO - iteration:75 step:4500/10100, NER loss:      nan
2019-02-22 06:14:14,199 - log/train6.log - INFO - iteration:75 step:4600/10100, NER loss:      nan
2019-02-22 06:14:23,662 - log/train6.log - INFO - iteration:75 step:4700/10100, NER loss:      nan
2019-02-22 06:14:32,730 - log/train6.log - INFO - iteration:75 step:4800/10100, NER loss:      nan
2019-02-22 06:14:42,562 - log/train6.log - INFO - iteration:75 step:4900/10100, NER loss:      nan
2019-02-22 06:14:52,310 - log/train6.log - INFO - iteration:75 step:5000/10100, NER loss:      nan
2019-02-22 06:15:00,247 - log/train6.log - INFO - iteration:75 step:5100/10100, NER loss:      nan
2019-02-22 06:15:10,240 - log/train6.log - INFO - iteration:75 step:5200/10100, NER loss:      nan
2019-02-22 06:15:19,406 - log/train6.log - INFO - iteration:75 step:5300/10100, NER loss:      nan
2019-02-22 06:15:28,411 - log/train6.log - INFO - iteration:75 step:5400/10100, NER loss:      nan
2019-02-22 06:15:38,045 - log/train6.log - INFO - iteration:75 step:5500/10100, NER loss:      nan
2019-02-22 06:15:47,048 - log/train6.log - INFO - iteration:75 step:5600/10100, NER loss:      nan
2019-02-22 06:15:57,136 - log/train6.log - INFO - iteration:75 step:5700/10100, NER loss:      nan
2019-02-22 06:16:05,658 - log/train6.log - INFO - iteration:75 step:5800/10100, NER loss:      nan
2019-02-22 06:16:14,556 - log/train6.log - INFO - iteration:75 step:5900/10100, NER loss:      nan
2019-02-22 06:16:23,957 - log/train6.log - INFO - iteration:75 step:6000/10100, NER loss:      nan
2019-02-22 06:16:33,248 - log/train6.log - INFO - iteration:75 step:6100/10100, NER loss:      nan
2019-02-22 06:16:42,151 - log/train6.log - INFO - iteration:75 step:6200/10100, NER loss:      nan
2019-02-22 06:16:51,507 - log/train6.log - INFO - iteration:75 step:6300/10100, NER loss:      nan
2019-02-22 06:17:01,115 - log/train6.log - INFO - iteration:75 step:6400/10100, NER loss:      nan
2019-02-22 06:17:09,977 - log/train6.log - INFO - iteration:75 step:6500/10100, NER loss:      nan
2019-02-22 06:17:19,591 - log/train6.log - INFO - iteration:75 step:6600/10100, NER loss:      nan
2019-02-22 06:17:29,436 - log/train6.log - INFO - iteration:75 step:6700/10100, NER loss:      nan
2019-02-22 06:17:39,005 - log/train6.log - INFO - iteration:75 step:6800/10100, NER loss:      nan
2019-02-22 06:17:47,974 - log/train6.log - INFO - iteration:75 step:6900/10100, NER loss:      nan
2019-02-22 06:17:58,261 - log/train6.log - INFO - iteration:75 step:7000/10100, NER loss:      nan
2019-02-22 06:18:07,140 - log/train6.log - INFO - iteration:75 step:7100/10100, NER loss:      nan
2019-02-22 06:18:18,770 - log/train6.log - INFO - iteration:75 step:7200/10100, NER loss:      nan
2019-02-22 06:18:28,535 - log/train6.log - INFO - iteration:75 step:7300/10100, NER loss:      nan
2019-02-22 06:18:37,544 - log/train6.log - INFO - iteration:75 step:7400/10100, NER loss:      nan
2019-02-22 06:18:46,599 - log/train6.log - INFO - iteration:75 step:7500/10100, NER loss:      nan
2019-02-22 06:18:56,791 - log/train6.log - INFO - iteration:75 step:7600/10100, NER loss:      nan
2019-02-22 06:19:05,751 - log/train6.log - INFO - iteration:75 step:7700/10100, NER loss:      nan
2019-02-22 06:19:15,314 - log/train6.log - INFO - iteration:75 step:7800/10100, NER loss:      nan
2019-02-22 06:19:25,406 - log/train6.log - INFO - iteration:75 step:7900/10100, NER loss:      nan
2019-02-22 06:19:35,054 - log/train6.log - INFO - iteration:75 step:8000/10100, NER loss:      nan
2019-02-22 06:19:44,258 - log/train6.log - INFO - iteration:75 step:8100/10100, NER loss:      nan
2019-02-22 06:19:52,525 - log/train6.log - INFO - iteration:75 step:8200/10100, NER loss:      nan
2019-02-22 06:20:01,217 - log/train6.log - INFO - iteration:75 step:8300/10100, NER loss:      nan
2019-02-22 06:20:10,279 - log/train6.log - INFO - iteration:75 step:8400/10100, NER loss:      nan
2019-02-22 06:20:19,927 - log/train6.log - INFO - iteration:75 step:8500/10100, NER loss:      nan
2019-02-22 06:20:30,260 - log/train6.log - INFO - iteration:75 step:8600/10100, NER loss:      nan
2019-02-22 06:20:49,949 - log/train6.log - INFO - iteration:75 step:8700/10100, NER loss:      nan
2019-02-22 06:20:58,164 - log/train6.log - INFO - iteration:75 step:8800/10100, NER loss:      nan
2019-02-22 06:21:06,529 - log/train6.log - INFO - iteration:75 step:8900/10100, NER loss:      nan
2019-02-22 06:21:16,168 - log/train6.log - INFO - iteration:75 step:9000/10100, NER loss:      nan
2019-02-22 06:21:24,906 - log/train6.log - INFO - iteration:75 step:9100/10100, NER loss:      nan
2019-02-22 06:21:34,248 - log/train6.log - INFO - iteration:75 step:9200/10100, NER loss:      nan
2019-02-22 06:21:43,377 - log/train6.log - INFO - iteration:75 step:9300/10100, NER loss:      nan
2019-02-22 06:21:52,838 - log/train6.log - INFO - iteration:75 step:9400/10100, NER loss:      nan
2019-02-22 06:22:02,298 - log/train6.log - INFO - iteration:75 step:9500/10100, NER loss:      nan
2019-02-22 06:22:11,603 - log/train6.log - INFO - iteration:75 step:9600/10100, NER loss:      nan
2019-02-22 06:22:21,426 - log/train6.log - INFO - iteration:75 step:9700/10100, NER loss:      nan
2019-02-22 06:22:30,009 - log/train6.log - INFO - iteration:75 step:9800/10100, NER loss:      nan
2019-02-22 06:22:40,099 - log/train6.log - INFO - iteration:75 step:9900/10100, NER loss:      nan
2019-02-22 06:22:49,829 - log/train6.log - INFO - iteration:75 step:10000/10100, NER loss:      nan
2019-02-22 06:22:59,466 - log/train6.log - INFO - iteration:76 step:0/10100, NER loss:      nan
2019-02-22 06:22:59,468 - log/train6.log - INFO - evaluate:dev
2019-02-22 06:23:27,944 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 06:23:27,945 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 06:23:27,946 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:23:27,946 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:23:27,946 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:23:27,947 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:23:27,947 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:23:27,947 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:23:27,957 - log/train6.log - INFO - evaluate:test
2019-02-22 06:23:34,490 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 06:23:34,490 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 06:23:34,491 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:23:34,491 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:23:34,491 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:23:34,492 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:23:34,492 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:23:34,492 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 06:23:44,101 - log/train6.log - INFO - iteration:76 step:100/10100, NER loss:      nan
2019-02-22 06:24:01,166 - log/train6.log - INFO - iteration:76 step:200/10100, NER loss:      nan
2019-02-22 06:24:10,722 - log/train6.log - INFO - iteration:76 step:300/10100, NER loss:      nan
2019-02-22 06:24:20,145 - log/train6.log - INFO - iteration:76 step:400/10100, NER loss:      nan
2019-02-22 06:24:29,122 - log/train6.log - INFO - iteration:76 step:500/10100, NER loss:      nan
2019-02-22 06:24:38,318 - log/train6.log - INFO - iteration:76 step:600/10100, NER loss:      nan
2019-02-22 06:24:48,013 - log/train6.log - INFO - iteration:76 step:700/10100, NER loss:      nan
2019-02-22 06:24:57,133 - log/train6.log - INFO - iteration:76 step:800/10100, NER loss:      nan
2019-02-22 06:25:06,409 - log/train6.log - INFO - iteration:76 step:900/10100, NER loss:      nan
2019-02-22 06:25:15,491 - log/train6.log - INFO - iteration:76 step:1000/10100, NER loss:      nan
2019-02-22 06:25:35,216 - log/train6.log - INFO - iteration:76 step:1100/10100, NER loss:      nan
2019-02-22 06:25:44,018 - log/train6.log - INFO - iteration:76 step:1200/10100, NER loss:      nan
2019-02-22 06:25:53,361 - log/train6.log - INFO - iteration:76 step:1300/10100, NER loss:      nan
2019-02-22 06:26:02,960 - log/train6.log - INFO - iteration:76 step:1400/10100, NER loss:      nan
2019-02-22 06:26:13,077 - log/train6.log - INFO - iteration:76 step:1500/10100, NER loss:      nan
2019-02-22 06:26:22,435 - log/train6.log - INFO - iteration:76 step:1600/10100, NER loss:      nan
2019-02-22 06:26:31,821 - log/train6.log - INFO - iteration:76 step:1700/10100, NER loss:      nan
2019-02-22 06:26:42,265 - log/train6.log - INFO - iteration:76 step:1800/10100, NER loss:      nan
2019-02-22 06:26:51,360 - log/train6.log - INFO - iteration:76 step:1900/10100, NER loss:      nan
2019-02-22 06:27:00,495 - log/train6.log - INFO - iteration:76 step:2000/10100, NER loss:      nan
2019-02-22 06:27:10,304 - log/train6.log - INFO - iteration:76 step:2100/10100, NER loss:      nan
2019-02-22 06:27:19,714 - log/train6.log - INFO - iteration:76 step:2200/10100, NER loss:      nan
2019-02-22 06:27:28,848 - log/train6.log - INFO - iteration:76 step:2300/10100, NER loss:      nan
2019-02-22 06:27:38,473 - log/train6.log - INFO - iteration:76 step:2400/10100, NER loss:      nan
2019-02-22 06:27:47,633 - log/train6.log - INFO - iteration:76 step:2500/10100, NER loss:      nan
2019-02-22 06:27:56,771 - log/train6.log - INFO - iteration:76 step:2600/10100, NER loss:      nan
2019-02-22 06:28:06,715 - log/train6.log - INFO - iteration:76 step:2700/10100, NER loss:      nan
2019-02-22 06:28:15,798 - log/train6.log - INFO - iteration:76 step:2800/10100, NER loss:      nan
2019-02-22 06:28:25,227 - log/train6.log - INFO - iteration:76 step:2900/10100, NER loss:      nan
2019-02-22 06:28:35,137 - log/train6.log - INFO - iteration:76 step:3000/10100, NER loss:      nan
2019-02-22 06:28:44,201 - log/train6.log - INFO - iteration:76 step:3100/10100, NER loss:      nan
2019-02-22 06:28:52,938 - log/train6.log - INFO - iteration:76 step:3200/10100, NER loss:      nan
2019-02-22 06:29:02,160 - log/train6.log - INFO - iteration:76 step:3300/10100, NER loss:      nan
2019-02-22 06:29:10,811 - log/train6.log - INFO - iteration:76 step:3400/10100, NER loss:      nan
2019-02-22 06:29:19,784 - log/train6.log - INFO - iteration:76 step:3500/10100, NER loss:      nan
2019-02-22 06:29:28,727 - log/train6.log - INFO - iteration:76 step:3600/10100, NER loss:      nan
2019-02-22 06:29:38,547 - log/train6.log - INFO - iteration:76 step:3700/10100, NER loss:      nan
2019-02-22 06:29:47,892 - log/train6.log - INFO - iteration:76 step:3800/10100, NER loss:      nan
2019-02-22 06:29:57,406 - log/train6.log - INFO - iteration:76 step:3900/10100, NER loss:      nan
2019-02-22 06:30:07,030 - log/train6.log - INFO - iteration:76 step:4000/10100, NER loss:      nan
2019-02-22 06:30:15,470 - log/train6.log - INFO - iteration:76 step:4100/10100, NER loss:      nan
2019-02-22 06:30:24,840 - log/train6.log - INFO - iteration:76 step:4200/10100, NER loss:      nan
2019-02-22 06:30:33,763 - log/train6.log - INFO - iteration:76 step:4300/10100, NER loss:      nan
2019-02-22 06:30:42,284 - log/train6.log - INFO - iteration:76 step:4400/10100, NER loss:      nan
2019-02-22 06:30:51,941 - log/train6.log - INFO - iteration:76 step:4500/10100, NER loss:      nan
2019-02-22 06:31:00,607 - log/train6.log - INFO - iteration:76 step:4600/10100, NER loss:      nan
2019-02-22 06:31:11,219 - log/train6.log - INFO - iteration:76 step:4700/10100, NER loss:      nan
2019-02-22 06:31:20,951 - log/train6.log - INFO - iteration:76 step:4800/10100, NER loss:      nan
2019-02-22 06:31:31,263 - log/train6.log - INFO - iteration:76 step:4900/10100, NER loss:      nan
2019-02-22 06:31:40,945 - log/train6.log - INFO - iteration:76 step:5000/10100, NER loss:      nan
2019-02-22 08:31:46,729 - log/train6.log - INFO - iteration:76 step:5100/10100, NER loss:      nan
2019-02-22 08:31:48,876 - log/train6.log - INFO - iteration:76 step:5200/10100, NER loss:      nan
2019-02-22 08:31:50,630 - log/train6.log - INFO - iteration:76 step:5300/10100, NER loss:      nan
2019-02-22 08:31:52,725 - log/train6.log - INFO - iteration:76 step:5400/10100, NER loss:      nan
2019-02-22 08:31:54,882 - log/train6.log - INFO - iteration:76 step:5500/10100, NER loss:      nan
2019-02-22 08:32:03,938 - log/train6.log - INFO - iteration:76 step:5600/10100, NER loss:      nan
2019-02-22 08:32:13,596 - log/train6.log - INFO - iteration:76 step:5700/10100, NER loss:      nan
2019-02-22 08:32:22,475 - log/train6.log - INFO - iteration:76 step:5800/10100, NER loss:      nan
2019-02-22 08:32:31,655 - log/train6.log - INFO - iteration:76 step:5900/10100, NER loss:      nan
2019-02-22 08:32:40,934 - log/train6.log - INFO - iteration:76 step:6000/10100, NER loss:      nan
2019-02-22 08:32:50,677 - log/train6.log - INFO - iteration:76 step:6100/10100, NER loss:      nan
2019-02-22 08:32:59,905 - log/train6.log - INFO - iteration:76 step:6200/10100, NER loss:      nan
2019-02-22 08:33:08,550 - log/train6.log - INFO - iteration:76 step:6300/10100, NER loss:      nan
2019-02-22 08:33:18,099 - log/train6.log - INFO - iteration:76 step:6400/10100, NER loss:      nan
2019-02-22 08:33:28,379 - log/train6.log - INFO - iteration:76 step:6500/10100, NER loss:      nan
2019-02-22 08:33:38,094 - log/train6.log - INFO - iteration:76 step:6600/10100, NER loss:      nan
2019-02-22 08:33:47,850 - log/train6.log - INFO - iteration:76 step:6700/10100, NER loss:      nan
2019-02-22 08:33:57,260 - log/train6.log - INFO - iteration:76 step:6800/10100, NER loss:      nan
2019-02-22 08:34:06,984 - log/train6.log - INFO - iteration:76 step:6900/10100, NER loss:      nan
2019-02-22 08:34:15,559 - log/train6.log - INFO - iteration:76 step:7000/10100, NER loss:      nan
2019-02-22 08:34:25,353 - log/train6.log - INFO - iteration:76 step:7100/10100, NER loss:      nan
2019-02-22 08:34:34,460 - log/train6.log - INFO - iteration:76 step:7200/10100, NER loss:      nan
2019-02-22 08:34:43,303 - log/train6.log - INFO - iteration:76 step:7300/10100, NER loss:      nan
2019-02-22 08:34:52,207 - log/train6.log - INFO - iteration:76 step:7400/10100, NER loss:      nan
2019-02-22 08:35:00,730 - log/train6.log - INFO - iteration:76 step:7500/10100, NER loss:      nan
2019-02-22 08:35:10,063 - log/train6.log - INFO - iteration:76 step:7600/10100, NER loss:      nan
2019-02-22 08:35:20,759 - log/train6.log - INFO - iteration:76 step:7700/10100, NER loss:      nan
2019-02-22 08:35:30,081 - log/train6.log - INFO - iteration:76 step:7800/10100, NER loss:      nan
2019-02-22 08:35:39,850 - log/train6.log - INFO - iteration:76 step:7900/10100, NER loss:      nan
2019-02-22 08:35:49,141 - log/train6.log - INFO - iteration:76 step:8000/10100, NER loss:      nan
2019-02-22 08:35:59,151 - log/train6.log - INFO - iteration:76 step:8100/10100, NER loss:      nan
2019-02-22 08:36:08,281 - log/train6.log - INFO - iteration:76 step:8200/10100, NER loss:      nan
2019-02-22 08:36:18,118 - log/train6.log - INFO - iteration:76 step:8300/10100, NER loss:      nan
2019-02-22 08:36:27,640 - log/train6.log - INFO - iteration:76 step:8400/10100, NER loss:      nan
2019-02-22 08:36:37,508 - log/train6.log - INFO - iteration:76 step:8500/10100, NER loss:      nan
2019-02-22 08:36:47,061 - log/train6.log - INFO - iteration:76 step:8600/10100, NER loss:      nan
2019-02-22 08:36:57,126 - log/train6.log - INFO - iteration:76 step:8700/10100, NER loss:      nan
2019-02-22 08:37:06,017 - log/train6.log - INFO - iteration:76 step:8800/10100, NER loss:      nan
2019-02-22 08:37:15,577 - log/train6.log - INFO - iteration:76 step:8900/10100, NER loss:      nan
2019-02-22 08:37:24,537 - log/train6.log - INFO - iteration:76 step:9000/10100, NER loss:      nan
2019-02-22 08:37:33,176 - log/train6.log - INFO - iteration:76 step:9100/10100, NER loss:      nan
2019-02-22 08:37:43,399 - log/train6.log - INFO - iteration:76 step:9200/10100, NER loss:      nan
2019-02-22 08:37:52,186 - log/train6.log - INFO - iteration:76 step:9300/10100, NER loss:      nan
2019-02-22 08:38:00,958 - log/train6.log - INFO - iteration:76 step:9400/10100, NER loss:      nan
2019-02-22 08:38:09,769 - log/train6.log - INFO - iteration:76 step:9500/10100, NER loss:      nan
2019-02-22 08:38:19,575 - log/train6.log - INFO - iteration:76 step:9600/10100, NER loss:      nan
2019-02-22 08:38:30,053 - log/train6.log - INFO - iteration:76 step:9700/10100, NER loss:      nan
2019-02-22 08:38:39,111 - log/train6.log - INFO - iteration:76 step:9800/10100, NER loss:      nan
2019-02-22 08:38:48,497 - log/train6.log - INFO - iteration:76 step:9900/10100, NER loss:      nan
2019-02-22 08:38:57,395 - log/train6.log - INFO - iteration:76 step:10000/10100, NER loss:      nan
2019-02-22 08:39:17,129 - log/train6.log - INFO - iteration:77 step:0/10100, NER loss:      nan
2019-02-22 08:39:17,129 - log/train6.log - INFO - evaluate:dev
2019-02-22 08:39:45,613 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 08:39:45,615 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 08:39:45,615 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:39:45,616 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:39:45,616 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:39:45,616 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:39:45,617 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:39:45,617 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:39:45,627 - log/train6.log - INFO - evaluate:test
2019-02-22 08:39:52,171 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 08:39:52,173 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 08:39:52,173 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:39:52,173 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:39:52,174 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:39:52,174 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:39:52,174 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:39:52,175 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:40:01,869 - log/train6.log - INFO - iteration:77 step:100/10100, NER loss:      nan
2019-02-22 08:40:10,983 - log/train6.log - INFO - iteration:77 step:200/10100, NER loss:      nan
2019-02-22 08:40:20,105 - log/train6.log - INFO - iteration:77 step:300/10100, NER loss:      nan
2019-02-22 08:40:29,695 - log/train6.log - INFO - iteration:77 step:400/10100, NER loss:      nan
2019-02-22 08:40:38,912 - log/train6.log - INFO - iteration:77 step:500/10100, NER loss:      nan
2019-02-22 08:40:47,540 - log/train6.log - INFO - iteration:77 step:600/10100, NER loss:      nan
2019-02-22 08:40:56,457 - log/train6.log - INFO - iteration:77 step:700/10100, NER loss:      nan
2019-02-22 08:41:05,725 - log/train6.log - INFO - iteration:77 step:800/10100, NER loss:      nan
2019-02-22 08:41:14,443 - log/train6.log - INFO - iteration:77 step:900/10100, NER loss:      nan
2019-02-22 08:41:23,799 - log/train6.log - INFO - iteration:77 step:1000/10100, NER loss:      nan
2019-02-22 08:41:32,410 - log/train6.log - INFO - iteration:77 step:1100/10100, NER loss:      nan
2019-02-22 08:41:41,699 - log/train6.log - INFO - iteration:77 step:1200/10100, NER loss:      nan
2019-02-22 08:41:52,393 - log/train6.log - INFO - iteration:77 step:1300/10100, NER loss:      nan
2019-02-22 08:42:01,949 - log/train6.log - INFO - iteration:77 step:1400/10100, NER loss:      nan
2019-02-22 08:42:11,606 - log/train6.log - INFO - iteration:77 step:1500/10100, NER loss:      nan
2019-02-22 08:42:20,874 - log/train6.log - INFO - iteration:77 step:1600/10100, NER loss:      nan
2019-02-22 08:42:31,386 - log/train6.log - INFO - iteration:77 step:1700/10100, NER loss:      nan
2019-02-22 08:42:41,637 - log/train6.log - INFO - iteration:77 step:1800/10100, NER loss:      nan
2019-02-22 08:42:50,909 - log/train6.log - INFO - iteration:77 step:1900/10100, NER loss:      nan
2019-02-22 08:42:59,878 - log/train6.log - INFO - iteration:77 step:2000/10100, NER loss:      nan
2019-02-22 08:43:09,330 - log/train6.log - INFO - iteration:77 step:2100/10100, NER loss:      nan
2019-02-22 08:43:19,963 - log/train6.log - INFO - iteration:77 step:2200/10100, NER loss:      nan
2019-02-22 08:43:29,518 - log/train6.log - INFO - iteration:77 step:2300/10100, NER loss:      nan
2019-02-22 08:43:39,673 - log/train6.log - INFO - iteration:77 step:2400/10100, NER loss:      nan
2019-02-22 08:43:48,425 - log/train6.log - INFO - iteration:77 step:2500/10100, NER loss:      nan
2019-02-22 08:43:58,104 - log/train6.log - INFO - iteration:77 step:2600/10100, NER loss:      nan
2019-02-22 08:44:08,290 - log/train6.log - INFO - iteration:77 step:2700/10100, NER loss:      nan
2019-02-22 08:44:17,832 - log/train6.log - INFO - iteration:77 step:2800/10100, NER loss:      nan
2019-02-22 08:44:26,059 - log/train6.log - INFO - iteration:77 step:2900/10100, NER loss:      nan
2019-02-22 08:44:43,522 - log/train6.log - INFO - iteration:77 step:3000/10100, NER loss:      nan
2019-02-22 08:44:54,234 - log/train6.log - INFO - iteration:77 step:3100/10100, NER loss:      nan
2019-02-22 08:45:04,263 - log/train6.log - INFO - iteration:77 step:3200/10100, NER loss:      nan
2019-02-22 08:45:12,918 - log/train6.log - INFO - iteration:77 step:3300/10100, NER loss:      nan
2019-02-22 08:45:21,727 - log/train6.log - INFO - iteration:77 step:3400/10100, NER loss:      nan
2019-02-22 08:45:30,709 - log/train6.log - INFO - iteration:77 step:3500/10100, NER loss:      nan
2019-02-22 08:45:39,467 - log/train6.log - INFO - iteration:77 step:3600/10100, NER loss:      nan
2019-02-22 08:45:49,074 - log/train6.log - INFO - iteration:77 step:3700/10100, NER loss:      nan
2019-02-22 08:45:59,317 - log/train6.log - INFO - iteration:77 step:3800/10100, NER loss:      nan
2019-02-22 08:46:09,755 - log/train6.log - INFO - iteration:77 step:3900/10100, NER loss:      nan
2019-02-22 08:46:19,237 - log/train6.log - INFO - iteration:77 step:4000/10100, NER loss:      nan
2019-02-22 08:46:27,951 - log/train6.log - INFO - iteration:77 step:4100/10100, NER loss:      nan
2019-02-22 08:46:38,356 - log/train6.log - INFO - iteration:77 step:4200/10100, NER loss:      nan
2019-02-22 08:46:47,218 - log/train6.log - INFO - iteration:77 step:4300/10100, NER loss:      nan
2019-02-22 08:46:56,371 - log/train6.log - INFO - iteration:77 step:4400/10100, NER loss:      nan
2019-02-22 08:47:05,899 - log/train6.log - INFO - iteration:77 step:4500/10100, NER loss:      nan
2019-02-22 08:47:14,799 - log/train6.log - INFO - iteration:77 step:4600/10100, NER loss:      nan
2019-02-22 08:47:23,993 - log/train6.log - INFO - iteration:77 step:4700/10100, NER loss:      nan
2019-02-22 08:47:33,668 - log/train6.log - INFO - iteration:77 step:4800/10100, NER loss:      nan
2019-02-22 08:47:43,654 - log/train6.log - INFO - iteration:77 step:4900/10100, NER loss:      nan
2019-02-22 08:47:53,468 - log/train6.log - INFO - iteration:77 step:5000/10100, NER loss:      nan
2019-02-22 08:48:02,879 - log/train6.log - INFO - iteration:77 step:5100/10100, NER loss:      nan
2019-02-22 08:48:19,728 - log/train6.log - INFO - iteration:77 step:5200/10100, NER loss:      nan
2019-02-22 08:48:28,446 - log/train6.log - INFO - iteration:77 step:5300/10100, NER loss:      nan
2019-02-22 08:48:37,646 - log/train6.log - INFO - iteration:77 step:5400/10100, NER loss:      nan
2019-02-22 08:48:45,931 - log/train6.log - INFO - iteration:77 step:5500/10100, NER loss:      nan
2019-02-22 08:49:04,208 - log/train6.log - INFO - iteration:77 step:5600/10100, NER loss:      nan
2019-02-22 08:49:13,648 - log/train6.log - INFO - iteration:77 step:5700/10100, NER loss:      nan
2019-02-22 08:49:23,691 - log/train6.log - INFO - iteration:77 step:5800/10100, NER loss:      nan
2019-02-22 08:49:33,291 - log/train6.log - INFO - iteration:77 step:5900/10100, NER loss:      nan
2019-02-22 08:49:42,893 - log/train6.log - INFO - iteration:77 step:6000/10100, NER loss:      nan
2019-02-22 08:49:51,426 - log/train6.log - INFO - iteration:77 step:6100/10100, NER loss:      nan
2019-02-22 08:49:59,903 - log/train6.log - INFO - iteration:77 step:6200/10100, NER loss:      nan
2019-02-22 08:50:09,019 - log/train6.log - INFO - iteration:77 step:6300/10100, NER loss:      nan
2019-02-22 08:50:18,160 - log/train6.log - INFO - iteration:77 step:6400/10100, NER loss:      nan
2019-02-22 08:50:28,555 - log/train6.log - INFO - iteration:77 step:6500/10100, NER loss:      nan
2019-02-22 08:50:37,965 - log/train6.log - INFO - iteration:77 step:6600/10100, NER loss:      nan
2019-02-22 08:50:48,207 - log/train6.log - INFO - iteration:77 step:6700/10100, NER loss:      nan
2019-02-22 08:50:58,072 - log/train6.log - INFO - iteration:77 step:6800/10100, NER loss:      nan
2019-02-22 08:51:07,331 - log/train6.log - INFO - iteration:77 step:6900/10100, NER loss:      nan
2019-02-22 08:51:16,469 - log/train6.log - INFO - iteration:77 step:7000/10100, NER loss:      nan
2019-02-22 08:51:26,149 - log/train6.log - INFO - iteration:77 step:7100/10100, NER loss:      nan
2019-02-22 08:51:35,847 - log/train6.log - INFO - iteration:77 step:7200/10100, NER loss:      nan
2019-02-22 08:51:44,931 - log/train6.log - INFO - iteration:77 step:7300/10100, NER loss:      nan
2019-02-22 08:51:54,230 - log/train6.log - INFO - iteration:77 step:7400/10100, NER loss:      nan
2019-02-22 08:52:04,265 - log/train6.log - INFO - iteration:77 step:7500/10100, NER loss:      nan
2019-02-22 08:52:13,781 - log/train6.log - INFO - iteration:77 step:7600/10100, NER loss:      nan
2019-02-22 08:52:22,381 - log/train6.log - INFO - iteration:77 step:7700/10100, NER loss:      nan
2019-02-22 08:52:31,973 - log/train6.log - INFO - iteration:77 step:7800/10100, NER loss:      nan
2019-02-22 08:52:41,874 - log/train6.log - INFO - iteration:77 step:7900/10100, NER loss:      nan
2019-02-22 08:52:51,676 - log/train6.log - INFO - iteration:77 step:8000/10100, NER loss:      nan
2019-02-22 08:53:02,029 - log/train6.log - INFO - iteration:77 step:8100/10100, NER loss:      nan
2019-02-22 08:53:11,252 - log/train6.log - INFO - iteration:77 step:8200/10100, NER loss:      nan
2019-02-22 08:53:20,562 - log/train6.log - INFO - iteration:77 step:8300/10100, NER loss:      nan
2019-02-22 08:53:29,050 - log/train6.log - INFO - iteration:77 step:8400/10100, NER loss:      nan
2019-02-22 08:53:39,074 - log/train6.log - INFO - iteration:77 step:8500/10100, NER loss:      nan
2019-02-22 08:53:47,946 - log/train6.log - INFO - iteration:77 step:8600/10100, NER loss:      nan
2019-02-22 08:53:58,358 - log/train6.log - INFO - iteration:77 step:8700/10100, NER loss:      nan
2019-02-22 08:54:07,195 - log/train6.log - INFO - iteration:77 step:8800/10100, NER loss:      nan
2019-02-22 08:54:16,588 - log/train6.log - INFO - iteration:77 step:8900/10100, NER loss:      nan
2019-02-22 08:54:25,683 - log/train6.log - INFO - iteration:77 step:9000/10100, NER loss:      nan
2019-02-22 08:54:34,147 - log/train6.log - INFO - iteration:77 step:9100/10100, NER loss:      nan
2019-02-22 08:54:43,346 - log/train6.log - INFO - iteration:77 step:9200/10100, NER loss:      nan
2019-02-22 08:54:52,720 - log/train6.log - INFO - iteration:77 step:9300/10100, NER loss:      nan
2019-02-22 08:55:03,129 - log/train6.log - INFO - iteration:77 step:9400/10100, NER loss:      nan
2019-02-22 08:55:13,411 - log/train6.log - INFO - iteration:77 step:9500/10100, NER loss:      nan
2019-02-22 08:55:22,856 - log/train6.log - INFO - iteration:77 step:9600/10100, NER loss:      nan
2019-02-22 08:55:31,875 - log/train6.log - INFO - iteration:77 step:9700/10100, NER loss:      nan
2019-02-22 08:55:40,458 - log/train6.log - INFO - iteration:77 step:9800/10100, NER loss:      nan
2019-02-22 08:55:48,678 - log/train6.log - INFO - iteration:77 step:9900/10100, NER loss:      nan
2019-02-22 08:55:57,395 - log/train6.log - INFO - iteration:77 step:10000/10100, NER loss:      nan
2019-02-22 08:56:06,995 - log/train6.log - INFO - iteration:78 step:0/10100, NER loss:      nan
2019-02-22 08:56:06,996 - log/train6.log - INFO - evaluate:dev
2019-02-22 08:56:35,530 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 08:56:35,532 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 08:56:35,533 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:56:35,533 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:56:35,533 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:56:35,534 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:56:35,534 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:56:35,534 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:56:35,545 - log/train6.log - INFO - evaluate:test
2019-02-22 08:56:42,069 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 08:56:42,069 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 08:56:42,069 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:56:42,070 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:56:42,070 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:56:42,070 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:56:42,071 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:56:42,071 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 08:56:53,046 - log/train6.log - INFO - iteration:78 step:100/10100, NER loss:      nan
2019-02-22 08:57:02,280 - log/train6.log - INFO - iteration:78 step:200/10100, NER loss:      nan
2019-02-22 08:57:12,176 - log/train6.log - INFO - iteration:78 step:300/10100, NER loss:      nan
2019-02-22 08:57:21,287 - log/train6.log - INFO - iteration:78 step:400/10100, NER loss:      nan
2019-02-22 08:57:30,925 - log/train6.log - INFO - iteration:78 step:500/10100, NER loss:      nan
2019-02-22 08:57:47,516 - log/train6.log - INFO - iteration:78 step:600/10100, NER loss:      nan
2019-02-22 08:57:56,421 - log/train6.log - INFO - iteration:78 step:700/10100, NER loss:      nan
2019-02-22 08:58:05,654 - log/train6.log - INFO - iteration:78 step:800/10100, NER loss:      nan
2019-02-22 08:58:15,463 - log/train6.log - INFO - iteration:78 step:900/10100, NER loss:      nan
2019-02-22 08:58:24,019 - log/train6.log - INFO - iteration:78 step:1000/10100, NER loss:      nan
2019-02-22 08:58:32,637 - log/train6.log - INFO - iteration:78 step:1100/10100, NER loss:      nan
2019-02-22 08:58:42,005 - log/train6.log - INFO - iteration:78 step:1200/10100, NER loss:      nan
2019-02-22 08:58:51,494 - log/train6.log - INFO - iteration:78 step:1300/10100, NER loss:      nan
2019-02-22 08:59:01,130 - log/train6.log - INFO - iteration:78 step:1400/10100, NER loss:      nan
2019-02-22 08:59:09,239 - log/train6.log - INFO - iteration:78 step:1500/10100, NER loss:      nan
2019-02-22 08:59:18,989 - log/train6.log - INFO - iteration:78 step:1600/10100, NER loss:      nan
2019-02-22 08:59:28,048 - log/train6.log - INFO - iteration:78 step:1700/10100, NER loss:      nan
2019-02-22 08:59:37,337 - log/train6.log - INFO - iteration:78 step:1800/10100, NER loss:      nan
2019-02-22 08:59:46,631 - log/train6.log - INFO - iteration:78 step:1900/10100, NER loss:      nan
2019-02-22 08:59:55,460 - log/train6.log - INFO - iteration:78 step:2000/10100, NER loss:      nan
2019-02-22 09:00:04,737 - log/train6.log - INFO - iteration:78 step:2100/10100, NER loss:      nan
2019-02-22 09:00:13,151 - log/train6.log - INFO - iteration:78 step:2200/10100, NER loss:      nan
2019-02-22 09:00:22,099 - log/train6.log - INFO - iteration:78 step:2300/10100, NER loss:      nan
2019-02-22 09:00:32,073 - log/train6.log - INFO - iteration:78 step:2400/10100, NER loss:      nan
2019-02-22 09:00:41,119 - log/train6.log - INFO - iteration:78 step:2500/10100, NER loss:      nan
2019-02-22 09:00:49,889 - log/train6.log - INFO - iteration:78 step:2600/10100, NER loss:      nan
2019-02-22 09:00:59,654 - log/train6.log - INFO - iteration:78 step:2700/10100, NER loss:      nan
2019-02-22 09:01:09,011 - log/train6.log - INFO - iteration:78 step:2800/10100, NER loss:      nan
2019-02-22 09:01:18,879 - log/train6.log - INFO - iteration:78 step:2900/10100, NER loss:      nan
2019-02-22 09:01:28,508 - log/train6.log - INFO - iteration:78 step:3000/10100, NER loss:      nan
2019-02-22 09:01:37,392 - log/train6.log - INFO - iteration:78 step:3100/10100, NER loss:      nan
2019-02-22 09:01:46,954 - log/train6.log - INFO - iteration:78 step:3200/10100, NER loss:      nan
2019-02-22 09:55:25,342 - log/train6.log - INFO - iteration:78 step:3300/10100, NER loss:      nan
2019-02-22 09:55:27,327 - log/train6.log - INFO - iteration:78 step:3400/10100, NER loss:      nan
2019-02-22 09:55:29,392 - log/train6.log - INFO - iteration:78 step:3500/10100, NER loss:      nan
2019-02-22 09:55:31,578 - log/train6.log - INFO - iteration:78 step:3600/10100, NER loss:      nan
2019-02-22 09:55:33,439 - log/train6.log - INFO - iteration:78 step:3700/10100, NER loss:      nan
2019-02-22 09:55:41,015 - log/train6.log - INFO - iteration:78 step:3800/10100, NER loss:      nan
2019-02-22 09:55:50,101 - log/train6.log - INFO - iteration:78 step:3900/10100, NER loss:      nan
2019-02-22 09:55:59,041 - log/train6.log - INFO - iteration:78 step:4000/10100, NER loss:      nan
2019-02-22 09:56:08,167 - log/train6.log - INFO - iteration:78 step:4100/10100, NER loss:      nan
2019-02-22 09:56:16,218 - log/train6.log - INFO - iteration:78 step:4200/10100, NER loss:      nan
2019-02-22 10:28:37,980 - log/train6.log - INFO - iteration:78 step:4300/10100, NER loss:      nan
2019-02-22 10:28:40,927 - log/train6.log - INFO - iteration:78 step:4400/10100, NER loss:      nan
2019-02-22 10:28:43,243 - log/train6.log - INFO - iteration:78 step:4500/10100, NER loss:      nan
2019-02-22 10:28:45,597 - log/train6.log - INFO - iteration:78 step:4600/10100, NER loss:      nan
2019-02-22 10:28:47,608 - log/train6.log - INFO - iteration:78 step:4700/10100, NER loss:      nan
2019-02-22 10:28:50,035 - log/train6.log - INFO - iteration:78 step:4800/10100, NER loss:      nan
2019-02-22 10:28:52,598 - log/train6.log - INFO - iteration:78 step:4900/10100, NER loss:      nan
2019-02-22 10:28:55,459 - log/train6.log - INFO - iteration:78 step:5000/10100, NER loss:      nan
2019-02-22 10:28:59,562 - log/train6.log - INFO - iteration:78 step:5100/10100, NER loss:      nan
2019-02-22 10:29:01,585 - log/train6.log - INFO - iteration:78 step:5200/10100, NER loss:      nan
2019-02-22 10:29:03,718 - log/train6.log - INFO - iteration:78 step:5300/10100, NER loss:      nan
2019-02-22 10:29:06,045 - log/train6.log - INFO - iteration:78 step:5400/10100, NER loss:      nan
2019-02-22 10:29:07,763 - log/train6.log - INFO - iteration:78 step:5500/10100, NER loss:      nan
2019-02-22 10:29:09,644 - log/train6.log - INFO - iteration:78 step:5600/10100, NER loss:      nan
2019-02-22 10:29:11,920 - log/train6.log - INFO - iteration:78 step:5700/10100, NER loss:      nan
2019-02-22 10:29:14,268 - log/train6.log - INFO - iteration:78 step:5800/10100, NER loss:      nan
2019-02-22 10:29:16,533 - log/train6.log - INFO - iteration:78 step:5900/10100, NER loss:      nan
2019-02-22 10:29:19,118 - log/train6.log - INFO - iteration:78 step:6000/10100, NER loss:      nan
2019-02-22 10:29:21,430 - log/train6.log - INFO - iteration:78 step:6100/10100, NER loss:      nan
2019-02-22 10:29:23,653 - log/train6.log - INFO - iteration:78 step:6200/10100, NER loss:      nan
2019-02-22 10:29:26,135 - log/train6.log - INFO - iteration:78 step:6300/10100, NER loss:      nan
2019-02-22 10:29:28,282 - log/train6.log - INFO - iteration:78 step:6400/10100, NER loss:      nan
2019-02-22 10:29:30,669 - log/train6.log - INFO - iteration:78 step:6500/10100, NER loss:      nan
2019-02-22 10:29:32,784 - log/train6.log - INFO - iteration:78 step:6600/10100, NER loss:      nan
2019-02-22 10:29:35,036 - log/train6.log - INFO - iteration:78 step:6700/10100, NER loss:      nan
2019-02-22 10:29:37,315 - log/train6.log - INFO - iteration:78 step:6800/10100, NER loss:      nan
2019-02-22 10:29:40,140 - log/train6.log - INFO - iteration:78 step:6900/10100, NER loss:      nan
2019-02-22 10:29:42,294 - log/train6.log - INFO - iteration:78 step:7000/10100, NER loss:      nan
2019-02-22 10:29:44,604 - log/train6.log - INFO - iteration:78 step:7100/10100, NER loss:      nan
2019-02-22 10:29:46,665 - log/train6.log - INFO - iteration:78 step:7200/10100, NER loss:      nan
2019-02-22 10:29:49,006 - log/train6.log - INFO - iteration:78 step:7300/10100, NER loss:      nan
2019-02-22 10:29:51,030 - log/train6.log - INFO - iteration:78 step:7400/10100, NER loss:      nan
2019-02-22 10:29:53,353 - log/train6.log - INFO - iteration:78 step:7500/10100, NER loss:      nan
2019-02-22 10:29:55,631 - log/train6.log - INFO - iteration:78 step:7600/10100, NER loss:      nan
2019-02-22 10:29:57,801 - log/train6.log - INFO - iteration:78 step:7700/10100, NER loss:      nan
2019-02-22 10:29:59,957 - log/train6.log - INFO - iteration:78 step:7800/10100, NER loss:      nan
2019-02-22 10:30:02,137 - log/train6.log - INFO - iteration:78 step:7900/10100, NER loss:      nan
2019-02-22 10:30:04,208 - log/train6.log - INFO - iteration:78 step:8000/10100, NER loss:      nan
2019-02-22 10:30:06,263 - log/train6.log - INFO - iteration:78 step:8100/10100, NER loss:      nan
2019-02-22 10:30:08,451 - log/train6.log - INFO - iteration:78 step:8200/10100, NER loss:      nan
2019-02-22 10:30:10,544 - log/train6.log - INFO - iteration:78 step:8300/10100, NER loss:      nan
2019-02-22 10:30:12,648 - log/train6.log - INFO - iteration:78 step:8400/10100, NER loss:      nan
2019-02-22 10:30:14,905 - log/train6.log - INFO - iteration:78 step:8500/10100, NER loss:      nan
2019-02-22 10:30:17,014 - log/train6.log - INFO - iteration:78 step:8600/10100, NER loss:      nan
2019-02-22 10:30:19,138 - log/train6.log - INFO - iteration:78 step:8700/10100, NER loss:      nan
2019-02-22 10:30:21,293 - log/train6.log - INFO - iteration:78 step:8800/10100, NER loss:      nan
2019-02-22 10:30:23,426 - log/train6.log - INFO - iteration:78 step:8900/10100, NER loss:      nan
2019-02-22 10:30:25,661 - log/train6.log - INFO - iteration:78 step:9000/10100, NER loss:      nan
2019-02-22 10:30:27,919 - log/train6.log - INFO - iteration:78 step:9100/10100, NER loss:      nan
2019-02-22 10:30:29,946 - log/train6.log - INFO - iteration:78 step:9200/10100, NER loss:      nan
2019-02-22 10:30:32,022 - log/train6.log - INFO - iteration:78 step:9300/10100, NER loss:      nan
2019-02-22 10:30:34,257 - log/train6.log - INFO - iteration:78 step:9400/10100, NER loss:      nan
2019-02-22 10:30:38,783 - log/train6.log - INFO - iteration:78 step:9500/10100, NER loss:      nan
2019-02-22 10:30:40,899 - log/train6.log - INFO - iteration:78 step:9600/10100, NER loss:      nan
2019-02-22 10:30:42,972 - log/train6.log - INFO - iteration:78 step:9700/10100, NER loss:      nan
2019-02-22 10:30:44,924 - log/train6.log - INFO - iteration:78 step:9800/10100, NER loss:      nan
2019-02-22 10:30:47,113 - log/train6.log - INFO - iteration:78 step:9900/10100, NER loss:      nan
2019-02-22 10:30:49,189 - log/train6.log - INFO - iteration:78 step:10000/10100, NER loss:      nan
2019-02-22 10:30:51,262 - log/train6.log - INFO - iteration:79 step:0/10100, NER loss:      nan
2019-02-22 10:30:51,262 - log/train6.log - INFO - evaluate:dev
2019-02-22 10:30:57,821 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 10:30:57,822 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 10:30:57,822 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:30:57,822 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:30:57,823 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:30:57,823 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:30:57,823 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:30:57,823 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:30:57,828 - log/train6.log - INFO - evaluate:test
2019-02-22 10:30:59,287 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 10:30:59,287 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 10:30:59,287 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:30:59,287 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:30:59,287 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:30:59,287 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:30:59,288 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:30:59,288 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:31:01,438 - log/train6.log - INFO - iteration:79 step:100/10100, NER loss:      nan
2019-02-22 10:31:03,426 - log/train6.log - INFO - iteration:79 step:200/10100, NER loss:      nan
2019-02-22 10:31:05,575 - log/train6.log - INFO - iteration:79 step:300/10100, NER loss:      nan
2019-02-22 10:31:07,423 - log/train6.log - INFO - iteration:79 step:400/10100, NER loss:      nan
2019-02-22 10:31:09,583 - log/train6.log - INFO - iteration:79 step:500/10100, NER loss:      nan
2019-02-22 10:31:11,531 - log/train6.log - INFO - iteration:79 step:600/10100, NER loss:      nan
2019-02-22 10:31:13,663 - log/train6.log - INFO - iteration:79 step:700/10100, NER loss:      nan
2019-02-22 10:31:15,891 - log/train6.log - INFO - iteration:79 step:800/10100, NER loss:      nan
2019-02-22 10:31:18,029 - log/train6.log - INFO - iteration:79 step:900/10100, NER loss:      nan
2019-02-22 10:31:20,075 - log/train6.log - INFO - iteration:79 step:1000/10100, NER loss:      nan
2019-02-22 10:31:22,296 - log/train6.log - INFO - iteration:79 step:1100/10100, NER loss:      nan
2019-02-22 10:31:24,301 - log/train6.log - INFO - iteration:79 step:1200/10100, NER loss:      nan
2019-02-22 10:31:26,362 - log/train6.log - INFO - iteration:79 step:1300/10100, NER loss:      nan
2019-02-22 10:31:28,323 - log/train6.log - INFO - iteration:79 step:1400/10100, NER loss:      nan
2019-02-22 10:31:30,317 - log/train6.log - INFO - iteration:79 step:1500/10100, NER loss:      nan
2019-02-22 10:31:32,665 - log/train6.log - INFO - iteration:79 step:1600/10100, NER loss:      nan
2019-02-22 10:31:34,833 - log/train6.log - INFO - iteration:79 step:1700/10100, NER loss:      nan
2019-02-22 10:31:36,831 - log/train6.log - INFO - iteration:79 step:1800/10100, NER loss:      nan
2019-02-22 10:31:38,860 - log/train6.log - INFO - iteration:79 step:1900/10100, NER loss:      nan
2019-02-22 10:31:40,812 - log/train6.log - INFO - iteration:79 step:2000/10100, NER loss:      nan
2019-02-22 10:31:42,966 - log/train6.log - INFO - iteration:79 step:2100/10100, NER loss:      nan
2019-02-22 10:31:44,896 - log/train6.log - INFO - iteration:79 step:2200/10100, NER loss:      nan
2019-02-22 10:31:46,945 - log/train6.log - INFO - iteration:79 step:2300/10100, NER loss:      nan
2019-02-22 10:31:49,343 - log/train6.log - INFO - iteration:79 step:2400/10100, NER loss:      nan
2019-02-22 10:31:51,264 - log/train6.log - INFO - iteration:79 step:2500/10100, NER loss:      nan
2019-02-22 10:31:53,473 - log/train6.log - INFO - iteration:79 step:2600/10100, NER loss:      nan
2019-02-22 10:31:55,437 - log/train6.log - INFO - iteration:79 step:2700/10100, NER loss:      nan
2019-02-22 10:31:58,221 - log/train6.log - INFO - iteration:79 step:2800/10100, NER loss:      nan
2019-02-22 10:32:00,548 - log/train6.log - INFO - iteration:79 step:2900/10100, NER loss:      nan
2019-02-22 10:32:02,595 - log/train6.log - INFO - iteration:79 step:3000/10100, NER loss:      nan
2019-02-22 10:32:04,811 - log/train6.log - INFO - iteration:79 step:3100/10100, NER loss:      nan
2019-02-22 10:32:06,845 - log/train6.log - INFO - iteration:79 step:3200/10100, NER loss:      nan
2019-02-22 10:32:08,993 - log/train6.log - INFO - iteration:79 step:3300/10100, NER loss:      nan
2019-02-22 10:32:11,023 - log/train6.log - INFO - iteration:79 step:3400/10100, NER loss:      nan
2019-02-22 10:32:12,981 - log/train6.log - INFO - iteration:79 step:3500/10100, NER loss:      nan
2019-02-22 10:32:15,058 - log/train6.log - INFO - iteration:79 step:3600/10100, NER loss:      nan
2019-02-22 10:32:17,192 - log/train6.log - INFO - iteration:79 step:3700/10100, NER loss:      nan
2019-02-22 10:32:19,529 - log/train6.log - INFO - iteration:79 step:3800/10100, NER loss:      nan
2019-02-22 10:32:21,549 - log/train6.log - INFO - iteration:79 step:3900/10100, NER loss:      nan
2019-02-22 10:32:23,640 - log/train6.log - INFO - iteration:79 step:4000/10100, NER loss:      nan
2019-02-22 10:32:25,861 - log/train6.log - INFO - iteration:79 step:4100/10100, NER loss:      nan
2019-02-22 10:32:27,949 - log/train6.log - INFO - iteration:79 step:4200/10100, NER loss:      nan
2019-02-22 10:32:29,987 - log/train6.log - INFO - iteration:79 step:4300/10100, NER loss:      nan
2019-02-22 10:32:32,159 - log/train6.log - INFO - iteration:79 step:4400/10100, NER loss:      nan
2019-02-22 10:32:34,374 - log/train6.log - INFO - iteration:79 step:4500/10100, NER loss:      nan
2019-02-22 10:32:36,391 - log/train6.log - INFO - iteration:79 step:4600/10100, NER loss:      nan
2019-02-22 10:32:38,588 - log/train6.log - INFO - iteration:79 step:4700/10100, NER loss:      nan
2019-02-22 10:32:40,719 - log/train6.log - INFO - iteration:79 step:4800/10100, NER loss:      nan
2019-02-22 10:32:42,714 - log/train6.log - INFO - iteration:79 step:4900/10100, NER loss:      nan
2019-02-22 10:32:44,887 - log/train6.log - INFO - iteration:79 step:5000/10100, NER loss:      nan
2019-02-22 10:32:47,305 - log/train6.log - INFO - iteration:79 step:5100/10100, NER loss:      nan
2019-02-22 10:32:49,332 - log/train6.log - INFO - iteration:79 step:5200/10100, NER loss:      nan
2019-02-22 10:32:51,584 - log/train6.log - INFO - iteration:79 step:5300/10100, NER loss:      nan
2019-02-22 10:32:53,638 - log/train6.log - INFO - iteration:79 step:5400/10100, NER loss:      nan
2019-02-22 10:32:55,680 - log/train6.log - INFO - iteration:79 step:5500/10100, NER loss:      nan
2019-02-22 10:32:57,736 - log/train6.log - INFO - iteration:79 step:5600/10100, NER loss:      nan
2019-02-22 10:32:59,779 - log/train6.log - INFO - iteration:79 step:5700/10100, NER loss:      nan
2019-02-22 10:33:01,919 - log/train6.log - INFO - iteration:79 step:5800/10100, NER loss:      nan
2019-02-22 10:33:04,337 - log/train6.log - INFO - iteration:79 step:5900/10100, NER loss:      nan
2019-02-22 10:33:06,311 - log/train6.log - INFO - iteration:79 step:6000/10100, NER loss:      nan
2019-02-22 10:33:08,435 - log/train6.log - INFO - iteration:79 step:6100/10100, NER loss:      nan
2019-02-22 10:33:10,542 - log/train6.log - INFO - iteration:79 step:6200/10100, NER loss:      nan
2019-02-22 10:33:14,521 - log/train6.log - INFO - iteration:79 step:6300/10100, NER loss:      nan
2019-02-22 10:33:16,622 - log/train6.log - INFO - iteration:79 step:6400/10100, NER loss:      nan
2019-02-22 10:33:18,863 - log/train6.log - INFO - iteration:79 step:6500/10100, NER loss:      nan
2019-02-22 10:33:20,869 - log/train6.log - INFO - iteration:79 step:6600/10100, NER loss:      nan
2019-02-22 10:33:23,079 - log/train6.log - INFO - iteration:79 step:6700/10100, NER loss:      nan
2019-02-22 10:33:25,104 - log/train6.log - INFO - iteration:79 step:6800/10100, NER loss:      nan
2019-02-22 10:33:27,323 - log/train6.log - INFO - iteration:79 step:6900/10100, NER loss:      nan
2019-02-22 10:33:31,583 - log/train6.log - INFO - iteration:79 step:7000/10100, NER loss:      nan
2019-02-22 10:33:33,548 - log/train6.log - INFO - iteration:79 step:7100/10100, NER loss:      nan
2019-02-22 10:33:35,721 - log/train6.log - INFO - iteration:79 step:7200/10100, NER loss:      nan
2019-02-22 10:33:37,854 - log/train6.log - INFO - iteration:79 step:7300/10100, NER loss:      nan
2019-02-22 10:33:39,786 - log/train6.log - INFO - iteration:79 step:7400/10100, NER loss:      nan
2019-02-22 10:33:41,783 - log/train6.log - INFO - iteration:79 step:7500/10100, NER loss:      nan
2019-02-22 10:33:43,874 - log/train6.log - INFO - iteration:79 step:7600/10100, NER loss:      nan
2019-02-22 10:33:45,949 - log/train6.log - INFO - iteration:79 step:7700/10100, NER loss:      nan
2019-02-22 10:33:48,081 - log/train6.log - INFO - iteration:79 step:7800/10100, NER loss:      nan
2019-02-22 10:33:49,973 - log/train6.log - INFO - iteration:79 step:7900/10100, NER loss:      nan
2019-02-22 10:33:52,038 - log/train6.log - INFO - iteration:79 step:8000/10100, NER loss:      nan
2019-02-22 10:33:54,263 - log/train6.log - INFO - iteration:79 step:8100/10100, NER loss:      nan
2019-02-22 10:33:56,343 - log/train6.log - INFO - iteration:79 step:8200/10100, NER loss:      nan
2019-02-22 10:33:58,577 - log/train6.log - INFO - iteration:79 step:8300/10100, NER loss:      nan
2019-02-22 10:34:00,723 - log/train6.log - INFO - iteration:79 step:8400/10100, NER loss:      nan
2019-02-22 10:34:02,969 - log/train6.log - INFO - iteration:79 step:8500/10100, NER loss:      nan
2019-02-22 10:34:05,049 - log/train6.log - INFO - iteration:79 step:8600/10100, NER loss:      nan
2019-02-22 10:34:07,118 - log/train6.log - INFO - iteration:79 step:8700/10100, NER loss:      nan
2019-02-22 10:34:09,454 - log/train6.log - INFO - iteration:79 step:8800/10100, NER loss:      nan
2019-02-22 10:34:11,411 - log/train6.log - INFO - iteration:79 step:8900/10100, NER loss:      nan
2019-02-22 10:34:13,422 - log/train6.log - INFO - iteration:79 step:9000/10100, NER loss:      nan
2019-02-22 10:34:15,670 - log/train6.log - INFO - iteration:79 step:9100/10100, NER loss:      nan
2019-02-22 10:34:17,721 - log/train6.log - INFO - iteration:79 step:9200/10100, NER loss:      nan
2019-02-22 10:34:19,948 - log/train6.log - INFO - iteration:79 step:9300/10100, NER loss:      nan
2019-02-22 10:34:21,977 - log/train6.log - INFO - iteration:79 step:9400/10100, NER loss:      nan
2019-02-22 10:34:24,443 - log/train6.log - INFO - iteration:79 step:9500/10100, NER loss:      nan
2019-02-22 10:34:26,656 - log/train6.log - INFO - iteration:79 step:9600/10100, NER loss:      nan
2019-02-22 10:34:28,902 - log/train6.log - INFO - iteration:79 step:9700/10100, NER loss:      nan
2019-02-22 10:34:31,203 - log/train6.log - INFO - iteration:79 step:9800/10100, NER loss:      nan
2019-02-22 10:34:33,189 - log/train6.log - INFO - iteration:79 step:9900/10100, NER loss:      nan
2019-02-22 10:34:35,417 - log/train6.log - INFO - iteration:79 step:10000/10100, NER loss:      nan
2019-02-22 10:34:39,194 - log/train6.log - INFO - iteration:80 step:0/10100, NER loss:      nan
2019-02-22 10:34:39,195 - log/train6.log - INFO - evaluate:dev
2019-02-22 10:34:45,676 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 10:34:45,677 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 10:34:45,677 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:34:45,677 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:34:45,677 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:34:45,677 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:34:45,677 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:34:45,677 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:34:45,680 - log/train6.log - INFO - evaluate:test
2019-02-22 10:34:47,140 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 10:34:47,140 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 10:34:47,140 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:34:47,140 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:34:47,140 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:34:47,140 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:34:47,141 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:34:47,141 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:34:49,136 - log/train6.log - INFO - iteration:80 step:100/10100, NER loss:      nan
2019-02-22 10:34:51,128 - log/train6.log - INFO - iteration:80 step:200/10100, NER loss:      nan
2019-02-22 10:34:53,163 - log/train6.log - INFO - iteration:80 step:300/10100, NER loss:      nan
2019-02-22 10:34:55,053 - log/train6.log - INFO - iteration:80 step:400/10100, NER loss:      nan
2019-02-22 10:34:56,852 - log/train6.log - INFO - iteration:80 step:500/10100, NER loss:      nan
2019-02-22 10:34:58,901 - log/train6.log - INFO - iteration:80 step:600/10100, NER loss:      nan
2019-02-22 10:35:01,002 - log/train6.log - INFO - iteration:80 step:700/10100, NER loss:      nan
2019-02-22 10:35:03,342 - log/train6.log - INFO - iteration:80 step:800/10100, NER loss:      nan
2019-02-22 10:35:05,378 - log/train6.log - INFO - iteration:80 step:900/10100, NER loss:      nan
2019-02-22 10:35:07,385 - log/train6.log - INFO - iteration:80 step:1000/10100, NER loss:      nan
2019-02-22 10:35:09,409 - log/train6.log - INFO - iteration:80 step:1100/10100, NER loss:      nan
2019-02-22 10:35:11,391 - log/train6.log - INFO - iteration:80 step:1200/10100, NER loss:      nan
2019-02-22 10:35:15,330 - log/train6.log - INFO - iteration:80 step:1300/10100, NER loss:      nan
2019-02-22 10:35:17,362 - log/train6.log - INFO - iteration:80 step:1400/10100, NER loss:      nan
2019-02-22 10:35:21,919 - log/train6.log - INFO - iteration:80 step:1500/10100, NER loss:      nan
2019-02-22 10:35:23,772 - log/train6.log - INFO - iteration:80 step:1600/10100, NER loss:      nan
2019-02-22 10:35:25,781 - log/train6.log - INFO - iteration:80 step:1700/10100, NER loss:      nan
2019-02-22 10:35:27,947 - log/train6.log - INFO - iteration:80 step:1800/10100, NER loss:      nan
2019-02-22 10:35:30,207 - log/train6.log - INFO - iteration:80 step:1900/10100, NER loss:      nan
2019-02-22 10:35:32,459 - log/train6.log - INFO - iteration:80 step:2000/10100, NER loss:      nan
2019-02-22 10:35:34,549 - log/train6.log - INFO - iteration:80 step:2100/10100, NER loss:      nan
2019-02-22 10:35:37,221 - log/train6.log - INFO - iteration:80 step:2200/10100, NER loss:      nan
2019-02-22 10:35:39,730 - log/train6.log - INFO - iteration:80 step:2300/10100, NER loss:      nan
2019-02-22 10:35:41,928 - log/train6.log - INFO - iteration:80 step:2400/10100, NER loss:      nan
2019-02-22 10:35:44,475 - log/train6.log - INFO - iteration:80 step:2500/10100, NER loss:      nan
2019-02-22 10:35:46,832 - log/train6.log - INFO - iteration:80 step:2600/10100, NER loss:      nan
2019-02-22 10:35:49,004 - log/train6.log - INFO - iteration:80 step:2700/10100, NER loss:      nan
2019-02-22 10:35:51,283 - log/train6.log - INFO - iteration:80 step:2800/10100, NER loss:      nan
2019-02-22 10:35:53,514 - log/train6.log - INFO - iteration:80 step:2900/10100, NER loss:      nan
2019-02-22 10:35:55,515 - log/train6.log - INFO - iteration:80 step:3000/10100, NER loss:      nan
2019-02-22 10:35:57,553 - log/train6.log - INFO - iteration:80 step:3100/10100, NER loss:      nan
2019-02-22 10:35:59,908 - log/train6.log - INFO - iteration:80 step:3200/10100, NER loss:      nan
2019-02-22 10:36:02,307 - log/train6.log - INFO - iteration:80 step:3300/10100, NER loss:      nan
2019-02-22 10:36:04,549 - log/train6.log - INFO - iteration:80 step:3400/10100, NER loss:      nan
2019-02-22 10:36:06,707 - log/train6.log - INFO - iteration:80 step:3500/10100, NER loss:      nan
2019-02-22 10:36:09,195 - log/train6.log - INFO - iteration:80 step:3600/10100, NER loss:      nan
2019-02-22 10:36:11,621 - log/train6.log - INFO - iteration:80 step:3700/10100, NER loss:      nan
2019-02-22 10:36:13,803 - log/train6.log - INFO - iteration:80 step:3800/10100, NER loss:      nan
2019-02-22 10:36:16,080 - log/train6.log - INFO - iteration:80 step:3900/10100, NER loss:      nan
2019-02-22 10:36:18,321 - log/train6.log - INFO - iteration:80 step:4000/10100, NER loss:      nan
2019-02-22 10:36:20,630 - log/train6.log - INFO - iteration:80 step:4100/10100, NER loss:      nan
2019-02-22 10:36:22,628 - log/train6.log - INFO - iteration:80 step:4200/10100, NER loss:      nan
2019-02-22 10:36:24,829 - log/train6.log - INFO - iteration:80 step:4300/10100, NER loss:      nan
2019-02-22 10:36:26,916 - log/train6.log - INFO - iteration:80 step:4400/10100, NER loss:      nan
2019-02-22 10:36:29,144 - log/train6.log - INFO - iteration:80 step:4500/10100, NER loss:      nan
2019-02-22 10:36:31,173 - log/train6.log - INFO - iteration:80 step:4600/10100, NER loss:      nan
2019-02-22 10:36:33,315 - log/train6.log - INFO - iteration:80 step:4700/10100, NER loss:      nan
2019-02-22 10:36:35,585 - log/train6.log - INFO - iteration:80 step:4800/10100, NER loss:      nan
2019-02-22 10:36:37,835 - log/train6.log - INFO - iteration:80 step:4900/10100, NER loss:      nan
2019-02-22 10:36:40,024 - log/train6.log - INFO - iteration:80 step:5000/10100, NER loss:      nan
2019-02-22 10:36:42,423 - log/train6.log - INFO - iteration:80 step:5100/10100, NER loss:      nan
2019-02-22 10:36:44,727 - log/train6.log - INFO - iteration:80 step:5200/10100, NER loss:      nan
2019-02-22 10:36:46,742 - log/train6.log - INFO - iteration:80 step:5300/10100, NER loss:      nan
2019-02-22 10:36:48,867 - log/train6.log - INFO - iteration:80 step:5400/10100, NER loss:      nan
2019-02-22 10:36:51,112 - log/train6.log - INFO - iteration:80 step:5500/10100, NER loss:      nan
2019-02-22 10:36:53,435 - log/train6.log - INFO - iteration:80 step:5600/10100, NER loss:      nan
2019-02-22 10:36:55,671 - log/train6.log - INFO - iteration:80 step:5700/10100, NER loss:      nan
2019-02-22 10:36:58,017 - log/train6.log - INFO - iteration:80 step:5800/10100, NER loss:      nan
2019-02-22 10:37:00,385 - log/train6.log - INFO - iteration:80 step:5900/10100, NER loss:      nan
2019-02-22 10:37:02,954 - log/train6.log - INFO - iteration:80 step:6000/10100, NER loss:      nan
2019-02-22 10:37:05,490 - log/train6.log - INFO - iteration:80 step:6100/10100, NER loss:      nan
2019-02-22 10:37:07,815 - log/train6.log - INFO - iteration:80 step:6200/10100, NER loss:      nan
2019-02-22 10:37:10,239 - log/train6.log - INFO - iteration:80 step:6300/10100, NER loss:      nan
2019-02-22 10:37:12,435 - log/train6.log - INFO - iteration:80 step:6400/10100, NER loss:      nan
2019-02-22 10:37:14,778 - log/train6.log - INFO - iteration:80 step:6500/10100, NER loss:      nan
2019-02-22 10:37:17,170 - log/train6.log - INFO - iteration:80 step:6600/10100, NER loss:      nan
2019-02-22 10:37:20,274 - log/train6.log - INFO - iteration:80 step:6700/10100, NER loss:      nan
2019-02-22 10:37:22,805 - log/train6.log - INFO - iteration:80 step:6800/10100, NER loss:      nan
2019-02-22 10:37:24,994 - log/train6.log - INFO - iteration:80 step:6900/10100, NER loss:      nan
2019-02-22 10:37:27,238 - log/train6.log - INFO - iteration:80 step:7000/10100, NER loss:      nan
2019-02-22 10:37:29,704 - log/train6.log - INFO - iteration:80 step:7100/10100, NER loss:      nan
2019-02-22 10:37:32,344 - log/train6.log - INFO - iteration:80 step:7200/10100, NER loss:      nan
2019-02-22 10:37:34,749 - log/train6.log - INFO - iteration:80 step:7300/10100, NER loss:      nan
2019-02-22 10:37:36,840 - log/train6.log - INFO - iteration:80 step:7400/10100, NER loss:      nan
2019-02-22 10:37:39,323 - log/train6.log - INFO - iteration:80 step:7500/10100, NER loss:      nan
2019-02-22 10:37:41,381 - log/train6.log - INFO - iteration:80 step:7600/10100, NER loss:      nan
2019-02-22 10:37:43,721 - log/train6.log - INFO - iteration:80 step:7700/10100, NER loss:      nan
2019-02-22 10:37:46,291 - log/train6.log - INFO - iteration:80 step:7800/10100, NER loss:      nan
2019-02-22 10:37:48,610 - log/train6.log - INFO - iteration:80 step:7900/10100, NER loss:      nan
2019-02-22 10:37:50,787 - log/train6.log - INFO - iteration:80 step:8000/10100, NER loss:      nan
2019-02-22 10:37:52,967 - log/train6.log - INFO - iteration:80 step:8100/10100, NER loss:      nan
2019-02-22 10:37:55,246 - log/train6.log - INFO - iteration:80 step:8200/10100, NER loss:      nan
2019-02-22 10:37:57,513 - log/train6.log - INFO - iteration:80 step:8300/10100, NER loss:      nan
2019-02-22 10:37:59,802 - log/train6.log - INFO - iteration:80 step:8400/10100, NER loss:      nan
2019-02-22 10:38:02,032 - log/train6.log - INFO - iteration:80 step:8500/10100, NER loss:      nan
2019-02-22 10:38:06,339 - log/train6.log - INFO - iteration:80 step:8600/10100, NER loss:      nan
2019-02-22 10:38:08,502 - log/train6.log - INFO - iteration:80 step:8700/10100, NER loss:      nan
2019-02-22 10:38:11,023 - log/train6.log - INFO - iteration:80 step:8800/10100, NER loss:      nan
2019-02-22 10:38:13,147 - log/train6.log - INFO - iteration:80 step:8900/10100, NER loss:      nan
2019-02-22 10:38:15,544 - log/train6.log - INFO - iteration:80 step:9000/10100, NER loss:      nan
2019-02-22 10:38:17,939 - log/train6.log - INFO - iteration:80 step:9100/10100, NER loss:      nan
2019-02-22 10:38:20,328 - log/train6.log - INFO - iteration:80 step:9200/10100, NER loss:      nan
2019-02-22 10:38:22,688 - log/train6.log - INFO - iteration:80 step:9300/10100, NER loss:      nan
2019-02-22 10:38:24,915 - log/train6.log - INFO - iteration:80 step:9400/10100, NER loss:      nan
2019-02-22 10:38:27,317 - log/train6.log - INFO - iteration:80 step:9500/10100, NER loss:      nan
2019-02-22 10:38:29,301 - log/train6.log - INFO - iteration:80 step:9600/10100, NER loss:      nan
2019-02-22 10:38:31,364 - log/train6.log - INFO - iteration:80 step:9700/10100, NER loss:      nan
2019-02-22 10:38:33,633 - log/train6.log - INFO - iteration:80 step:9800/10100, NER loss:      nan
2019-02-22 10:38:35,827 - log/train6.log - INFO - iteration:80 step:9900/10100, NER loss:      nan
2019-02-22 10:38:37,741 - log/train6.log - INFO - iteration:80 step:10000/10100, NER loss:      nan
2019-02-22 10:38:40,012 - log/train6.log - INFO - iteration:81 step:0/10100, NER loss:      nan
2019-02-22 10:38:40,013 - log/train6.log - INFO - evaluate:dev
2019-02-22 10:38:46,981 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 10:38:46,982 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 10:38:46,982 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:38:46,982 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:38:46,982 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:38:46,982 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:38:46,982 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:38:46,982 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:38:46,985 - log/train6.log - INFO - evaluate:test
2019-02-22 10:38:48,434 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 10:38:48,434 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 10:38:48,434 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:38:48,434 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:38:48,434 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:38:48,434 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:38:48,434 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:38:48,434 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:38:50,332 - log/train6.log - INFO - iteration:81 step:100/10100, NER loss:      nan
2019-02-22 10:38:52,262 - log/train6.log - INFO - iteration:81 step:200/10100, NER loss:      nan
2019-02-22 10:38:54,226 - log/train6.log - INFO - iteration:81 step:300/10100, NER loss:      nan
2019-02-22 10:38:56,313 - log/train6.log - INFO - iteration:81 step:400/10100, NER loss:      nan
2019-02-22 10:38:58,426 - log/train6.log - INFO - iteration:81 step:500/10100, NER loss:      nan
2019-02-22 10:39:00,433 - log/train6.log - INFO - iteration:81 step:600/10100, NER loss:      nan
2019-02-22 10:39:02,741 - log/train6.log - INFO - iteration:81 step:700/10100, NER loss:      nan
2019-02-22 10:39:04,861 - log/train6.log - INFO - iteration:81 step:800/10100, NER loss:      nan
2019-02-22 10:39:07,016 - log/train6.log - INFO - iteration:81 step:900/10100, NER loss:      nan
2019-02-22 10:39:09,273 - log/train6.log - INFO - iteration:81 step:1000/10100, NER loss:      nan
2019-02-22 10:39:11,621 - log/train6.log - INFO - iteration:81 step:1100/10100, NER loss:      nan
2019-02-22 10:39:13,796 - log/train6.log - INFO - iteration:81 step:1200/10100, NER loss:      nan
2019-02-22 10:39:15,741 - log/train6.log - INFO - iteration:81 step:1300/10100, NER loss:      nan
2019-02-22 10:39:17,608 - log/train6.log - INFO - iteration:81 step:1400/10100, NER loss:      nan
2019-02-22 10:39:19,711 - log/train6.log - INFO - iteration:81 step:1500/10100, NER loss:      nan
2019-02-22 10:39:21,729 - log/train6.log - INFO - iteration:81 step:1600/10100, NER loss:      nan
2019-02-22 10:39:24,095 - log/train6.log - INFO - iteration:81 step:1700/10100, NER loss:      nan
2019-02-22 10:39:26,274 - log/train6.log - INFO - iteration:81 step:1800/10100, NER loss:      nan
2019-02-22 10:39:28,742 - log/train6.log - INFO - iteration:81 step:1900/10100, NER loss:      nan
2019-02-22 10:39:31,048 - log/train6.log - INFO - iteration:81 step:2000/10100, NER loss:      nan
2019-02-22 10:39:33,213 - log/train6.log - INFO - iteration:81 step:2100/10100, NER loss:      nan
2019-02-22 10:39:35,401 - log/train6.log - INFO - iteration:81 step:2200/10100, NER loss:      nan
2019-02-22 10:39:37,699 - log/train6.log - INFO - iteration:81 step:2300/10100, NER loss:      nan
2019-02-22 10:39:42,022 - log/train6.log - INFO - iteration:81 step:2400/10100, NER loss:      nan
2019-02-22 10:39:44,251 - log/train6.log - INFO - iteration:81 step:2500/10100, NER loss:      nan
2019-02-22 10:39:46,362 - log/train6.log - INFO - iteration:81 step:2600/10100, NER loss:      nan
2019-02-22 10:39:48,374 - log/train6.log - INFO - iteration:81 step:2700/10100, NER loss:      nan
2019-02-22 10:39:50,630 - log/train6.log - INFO - iteration:81 step:2800/10100, NER loss:      nan
2019-02-22 10:39:52,851 - log/train6.log - INFO - iteration:81 step:2900/10100, NER loss:      nan
2019-02-22 10:39:55,408 - log/train6.log - INFO - iteration:81 step:3000/10100, NER loss:      nan
2019-02-22 10:39:57,659 - log/train6.log - INFO - iteration:81 step:3100/10100, NER loss:      nan
2019-02-22 10:40:00,445 - log/train6.log - INFO - iteration:81 step:3200/10100, NER loss:      nan
2019-02-22 10:40:03,225 - log/train6.log - INFO - iteration:81 step:3300/10100, NER loss:      nan
2019-02-22 10:40:05,665 - log/train6.log - INFO - iteration:81 step:3400/10100, NER loss:      nan
2019-02-22 10:40:08,056 - log/train6.log - INFO - iteration:81 step:3500/10100, NER loss:      nan
2019-02-22 10:40:13,171 - log/train6.log - INFO - iteration:81 step:3600/10100, NER loss:      nan
2019-02-22 10:40:16,389 - log/train6.log - INFO - iteration:81 step:3700/10100, NER loss:      nan
2019-02-22 10:40:18,714 - log/train6.log - INFO - iteration:81 step:3800/10100, NER loss:      nan
2019-02-22 10:40:20,875 - log/train6.log - INFO - iteration:81 step:3900/10100, NER loss:      nan
2019-02-22 10:40:23,157 - log/train6.log - INFO - iteration:81 step:4000/10100, NER loss:      nan
2019-02-22 10:40:25,011 - log/train6.log - INFO - iteration:81 step:4100/10100, NER loss:      nan
2019-02-22 10:40:27,288 - log/train6.log - INFO - iteration:81 step:4200/10100, NER loss:      nan
2019-02-22 10:40:29,530 - log/train6.log - INFO - iteration:81 step:4300/10100, NER loss:      nan
2019-02-22 10:40:31,522 - log/train6.log - INFO - iteration:81 step:4400/10100, NER loss:      nan
2019-02-22 10:40:33,584 - log/train6.log - INFO - iteration:81 step:4500/10100, NER loss:      nan
2019-02-22 10:40:35,643 - log/train6.log - INFO - iteration:81 step:4600/10100, NER loss:      nan
2019-02-22 10:40:37,527 - log/train6.log - INFO - iteration:81 step:4700/10100, NER loss:      nan
2019-02-22 10:40:41,729 - log/train6.log - INFO - iteration:81 step:4800/10100, NER loss:      nan
2019-02-22 10:40:44,267 - log/train6.log - INFO - iteration:81 step:4900/10100, NER loss:      nan
2019-02-22 10:40:46,489 - log/train6.log - INFO - iteration:81 step:5000/10100, NER loss:      nan
2019-02-22 10:40:48,792 - log/train6.log - INFO - iteration:81 step:5100/10100, NER loss:      nan
2019-02-22 10:40:50,902 - log/train6.log - INFO - iteration:81 step:5200/10100, NER loss:      nan
2019-02-22 10:40:53,203 - log/train6.log - INFO - iteration:81 step:5300/10100, NER loss:      nan
2019-02-22 10:40:55,481 - log/train6.log - INFO - iteration:81 step:5400/10100, NER loss:      nan
2019-02-22 10:40:57,574 - log/train6.log - INFO - iteration:81 step:5500/10100, NER loss:      nan
2019-02-22 10:40:59,680 - log/train6.log - INFO - iteration:81 step:5600/10100, NER loss:      nan
2019-02-22 10:41:01,801 - log/train6.log - INFO - iteration:81 step:5700/10100, NER loss:      nan
2019-02-22 10:41:04,327 - log/train6.log - INFO - iteration:81 step:5800/10100, NER loss:      nan
2019-02-22 10:41:06,856 - log/train6.log - INFO - iteration:81 step:5900/10100, NER loss:      nan
2019-02-22 10:41:09,027 - log/train6.log - INFO - iteration:81 step:6000/10100, NER loss:      nan
2019-02-22 10:41:11,055 - log/train6.log - INFO - iteration:81 step:6100/10100, NER loss:      nan
2019-02-22 10:41:13,445 - log/train6.log - INFO - iteration:81 step:6200/10100, NER loss:      nan
2019-02-22 10:41:15,789 - log/train6.log - INFO - iteration:81 step:6300/10100, NER loss:      nan
2019-02-22 10:41:17,879 - log/train6.log - INFO - iteration:81 step:6400/10100, NER loss:      nan
2019-02-22 10:41:20,034 - log/train6.log - INFO - iteration:81 step:6500/10100, NER loss:      nan
2019-02-22 10:41:22,251 - log/train6.log - INFO - iteration:81 step:6600/10100, NER loss:      nan
2019-02-22 10:41:24,863 - log/train6.log - INFO - iteration:81 step:6700/10100, NER loss:      nan
2019-02-22 10:41:27,267 - log/train6.log - INFO - iteration:81 step:6800/10100, NER loss:      nan
2019-02-22 10:41:29,413 - log/train6.log - INFO - iteration:81 step:6900/10100, NER loss:      nan
2019-02-22 10:41:31,837 - log/train6.log - INFO - iteration:81 step:7000/10100, NER loss:      nan
2019-02-22 10:41:34,036 - log/train6.log - INFO - iteration:81 step:7100/10100, NER loss:      nan
2019-02-22 10:41:36,022 - log/train6.log - INFO - iteration:81 step:7200/10100, NER loss:      nan
2019-02-22 10:41:38,042 - log/train6.log - INFO - iteration:81 step:7300/10100, NER loss:      nan
2019-02-22 10:41:40,310 - log/train6.log - INFO - iteration:81 step:7400/10100, NER loss:      nan
2019-02-22 10:41:42,767 - log/train6.log - INFO - iteration:81 step:7500/10100, NER loss:      nan
2019-02-22 10:41:45,257 - log/train6.log - INFO - iteration:81 step:7600/10100, NER loss:      nan
2019-02-22 10:41:47,441 - log/train6.log - INFO - iteration:81 step:7700/10100, NER loss:      nan
2019-02-22 10:41:49,726 - log/train6.log - INFO - iteration:81 step:7800/10100, NER loss:      nan
2019-02-22 10:41:51,886 - log/train6.log - INFO - iteration:81 step:7900/10100, NER loss:      nan
2019-02-22 10:41:54,133 - log/train6.log - INFO - iteration:81 step:8000/10100, NER loss:      nan
2019-02-22 10:41:56,218 - log/train6.log - INFO - iteration:81 step:8100/10100, NER loss:      nan
2019-02-22 10:41:58,333 - log/train6.log - INFO - iteration:81 step:8200/10100, NER loss:      nan
2019-02-22 10:42:00,381 - log/train6.log - INFO - iteration:81 step:8300/10100, NER loss:      nan
2019-02-22 10:42:02,388 - log/train6.log - INFO - iteration:81 step:8400/10100, NER loss:      nan
2019-02-22 10:42:04,721 - log/train6.log - INFO - iteration:81 step:8500/10100, NER loss:      nan
2019-02-22 10:42:07,042 - log/train6.log - INFO - iteration:81 step:8600/10100, NER loss:      nan
2019-02-22 10:42:09,349 - log/train6.log - INFO - iteration:81 step:8700/10100, NER loss:      nan
2019-02-22 10:42:11,540 - log/train6.log - INFO - iteration:81 step:8800/10100, NER loss:      nan
2019-02-22 10:42:13,617 - log/train6.log - INFO - iteration:81 step:8900/10100, NER loss:      nan
2019-02-22 10:42:15,923 - log/train6.log - INFO - iteration:81 step:9000/10100, NER loss:      nan
2019-02-22 10:42:18,236 - log/train6.log - INFO - iteration:81 step:9100/10100, NER loss:      nan
2019-02-22 10:42:20,468 - log/train6.log - INFO - iteration:81 step:9200/10100, NER loss:      nan
2019-02-22 10:42:22,513 - log/train6.log - INFO - iteration:81 step:9300/10100, NER loss:      nan
2019-02-22 10:42:25,061 - log/train6.log - INFO - iteration:81 step:9400/10100, NER loss:      nan
2019-02-22 10:42:27,651 - log/train6.log - INFO - iteration:81 step:9500/10100, NER loss:      nan
2019-02-22 10:42:30,366 - log/train6.log - INFO - iteration:81 step:9600/10100, NER loss:      nan
2019-02-22 10:42:32,687 - log/train6.log - INFO - iteration:81 step:9700/10100, NER loss:      nan
2019-02-22 10:42:34,627 - log/train6.log - INFO - iteration:81 step:9800/10100, NER loss:      nan
2019-02-22 10:42:36,787 - log/train6.log - INFO - iteration:81 step:9900/10100, NER loss:      nan
2019-02-22 10:42:39,186 - log/train6.log - INFO - iteration:81 step:10000/10100, NER loss:      nan
2019-02-22 10:42:41,366 - log/train6.log - INFO - iteration:82 step:0/10100, NER loss:      nan
2019-02-22 10:42:41,366 - log/train6.log - INFO - evaluate:dev
2019-02-22 10:42:48,109 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 10:42:48,109 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 10:42:48,110 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:42:48,110 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:42:48,110 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:42:48,110 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:42:48,110 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:42:48,110 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:42:48,113 - log/train6.log - INFO - evaluate:test
2019-02-22 10:42:49,576 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 10:42:49,576 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 10:42:49,576 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:42:49,576 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:42:49,576 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:42:49,577 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:42:49,577 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:42:49,577 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:42:51,736 - log/train6.log - INFO - iteration:82 step:100/10100, NER loss:      nan
2019-02-22 10:42:53,579 - log/train6.log - INFO - iteration:82 step:200/10100, NER loss:      nan
2019-02-22 10:42:55,635 - log/train6.log - INFO - iteration:82 step:300/10100, NER loss:      nan
2019-02-22 10:42:57,890 - log/train6.log - INFO - iteration:82 step:400/10100, NER loss:      nan
2019-02-22 10:43:00,241 - log/train6.log - INFO - iteration:82 step:500/10100, NER loss:      nan
2019-02-22 10:43:02,299 - log/train6.log - INFO - iteration:82 step:600/10100, NER loss:      nan
2019-02-22 10:43:04,322 - log/train6.log - INFO - iteration:82 step:700/10100, NER loss:      nan
2019-02-22 10:43:06,548 - log/train6.log - INFO - iteration:82 step:800/10100, NER loss:      nan
2019-02-22 10:43:08,701 - log/train6.log - INFO - iteration:82 step:900/10100, NER loss:      nan
2019-02-22 10:43:10,887 - log/train6.log - INFO - iteration:82 step:1000/10100, NER loss:      nan
2019-02-22 10:43:12,912 - log/train6.log - INFO - iteration:82 step:1100/10100, NER loss:      nan
2019-02-22 10:43:14,872 - log/train6.log - INFO - iteration:82 step:1200/10100, NER loss:      nan
2019-02-22 10:43:16,969 - log/train6.log - INFO - iteration:82 step:1300/10100, NER loss:      nan
2019-02-22 10:43:19,099 - log/train6.log - INFO - iteration:82 step:1400/10100, NER loss:      nan
2019-02-22 10:43:21,355 - log/train6.log - INFO - iteration:82 step:1500/10100, NER loss:      nan
2019-02-22 10:43:23,737 - log/train6.log - INFO - iteration:82 step:1600/10100, NER loss:      nan
2019-02-22 10:43:26,093 - log/train6.log - INFO - iteration:82 step:1700/10100, NER loss:      nan
2019-02-22 10:43:28,329 - log/train6.log - INFO - iteration:82 step:1800/10100, NER loss:      nan
2019-02-22 10:43:30,568 - log/train6.log - INFO - iteration:82 step:1900/10100, NER loss:      nan
2019-02-22 10:43:33,068 - log/train6.log - INFO - iteration:82 step:2000/10100, NER loss:      nan
2019-02-22 10:43:35,268 - log/train6.log - INFO - iteration:82 step:2100/10100, NER loss:      nan
2019-02-22 10:43:37,529 - log/train6.log - INFO - iteration:82 step:2200/10100, NER loss:      nan
2019-02-22 10:43:39,854 - log/train6.log - INFO - iteration:82 step:2300/10100, NER loss:      nan
2019-02-22 10:43:41,992 - log/train6.log - INFO - iteration:82 step:2400/10100, NER loss:      nan
2019-02-22 10:43:44,183 - log/train6.log - INFO - iteration:82 step:2500/10100, NER loss:      nan
2019-02-22 10:43:46,315 - log/train6.log - INFO - iteration:82 step:2600/10100, NER loss:      nan
2019-02-22 10:43:48,549 - log/train6.log - INFO - iteration:82 step:2700/10100, NER loss:      nan
2019-02-22 10:43:50,870 - log/train6.log - INFO - iteration:82 step:2800/10100, NER loss:      nan
2019-02-22 10:43:53,250 - log/train6.log - INFO - iteration:82 step:2900/10100, NER loss:      nan
2019-02-22 10:43:55,491 - log/train6.log - INFO - iteration:82 step:3000/10100, NER loss:      nan
2019-02-22 10:43:57,839 - log/train6.log - INFO - iteration:82 step:3100/10100, NER loss:      nan
2019-02-22 10:44:00,067 - log/train6.log - INFO - iteration:82 step:3200/10100, NER loss:      nan
2019-02-22 10:44:02,288 - log/train6.log - INFO - iteration:82 step:3300/10100, NER loss:      nan
2019-02-22 10:44:05,039 - log/train6.log - INFO - iteration:82 step:3400/10100, NER loss:      nan
2019-02-22 10:44:07,910 - log/train6.log - INFO - iteration:82 step:3500/10100, NER loss:      nan
2019-02-22 10:44:10,242 - log/train6.log - INFO - iteration:82 step:3600/10100, NER loss:      nan
2019-02-22 10:44:14,506 - log/train6.log - INFO - iteration:82 step:3700/10100, NER loss:      nan
2019-02-22 10:44:16,843 - log/train6.log - INFO - iteration:82 step:3800/10100, NER loss:      nan
2019-02-22 10:44:19,066 - log/train6.log - INFO - iteration:82 step:3900/10100, NER loss:      nan
2019-02-22 10:44:21,087 - log/train6.log - INFO - iteration:82 step:4000/10100, NER loss:      nan
2019-02-22 10:44:23,377 - log/train6.log - INFO - iteration:82 step:4100/10100, NER loss:      nan
2019-02-22 10:44:25,382 - log/train6.log - INFO - iteration:82 step:4200/10100, NER loss:      nan
2019-02-22 10:44:27,577 - log/train6.log - INFO - iteration:82 step:4300/10100, NER loss:      nan
2019-02-22 10:44:29,834 - log/train6.log - INFO - iteration:82 step:4400/10100, NER loss:      nan
2019-02-22 10:44:32,481 - log/train6.log - INFO - iteration:82 step:4500/10100, NER loss:      nan
2019-02-22 10:44:35,086 - log/train6.log - INFO - iteration:82 step:4600/10100, NER loss:      nan
2019-02-22 10:44:37,298 - log/train6.log - INFO - iteration:82 step:4700/10100, NER loss:      nan
2019-02-22 10:44:39,396 - log/train6.log - INFO - iteration:82 step:4800/10100, NER loss:      nan
2019-02-22 10:44:41,721 - log/train6.log - INFO - iteration:82 step:4900/10100, NER loss:      nan
2019-02-22 10:44:44,501 - log/train6.log - INFO - iteration:82 step:5000/10100, NER loss:      nan
2019-02-22 10:44:46,768 - log/train6.log - INFO - iteration:82 step:5100/10100, NER loss:      nan
2019-02-22 10:44:48,812 - log/train6.log - INFO - iteration:82 step:5200/10100, NER loss:      nan
2019-02-22 10:44:51,040 - log/train6.log - INFO - iteration:82 step:5300/10100, NER loss:      nan
2019-02-22 10:44:53,299 - log/train6.log - INFO - iteration:82 step:5400/10100, NER loss:      nan
2019-02-22 10:44:55,435 - log/train6.log - INFO - iteration:82 step:5500/10100, NER loss:      nan
2019-02-22 10:44:57,623 - log/train6.log - INFO - iteration:82 step:5600/10100, NER loss:      nan
2019-02-22 10:45:02,042 - log/train6.log - INFO - iteration:82 step:5700/10100, NER loss:      nan
2019-02-22 10:45:04,199 - log/train6.log - INFO - iteration:82 step:5800/10100, NER loss:      nan
2019-02-22 10:45:08,424 - log/train6.log - INFO - iteration:82 step:5900/10100, NER loss:      nan
2019-02-22 10:45:10,896 - log/train6.log - INFO - iteration:82 step:6000/10100, NER loss:      nan
2019-02-22 10:45:13,093 - log/train6.log - INFO - iteration:82 step:6100/10100, NER loss:      nan
2019-02-22 10:45:15,574 - log/train6.log - INFO - iteration:82 step:6200/10100, NER loss:      nan
2019-02-22 10:45:17,998 - log/train6.log - INFO - iteration:82 step:6300/10100, NER loss:      nan
2019-02-22 10:45:20,558 - log/train6.log - INFO - iteration:82 step:6400/10100, NER loss:      nan
2019-02-22 10:45:22,826 - log/train6.log - INFO - iteration:82 step:6500/10100, NER loss:      nan
2019-02-22 10:45:25,110 - log/train6.log - INFO - iteration:82 step:6600/10100, NER loss:      nan
2019-02-22 10:45:27,376 - log/train6.log - INFO - iteration:82 step:6700/10100, NER loss:      nan
2019-02-22 10:45:29,692 - log/train6.log - INFO - iteration:82 step:6800/10100, NER loss:      nan
2019-02-22 10:45:31,810 - log/train6.log - INFO - iteration:82 step:6900/10100, NER loss:      nan
2019-02-22 10:45:33,819 - log/train6.log - INFO - iteration:82 step:7000/10100, NER loss:      nan
2019-02-22 10:45:36,328 - log/train6.log - INFO - iteration:82 step:7100/10100, NER loss:      nan
2019-02-22 10:45:38,443 - log/train6.log - INFO - iteration:82 step:7200/10100, NER loss:      nan
2019-02-22 10:45:40,784 - log/train6.log - INFO - iteration:82 step:7300/10100, NER loss:      nan
2019-02-22 10:45:42,889 - log/train6.log - INFO - iteration:82 step:7400/10100, NER loss:      nan
2019-02-22 10:45:45,060 - log/train6.log - INFO - iteration:82 step:7500/10100, NER loss:      nan
2019-02-22 10:45:47,352 - log/train6.log - INFO - iteration:82 step:7600/10100, NER loss:      nan
2019-02-22 10:45:49,584 - log/train6.log - INFO - iteration:82 step:7700/10100, NER loss:      nan
2019-02-22 10:45:51,974 - log/train6.log - INFO - iteration:82 step:7800/10100, NER loss:      nan
2019-02-22 10:45:54,082 - log/train6.log - INFO - iteration:82 step:7900/10100, NER loss:      nan
2019-02-22 10:45:56,439 - log/train6.log - INFO - iteration:82 step:8000/10100, NER loss:      nan
2019-02-22 10:45:58,519 - log/train6.log - INFO - iteration:82 step:8100/10100, NER loss:      nan
2019-02-22 10:46:00,728 - log/train6.log - INFO - iteration:82 step:8200/10100, NER loss:      nan
2019-02-22 10:46:02,791 - log/train6.log - INFO - iteration:82 step:8300/10100, NER loss:      nan
2019-02-22 10:46:05,143 - log/train6.log - INFO - iteration:82 step:8400/10100, NER loss:      nan
2019-02-22 10:46:07,306 - log/train6.log - INFO - iteration:82 step:8500/10100, NER loss:      nan
2019-02-22 10:46:09,871 - log/train6.log - INFO - iteration:82 step:8600/10100, NER loss:      nan
2019-02-22 10:46:12,266 - log/train6.log - INFO - iteration:82 step:8700/10100, NER loss:      nan
2019-02-22 10:46:14,371 - log/train6.log - INFO - iteration:82 step:8800/10100, NER loss:      nan
2019-02-22 10:46:16,480 - log/train6.log - INFO - iteration:82 step:8900/10100, NER loss:      nan
2019-02-22 10:46:18,775 - log/train6.log - INFO - iteration:82 step:9000/10100, NER loss:      nan
2019-02-22 10:46:21,060 - log/train6.log - INFO - iteration:82 step:9100/10100, NER loss:      nan
2019-02-22 10:46:23,579 - log/train6.log - INFO - iteration:82 step:9200/10100, NER loss:      nan
2019-02-22 10:46:25,849 - log/train6.log - INFO - iteration:82 step:9300/10100, NER loss:      nan
2019-02-22 10:46:28,365 - log/train6.log - INFO - iteration:82 step:9400/10100, NER loss:      nan
2019-02-22 10:46:30,779 - log/train6.log - INFO - iteration:82 step:9500/10100, NER loss:      nan
2019-02-22 10:46:33,026 - log/train6.log - INFO - iteration:82 step:9600/10100, NER loss:      nan
2019-02-22 10:46:35,145 - log/train6.log - INFO - iteration:82 step:9700/10100, NER loss:      nan
2019-02-22 10:46:37,039 - log/train6.log - INFO - iteration:82 step:9800/10100, NER loss:      nan
2019-02-22 10:46:39,467 - log/train6.log - INFO - iteration:82 step:9900/10100, NER loss:      nan
2019-02-22 10:46:41,579 - log/train6.log - INFO - iteration:82 step:10000/10100, NER loss:      nan
2019-02-22 10:46:43,880 - log/train6.log - INFO - iteration:83 step:0/10100, NER loss:      nan
2019-02-22 10:46:43,881 - log/train6.log - INFO - evaluate:dev
2019-02-22 10:46:50,670 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 10:46:50,671 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 10:46:50,671 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:46:50,672 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:46:50,672 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:46:50,672 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:46:50,672 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:46:50,672 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:46:50,675 - log/train6.log - INFO - evaluate:test
2019-02-22 10:46:52,180 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 10:46:52,180 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 10:46:52,180 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:46:52,180 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:46:52,180 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:46:52,181 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:46:52,181 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:46:52,181 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:46:54,258 - log/train6.log - INFO - iteration:83 step:100/10100, NER loss:      nan
2019-02-22 10:46:57,023 - log/train6.log - INFO - iteration:83 step:200/10100, NER loss:      nan
2019-02-22 10:46:59,503 - log/train6.log - INFO - iteration:83 step:300/10100, NER loss:      nan
2019-02-22 10:47:01,924 - log/train6.log - INFO - iteration:83 step:400/10100, NER loss:      nan
2019-02-22 10:47:04,279 - log/train6.log - INFO - iteration:83 step:500/10100, NER loss:      nan
2019-02-22 10:47:06,422 - log/train6.log - INFO - iteration:83 step:600/10100, NER loss:      nan
2019-02-22 10:47:08,737 - log/train6.log - INFO - iteration:83 step:700/10100, NER loss:      nan
2019-02-22 10:47:11,139 - log/train6.log - INFO - iteration:83 step:800/10100, NER loss:      nan
2019-02-22 10:47:13,440 - log/train6.log - INFO - iteration:83 step:900/10100, NER loss:      nan
2019-02-22 10:47:17,619 - log/train6.log - INFO - iteration:83 step:1000/10100, NER loss:      nan
2019-02-22 10:47:20,273 - log/train6.log - INFO - iteration:83 step:1100/10100, NER loss:      nan
2019-02-22 10:47:22,824 - log/train6.log - INFO - iteration:83 step:1200/10100, NER loss:      nan
2019-02-22 10:47:25,428 - log/train6.log - INFO - iteration:83 step:1300/10100, NER loss:      nan
2019-02-22 10:47:27,712 - log/train6.log - INFO - iteration:83 step:1400/10100, NER loss:      nan
2019-02-22 10:47:29,962 - log/train6.log - INFO - iteration:83 step:1500/10100, NER loss:      nan
2019-02-22 10:47:32,783 - log/train6.log - INFO - iteration:83 step:1600/10100, NER loss:      nan
2019-02-22 10:47:35,777 - log/train6.log - INFO - iteration:83 step:1700/10100, NER loss:      nan
2019-02-22 10:47:38,268 - log/train6.log - INFO - iteration:83 step:1800/10100, NER loss:      nan
2019-02-22 10:47:40,840 - log/train6.log - INFO - iteration:83 step:1900/10100, NER loss:      nan
2019-02-22 10:47:43,231 - log/train6.log - INFO - iteration:83 step:2000/10100, NER loss:      nan
2019-02-22 10:47:45,374 - log/train6.log - INFO - iteration:83 step:2100/10100, NER loss:      nan
2019-02-22 10:47:48,025 - log/train6.log - INFO - iteration:83 step:2200/10100, NER loss:      nan
2019-02-22 10:47:50,279 - log/train6.log - INFO - iteration:83 step:2300/10100, NER loss:      nan
2019-02-22 10:47:52,862 - log/train6.log - INFO - iteration:83 step:2400/10100, NER loss:      nan
2019-02-22 10:47:55,745 - log/train6.log - INFO - iteration:83 step:2500/10100, NER loss:      nan
2019-02-22 10:47:58,274 - log/train6.log - INFO - iteration:83 step:2600/10100, NER loss:      nan
2019-02-22 10:48:00,711 - log/train6.log - INFO - iteration:83 step:2700/10100, NER loss:      nan
2019-02-22 10:48:02,825 - log/train6.log - INFO - iteration:83 step:2800/10100, NER loss:      nan
2019-02-22 10:48:05,208 - log/train6.log - INFO - iteration:83 step:2900/10100, NER loss:      nan
2019-02-22 10:48:07,549 - log/train6.log - INFO - iteration:83 step:3000/10100, NER loss:      nan
2019-02-22 10:48:09,908 - log/train6.log - INFO - iteration:83 step:3100/10100, NER loss:      nan
2019-02-22 10:48:16,439 - log/train6.log - INFO - iteration:83 step:3200/10100, NER loss:      nan
2019-02-22 10:48:18,599 - log/train6.log - INFO - iteration:83 step:3300/10100, NER loss:      nan
2019-02-22 10:48:20,628 - log/train6.log - INFO - iteration:83 step:3400/10100, NER loss:      nan
2019-02-22 10:48:22,680 - log/train6.log - INFO - iteration:83 step:3500/10100, NER loss:      nan
2019-02-22 10:48:25,057 - log/train6.log - INFO - iteration:83 step:3600/10100, NER loss:      nan
2019-02-22 10:48:27,026 - log/train6.log - INFO - iteration:83 step:3700/10100, NER loss:      nan
2019-02-22 10:48:29,326 - log/train6.log - INFO - iteration:83 step:3800/10100, NER loss:      nan
2019-02-22 10:48:31,334 - log/train6.log - INFO - iteration:83 step:3900/10100, NER loss:      nan
2019-02-22 10:48:33,532 - log/train6.log - INFO - iteration:83 step:4000/10100, NER loss:      nan
2019-02-22 10:48:35,660 - log/train6.log - INFO - iteration:83 step:4100/10100, NER loss:      nan
2019-02-22 10:48:37,842 - log/train6.log - INFO - iteration:83 step:4200/10100, NER loss:      nan
2019-02-22 10:48:39,964 - log/train6.log - INFO - iteration:83 step:4300/10100, NER loss:      nan
2019-02-22 10:48:41,927 - log/train6.log - INFO - iteration:83 step:4400/10100, NER loss:      nan
2019-02-22 10:48:43,955 - log/train6.log - INFO - iteration:83 step:4500/10100, NER loss:      nan
2019-02-22 10:48:46,108 - log/train6.log - INFO - iteration:83 step:4600/10100, NER loss:      nan
2019-02-22 10:48:48,250 - log/train6.log - INFO - iteration:83 step:4700/10100, NER loss:      nan
2019-02-22 10:48:50,498 - log/train6.log - INFO - iteration:83 step:4800/10100, NER loss:      nan
2019-02-22 10:48:52,483 - log/train6.log - INFO - iteration:83 step:4900/10100, NER loss:      nan
2019-02-22 10:48:54,466 - log/train6.log - INFO - iteration:83 step:5000/10100, NER loss:      nan
2019-02-22 10:48:56,750 - log/train6.log - INFO - iteration:83 step:5100/10100, NER loss:      nan
2019-02-22 10:48:58,874 - log/train6.log - INFO - iteration:83 step:5200/10100, NER loss:      nan
2019-02-22 10:49:00,989 - log/train6.log - INFO - iteration:83 step:5300/10100, NER loss:      nan
2019-02-22 10:49:02,954 - log/train6.log - INFO - iteration:83 step:5400/10100, NER loss:      nan
2019-02-22 10:49:05,158 - log/train6.log - INFO - iteration:83 step:5500/10100, NER loss:      nan
2019-02-22 10:49:07,091 - log/train6.log - INFO - iteration:83 step:5600/10100, NER loss:      nan
2019-02-22 10:49:09,278 - log/train6.log - INFO - iteration:83 step:5700/10100, NER loss:      nan
2019-02-22 10:49:11,628 - log/train6.log - INFO - iteration:83 step:5800/10100, NER loss:      nan
2019-02-22 10:49:13,725 - log/train6.log - INFO - iteration:83 step:5900/10100, NER loss:      nan
2019-02-22 10:49:15,801 - log/train6.log - INFO - iteration:83 step:6000/10100, NER loss:      nan
2019-02-22 10:49:18,079 - log/train6.log - INFO - iteration:83 step:6100/10100, NER loss:      nan
2019-02-22 10:49:20,433 - log/train6.log - INFO - iteration:83 step:6200/10100, NER loss:      nan
2019-02-22 10:49:23,100 - log/train6.log - INFO - iteration:83 step:6300/10100, NER loss:      nan
2019-02-22 10:49:25,368 - log/train6.log - INFO - iteration:83 step:6400/10100, NER loss:      nan
2019-02-22 10:49:27,429 - log/train6.log - INFO - iteration:83 step:6500/10100, NER loss:      nan
2019-02-22 10:49:29,746 - log/train6.log - INFO - iteration:83 step:6600/10100, NER loss:      nan
2019-02-22 10:49:31,858 - log/train6.log - INFO - iteration:83 step:6700/10100, NER loss:      nan
2019-02-22 10:49:33,870 - log/train6.log - INFO - iteration:83 step:6800/10100, NER loss:      nan
2019-02-22 10:49:35,915 - log/train6.log - INFO - iteration:83 step:6900/10100, NER loss:      nan
2019-02-22 10:49:38,149 - log/train6.log - INFO - iteration:83 step:7000/10100, NER loss:      nan
2019-02-22 10:49:40,317 - log/train6.log - INFO - iteration:83 step:7100/10100, NER loss:      nan
2019-02-22 10:49:42,206 - log/train6.log - INFO - iteration:83 step:7200/10100, NER loss:      nan
2019-02-22 10:49:44,275 - log/train6.log - INFO - iteration:83 step:7300/10100, NER loss:      nan
2019-02-22 10:49:46,562 - log/train6.log - INFO - iteration:83 step:7400/10100, NER loss:      nan
2019-02-22 10:49:48,662 - log/train6.log - INFO - iteration:83 step:7500/10100, NER loss:      nan
2019-02-22 10:49:50,731 - log/train6.log - INFO - iteration:83 step:7600/10100, NER loss:      nan
2019-02-22 10:49:52,869 - log/train6.log - INFO - iteration:83 step:7700/10100, NER loss:      nan
2019-02-22 10:49:55,090 - log/train6.log - INFO - iteration:83 step:7800/10100, NER loss:      nan
2019-02-22 10:49:57,458 - log/train6.log - INFO - iteration:83 step:7900/10100, NER loss:      nan
2019-02-22 10:49:59,647 - log/train6.log - INFO - iteration:83 step:8000/10100, NER loss:      nan
2019-02-22 10:50:01,929 - log/train6.log - INFO - iteration:83 step:8100/10100, NER loss:      nan
2019-02-22 10:50:04,283 - log/train6.log - INFO - iteration:83 step:8200/10100, NER loss:      nan
2019-02-22 10:50:06,727 - log/train6.log - INFO - iteration:83 step:8300/10100, NER loss:      nan
2019-02-22 10:50:09,090 - log/train6.log - INFO - iteration:83 step:8400/10100, NER loss:      nan
2019-02-22 10:50:11,612 - log/train6.log - INFO - iteration:83 step:8500/10100, NER loss:      nan
2019-02-22 10:50:14,218 - log/train6.log - INFO - iteration:83 step:8600/10100, NER loss:      nan
2019-02-22 10:50:16,776 - log/train6.log - INFO - iteration:83 step:8700/10100, NER loss:      nan
2019-02-22 10:50:18,989 - log/train6.log - INFO - iteration:83 step:8800/10100, NER loss:      nan
2019-02-22 10:50:21,515 - log/train6.log - INFO - iteration:83 step:8900/10100, NER loss:      nan
2019-02-22 10:50:23,793 - log/train6.log - INFO - iteration:83 step:9000/10100, NER loss:      nan
2019-02-22 10:50:25,899 - log/train6.log - INFO - iteration:83 step:9100/10100, NER loss:      nan
2019-02-22 10:50:27,927 - log/train6.log - INFO - iteration:83 step:9200/10100, NER loss:      nan
2019-02-22 10:50:29,794 - log/train6.log - INFO - iteration:83 step:9300/10100, NER loss:      nan
2019-02-22 10:50:31,815 - log/train6.log - INFO - iteration:83 step:9400/10100, NER loss:      nan
2019-02-22 10:50:33,883 - log/train6.log - INFO - iteration:83 step:9500/10100, NER loss:      nan
2019-02-22 10:50:36,292 - log/train6.log - INFO - iteration:83 step:9600/10100, NER loss:      nan
2019-02-22 10:50:38,543 - log/train6.log - INFO - iteration:83 step:9700/10100, NER loss:      nan
2019-02-22 10:50:40,806 - log/train6.log - INFO - iteration:83 step:9800/10100, NER loss:      nan
2019-02-22 10:50:43,262 - log/train6.log - INFO - iteration:83 step:9900/10100, NER loss:      nan
2019-02-22 10:50:45,455 - log/train6.log - INFO - iteration:83 step:10000/10100, NER loss:      nan
2019-02-22 10:50:47,770 - log/train6.log - INFO - iteration:84 step:0/10100, NER loss:      nan
2019-02-22 10:50:47,770 - log/train6.log - INFO - evaluate:dev
2019-02-22 10:50:54,678 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 10:50:54,678 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 10:50:54,679 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:50:54,679 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:50:54,679 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:50:54,679 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:50:54,679 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:50:54,679 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:50:54,682 - log/train6.log - INFO - evaluate:test
2019-02-22 10:50:56,135 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 10:50:56,135 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 10:50:56,135 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:50:56,135 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:50:56,135 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:50:56,135 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:50:56,135 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:50:56,135 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:50:58,490 - log/train6.log - INFO - iteration:84 step:100/10100, NER loss:      nan
2019-02-22 10:51:00,618 - log/train6.log - INFO - iteration:84 step:200/10100, NER loss:      nan
2019-02-22 10:51:02,592 - log/train6.log - INFO - iteration:84 step:300/10100, NER loss:      nan
2019-02-22 10:51:04,554 - log/train6.log - INFO - iteration:84 step:400/10100, NER loss:      nan
2019-02-22 10:51:06,526 - log/train6.log - INFO - iteration:84 step:500/10100, NER loss:      nan
2019-02-22 10:51:08,683 - log/train6.log - INFO - iteration:84 step:600/10100, NER loss:      nan
2019-02-22 10:51:10,925 - log/train6.log - INFO - iteration:84 step:700/10100, NER loss:      nan
2019-02-22 10:51:13,173 - log/train6.log - INFO - iteration:84 step:800/10100, NER loss:      nan
2019-02-22 10:51:15,424 - log/train6.log - INFO - iteration:84 step:900/10100, NER loss:      nan
2019-02-22 10:51:17,523 - log/train6.log - INFO - iteration:84 step:1000/10100, NER loss:      nan
2019-02-22 10:51:19,841 - log/train6.log - INFO - iteration:84 step:1100/10100, NER loss:      nan
2019-02-22 10:51:22,065 - log/train6.log - INFO - iteration:84 step:1200/10100, NER loss:      nan
2019-02-22 10:51:24,341 - log/train6.log - INFO - iteration:84 step:1300/10100, NER loss:      nan
2019-02-22 10:51:26,279 - log/train6.log - INFO - iteration:84 step:1400/10100, NER loss:      nan
2019-02-22 10:51:28,310 - log/train6.log - INFO - iteration:84 step:1500/10100, NER loss:      nan
2019-02-22 10:51:30,427 - log/train6.log - INFO - iteration:84 step:1600/10100, NER loss:      nan
2019-02-22 10:51:32,581 - log/train6.log - INFO - iteration:84 step:1700/10100, NER loss:      nan
2019-02-22 10:51:34,688 - log/train6.log - INFO - iteration:84 step:1800/10100, NER loss:      nan
2019-02-22 10:51:36,868 - log/train6.log - INFO - iteration:84 step:1900/10100, NER loss:      nan
2019-02-22 10:51:38,942 - log/train6.log - INFO - iteration:84 step:2000/10100, NER loss:      nan
2019-02-22 10:51:41,157 - log/train6.log - INFO - iteration:84 step:2100/10100, NER loss:      nan
2019-02-22 10:51:43,186 - log/train6.log - INFO - iteration:84 step:2200/10100, NER loss:      nan
2019-02-22 10:51:47,420 - log/train6.log - INFO - iteration:84 step:2300/10100, NER loss:      nan
2019-02-22 10:51:49,453 - log/train6.log - INFO - iteration:84 step:2400/10100, NER loss:      nan
2019-02-22 10:51:51,604 - log/train6.log - INFO - iteration:84 step:2500/10100, NER loss:      nan
2019-02-22 10:51:53,746 - log/train6.log - INFO - iteration:84 step:2600/10100, NER loss:      nan
2019-02-22 10:51:56,094 - log/train6.log - INFO - iteration:84 step:2700/10100, NER loss:      nan
2019-02-22 10:51:58,049 - log/train6.log - INFO - iteration:84 step:2800/10100, NER loss:      nan
2019-02-22 10:52:00,312 - log/train6.log - INFO - iteration:84 step:2900/10100, NER loss:      nan
2019-02-22 10:52:02,515 - log/train6.log - INFO - iteration:84 step:3000/10100, NER loss:      nan
2019-02-22 10:52:04,754 - log/train6.log - INFO - iteration:84 step:3100/10100, NER loss:      nan
2019-02-22 10:52:06,900 - log/train6.log - INFO - iteration:84 step:3200/10100, NER loss:      nan
2019-02-22 10:52:09,134 - log/train6.log - INFO - iteration:84 step:3300/10100, NER loss:      nan
2019-02-22 10:52:11,135 - log/train6.log - INFO - iteration:84 step:3400/10100, NER loss:      nan
2019-02-22 10:52:13,429 - log/train6.log - INFO - iteration:84 step:3500/10100, NER loss:      nan
2019-02-22 10:52:15,486 - log/train6.log - INFO - iteration:84 step:3600/10100, NER loss:      nan
2019-02-22 10:52:17,503 - log/train6.log - INFO - iteration:84 step:3700/10100, NER loss:      nan
2019-02-22 10:52:19,796 - log/train6.log - INFO - iteration:84 step:3800/10100, NER loss:      nan
2019-02-22 10:52:22,216 - log/train6.log - INFO - iteration:84 step:3900/10100, NER loss:      nan
2019-02-22 10:52:24,690 - log/train6.log - INFO - iteration:84 step:4000/10100, NER loss:      nan
2019-02-22 10:52:26,978 - log/train6.log - INFO - iteration:84 step:4100/10100, NER loss:      nan
2019-02-22 10:52:29,493 - log/train6.log - INFO - iteration:84 step:4200/10100, NER loss:      nan
2019-02-22 10:52:31,734 - log/train6.log - INFO - iteration:84 step:4300/10100, NER loss:      nan
2019-02-22 10:52:34,561 - log/train6.log - INFO - iteration:84 step:4400/10100, NER loss:      nan
2019-02-22 10:52:37,128 - log/train6.log - INFO - iteration:84 step:4500/10100, NER loss:      nan
2019-02-22 10:52:39,589 - log/train6.log - INFO - iteration:84 step:4600/10100, NER loss:      nan
2019-02-22 10:52:42,135 - log/train6.log - INFO - iteration:84 step:4700/10100, NER loss:      nan
2019-02-22 10:52:44,606 - log/train6.log - INFO - iteration:84 step:4800/10100, NER loss:      nan
2019-02-22 10:52:46,950 - log/train6.log - INFO - iteration:84 step:4900/10100, NER loss:      nan
2019-02-22 10:52:49,062 - log/train6.log - INFO - iteration:84 step:5000/10100, NER loss:      nan
2019-02-22 10:52:51,425 - log/train6.log - INFO - iteration:84 step:5100/10100, NER loss:      nan
2019-02-22 10:52:54,193 - log/train6.log - INFO - iteration:84 step:5200/10100, NER loss:      nan
2019-02-22 10:52:56,466 - log/train6.log - INFO - iteration:84 step:5300/10100, NER loss:      nan
2019-02-22 10:52:58,794 - log/train6.log - INFO - iteration:84 step:5400/10100, NER loss:      nan
2019-02-22 10:53:01,208 - log/train6.log - INFO - iteration:84 step:5500/10100, NER loss:      nan
2019-02-22 10:53:03,319 - log/train6.log - INFO - iteration:84 step:5600/10100, NER loss:      nan
2019-02-22 10:53:05,621 - log/train6.log - INFO - iteration:84 step:5700/10100, NER loss:      nan
2019-02-22 10:53:07,732 - log/train6.log - INFO - iteration:84 step:5800/10100, NER loss:      nan
2019-02-22 10:53:10,281 - log/train6.log - INFO - iteration:84 step:5900/10100, NER loss:      nan
2019-02-22 10:53:12,652 - log/train6.log - INFO - iteration:84 step:6000/10100, NER loss:      nan
2019-02-22 10:53:15,159 - log/train6.log - INFO - iteration:84 step:6100/10100, NER loss:      nan
2019-02-22 10:53:17,757 - log/train6.log - INFO - iteration:84 step:6200/10100, NER loss:      nan
2019-02-22 10:53:20,116 - log/train6.log - INFO - iteration:84 step:6300/10100, NER loss:      nan
2019-02-22 10:53:22,976 - log/train6.log - INFO - iteration:84 step:6400/10100, NER loss:      nan
2019-02-22 10:53:25,234 - log/train6.log - INFO - iteration:84 step:6500/10100, NER loss:      nan
2019-02-22 10:53:27,584 - log/train6.log - INFO - iteration:84 step:6600/10100, NER loss:      nan
2019-02-22 10:53:29,950 - log/train6.log - INFO - iteration:84 step:6700/10100, NER loss:      nan
2019-02-22 10:53:32,494 - log/train6.log - INFO - iteration:84 step:6800/10100, NER loss:      nan
2019-02-22 10:53:34,892 - log/train6.log - INFO - iteration:84 step:6900/10100, NER loss:      nan
2019-02-22 10:53:37,343 - log/train6.log - INFO - iteration:84 step:7000/10100, NER loss:      nan
2019-02-22 10:53:40,048 - log/train6.log - INFO - iteration:84 step:7100/10100, NER loss:      nan
2019-02-22 10:53:42,479 - log/train6.log - INFO - iteration:84 step:7200/10100, NER loss:      nan
2019-02-22 10:53:44,908 - log/train6.log - INFO - iteration:84 step:7300/10100, NER loss:      nan
2019-02-22 10:53:47,259 - log/train6.log - INFO - iteration:84 step:7400/10100, NER loss:      nan
2019-02-22 10:53:49,882 - log/train6.log - INFO - iteration:84 step:7500/10100, NER loss:      nan
2019-02-22 10:53:52,562 - log/train6.log - INFO - iteration:84 step:7600/10100, NER loss:      nan
2019-02-22 10:53:54,835 - log/train6.log - INFO - iteration:84 step:7700/10100, NER loss:      nan
2019-02-22 10:53:57,355 - log/train6.log - INFO - iteration:84 step:7800/10100, NER loss:      nan
2019-02-22 10:53:59,913 - log/train6.log - INFO - iteration:84 step:7900/10100, NER loss:      nan
2019-02-22 10:54:02,328 - log/train6.log - INFO - iteration:84 step:8000/10100, NER loss:      nan
2019-02-22 10:54:04,856 - log/train6.log - INFO - iteration:84 step:8100/10100, NER loss:      nan
2019-02-22 10:54:07,610 - log/train6.log - INFO - iteration:84 step:8200/10100, NER loss:      nan
2019-02-22 10:54:10,027 - log/train6.log - INFO - iteration:84 step:8300/10100, NER loss:      nan
2019-02-22 10:54:14,041 - log/train6.log - INFO - iteration:84 step:8400/10100, NER loss:      nan
2019-02-22 10:54:16,229 - log/train6.log - INFO - iteration:84 step:8500/10100, NER loss:      nan
2019-02-22 10:54:18,583 - log/train6.log - INFO - iteration:84 step:8600/10100, NER loss:      nan
2019-02-22 10:54:21,265 - log/train6.log - INFO - iteration:84 step:8700/10100, NER loss:      nan
2019-02-22 10:54:23,746 - log/train6.log - INFO - iteration:84 step:8800/10100, NER loss:      nan
2019-02-22 10:54:26,177 - log/train6.log - INFO - iteration:84 step:8900/10100, NER loss:      nan
2019-02-22 10:54:28,596 - log/train6.log - INFO - iteration:84 step:9000/10100, NER loss:      nan
2019-02-22 10:54:30,719 - log/train6.log - INFO - iteration:84 step:9100/10100, NER loss:      nan
2019-02-22 10:54:32,747 - log/train6.log - INFO - iteration:84 step:9200/10100, NER loss:      nan
2019-02-22 10:54:35,386 - log/train6.log - INFO - iteration:84 step:9300/10100, NER loss:      nan
2019-02-22 10:54:40,266 - log/train6.log - INFO - iteration:84 step:9400/10100, NER loss:      nan
2019-02-22 10:54:42,582 - log/train6.log - INFO - iteration:84 step:9500/10100, NER loss:      nan
2019-02-22 10:54:44,810 - log/train6.log - INFO - iteration:84 step:9600/10100, NER loss:      nan
2019-02-22 10:54:47,177 - log/train6.log - INFO - iteration:84 step:9700/10100, NER loss:      nan
2019-02-22 10:54:49,806 - log/train6.log - INFO - iteration:84 step:9800/10100, NER loss:      nan
2019-02-22 10:54:51,909 - log/train6.log - INFO - iteration:84 step:9900/10100, NER loss:      nan
2019-02-22 10:54:54,467 - log/train6.log - INFO - iteration:84 step:10000/10100, NER loss:      nan
2019-02-22 10:54:56,713 - log/train6.log - INFO - iteration:85 step:0/10100, NER loss:      nan
2019-02-22 10:54:56,713 - log/train6.log - INFO - evaluate:dev
2019-02-22 10:55:03,804 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 10:55:03,805 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 10:55:03,805 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:55:03,805 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:55:03,805 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:55:03,805 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:55:03,805 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:55:03,805 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:55:03,808 - log/train6.log - INFO - evaluate:test
2019-02-22 10:55:05,394 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 10:55:05,394 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 10:55:05,394 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:55:05,394 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:55:05,394 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:55:05,394 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:55:05,394 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:55:05,394 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:55:07,846 - log/train6.log - INFO - iteration:85 step:100/10100, NER loss:      nan
2019-02-22 10:55:09,881 - log/train6.log - INFO - iteration:85 step:200/10100, NER loss:      nan
2019-02-22 10:55:12,413 - log/train6.log - INFO - iteration:85 step:300/10100, NER loss:      nan
2019-02-22 10:55:14,562 - log/train6.log - INFO - iteration:85 step:400/10100, NER loss:      nan
2019-02-22 10:55:16,717 - log/train6.log - INFO - iteration:85 step:500/10100, NER loss:      nan
2019-02-22 10:55:19,099 - log/train6.log - INFO - iteration:85 step:600/10100, NER loss:      nan
2019-02-22 10:55:21,685 - log/train6.log - INFO - iteration:85 step:700/10100, NER loss:      nan
2019-02-22 10:55:23,977 - log/train6.log - INFO - iteration:85 step:800/10100, NER loss:      nan
2019-02-22 10:55:26,113 - log/train6.log - INFO - iteration:85 step:900/10100, NER loss:      nan
2019-02-22 10:55:28,031 - log/train6.log - INFO - iteration:85 step:1000/10100, NER loss:      nan
2019-02-22 10:55:30,567 - log/train6.log - INFO - iteration:85 step:1100/10100, NER loss:      nan
2019-02-22 10:55:33,002 - log/train6.log - INFO - iteration:85 step:1200/10100, NER loss:      nan
2019-02-22 10:55:35,193 - log/train6.log - INFO - iteration:85 step:1300/10100, NER loss:      nan
2019-02-22 10:55:37,627 - log/train6.log - INFO - iteration:85 step:1400/10100, NER loss:      nan
2019-02-22 10:55:40,393 - log/train6.log - INFO - iteration:85 step:1500/10100, NER loss:      nan
2019-02-22 10:55:43,120 - log/train6.log - INFO - iteration:85 step:1600/10100, NER loss:      nan
2019-02-22 10:55:45,822 - log/train6.log - INFO - iteration:85 step:1700/10100, NER loss:      nan
2019-02-22 10:55:47,980 - log/train6.log - INFO - iteration:85 step:1800/10100, NER loss:      nan
2019-02-22 10:55:50,362 - log/train6.log - INFO - iteration:85 step:1900/10100, NER loss:      nan
2019-02-22 10:55:53,142 - log/train6.log - INFO - iteration:85 step:2000/10100, NER loss:      nan
2019-02-22 10:55:55,534 - log/train6.log - INFO - iteration:85 step:2100/10100, NER loss:      nan
2019-02-22 10:55:57,815 - log/train6.log - INFO - iteration:85 step:2200/10100, NER loss:      nan
2019-02-22 10:56:00,314 - log/train6.log - INFO - iteration:85 step:2300/10100, NER loss:      nan
2019-02-22 10:56:02,755 - log/train6.log - INFO - iteration:85 step:2400/10100, NER loss:      nan
2019-02-22 10:56:05,209 - log/train6.log - INFO - iteration:85 step:2500/10100, NER loss:      nan
2019-02-22 10:56:07,640 - log/train6.log - INFO - iteration:85 step:2600/10100, NER loss:      nan
2019-02-22 10:56:09,880 - log/train6.log - INFO - iteration:85 step:2700/10100, NER loss:      nan
2019-02-22 10:56:12,228 - log/train6.log - INFO - iteration:85 step:2800/10100, NER loss:      nan
2019-02-22 10:56:14,491 - log/train6.log - INFO - iteration:85 step:2900/10100, NER loss:      nan
2019-02-22 10:56:16,994 - log/train6.log - INFO - iteration:85 step:3000/10100, NER loss:      nan
2019-02-22 10:56:19,440 - log/train6.log - INFO - iteration:85 step:3100/10100, NER loss:      nan
2019-02-22 10:56:21,938 - log/train6.log - INFO - iteration:85 step:3200/10100, NER loss:      nan
2019-02-22 10:56:24,611 - log/train6.log - INFO - iteration:85 step:3300/10100, NER loss:      nan
2019-02-22 10:56:27,160 - log/train6.log - INFO - iteration:85 step:3400/10100, NER loss:      nan
2019-02-22 10:56:29,655 - log/train6.log - INFO - iteration:85 step:3500/10100, NER loss:      nan
2019-02-22 10:56:32,607 - log/train6.log - INFO - iteration:85 step:3600/10100, NER loss:      nan
2019-02-22 10:56:35,161 - log/train6.log - INFO - iteration:85 step:3700/10100, NER loss:      nan
2019-02-22 10:56:37,339 - log/train6.log - INFO - iteration:85 step:3800/10100, NER loss:      nan
2019-02-22 10:56:39,640 - log/train6.log - INFO - iteration:85 step:3900/10100, NER loss:      nan
2019-02-22 10:56:42,101 - log/train6.log - INFO - iteration:85 step:4000/10100, NER loss:      nan
2019-02-22 10:56:46,686 - log/train6.log - INFO - iteration:85 step:4100/10100, NER loss:      nan
2019-02-22 10:56:48,940 - log/train6.log - INFO - iteration:85 step:4200/10100, NER loss:      nan
2019-02-22 10:56:50,986 - log/train6.log - INFO - iteration:85 step:4300/10100, NER loss:      nan
2019-02-22 10:56:53,351 - log/train6.log - INFO - iteration:85 step:4400/10100, NER loss:      nan
2019-02-22 10:56:57,797 - log/train6.log - INFO - iteration:85 step:4500/10100, NER loss:      nan
2019-02-22 10:57:00,278 - log/train6.log - INFO - iteration:85 step:4600/10100, NER loss:      nan
2019-02-22 10:57:02,578 - log/train6.log - INFO - iteration:85 step:4700/10100, NER loss:      nan
2019-02-22 10:57:05,064 - log/train6.log - INFO - iteration:85 step:4800/10100, NER loss:      nan
2019-02-22 10:57:07,645 - log/train6.log - INFO - iteration:85 step:4900/10100, NER loss:      nan
2019-02-22 10:57:09,989 - log/train6.log - INFO - iteration:85 step:5000/10100, NER loss:      nan
2019-02-22 10:57:12,425 - log/train6.log - INFO - iteration:85 step:5100/10100, NER loss:      nan
2019-02-22 10:57:14,891 - log/train6.log - INFO - iteration:85 step:5200/10100, NER loss:      nan
2019-02-22 10:57:17,305 - log/train6.log - INFO - iteration:85 step:5300/10100, NER loss:      nan
2019-02-22 10:57:19,886 - log/train6.log - INFO - iteration:85 step:5400/10100, NER loss:      nan
2019-02-22 10:57:22,575 - log/train6.log - INFO - iteration:85 step:5500/10100, NER loss:      nan
2019-02-22 10:57:25,101 - log/train6.log - INFO - iteration:85 step:5600/10100, NER loss:      nan
2019-02-22 10:57:27,483 - log/train6.log - INFO - iteration:85 step:5700/10100, NER loss:      nan
2019-02-22 10:57:29,818 - log/train6.log - INFO - iteration:85 step:5800/10100, NER loss:      nan
2019-02-22 10:57:32,257 - log/train6.log - INFO - iteration:85 step:5900/10100, NER loss:      nan
2019-02-22 10:57:34,746 - log/train6.log - INFO - iteration:85 step:6000/10100, NER loss:      nan
2019-02-22 10:57:36,915 - log/train6.log - INFO - iteration:85 step:6100/10100, NER loss:      nan
2019-02-22 10:57:39,323 - log/train6.log - INFO - iteration:85 step:6200/10100, NER loss:      nan
2019-02-22 10:57:41,760 - log/train6.log - INFO - iteration:85 step:6300/10100, NER loss:      nan
2019-02-22 10:57:44,378 - log/train6.log - INFO - iteration:85 step:6400/10100, NER loss:      nan
2019-02-22 10:57:46,316 - log/train6.log - INFO - iteration:85 step:6500/10100, NER loss:      nan
2019-02-22 10:57:48,409 - log/train6.log - INFO - iteration:85 step:6600/10100, NER loss:      nan
2019-02-22 10:57:51,043 - log/train6.log - INFO - iteration:85 step:6700/10100, NER loss:      nan
2019-02-22 10:57:53,333 - log/train6.log - INFO - iteration:85 step:6800/10100, NER loss:      nan
2019-02-22 10:57:56,001 - log/train6.log - INFO - iteration:85 step:6900/10100, NER loss:      nan
2019-02-22 10:57:58,558 - log/train6.log - INFO - iteration:85 step:7000/10100, NER loss:      nan
2019-02-22 10:58:00,966 - log/train6.log - INFO - iteration:85 step:7100/10100, NER loss:      nan
2019-02-22 10:58:03,349 - log/train6.log - INFO - iteration:85 step:7200/10100, NER loss:      nan
2019-02-22 10:58:05,964 - log/train6.log - INFO - iteration:85 step:7300/10100, NER loss:      nan
2019-02-22 10:58:07,974 - log/train6.log - INFO - iteration:85 step:7400/10100, NER loss:      nan
2019-02-22 10:58:10,431 - log/train6.log - INFO - iteration:85 step:7500/10100, NER loss:      nan
2019-02-22 10:58:12,818 - log/train6.log - INFO - iteration:85 step:7600/10100, NER loss:      nan
2019-02-22 10:58:15,420 - log/train6.log - INFO - iteration:85 step:7700/10100, NER loss:      nan
2019-02-22 10:58:17,692 - log/train6.log - INFO - iteration:85 step:7800/10100, NER loss:      nan
2019-02-22 10:58:22,821 - log/train6.log - INFO - iteration:85 step:7900/10100, NER loss:      nan
2019-02-22 10:58:25,972 - log/train6.log - INFO - iteration:85 step:8000/10100, NER loss:      nan
2019-02-22 10:58:28,533 - log/train6.log - INFO - iteration:85 step:8100/10100, NER loss:      nan
2019-02-22 10:58:30,945 - log/train6.log - INFO - iteration:85 step:8200/10100, NER loss:      nan
2019-02-22 10:58:33,422 - log/train6.log - INFO - iteration:85 step:8300/10100, NER loss:      nan
2019-02-22 10:58:35,669 - log/train6.log - INFO - iteration:85 step:8400/10100, NER loss:      nan
2019-02-22 10:58:37,866 - log/train6.log - INFO - iteration:85 step:8500/10100, NER loss:      nan
2019-02-22 10:58:40,113 - log/train6.log - INFO - iteration:85 step:8600/10100, NER loss:      nan
2019-02-22 10:58:42,724 - log/train6.log - INFO - iteration:85 step:8700/10100, NER loss:      nan
2019-02-22 10:58:44,939 - log/train6.log - INFO - iteration:85 step:8800/10100, NER loss:      nan
2019-02-22 10:58:46,921 - log/train6.log - INFO - iteration:85 step:8900/10100, NER loss:      nan
2019-02-22 10:58:49,133 - log/train6.log - INFO - iteration:85 step:9000/10100, NER loss:      nan
2019-02-22 10:58:51,429 - log/train6.log - INFO - iteration:85 step:9100/10100, NER loss:      nan
2019-02-22 10:58:53,523 - log/train6.log - INFO - iteration:85 step:9200/10100, NER loss:      nan
2019-02-22 10:58:55,810 - log/train6.log - INFO - iteration:85 step:9300/10100, NER loss:      nan
2019-02-22 10:58:58,037 - log/train6.log - INFO - iteration:85 step:9400/10100, NER loss:      nan
2019-02-22 10:59:00,231 - log/train6.log - INFO - iteration:85 step:9500/10100, NER loss:      nan
2019-02-22 10:59:02,377 - log/train6.log - INFO - iteration:85 step:9600/10100, NER loss:      nan
2019-02-22 10:59:04,686 - log/train6.log - INFO - iteration:85 step:9700/10100, NER loss:      nan
2019-02-22 10:59:06,972 - log/train6.log - INFO - iteration:85 step:9800/10100, NER loss:      nan
2019-02-22 10:59:09,230 - log/train6.log - INFO - iteration:85 step:9900/10100, NER loss:      nan
2019-02-22 10:59:11,474 - log/train6.log - INFO - iteration:85 step:10000/10100, NER loss:      nan
2019-02-22 10:59:13,663 - log/train6.log - INFO - iteration:86 step:0/10100, NER loss:      nan
2019-02-22 10:59:13,663 - log/train6.log - INFO - evaluate:dev
2019-02-22 10:59:20,625 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 10:59:20,625 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 10:59:20,626 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:59:20,626 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:59:20,626 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:59:20,626 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:59:20,626 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:59:20,627 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:59:20,630 - log/train6.log - INFO - evaluate:test
2019-02-22 10:59:22,080 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 10:59:22,080 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 10:59:22,080 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:59:22,080 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:59:22,080 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:59:22,080 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:59:22,080 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:59:22,080 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 10:59:24,161 - log/train6.log - INFO - iteration:86 step:100/10100, NER loss:      nan
2019-02-22 10:59:26,253 - log/train6.log - INFO - iteration:86 step:200/10100, NER loss:      nan
2019-02-22 10:59:28,420 - log/train6.log - INFO - iteration:86 step:300/10100, NER loss:      nan
2019-02-22 10:59:30,846 - log/train6.log - INFO - iteration:86 step:400/10100, NER loss:      nan
2019-02-22 10:59:33,098 - log/train6.log - INFO - iteration:86 step:500/10100, NER loss:      nan
2019-02-22 10:59:35,395 - log/train6.log - INFO - iteration:86 step:600/10100, NER loss:      nan
2019-02-22 10:59:37,661 - log/train6.log - INFO - iteration:86 step:700/10100, NER loss:      nan
2019-02-22 10:59:39,828 - log/train6.log - INFO - iteration:86 step:800/10100, NER loss:      nan
2019-02-22 10:59:42,205 - log/train6.log - INFO - iteration:86 step:900/10100, NER loss:      nan
2019-02-22 10:59:44,341 - log/train6.log - INFO - iteration:86 step:1000/10100, NER loss:      nan
2019-02-22 10:59:46,350 - log/train6.log - INFO - iteration:86 step:1100/10100, NER loss:      nan
2019-02-22 10:59:48,646 - log/train6.log - INFO - iteration:86 step:1200/10100, NER loss:      nan
2019-02-22 10:59:51,018 - log/train6.log - INFO - iteration:86 step:1300/10100, NER loss:      nan
2019-02-22 10:59:53,432 - log/train6.log - INFO - iteration:86 step:1400/10100, NER loss:      nan
2019-02-22 10:59:55,933 - log/train6.log - INFO - iteration:86 step:1500/10100, NER loss:      nan
2019-02-22 10:59:58,568 - log/train6.log - INFO - iteration:86 step:1600/10100, NER loss:      nan
2019-02-22 11:00:01,076 - log/train6.log - INFO - iteration:86 step:1700/10100, NER loss:      nan
2019-02-22 11:00:03,331 - log/train6.log - INFO - iteration:86 step:1800/10100, NER loss:      nan
2019-02-22 11:00:05,810 - log/train6.log - INFO - iteration:86 step:1900/10100, NER loss:      nan
2019-02-22 11:00:08,104 - log/train6.log - INFO - iteration:86 step:2000/10100, NER loss:      nan
2019-02-22 11:00:12,695 - log/train6.log - INFO - iteration:86 step:2100/10100, NER loss:      nan
2019-02-22 11:00:14,779 - log/train6.log - INFO - iteration:86 step:2200/10100, NER loss:      nan
2019-02-22 11:00:16,870 - log/train6.log - INFO - iteration:86 step:2300/10100, NER loss:      nan
2019-02-22 11:00:18,934 - log/train6.log - INFO - iteration:86 step:2400/10100, NER loss:      nan
2019-02-22 11:00:21,034 - log/train6.log - INFO - iteration:86 step:2500/10100, NER loss:      nan
2019-02-22 11:00:23,108 - log/train6.log - INFO - iteration:86 step:2600/10100, NER loss:      nan
2019-02-22 11:00:25,225 - log/train6.log - INFO - iteration:86 step:2700/10100, NER loss:      nan
2019-02-22 11:00:27,278 - log/train6.log - INFO - iteration:86 step:2800/10100, NER loss:      nan
2019-02-22 11:00:29,438 - log/train6.log - INFO - iteration:86 step:2900/10100, NER loss:      nan
2019-02-22 11:00:31,902 - log/train6.log - INFO - iteration:86 step:3000/10100, NER loss:      nan
2019-02-22 11:00:34,161 - log/train6.log - INFO - iteration:86 step:3100/10100, NER loss:      nan
2019-02-22 11:00:36,345 - log/train6.log - INFO - iteration:86 step:3200/10100, NER loss:      nan
2019-02-22 11:00:38,467 - log/train6.log - INFO - iteration:86 step:3300/10100, NER loss:      nan
2019-02-22 11:00:40,442 - log/train6.log - INFO - iteration:86 step:3400/10100, NER loss:      nan
2019-02-22 11:00:42,620 - log/train6.log - INFO - iteration:86 step:3500/10100, NER loss:      nan
2019-02-22 11:00:46,830 - log/train6.log - INFO - iteration:86 step:3600/10100, NER loss:      nan
2019-02-22 11:00:48,876 - log/train6.log - INFO - iteration:86 step:3700/10100, NER loss:      nan
2019-02-22 11:00:51,204 - log/train6.log - INFO - iteration:86 step:3800/10100, NER loss:      nan
2019-02-22 11:00:53,606 - log/train6.log - INFO - iteration:86 step:3900/10100, NER loss:      nan
2019-02-22 11:00:55,651 - log/train6.log - INFO - iteration:86 step:4000/10100, NER loss:      nan
2019-02-22 11:00:57,890 - log/train6.log - INFO - iteration:86 step:4100/10100, NER loss:      nan
2019-02-22 11:01:00,070 - log/train6.log - INFO - iteration:86 step:4200/10100, NER loss:      nan
2019-02-22 11:01:02,283 - log/train6.log - INFO - iteration:86 step:4300/10100, NER loss:      nan
2019-02-22 11:01:04,577 - log/train6.log - INFO - iteration:86 step:4400/10100, NER loss:      nan
2019-02-22 11:01:06,627 - log/train6.log - INFO - iteration:86 step:4500/10100, NER loss:      nan
2019-02-22 11:01:08,816 - log/train6.log - INFO - iteration:86 step:4600/10100, NER loss:      nan
2019-02-22 11:01:11,018 - log/train6.log - INFO - iteration:86 step:4700/10100, NER loss:      nan
2019-02-22 11:01:13,256 - log/train6.log - INFO - iteration:86 step:4800/10100, NER loss:      nan
2019-02-22 11:01:15,215 - log/train6.log - INFO - iteration:86 step:4900/10100, NER loss:      nan
2019-02-22 11:01:17,917 - log/train6.log - INFO - iteration:86 step:5000/10100, NER loss:      nan
2019-02-22 11:01:20,611 - log/train6.log - INFO - iteration:86 step:5100/10100, NER loss:      nan
2019-02-22 11:01:22,886 - log/train6.log - INFO - iteration:86 step:5200/10100, NER loss:      nan
2019-02-22 11:01:25,348 - log/train6.log - INFO - iteration:86 step:5300/10100, NER loss:      nan
2019-02-22 11:01:27,383 - log/train6.log - INFO - iteration:86 step:5400/10100, NER loss:      nan
2019-02-22 11:01:30,118 - log/train6.log - INFO - iteration:86 step:5500/10100, NER loss:      nan
2019-02-22 11:01:32,166 - log/train6.log - INFO - iteration:86 step:5600/10100, NER loss:      nan
2019-02-22 11:01:34,328 - log/train6.log - INFO - iteration:86 step:5700/10100, NER loss:      nan
2019-02-22 11:01:36,595 - log/train6.log - INFO - iteration:86 step:5800/10100, NER loss:      nan
2019-02-22 11:01:38,803 - log/train6.log - INFO - iteration:86 step:5900/10100, NER loss:      nan
2019-02-22 11:01:40,984 - log/train6.log - INFO - iteration:86 step:6000/10100, NER loss:      nan
2019-02-22 11:01:43,051 - log/train6.log - INFO - iteration:86 step:6100/10100, NER loss:      nan
2019-02-22 11:01:45,195 - log/train6.log - INFO - iteration:86 step:6200/10100, NER loss:      nan
2019-02-22 11:01:47,334 - log/train6.log - INFO - iteration:86 step:6300/10100, NER loss:      nan
2019-02-22 11:01:49,792 - log/train6.log - INFO - iteration:86 step:6400/10100, NER loss:      nan
2019-02-22 11:01:52,056 - log/train6.log - INFO - iteration:86 step:6500/10100, NER loss:      nan
2019-02-22 11:01:54,308 - log/train6.log - INFO - iteration:86 step:6600/10100, NER loss:      nan
2019-02-22 11:01:56,363 - log/train6.log - INFO - iteration:86 step:6700/10100, NER loss:      nan
2019-02-22 11:01:58,480 - log/train6.log - INFO - iteration:86 step:6800/10100, NER loss:      nan
2019-02-22 11:02:02,455 - log/train6.log - INFO - iteration:86 step:6900/10100, NER loss:      nan
2019-02-22 11:02:04,692 - log/train6.log - INFO - iteration:86 step:7000/10100, NER loss:      nan
2019-02-22 11:02:06,604 - log/train6.log - INFO - iteration:86 step:7100/10100, NER loss:      nan
2019-02-22 11:02:08,962 - log/train6.log - INFO - iteration:86 step:7200/10100, NER loss:      nan
2019-02-22 11:02:11,094 - log/train6.log - INFO - iteration:86 step:7300/10100, NER loss:      nan
2019-02-22 11:02:13,059 - log/train6.log - INFO - iteration:86 step:7400/10100, NER loss:      nan
2019-02-22 11:02:15,209 - log/train6.log - INFO - iteration:86 step:7500/10100, NER loss:      nan
2019-02-22 11:02:17,319 - log/train6.log - INFO - iteration:86 step:7600/10100, NER loss:      nan
2019-02-22 11:02:19,304 - log/train6.log - INFO - iteration:86 step:7700/10100, NER loss:      nan
2019-02-22 11:02:21,361 - log/train6.log - INFO - iteration:86 step:7800/10100, NER loss:      nan
2019-02-22 11:02:23,787 - log/train6.log - INFO - iteration:86 step:7900/10100, NER loss:      nan
2019-02-22 11:02:25,943 - log/train6.log - INFO - iteration:86 step:8000/10100, NER loss:      nan
2019-02-22 11:02:28,423 - log/train6.log - INFO - iteration:86 step:8100/10100, NER loss:      nan
2019-02-22 11:02:30,913 - log/train6.log - INFO - iteration:86 step:8200/10100, NER loss:      nan
2019-02-22 11:02:33,235 - log/train6.log - INFO - iteration:86 step:8300/10100, NER loss:      nan
2019-02-22 11:02:35,362 - log/train6.log - INFO - iteration:86 step:8400/10100, NER loss:      nan
2019-02-22 11:02:37,817 - log/train6.log - INFO - iteration:86 step:8500/10100, NER loss:      nan
2019-02-22 11:02:40,617 - log/train6.log - INFO - iteration:86 step:8600/10100, NER loss:      nan
2019-02-22 11:02:43,085 - log/train6.log - INFO - iteration:86 step:8700/10100, NER loss:      nan
2019-02-22 11:02:45,651 - log/train6.log - INFO - iteration:86 step:8800/10100, NER loss:      nan
2019-02-22 11:02:48,035 - log/train6.log - INFO - iteration:86 step:8900/10100, NER loss:      nan
2019-02-22 11:02:50,656 - log/train6.log - INFO - iteration:86 step:9000/10100, NER loss:      nan
2019-02-22 11:02:52,857 - log/train6.log - INFO - iteration:86 step:9100/10100, NER loss:      nan
2019-02-22 11:02:55,211 - log/train6.log - INFO - iteration:86 step:9200/10100, NER loss:      nan
2019-02-22 11:02:57,622 - log/train6.log - INFO - iteration:86 step:9300/10100, NER loss:      nan
2019-02-22 11:03:00,010 - log/train6.log - INFO - iteration:86 step:9400/10100, NER loss:      nan
2019-02-22 11:03:02,203 - log/train6.log - INFO - iteration:86 step:9500/10100, NER loss:      nan
2019-02-22 11:03:04,981 - log/train6.log - INFO - iteration:86 step:9600/10100, NER loss:      nan
2019-02-22 11:03:07,504 - log/train6.log - INFO - iteration:86 step:9700/10100, NER loss:      nan
2019-02-22 11:03:10,105 - log/train6.log - INFO - iteration:86 step:9800/10100, NER loss:      nan
2019-02-22 11:03:12,433 - log/train6.log - INFO - iteration:86 step:9900/10100, NER loss:      nan
2019-02-22 11:03:14,492 - log/train6.log - INFO - iteration:86 step:10000/10100, NER loss:      nan
2019-02-22 11:03:16,886 - log/train6.log - INFO - iteration:87 step:0/10100, NER loss:      nan
2019-02-22 11:03:16,887 - log/train6.log - INFO - evaluate:dev
2019-02-22 11:03:23,577 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:03:23,577 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:03:23,577 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:03:23,577 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:03:23,577 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:03:23,577 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:03:23,577 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:03:23,577 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:03:23,581 - log/train6.log - INFO - evaluate:test
2019-02-22 11:03:25,087 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:03:25,087 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:03:25,087 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:03:25,087 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:03:25,087 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:03:25,087 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:03:25,088 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:03:25,088 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:03:27,567 - log/train6.log - INFO - iteration:87 step:100/10100, NER loss:      nan
2019-02-22 11:03:29,847 - log/train6.log - INFO - iteration:87 step:200/10100, NER loss:      nan
2019-02-22 11:03:31,843 - log/train6.log - INFO - iteration:87 step:300/10100, NER loss:      nan
2019-02-22 11:03:34,008 - log/train6.log - INFO - iteration:87 step:400/10100, NER loss:      nan
2019-02-22 11:03:36,475 - log/train6.log - INFO - iteration:87 step:500/10100, NER loss:      nan
2019-02-22 11:03:39,048 - log/train6.log - INFO - iteration:87 step:600/10100, NER loss:      nan
2019-02-22 11:03:41,442 - log/train6.log - INFO - iteration:87 step:700/10100, NER loss:      nan
2019-02-22 11:03:43,914 - log/train6.log - INFO - iteration:87 step:800/10100, NER loss:      nan
2019-02-22 11:03:46,393 - log/train6.log - INFO - iteration:87 step:900/10100, NER loss:      nan
2019-02-22 11:03:48,988 - log/train6.log - INFO - iteration:87 step:1000/10100, NER loss:      nan
2019-02-22 11:03:51,585 - log/train6.log - INFO - iteration:87 step:1100/10100, NER loss:      nan
2019-02-22 11:03:53,956 - log/train6.log - INFO - iteration:87 step:1200/10100, NER loss:      nan
2019-02-22 11:03:56,830 - log/train6.log - INFO - iteration:87 step:1300/10100, NER loss:      nan
2019-02-22 11:03:59,257 - log/train6.log - INFO - iteration:87 step:1400/10100, NER loss:      nan
2019-02-22 11:04:01,799 - log/train6.log - INFO - iteration:87 step:1500/10100, NER loss:      nan
2019-02-22 11:04:04,185 - log/train6.log - INFO - iteration:87 step:1600/10100, NER loss:      nan
2019-02-22 11:04:06,324 - log/train6.log - INFO - iteration:87 step:1700/10100, NER loss:      nan
2019-02-22 11:04:08,521 - log/train6.log - INFO - iteration:87 step:1800/10100, NER loss:      nan
2019-02-22 11:04:10,926 - log/train6.log - INFO - iteration:87 step:1900/10100, NER loss:      nan
2019-02-22 11:04:13,044 - log/train6.log - INFO - iteration:87 step:2000/10100, NER loss:      nan
2019-02-22 11:04:15,229 - log/train6.log - INFO - iteration:87 step:2100/10100, NER loss:      nan
2019-02-22 11:04:17,816 - log/train6.log - INFO - iteration:87 step:2200/10100, NER loss:      nan
2019-02-22 11:04:20,299 - log/train6.log - INFO - iteration:87 step:2300/10100, NER loss:      nan
2019-02-22 11:04:22,503 - log/train6.log - INFO - iteration:87 step:2400/10100, NER loss:      nan
2019-02-22 11:04:24,856 - log/train6.log - INFO - iteration:87 step:2500/10100, NER loss:      nan
2019-02-22 11:04:27,458 - log/train6.log - INFO - iteration:87 step:2600/10100, NER loss:      nan
2019-02-22 11:04:29,761 - log/train6.log - INFO - iteration:87 step:2700/10100, NER loss:      nan
2019-02-22 11:04:32,260 - log/train6.log - INFO - iteration:87 step:2800/10100, NER loss:      nan
2019-02-22 11:04:34,860 - log/train6.log - INFO - iteration:87 step:2900/10100, NER loss:      nan
2019-02-22 11:04:37,351 - log/train6.log - INFO - iteration:87 step:3000/10100, NER loss:      nan
2019-02-22 11:04:39,449 - log/train6.log - INFO - iteration:87 step:3100/10100, NER loss:      nan
2019-02-22 11:04:41,646 - log/train6.log - INFO - iteration:87 step:3200/10100, NER loss:      nan
2019-02-22 11:04:43,918 - log/train6.log - INFO - iteration:87 step:3300/10100, NER loss:      nan
2019-02-22 11:04:46,299 - log/train6.log - INFO - iteration:87 step:3400/10100, NER loss:      nan
2019-02-22 11:04:48,668 - log/train6.log - INFO - iteration:87 step:3500/10100, NER loss:      nan
2019-02-22 11:04:51,120 - log/train6.log - INFO - iteration:87 step:3600/10100, NER loss:      nan
2019-02-22 11:04:53,375 - log/train6.log - INFO - iteration:87 step:3700/10100, NER loss:      nan
2019-02-22 11:04:55,850 - log/train6.log - INFO - iteration:87 step:3800/10100, NER loss:      nan
2019-02-22 11:04:58,078 - log/train6.log - INFO - iteration:87 step:3900/10100, NER loss:      nan
2019-02-22 11:05:00,457 - log/train6.log - INFO - iteration:87 step:4000/10100, NER loss:      nan
2019-02-22 11:05:04,900 - log/train6.log - INFO - iteration:87 step:4100/10100, NER loss:      nan
2019-02-22 11:05:07,139 - log/train6.log - INFO - iteration:87 step:4200/10100, NER loss:      nan
2019-02-22 11:05:09,515 - log/train6.log - INFO - iteration:87 step:4300/10100, NER loss:      nan
2019-02-22 11:05:11,591 - log/train6.log - INFO - iteration:87 step:4400/10100, NER loss:      nan
2019-02-22 11:05:14,884 - log/train6.log - INFO - iteration:87 step:4500/10100, NER loss:      nan
2019-02-22 11:05:17,503 - log/train6.log - INFO - iteration:87 step:4600/10100, NER loss:      nan
2019-02-22 11:05:19,720 - log/train6.log - INFO - iteration:87 step:4700/10100, NER loss:      nan
2019-02-22 11:05:22,028 - log/train6.log - INFO - iteration:87 step:4800/10100, NER loss:      nan
2019-02-22 11:05:24,495 - log/train6.log - INFO - iteration:87 step:4900/10100, NER loss:      nan
2019-02-22 11:05:26,897 - log/train6.log - INFO - iteration:87 step:5000/10100, NER loss:      nan
2019-02-22 11:05:29,245 - log/train6.log - INFO - iteration:87 step:5100/10100, NER loss:      nan
2019-02-22 11:05:31,748 - log/train6.log - INFO - iteration:87 step:5200/10100, NER loss:      nan
2019-02-22 11:05:34,004 - log/train6.log - INFO - iteration:87 step:5300/10100, NER loss:      nan
2019-02-22 11:05:36,625 - log/train6.log - INFO - iteration:87 step:5400/10100, NER loss:      nan
2019-02-22 11:05:39,302 - log/train6.log - INFO - iteration:87 step:5500/10100, NER loss:      nan
2019-02-22 11:05:41,657 - log/train6.log - INFO - iteration:87 step:5600/10100, NER loss:      nan
2019-02-22 11:05:44,392 - log/train6.log - INFO - iteration:87 step:5700/10100, NER loss:      nan
2019-02-22 11:05:46,888 - log/train6.log - INFO - iteration:87 step:5800/10100, NER loss:      nan
2019-02-22 11:05:49,769 - log/train6.log - INFO - iteration:87 step:5900/10100, NER loss:      nan
2019-02-22 11:05:52,120 - log/train6.log - INFO - iteration:87 step:6000/10100, NER loss:      nan
2019-02-22 11:05:54,450 - log/train6.log - INFO - iteration:87 step:6100/10100, NER loss:      nan
2019-02-22 11:05:56,958 - log/train6.log - INFO - iteration:87 step:6200/10100, NER loss:      nan
2019-02-22 11:05:59,537 - log/train6.log - INFO - iteration:87 step:6300/10100, NER loss:      nan
2019-02-22 11:06:02,036 - log/train6.log - INFO - iteration:87 step:6400/10100, NER loss:      nan
2019-02-22 11:06:04,439 - log/train6.log - INFO - iteration:87 step:6500/10100, NER loss:      nan
2019-02-22 11:06:09,388 - log/train6.log - INFO - iteration:87 step:6600/10100, NER loss:      nan
2019-02-22 11:06:11,808 - log/train6.log - INFO - iteration:87 step:6700/10100, NER loss:      nan
2019-02-22 11:06:14,161 - log/train6.log - INFO - iteration:87 step:6800/10100, NER loss:      nan
2019-02-22 11:06:16,831 - log/train6.log - INFO - iteration:87 step:6900/10100, NER loss:      nan
2019-02-22 11:06:19,437 - log/train6.log - INFO - iteration:87 step:7000/10100, NER loss:      nan
2019-02-22 11:06:21,784 - log/train6.log - INFO - iteration:87 step:7100/10100, NER loss:      nan
2019-02-22 11:06:24,189 - log/train6.log - INFO - iteration:87 step:7200/10100, NER loss:      nan
2019-02-22 11:06:26,396 - log/train6.log - INFO - iteration:87 step:7300/10100, NER loss:      nan
2019-02-22 11:06:28,613 - log/train6.log - INFO - iteration:87 step:7400/10100, NER loss:      nan
2019-02-22 11:06:30,812 - log/train6.log - INFO - iteration:87 step:7500/10100, NER loss:      nan
2019-02-22 11:06:33,584 - log/train6.log - INFO - iteration:87 step:7600/10100, NER loss:      nan
2019-02-22 11:06:35,804 - log/train6.log - INFO - iteration:87 step:7700/10100, NER loss:      nan
2019-02-22 11:06:38,249 - log/train6.log - INFO - iteration:87 step:7800/10100, NER loss:      nan
2019-02-22 11:06:40,618 - log/train6.log - INFO - iteration:87 step:7900/10100, NER loss:      nan
2019-02-22 11:06:43,323 - log/train6.log - INFO - iteration:87 step:8000/10100, NER loss:      nan
2019-02-22 11:06:45,814 - log/train6.log - INFO - iteration:87 step:8100/10100, NER loss:      nan
2019-02-22 11:06:47,916 - log/train6.log - INFO - iteration:87 step:8200/10100, NER loss:      nan
2019-02-22 11:06:50,124 - log/train6.log - INFO - iteration:87 step:8300/10100, NER loss:      nan
2019-02-22 11:06:52,416 - log/train6.log - INFO - iteration:87 step:8400/10100, NER loss:      nan
2019-02-22 11:06:54,458 - log/train6.log - INFO - iteration:87 step:8500/10100, NER loss:      nan
2019-02-22 11:06:56,594 - log/train6.log - INFO - iteration:87 step:8600/10100, NER loss:      nan
2019-02-22 11:06:58,892 - log/train6.log - INFO - iteration:87 step:8700/10100, NER loss:      nan
2019-02-22 11:07:01,042 - log/train6.log - INFO - iteration:87 step:8800/10100, NER loss:      nan
2019-02-22 11:07:03,173 - log/train6.log - INFO - iteration:87 step:8900/10100, NER loss:      nan
2019-02-22 11:07:05,249 - log/train6.log - INFO - iteration:87 step:9000/10100, NER loss:      nan
2019-02-22 11:07:07,427 - log/train6.log - INFO - iteration:87 step:9100/10100, NER loss:      nan
2019-02-22 11:07:09,565 - log/train6.log - INFO - iteration:87 step:9200/10100, NER loss:      nan
2019-02-22 11:07:11,750 - log/train6.log - INFO - iteration:87 step:9300/10100, NER loss:      nan
2019-02-22 11:07:13,835 - log/train6.log - INFO - iteration:87 step:9400/10100, NER loss:      nan
2019-02-22 11:07:15,788 - log/train6.log - INFO - iteration:87 step:9500/10100, NER loss:      nan
2019-02-22 11:07:20,424 - log/train6.log - INFO - iteration:87 step:9600/10100, NER loss:      nan
2019-02-22 11:07:22,570 - log/train6.log - INFO - iteration:87 step:9700/10100, NER loss:      nan
2019-02-22 11:07:24,650 - log/train6.log - INFO - iteration:87 step:9800/10100, NER loss:      nan
2019-02-22 11:07:26,859 - log/train6.log - INFO - iteration:87 step:9900/10100, NER loss:      nan
2019-02-22 11:07:28,946 - log/train6.log - INFO - iteration:87 step:10000/10100, NER loss:      nan
2019-02-22 11:07:31,164 - log/train6.log - INFO - iteration:88 step:0/10100, NER loss:      nan
2019-02-22 11:07:31,164 - log/train6.log - INFO - evaluate:dev
2019-02-22 11:07:37,737 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:07:37,737 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:07:37,738 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:07:37,738 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:07:37,738 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:07:37,738 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:07:37,738 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:07:37,738 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:07:37,741 - log/train6.log - INFO - evaluate:test
2019-02-22 11:07:39,198 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:07:39,200 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:07:39,200 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:07:39,200 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:07:39,200 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:07:39,200 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:07:39,200 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:07:39,200 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:07:41,226 - log/train6.log - INFO - iteration:88 step:100/10100, NER loss:      nan
2019-02-22 11:07:43,271 - log/train6.log - INFO - iteration:88 step:200/10100, NER loss:      nan
2019-02-22 11:07:45,242 - log/train6.log - INFO - iteration:88 step:300/10100, NER loss:      nan
2019-02-22 11:07:47,499 - log/train6.log - INFO - iteration:88 step:400/10100, NER loss:      nan
2019-02-22 11:07:50,053 - log/train6.log - INFO - iteration:88 step:500/10100, NER loss:      nan
2019-02-22 11:07:52,290 - log/train6.log - INFO - iteration:88 step:600/10100, NER loss:      nan
2019-02-22 11:07:54,375 - log/train6.log - INFO - iteration:88 step:700/10100, NER loss:      nan
2019-02-22 11:07:56,653 - log/train6.log - INFO - iteration:88 step:800/10100, NER loss:      nan
2019-02-22 11:07:58,755 - log/train6.log - INFO - iteration:88 step:900/10100, NER loss:      nan
2019-02-22 11:08:00,778 - log/train6.log - INFO - iteration:88 step:1000/10100, NER loss:      nan
2019-02-22 11:08:02,963 - log/train6.log - INFO - iteration:88 step:1100/10100, NER loss:      nan
2019-02-22 11:08:04,900 - log/train6.log - INFO - iteration:88 step:1200/10100, NER loss:      nan
2019-02-22 11:08:07,187 - log/train6.log - INFO - iteration:88 step:1300/10100, NER loss:      nan
2019-02-22 11:08:11,435 - log/train6.log - INFO - iteration:88 step:1400/10100, NER loss:      nan
2019-02-22 11:08:13,615 - log/train6.log - INFO - iteration:88 step:1500/10100, NER loss:      nan
2019-02-22 11:08:15,783 - log/train6.log - INFO - iteration:88 step:1600/10100, NER loss:      nan
2019-02-22 11:08:18,014 - log/train6.log - INFO - iteration:88 step:1700/10100, NER loss:      nan
2019-02-22 11:08:20,275 - log/train6.log - INFO - iteration:88 step:1800/10100, NER loss:      nan
2019-02-22 11:08:22,335 - log/train6.log - INFO - iteration:88 step:1900/10100, NER loss:      nan
2019-02-22 11:08:24,191 - log/train6.log - INFO - iteration:88 step:2000/10100, NER loss:      nan
2019-02-22 11:08:26,481 - log/train6.log - INFO - iteration:88 step:2100/10100, NER loss:      nan
2019-02-22 11:08:28,968 - log/train6.log - INFO - iteration:88 step:2200/10100, NER loss:      nan
2019-02-22 11:08:31,171 - log/train6.log - INFO - iteration:88 step:2300/10100, NER loss:      nan
2019-02-22 11:08:33,291 - log/train6.log - INFO - iteration:88 step:2400/10100, NER loss:      nan
2019-02-22 11:08:35,281 - log/train6.log - INFO - iteration:88 step:2500/10100, NER loss:      nan
2019-02-22 11:08:37,535 - log/train6.log - INFO - iteration:88 step:2600/10100, NER loss:      nan
2019-02-22 11:08:39,786 - log/train6.log - INFO - iteration:88 step:2700/10100, NER loss:      nan
2019-02-22 11:08:41,962 - log/train6.log - INFO - iteration:88 step:2800/10100, NER loss:      nan
2019-02-22 11:08:44,032 - log/train6.log - INFO - iteration:88 step:2900/10100, NER loss:      nan
2019-02-22 11:08:46,034 - log/train6.log - INFO - iteration:88 step:3000/10100, NER loss:      nan
2019-02-22 11:08:48,077 - log/train6.log - INFO - iteration:88 step:3100/10100, NER loss:      nan
2019-02-22 11:08:50,297 - log/train6.log - INFO - iteration:88 step:3200/10100, NER loss:      nan
2019-02-22 11:08:52,998 - log/train6.log - INFO - iteration:88 step:3300/10100, NER loss:      nan
2019-02-22 11:08:55,267 - log/train6.log - INFO - iteration:88 step:3400/10100, NER loss:      nan
2019-02-22 11:08:57,322 - log/train6.log - INFO - iteration:88 step:3500/10100, NER loss:      nan
2019-02-22 11:08:59,308 - log/train6.log - INFO - iteration:88 step:3600/10100, NER loss:      nan
2019-02-22 11:09:01,208 - log/train6.log - INFO - iteration:88 step:3700/10100, NER loss:      nan
2019-02-22 11:09:03,164 - log/train6.log - INFO - iteration:88 step:3800/10100, NER loss:      nan
2019-02-22 11:09:05,189 - log/train6.log - INFO - iteration:88 step:3900/10100, NER loss:      nan
2019-02-22 11:09:07,920 - log/train6.log - INFO - iteration:88 step:4000/10100, NER loss:      nan
2019-02-22 11:09:09,922 - log/train6.log - INFO - iteration:88 step:4100/10100, NER loss:      nan
2019-02-22 11:09:12,177 - log/train6.log - INFO - iteration:88 step:4200/10100, NER loss:      nan
2019-02-22 11:09:14,368 - log/train6.log - INFO - iteration:88 step:4300/10100, NER loss:      nan
2019-02-22 11:09:16,382 - log/train6.log - INFO - iteration:88 step:4400/10100, NER loss:      nan
2019-02-22 11:09:18,715 - log/train6.log - INFO - iteration:88 step:4500/10100, NER loss:      nan
2019-02-22 11:09:20,797 - log/train6.log - INFO - iteration:88 step:4600/10100, NER loss:      nan
2019-02-22 11:09:23,153 - log/train6.log - INFO - iteration:88 step:4700/10100, NER loss:      nan
2019-02-22 11:09:25,241 - log/train6.log - INFO - iteration:88 step:4800/10100, NER loss:      nan
2019-02-22 11:09:27,631 - log/train6.log - INFO - iteration:88 step:4900/10100, NER loss:      nan
2019-02-22 11:09:29,973 - log/train6.log - INFO - iteration:88 step:5000/10100, NER loss:      nan
2019-02-22 11:09:31,909 - log/train6.log - INFO - iteration:88 step:5100/10100, NER loss:      nan
2019-02-22 11:09:34,308 - log/train6.log - INFO - iteration:88 step:5200/10100, NER loss:      nan
2019-02-22 11:09:36,876 - log/train6.log - INFO - iteration:88 step:5300/10100, NER loss:      nan
2019-02-22 11:09:39,249 - log/train6.log - INFO - iteration:88 step:5400/10100, NER loss:      nan
2019-02-22 11:09:41,370 - log/train6.log - INFO - iteration:88 step:5500/10100, NER loss:      nan
2019-02-22 11:09:43,486 - log/train6.log - INFO - iteration:88 step:5600/10100, NER loss:      nan
2019-02-22 11:09:45,863 - log/train6.log - INFO - iteration:88 step:5700/10100, NER loss:      nan
2019-02-22 11:09:48,217 - log/train6.log - INFO - iteration:88 step:5800/10100, NER loss:      nan
2019-02-22 11:09:50,207 - log/train6.log - INFO - iteration:88 step:5900/10100, NER loss:      nan
2019-02-22 11:09:52,997 - log/train6.log - INFO - iteration:88 step:6000/10100, NER loss:      nan
2019-02-22 11:09:55,448 - log/train6.log - INFO - iteration:88 step:6100/10100, NER loss:      nan
2019-02-22 11:09:57,908 - log/train6.log - INFO - iteration:88 step:6200/10100, NER loss:      nan
2019-02-22 11:10:00,085 - log/train6.log - INFO - iteration:88 step:6300/10100, NER loss:      nan
2019-02-22 11:10:02,483 - log/train6.log - INFO - iteration:88 step:6400/10100, NER loss:      nan
2019-02-22 11:10:04,725 - log/train6.log - INFO - iteration:88 step:6500/10100, NER loss:      nan
2019-02-22 11:10:07,025 - log/train6.log - INFO - iteration:88 step:6600/10100, NER loss:      nan
2019-02-22 11:10:09,413 - log/train6.log - INFO - iteration:88 step:6700/10100, NER loss:      nan
2019-02-22 11:10:11,745 - log/train6.log - INFO - iteration:88 step:6800/10100, NER loss:      nan
2019-02-22 11:10:13,943 - log/train6.log - INFO - iteration:88 step:6900/10100, NER loss:      nan
2019-02-22 11:10:16,354 - log/train6.log - INFO - iteration:88 step:7000/10100, NER loss:      nan
2019-02-22 11:10:18,719 - log/train6.log - INFO - iteration:88 step:7100/10100, NER loss:      nan
2019-02-22 11:10:20,860 - log/train6.log - INFO - iteration:88 step:7200/10100, NER loss:      nan
2019-02-22 11:10:25,708 - log/train6.log - INFO - iteration:88 step:7300/10100, NER loss:      nan
2019-02-22 11:10:28,329 - log/train6.log - INFO - iteration:88 step:7400/10100, NER loss:      nan
2019-02-22 11:10:30,968 - log/train6.log - INFO - iteration:88 step:7500/10100, NER loss:      nan
2019-02-22 11:10:33,368 - log/train6.log - INFO - iteration:88 step:7600/10100, NER loss:      nan
2019-02-22 11:10:35,730 - log/train6.log - INFO - iteration:88 step:7700/10100, NER loss:      nan
2019-02-22 11:10:38,094 - log/train6.log - INFO - iteration:88 step:7800/10100, NER loss:      nan
2019-02-22 11:10:40,439 - log/train6.log - INFO - iteration:88 step:7900/10100, NER loss:      nan
2019-02-22 11:10:42,847 - log/train6.log - INFO - iteration:88 step:8000/10100, NER loss:      nan
2019-02-22 11:10:45,428 - log/train6.log - INFO - iteration:88 step:8100/10100, NER loss:      nan
2019-02-22 11:10:47,943 - log/train6.log - INFO - iteration:88 step:8200/10100, NER loss:      nan
2019-02-22 11:10:50,233 - log/train6.log - INFO - iteration:88 step:8300/10100, NER loss:      nan
2019-02-22 11:10:52,777 - log/train6.log - INFO - iteration:88 step:8400/10100, NER loss:      nan
2019-02-22 11:10:54,993 - log/train6.log - INFO - iteration:88 step:8500/10100, NER loss:      nan
2019-02-22 11:10:57,098 - log/train6.log - INFO - iteration:88 step:8600/10100, NER loss:      nan
2019-02-22 11:10:59,533 - log/train6.log - INFO - iteration:88 step:8700/10100, NER loss:      nan
2019-02-22 11:11:01,772 - log/train6.log - INFO - iteration:88 step:8800/10100, NER loss:      nan
2019-02-22 11:11:04,083 - log/train6.log - INFO - iteration:88 step:8900/10100, NER loss:      nan
2019-02-22 11:11:06,516 - log/train6.log - INFO - iteration:88 step:9000/10100, NER loss:      nan
2019-02-22 11:11:08,974 - log/train6.log - INFO - iteration:88 step:9100/10100, NER loss:      nan
2019-02-22 11:11:11,199 - log/train6.log - INFO - iteration:88 step:9200/10100, NER loss:      nan
2019-02-22 11:11:15,458 - log/train6.log - INFO - iteration:88 step:9300/10100, NER loss:      nan
2019-02-22 11:11:17,906 - log/train6.log - INFO - iteration:88 step:9400/10100, NER loss:      nan
2019-02-22 11:11:20,082 - log/train6.log - INFO - iteration:88 step:9500/10100, NER loss:      nan
2019-02-22 11:11:22,615 - log/train6.log - INFO - iteration:88 step:9600/10100, NER loss:      nan
2019-02-22 11:11:25,198 - log/train6.log - INFO - iteration:88 step:9700/10100, NER loss:      nan
2019-02-22 11:11:27,427 - log/train6.log - INFO - iteration:88 step:9800/10100, NER loss:      nan
2019-02-22 11:11:29,657 - log/train6.log - INFO - iteration:88 step:9900/10100, NER loss:      nan
2019-02-22 11:11:32,172 - log/train6.log - INFO - iteration:88 step:10000/10100, NER loss:      nan
2019-02-22 11:11:34,596 - log/train6.log - INFO - iteration:89 step:0/10100, NER loss:      nan
2019-02-22 11:11:34,596 - log/train6.log - INFO - evaluate:dev
2019-02-22 11:11:41,581 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:11:41,582 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:11:41,582 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:11:41,582 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:11:41,582 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:11:41,582 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:11:41,582 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:11:41,583 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:11:41,586 - log/train6.log - INFO - evaluate:test
2019-02-22 11:11:43,230 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:11:43,231 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:11:43,231 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:11:43,231 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:11:43,231 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:11:43,231 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:11:43,231 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:11:43,231 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:11:45,756 - log/train6.log - INFO - iteration:89 step:100/10100, NER loss:      nan
2019-02-22 11:11:47,951 - log/train6.log - INFO - iteration:89 step:200/10100, NER loss:      nan
2019-02-22 11:11:50,111 - log/train6.log - INFO - iteration:89 step:300/10100, NER loss:      nan
2019-02-22 11:11:52,398 - log/train6.log - INFO - iteration:89 step:400/10100, NER loss:      nan
2019-02-22 11:11:54,908 - log/train6.log - INFO - iteration:89 step:500/10100, NER loss:      nan
2019-02-22 11:11:57,372 - log/train6.log - INFO - iteration:89 step:600/10100, NER loss:      nan
2019-02-22 11:11:59,716 - log/train6.log - INFO - iteration:89 step:700/10100, NER loss:      nan
2019-02-22 11:12:01,970 - log/train6.log - INFO - iteration:89 step:800/10100, NER loss:      nan
2019-02-22 11:12:04,266 - log/train6.log - INFO - iteration:89 step:900/10100, NER loss:      nan
2019-02-22 11:12:06,346 - log/train6.log - INFO - iteration:89 step:1000/10100, NER loss:      nan
2019-02-22 11:12:08,443 - log/train6.log - INFO - iteration:89 step:1100/10100, NER loss:      nan
2019-02-22 11:12:10,914 - log/train6.log - INFO - iteration:89 step:1200/10100, NER loss:      nan
2019-02-22 11:12:15,585 - log/train6.log - INFO - iteration:89 step:1300/10100, NER loss:      nan
2019-02-22 11:12:17,943 - log/train6.log - INFO - iteration:89 step:1400/10100, NER loss:      nan
2019-02-22 11:12:20,414 - log/train6.log - INFO - iteration:89 step:1500/10100, NER loss:      nan
2019-02-22 11:12:22,492 - log/train6.log - INFO - iteration:89 step:1600/10100, NER loss:      nan
2019-02-22 11:12:24,609 - log/train6.log - INFO - iteration:89 step:1700/10100, NER loss:      nan
2019-02-22 11:12:26,766 - log/train6.log - INFO - iteration:89 step:1800/10100, NER loss:      nan
2019-02-22 11:12:28,939 - log/train6.log - INFO - iteration:89 step:1900/10100, NER loss:      nan
2019-02-22 11:12:31,180 - log/train6.log - INFO - iteration:89 step:2000/10100, NER loss:      nan
2019-02-22 11:12:33,306 - log/train6.log - INFO - iteration:89 step:2100/10100, NER loss:      nan
2019-02-22 11:12:35,486 - log/train6.log - INFO - iteration:89 step:2200/10100, NER loss:      nan
2019-02-22 11:12:37,529 - log/train6.log - INFO - iteration:89 step:2300/10100, NER loss:      nan
2019-02-22 11:12:41,605 - log/train6.log - INFO - iteration:89 step:2400/10100, NER loss:      nan
2019-02-22 11:12:43,586 - log/train6.log - INFO - iteration:89 step:2500/10100, NER loss:      nan
2019-02-22 11:12:45,572 - log/train6.log - INFO - iteration:89 step:2600/10100, NER loss:      nan
2019-02-22 11:12:47,619 - log/train6.log - INFO - iteration:89 step:2700/10100, NER loss:      nan
2019-02-22 11:12:49,695 - log/train6.log - INFO - iteration:89 step:2800/10100, NER loss:      nan
2019-02-22 11:12:52,132 - log/train6.log - INFO - iteration:89 step:2900/10100, NER loss:      nan
2019-02-22 11:12:54,540 - log/train6.log - INFO - iteration:89 step:3000/10100, NER loss:      nan
2019-02-22 11:12:57,505 - log/train6.log - INFO - iteration:89 step:3100/10100, NER loss:      nan
2019-02-22 11:13:01,489 - log/train6.log - INFO - iteration:89 step:3200/10100, NER loss:      nan
2019-02-22 11:13:03,947 - log/train6.log - INFO - iteration:89 step:3300/10100, NER loss:      nan
2019-02-22 11:13:06,391 - log/train6.log - INFO - iteration:89 step:3400/10100, NER loss:      nan
2019-02-22 11:13:08,687 - log/train6.log - INFO - iteration:89 step:3500/10100, NER loss:      nan
2019-02-22 11:13:11,182 - log/train6.log - INFO - iteration:89 step:3600/10100, NER loss:      nan
2019-02-22 11:13:13,535 - log/train6.log - INFO - iteration:89 step:3700/10100, NER loss:      nan
2019-02-22 11:13:15,985 - log/train6.log - INFO - iteration:89 step:3800/10100, NER loss:      nan
2019-02-22 11:13:18,520 - log/train6.log - INFO - iteration:89 step:3900/10100, NER loss:      nan
2019-02-22 11:13:21,044 - log/train6.log - INFO - iteration:89 step:4000/10100, NER loss:      nan
2019-02-22 11:13:23,486 - log/train6.log - INFO - iteration:89 step:4100/10100, NER loss:      nan
2019-02-22 11:13:25,680 - log/train6.log - INFO - iteration:89 step:4200/10100, NER loss:      nan
2019-02-22 11:13:27,843 - log/train6.log - INFO - iteration:89 step:4300/10100, NER loss:      nan
2019-02-22 11:13:30,383 - log/train6.log - INFO - iteration:89 step:4400/10100, NER loss:      nan
2019-02-22 11:13:32,822 - log/train6.log - INFO - iteration:89 step:4500/10100, NER loss:      nan
2019-02-22 11:13:35,433 - log/train6.log - INFO - iteration:89 step:4600/10100, NER loss:      nan
2019-02-22 11:13:38,005 - log/train6.log - INFO - iteration:89 step:4700/10100, NER loss:      nan
2019-02-22 11:13:40,373 - log/train6.log - INFO - iteration:89 step:4800/10100, NER loss:      nan
2019-02-22 11:13:42,937 - log/train6.log - INFO - iteration:89 step:4900/10100, NER loss:      nan
2019-02-22 11:13:45,356 - log/train6.log - INFO - iteration:89 step:5000/10100, NER loss:      nan
2019-02-22 11:13:47,930 - log/train6.log - INFO - iteration:89 step:5100/10100, NER loss:      nan
2019-02-22 11:13:50,848 - log/train6.log - INFO - iteration:89 step:5200/10100, NER loss:      nan
2019-02-22 11:13:53,197 - log/train6.log - INFO - iteration:89 step:5300/10100, NER loss:      nan
2019-02-22 11:13:55,421 - log/train6.log - INFO - iteration:89 step:5400/10100, NER loss:      nan
2019-02-22 11:13:57,947 - log/train6.log - INFO - iteration:89 step:5500/10100, NER loss:      nan
2019-02-22 11:14:00,297 - log/train6.log - INFO - iteration:89 step:5600/10100, NER loss:      nan
2019-02-22 11:14:02,510 - log/train6.log - INFO - iteration:89 step:5700/10100, NER loss:      nan
2019-02-22 11:14:04,435 - log/train6.log - INFO - iteration:89 step:5800/10100, NER loss:      nan
2019-02-22 11:14:06,788 - log/train6.log - INFO - iteration:89 step:5900/10100, NER loss:      nan
2019-02-22 11:14:09,242 - log/train6.log - INFO - iteration:89 step:6000/10100, NER loss:      nan
2019-02-22 11:14:11,533 - log/train6.log - INFO - iteration:89 step:6100/10100, NER loss:      nan
2019-02-22 11:14:13,746 - log/train6.log - INFO - iteration:89 step:6200/10100, NER loss:      nan
2019-02-22 11:14:15,893 - log/train6.log - INFO - iteration:89 step:6300/10100, NER loss:      nan
2019-02-22 11:14:17,986 - log/train6.log - INFO - iteration:89 step:6400/10100, NER loss:      nan
2019-02-22 11:14:20,184 - log/train6.log - INFO - iteration:89 step:6500/10100, NER loss:      nan
2019-02-22 11:14:22,300 - log/train6.log - INFO - iteration:89 step:6600/10100, NER loss:      nan
2019-02-22 11:14:24,205 - log/train6.log - INFO - iteration:89 step:6700/10100, NER loss:      nan
2019-02-22 11:14:26,275 - log/train6.log - INFO - iteration:89 step:6800/10100, NER loss:      nan
2019-02-22 11:14:28,407 - log/train6.log - INFO - iteration:89 step:6900/10100, NER loss:      nan
2019-02-22 11:14:30,869 - log/train6.log - INFO - iteration:89 step:7000/10100, NER loss:      nan
2019-02-22 11:14:33,359 - log/train6.log - INFO - iteration:89 step:7100/10100, NER loss:      nan
2019-02-22 11:14:35,458 - log/train6.log - INFO - iteration:89 step:7200/10100, NER loss:      nan
2019-02-22 11:14:37,513 - log/train6.log - INFO - iteration:89 step:7300/10100, NER loss:      nan
2019-02-22 11:14:39,589 - log/train6.log - INFO - iteration:89 step:7400/10100, NER loss:      nan
2019-02-22 11:14:42,166 - log/train6.log - INFO - iteration:89 step:7500/10100, NER loss:      nan
2019-02-22 11:14:44,665 - log/train6.log - INFO - iteration:89 step:7600/10100, NER loss:      nan
2019-02-22 11:14:46,989 - log/train6.log - INFO - iteration:89 step:7700/10100, NER loss:      nan
2019-02-22 11:14:49,057 - log/train6.log - INFO - iteration:89 step:7800/10100, NER loss:      nan
2019-02-22 11:14:51,302 - log/train6.log - INFO - iteration:89 step:7900/10100, NER loss:      nan
2019-02-22 11:14:53,629 - log/train6.log - INFO - iteration:89 step:8000/10100, NER loss:      nan
2019-02-22 11:14:55,755 - log/train6.log - INFO - iteration:89 step:8100/10100, NER loss:      nan
2019-02-22 11:14:57,838 - log/train6.log - INFO - iteration:89 step:8200/10100, NER loss:      nan
2019-02-22 11:14:59,882 - log/train6.log - INFO - iteration:89 step:8300/10100, NER loss:      nan
2019-02-22 11:15:02,052 - log/train6.log - INFO - iteration:89 step:8400/10100, NER loss:      nan
2019-02-22 11:15:04,239 - log/train6.log - INFO - iteration:89 step:8500/10100, NER loss:      nan
2019-02-22 11:15:06,505 - log/train6.log - INFO - iteration:89 step:8600/10100, NER loss:      nan
2019-02-22 11:15:08,626 - log/train6.log - INFO - iteration:89 step:8700/10100, NER loss:      nan
2019-02-22 11:15:10,960 - log/train6.log - INFO - iteration:89 step:8800/10100, NER loss:      nan
2019-02-22 11:15:13,206 - log/train6.log - INFO - iteration:89 step:8900/10100, NER loss:      nan
2019-02-22 11:15:15,509 - log/train6.log - INFO - iteration:89 step:9000/10100, NER loss:      nan
2019-02-22 11:15:17,638 - log/train6.log - INFO - iteration:89 step:9100/10100, NER loss:      nan
2019-02-22 11:15:19,948 - log/train6.log - INFO - iteration:89 step:9200/10100, NER loss:      nan
2019-02-22 11:15:22,041 - log/train6.log - INFO - iteration:89 step:9300/10100, NER loss:      nan
2019-02-22 11:15:24,293 - log/train6.log - INFO - iteration:89 step:9400/10100, NER loss:      nan
2019-02-22 11:15:26,348 - log/train6.log - INFO - iteration:89 step:9500/10100, NER loss:      nan
2019-02-22 11:15:28,211 - log/train6.log - INFO - iteration:89 step:9600/10100, NER loss:      nan
2019-02-22 11:15:30,398 - log/train6.log - INFO - iteration:89 step:9700/10100, NER loss:      nan
2019-02-22 11:15:32,766 - log/train6.log - INFO - iteration:89 step:9800/10100, NER loss:      nan
2019-02-22 11:15:34,792 - log/train6.log - INFO - iteration:89 step:9900/10100, NER loss:      nan
2019-02-22 11:15:36,828 - log/train6.log - INFO - iteration:89 step:10000/10100, NER loss:      nan
2019-02-22 11:15:38,940 - log/train6.log - INFO - iteration:90 step:0/10100, NER loss:      nan
2019-02-22 11:15:38,940 - log/train6.log - INFO - evaluate:dev
2019-02-22 11:15:45,429 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:15:45,430 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:15:45,430 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:15:45,430 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:15:45,430 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:15:45,430 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:15:45,430 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:15:45,430 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:15:45,433 - log/train6.log - INFO - evaluate:test
2019-02-22 11:15:46,890 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:15:46,890 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:15:46,890 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:15:46,890 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:15:46,890 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:15:46,890 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:15:46,890 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:15:46,891 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:15:48,989 - log/train6.log - INFO - iteration:90 step:100/10100, NER loss:      nan
2019-02-22 11:15:51,144 - log/train6.log - INFO - iteration:90 step:200/10100, NER loss:      nan
2019-02-22 11:15:55,489 - log/train6.log - INFO - iteration:90 step:300/10100, NER loss:      nan
2019-02-22 11:15:57,583 - log/train6.log - INFO - iteration:90 step:400/10100, NER loss:      nan
2019-02-22 11:15:59,615 - log/train6.log - INFO - iteration:90 step:500/10100, NER loss:      nan
2019-02-22 11:16:01,871 - log/train6.log - INFO - iteration:90 step:600/10100, NER loss:      nan
2019-02-22 11:16:04,036 - log/train6.log - INFO - iteration:90 step:700/10100, NER loss:      nan
2019-02-22 11:16:06,602 - log/train6.log - INFO - iteration:90 step:800/10100, NER loss:      nan
2019-02-22 11:16:08,597 - log/train6.log - INFO - iteration:90 step:900/10100, NER loss:      nan
2019-02-22 11:16:10,771 - log/train6.log - INFO - iteration:90 step:1000/10100, NER loss:      nan
2019-02-22 11:16:12,824 - log/train6.log - INFO - iteration:90 step:1100/10100, NER loss:      nan
2019-02-22 11:16:15,066 - log/train6.log - INFO - iteration:90 step:1200/10100, NER loss:      nan
2019-02-22 11:16:17,442 - log/train6.log - INFO - iteration:90 step:1300/10100, NER loss:      nan
2019-02-22 11:16:19,601 - log/train6.log - INFO - iteration:90 step:1400/10100, NER loss:      nan
2019-02-22 11:16:21,826 - log/train6.log - INFO - iteration:90 step:1500/10100, NER loss:      nan
2019-02-22 11:16:24,352 - log/train6.log - INFO - iteration:90 step:1600/10100, NER loss:      nan
2019-02-22 11:16:26,673 - log/train6.log - INFO - iteration:90 step:1700/10100, NER loss:      nan
2019-02-22 11:16:28,920 - log/train6.log - INFO - iteration:90 step:1800/10100, NER loss:      nan
2019-02-22 11:16:31,327 - log/train6.log - INFO - iteration:90 step:1900/10100, NER loss:      nan
2019-02-22 11:16:33,306 - log/train6.log - INFO - iteration:90 step:2000/10100, NER loss:      nan
2019-02-22 11:16:35,416 - log/train6.log - INFO - iteration:90 step:2100/10100, NER loss:      nan
2019-02-22 11:16:37,698 - log/train6.log - INFO - iteration:90 step:2200/10100, NER loss:      nan
2019-02-22 11:16:39,672 - log/train6.log - INFO - iteration:90 step:2300/10100, NER loss:      nan
2019-02-22 11:16:41,782 - log/train6.log - INFO - iteration:90 step:2400/10100, NER loss:      nan
2019-02-22 11:16:43,754 - log/train6.log - INFO - iteration:90 step:2500/10100, NER loss:      nan
2019-02-22 11:16:45,905 - log/train6.log - INFO - iteration:90 step:2600/10100, NER loss:      nan
2019-02-22 11:16:47,938 - log/train6.log - INFO - iteration:90 step:2700/10100, NER loss:      nan
2019-02-22 11:16:49,933 - log/train6.log - INFO - iteration:90 step:2800/10100, NER loss:      nan
2019-02-22 11:16:52,071 - log/train6.log - INFO - iteration:90 step:2900/10100, NER loss:      nan
2019-02-22 11:16:54,378 - log/train6.log - INFO - iteration:90 step:3000/10100, NER loss:      nan
2019-02-22 11:16:56,586 - log/train6.log - INFO - iteration:90 step:3100/10100, NER loss:      nan
2019-02-22 11:16:58,823 - log/train6.log - INFO - iteration:90 step:3200/10100, NER loss:      nan
2019-02-22 11:17:01,059 - log/train6.log - INFO - iteration:90 step:3300/10100, NER loss:      nan
2019-02-22 11:17:03,108 - log/train6.log - INFO - iteration:90 step:3400/10100, NER loss:      nan
2019-02-22 11:17:05,645 - log/train6.log - INFO - iteration:90 step:3500/10100, NER loss:      nan
2019-02-22 11:17:08,205 - log/train6.log - INFO - iteration:90 step:3600/10100, NER loss:      nan
2019-02-22 11:17:10,962 - log/train6.log - INFO - iteration:90 step:3700/10100, NER loss:      nan
2019-02-22 11:17:13,136 - log/train6.log - INFO - iteration:90 step:3800/10100, NER loss:      nan
2019-02-22 11:17:15,327 - log/train6.log - INFO - iteration:90 step:3900/10100, NER loss:      nan
2019-02-22 11:17:17,579 - log/train6.log - INFO - iteration:90 step:4000/10100, NER loss:      nan
2019-02-22 11:17:19,729 - log/train6.log - INFO - iteration:90 step:4100/10100, NER loss:      nan
2019-02-22 11:17:21,865 - log/train6.log - INFO - iteration:90 step:4200/10100, NER loss:      nan
2019-02-22 11:17:24,231 - log/train6.log - INFO - iteration:90 step:4300/10100, NER loss:      nan
2019-02-22 11:17:26,277 - log/train6.log - INFO - iteration:90 step:4400/10100, NER loss:      nan
2019-02-22 11:17:28,530 - log/train6.log - INFO - iteration:90 step:4500/10100, NER loss:      nan
2019-02-22 11:17:30,956 - log/train6.log - INFO - iteration:90 step:4600/10100, NER loss:      nan
2019-02-22 11:17:33,189 - log/train6.log - INFO - iteration:90 step:4700/10100, NER loss:      nan
2019-02-22 11:17:35,208 - log/train6.log - INFO - iteration:90 step:4800/10100, NER loss:      nan
2019-02-22 11:17:37,332 - log/train6.log - INFO - iteration:90 step:4900/10100, NER loss:      nan
2019-02-22 11:17:39,436 - log/train6.log - INFO - iteration:90 step:5000/10100, NER loss:      nan
2019-02-22 11:17:41,523 - log/train6.log - INFO - iteration:90 step:5100/10100, NER loss:      nan
2019-02-22 11:17:43,707 - log/train6.log - INFO - iteration:90 step:5200/10100, NER loss:      nan
2019-02-22 11:17:45,888 - log/train6.log - INFO - iteration:90 step:5300/10100, NER loss:      nan
2019-02-22 11:17:48,054 - log/train6.log - INFO - iteration:90 step:5400/10100, NER loss:      nan
2019-02-22 11:17:49,909 - log/train6.log - INFO - iteration:90 step:5500/10100, NER loss:      nan
2019-02-22 11:17:52,025 - log/train6.log - INFO - iteration:90 step:5600/10100, NER loss:      nan
2019-02-22 11:17:53,955 - log/train6.log - INFO - iteration:90 step:5700/10100, NER loss:      nan
2019-02-22 11:17:56,001 - log/train6.log - INFO - iteration:90 step:5800/10100, NER loss:      nan
2019-02-22 11:17:58,170 - log/train6.log - INFO - iteration:90 step:5900/10100, NER loss:      nan
2019-02-22 11:18:00,248 - log/train6.log - INFO - iteration:90 step:6000/10100, NER loss:      nan
2019-02-22 11:18:02,475 - log/train6.log - INFO - iteration:90 step:6100/10100, NER loss:      nan
2019-02-22 11:18:04,619 - log/train6.log - INFO - iteration:90 step:6200/10100, NER loss:      nan
2019-02-22 11:18:06,817 - log/train6.log - INFO - iteration:90 step:6300/10100, NER loss:      nan
2019-02-22 11:18:09,237 - log/train6.log - INFO - iteration:90 step:6400/10100, NER loss:      nan
2019-02-22 11:18:11,242 - log/train6.log - INFO - iteration:90 step:6500/10100, NER loss:      nan
2019-02-22 11:18:13,309 - log/train6.log - INFO - iteration:90 step:6600/10100, NER loss:      nan
2019-02-22 11:18:15,385 - log/train6.log - INFO - iteration:90 step:6700/10100, NER loss:      nan
2019-02-22 11:18:17,930 - log/train6.log - INFO - iteration:90 step:6800/10100, NER loss:      nan
2019-02-22 11:18:20,393 - log/train6.log - INFO - iteration:90 step:6900/10100, NER loss:      nan
2019-02-22 11:18:22,957 - log/train6.log - INFO - iteration:90 step:7000/10100, NER loss:      nan
2019-02-22 11:18:25,254 - log/train6.log - INFO - iteration:90 step:7100/10100, NER loss:      nan
2019-02-22 11:18:27,295 - log/train6.log - INFO - iteration:90 step:7200/10100, NER loss:      nan
2019-02-22 11:18:29,385 - log/train6.log - INFO - iteration:90 step:7300/10100, NER loss:      nan
2019-02-22 11:18:31,812 - log/train6.log - INFO - iteration:90 step:7400/10100, NER loss:      nan
2019-02-22 11:18:34,035 - log/train6.log - INFO - iteration:90 step:7500/10100, NER loss:      nan
2019-02-22 11:18:36,298 - log/train6.log - INFO - iteration:90 step:7600/10100, NER loss:      nan
2019-02-22 11:18:38,563 - log/train6.log - INFO - iteration:90 step:7700/10100, NER loss:      nan
2019-02-22 11:18:41,398 - log/train6.log - INFO - iteration:90 step:7800/10100, NER loss:      nan
2019-02-22 11:18:47,934 - log/train6.log - INFO - iteration:90 step:7900/10100, NER loss:      nan
2019-02-22 11:18:50,293 - log/train6.log - INFO - iteration:90 step:8000/10100, NER loss:      nan
2019-02-22 11:18:52,569 - log/train6.log - INFO - iteration:90 step:8100/10100, NER loss:      nan
2019-02-22 11:18:54,710 - log/train6.log - INFO - iteration:90 step:8200/10100, NER loss:      nan
2019-02-22 11:18:57,088 - log/train6.log - INFO - iteration:90 step:8300/10100, NER loss:      nan
2019-02-22 11:18:58,943 - log/train6.log - INFO - iteration:90 step:8400/10100, NER loss:      nan
2019-02-22 11:19:01,162 - log/train6.log - INFO - iteration:90 step:8500/10100, NER loss:      nan
2019-02-22 11:19:03,594 - log/train6.log - INFO - iteration:90 step:8600/10100, NER loss:      nan
2019-02-22 11:19:06,143 - log/train6.log - INFO - iteration:90 step:8700/10100, NER loss:      nan
2019-02-22 11:19:08,398 - log/train6.log - INFO - iteration:90 step:8800/10100, NER loss:      nan
2019-02-22 11:19:10,511 - log/train6.log - INFO - iteration:90 step:8900/10100, NER loss:      nan
2019-02-22 11:19:13,027 - log/train6.log - INFO - iteration:90 step:9000/10100, NER loss:      nan
2019-02-22 11:19:15,165 - log/train6.log - INFO - iteration:90 step:9100/10100, NER loss:      nan
2019-02-22 11:19:17,558 - log/train6.log - INFO - iteration:90 step:9200/10100, NER loss:      nan
2019-02-22 11:19:19,995 - log/train6.log - INFO - iteration:90 step:9300/10100, NER loss:      nan
2019-02-22 11:19:22,208 - log/train6.log - INFO - iteration:90 step:9400/10100, NER loss:      nan
2019-02-22 11:19:24,869 - log/train6.log - INFO - iteration:90 step:9500/10100, NER loss:      nan
2019-02-22 11:19:27,094 - log/train6.log - INFO - iteration:90 step:9600/10100, NER loss:      nan
2019-02-22 11:19:29,164 - log/train6.log - INFO - iteration:90 step:9700/10100, NER loss:      nan
2019-02-22 11:19:31,221 - log/train6.log - INFO - iteration:90 step:9800/10100, NER loss:      nan
2019-02-22 11:19:33,344 - log/train6.log - INFO - iteration:90 step:9900/10100, NER loss:      nan
2019-02-22 11:19:35,593 - log/train6.log - INFO - iteration:90 step:10000/10100, NER loss:      nan
2019-02-22 11:19:37,638 - log/train6.log - INFO - iteration:91 step:0/10100, NER loss:      nan
2019-02-22 11:19:37,638 - log/train6.log - INFO - evaluate:dev
2019-02-22 11:19:44,316 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:19:44,317 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:19:44,317 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:19:44,317 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:19:44,317 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:19:44,317 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:19:44,318 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:19:44,318 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:19:44,321 - log/train6.log - INFO - evaluate:test
2019-02-22 11:19:45,786 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:19:45,786 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:19:45,786 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:19:45,786 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:19:45,786 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:19:45,787 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:19:45,787 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:19:45,787 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:19:47,789 - log/train6.log - INFO - iteration:91 step:100/10100, NER loss:      nan
2019-02-22 11:19:50,077 - log/train6.log - INFO - iteration:91 step:200/10100, NER loss:      nan
2019-02-22 11:19:52,381 - log/train6.log - INFO - iteration:91 step:300/10100, NER loss:      nan
2019-02-22 11:19:54,413 - log/train6.log - INFO - iteration:91 step:400/10100, NER loss:      nan
2019-02-22 11:19:56,396 - log/train6.log - INFO - iteration:91 step:500/10100, NER loss:      nan
2019-02-22 11:19:58,573 - log/train6.log - INFO - iteration:91 step:600/10100, NER loss:      nan
2019-02-22 11:20:00,630 - log/train6.log - INFO - iteration:91 step:700/10100, NER loss:      nan
2019-02-22 11:20:02,714 - log/train6.log - INFO - iteration:91 step:800/10100, NER loss:      nan
2019-02-22 11:20:04,999 - log/train6.log - INFO - iteration:91 step:900/10100, NER loss:      nan
2019-02-22 11:20:07,106 - log/train6.log - INFO - iteration:91 step:1000/10100, NER loss:      nan
2019-02-22 11:20:09,414 - log/train6.log - INFO - iteration:91 step:1100/10100, NER loss:      nan
2019-02-22 11:20:11,364 - log/train6.log - INFO - iteration:91 step:1200/10100, NER loss:      nan
2019-02-22 11:20:13,611 - log/train6.log - INFO - iteration:91 step:1300/10100, NER loss:      nan
2019-02-22 11:20:15,781 - log/train6.log - INFO - iteration:91 step:1400/10100, NER loss:      nan
2019-02-22 11:20:17,949 - log/train6.log - INFO - iteration:91 step:1500/10100, NER loss:      nan
2019-02-22 11:20:19,979 - log/train6.log - INFO - iteration:91 step:1600/10100, NER loss:      nan
2019-02-22 11:20:21,961 - log/train6.log - INFO - iteration:91 step:1700/10100, NER loss:      nan
2019-02-22 11:20:24,207 - log/train6.log - INFO - iteration:91 step:1800/10100, NER loss:      nan
2019-02-22 11:20:26,327 - log/train6.log - INFO - iteration:91 step:1900/10100, NER loss:      nan
2019-02-22 11:20:28,487 - log/train6.log - INFO - iteration:91 step:2000/10100, NER loss:      nan
2019-02-22 11:20:30,777 - log/train6.log - INFO - iteration:91 step:2100/10100, NER loss:      nan
2019-02-22 11:20:33,081 - log/train6.log - INFO - iteration:91 step:2200/10100, NER loss:      nan
2019-02-22 11:20:35,059 - log/train6.log - INFO - iteration:91 step:2300/10100, NER loss:      nan
2019-02-22 11:20:37,103 - log/train6.log - INFO - iteration:91 step:2400/10100, NER loss:      nan
2019-02-22 11:20:39,257 - log/train6.log - INFO - iteration:91 step:2500/10100, NER loss:      nan
2019-02-22 11:20:41,416 - log/train6.log - INFO - iteration:91 step:2600/10100, NER loss:      nan
2019-02-22 11:20:44,147 - log/train6.log - INFO - iteration:91 step:2700/10100, NER loss:      nan
2019-02-22 11:20:46,266 - log/train6.log - INFO - iteration:91 step:2800/10100, NER loss:      nan
2019-02-22 11:20:50,295 - log/train6.log - INFO - iteration:91 step:2900/10100, NER loss:      nan
2019-02-22 11:20:52,439 - log/train6.log - INFO - iteration:91 step:3000/10100, NER loss:      nan
2019-02-22 11:20:54,655 - log/train6.log - INFO - iteration:91 step:3100/10100, NER loss:      nan
2019-02-22 11:20:56,972 - log/train6.log - INFO - iteration:91 step:3200/10100, NER loss:      nan
2019-02-22 11:20:59,094 - log/train6.log - INFO - iteration:91 step:3300/10100, NER loss:      nan
2019-02-22 11:21:03,508 - log/train6.log - INFO - iteration:91 step:3400/10100, NER loss:      nan
2019-02-22 11:21:05,738 - log/train6.log - INFO - iteration:91 step:3500/10100, NER loss:      nan
2019-02-22 11:21:07,794 - log/train6.log - INFO - iteration:91 step:3600/10100, NER loss:      nan
2019-02-22 11:21:09,969 - log/train6.log - INFO - iteration:91 step:3700/10100, NER loss:      nan
2019-02-22 11:21:12,128 - log/train6.log - INFO - iteration:91 step:3800/10100, NER loss:      nan
2019-02-22 11:21:14,251 - log/train6.log - INFO - iteration:91 step:3900/10100, NER loss:      nan
2019-02-22 11:21:16,400 - log/train6.log - INFO - iteration:91 step:4000/10100, NER loss:      nan
2019-02-22 11:21:18,669 - log/train6.log - INFO - iteration:91 step:4100/10100, NER loss:      nan
2019-02-22 11:21:20,867 - log/train6.log - INFO - iteration:91 step:4200/10100, NER loss:      nan
2019-02-22 11:21:22,896 - log/train6.log - INFO - iteration:91 step:4300/10100, NER loss:      nan
2019-02-22 11:21:25,026 - log/train6.log - INFO - iteration:91 step:4400/10100, NER loss:      nan
2019-02-22 11:21:27,236 - log/train6.log - INFO - iteration:91 step:4500/10100, NER loss:      nan
2019-02-22 11:21:29,334 - log/train6.log - INFO - iteration:91 step:4600/10100, NER loss:      nan
2019-02-22 11:21:31,240 - log/train6.log - INFO - iteration:91 step:4700/10100, NER loss:      nan
2019-02-22 11:21:33,249 - log/train6.log - INFO - iteration:91 step:4800/10100, NER loss:      nan
2019-02-22 11:21:35,460 - log/train6.log - INFO - iteration:91 step:4900/10100, NER loss:      nan
2019-02-22 11:21:37,567 - log/train6.log - INFO - iteration:91 step:5000/10100, NER loss:      nan
2019-02-22 11:21:39,681 - log/train6.log - INFO - iteration:91 step:5100/10100, NER loss:      nan
2019-02-22 11:21:41,874 - log/train6.log - INFO - iteration:91 step:5200/10100, NER loss:      nan
2019-02-22 11:21:44,065 - log/train6.log - INFO - iteration:91 step:5300/10100, NER loss:      nan
2019-02-22 11:21:45,945 - log/train6.log - INFO - iteration:91 step:5400/10100, NER loss:      nan
2019-02-22 11:21:47,917 - log/train6.log - INFO - iteration:91 step:5500/10100, NER loss:      nan
2019-02-22 11:21:49,976 - log/train6.log - INFO - iteration:91 step:5600/10100, NER loss:      nan
2019-02-22 11:21:52,227 - log/train6.log - INFO - iteration:91 step:5700/10100, NER loss:      nan
2019-02-22 11:21:54,480 - log/train6.log - INFO - iteration:91 step:5800/10100, NER loss:      nan
2019-02-22 11:21:56,725 - log/train6.log - INFO - iteration:91 step:5900/10100, NER loss:      nan
2019-02-22 11:21:58,913 - log/train6.log - INFO - iteration:91 step:6000/10100, NER loss:      nan
2019-02-22 11:22:01,038 - log/train6.log - INFO - iteration:91 step:6100/10100, NER loss:      nan
2019-02-22 11:22:03,052 - log/train6.log - INFO - iteration:91 step:6200/10100, NER loss:      nan
2019-02-22 11:22:05,121 - log/train6.log - INFO - iteration:91 step:6300/10100, NER loss:      nan
2019-02-22 11:22:07,080 - log/train6.log - INFO - iteration:91 step:6400/10100, NER loss:      nan
2019-02-22 11:22:09,174 - log/train6.log - INFO - iteration:91 step:6500/10100, NER loss:      nan
2019-02-22 11:22:11,431 - log/train6.log - INFO - iteration:91 step:6600/10100, NER loss:      nan
2019-02-22 11:22:13,583 - log/train6.log - INFO - iteration:91 step:6700/10100, NER loss:      nan
2019-02-22 11:22:15,756 - log/train6.log - INFO - iteration:91 step:6800/10100, NER loss:      nan
2019-02-22 11:22:17,988 - log/train6.log - INFO - iteration:91 step:6900/10100, NER loss:      nan
2019-02-22 11:22:20,147 - log/train6.log - INFO - iteration:91 step:7000/10100, NER loss:      nan
2019-02-22 11:22:22,255 - log/train6.log - INFO - iteration:91 step:7100/10100, NER loss:      nan
2019-02-22 11:22:24,360 - log/train6.log - INFO - iteration:91 step:7200/10100, NER loss:      nan
2019-02-22 11:22:26,573 - log/train6.log - INFO - iteration:91 step:7300/10100, NER loss:      nan
2019-02-22 11:22:28,892 - log/train6.log - INFO - iteration:91 step:7400/10100, NER loss:      nan
2019-02-22 11:22:30,930 - log/train6.log - INFO - iteration:91 step:7500/10100, NER loss:      nan
2019-02-22 11:22:32,914 - log/train6.log - INFO - iteration:91 step:7600/10100, NER loss:      nan
2019-02-22 11:22:34,932 - log/train6.log - INFO - iteration:91 step:7700/10100, NER loss:      nan
2019-02-22 11:22:36,972 - log/train6.log - INFO - iteration:91 step:7800/10100, NER loss:      nan
2019-02-22 11:22:39,237 - log/train6.log - INFO - iteration:91 step:7900/10100, NER loss:      nan
2019-02-22 11:22:41,491 - log/train6.log - INFO - iteration:91 step:8000/10100, NER loss:      nan
2019-02-22 11:22:43,524 - log/train6.log - INFO - iteration:91 step:8100/10100, NER loss:      nan
2019-02-22 11:22:45,447 - log/train6.log - INFO - iteration:91 step:8200/10100, NER loss:      nan
2019-02-22 11:22:47,603 - log/train6.log - INFO - iteration:91 step:8300/10100, NER loss:      nan
2019-02-22 11:22:49,767 - log/train6.log - INFO - iteration:91 step:8400/10100, NER loss:      nan
2019-02-22 11:22:52,000 - log/train6.log - INFO - iteration:91 step:8500/10100, NER loss:      nan
2019-02-22 11:22:54,200 - log/train6.log - INFO - iteration:91 step:8600/10100, NER loss:      nan
2019-02-22 11:22:56,280 - log/train6.log - INFO - iteration:91 step:8700/10100, NER loss:      nan
2019-02-22 11:22:58,383 - log/train6.log - INFO - iteration:91 step:8800/10100, NER loss:      nan
2019-02-22 11:23:00,532 - log/train6.log - INFO - iteration:91 step:8900/10100, NER loss:      nan
2019-02-22 11:23:04,624 - log/train6.log - INFO - iteration:91 step:9000/10100, NER loss:      nan
2019-02-22 11:23:07,195 - log/train6.log - INFO - iteration:91 step:9100/10100, NER loss:      nan
2019-02-22 11:23:09,574 - log/train6.log - INFO - iteration:91 step:9200/10100, NER loss:      nan
2019-02-22 11:23:11,832 - log/train6.log - INFO - iteration:91 step:9300/10100, NER loss:      nan
2019-02-22 11:23:13,982 - log/train6.log - INFO - iteration:91 step:9400/10100, NER loss:      nan
2019-02-22 11:23:16,079 - log/train6.log - INFO - iteration:91 step:9500/10100, NER loss:      nan
2019-02-22 11:23:18,337 - log/train6.log - INFO - iteration:91 step:9600/10100, NER loss:      nan
2019-02-22 11:23:20,566 - log/train6.log - INFO - iteration:91 step:9700/10100, NER loss:      nan
2019-02-22 11:23:22,866 - log/train6.log - INFO - iteration:91 step:9800/10100, NER loss:      nan
2019-02-22 11:23:25,099 - log/train6.log - INFO - iteration:91 step:9900/10100, NER loss:      nan
2019-02-22 11:23:27,238 - log/train6.log - INFO - iteration:91 step:10000/10100, NER loss:      nan
2019-02-22 11:23:29,541 - log/train6.log - INFO - iteration:92 step:0/10100, NER loss:      nan
2019-02-22 11:23:29,541 - log/train6.log - INFO - evaluate:dev
2019-02-22 11:23:36,094 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:23:36,094 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:23:36,095 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:23:36,095 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:23:36,095 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:23:36,095 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:23:36,095 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:23:36,096 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:23:36,099 - log/train6.log - INFO - evaluate:test
2019-02-22 11:23:37,541 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:23:37,541 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:23:37,541 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:23:37,541 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:23:37,541 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:23:37,541 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:23:37,541 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:23:37,541 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:23:39,727 - log/train6.log - INFO - iteration:92 step:100/10100, NER loss:      nan
2019-02-22 11:23:41,818 - log/train6.log - INFO - iteration:92 step:200/10100, NER loss:      nan
2019-02-22 11:23:43,848 - log/train6.log - INFO - iteration:92 step:300/10100, NER loss:      nan
2019-02-22 11:23:45,955 - log/train6.log - INFO - iteration:92 step:400/10100, NER loss:      nan
2019-02-22 11:23:48,117 - log/train6.log - INFO - iteration:92 step:500/10100, NER loss:      nan
2019-02-22 11:23:50,386 - log/train6.log - INFO - iteration:92 step:600/10100, NER loss:      nan
2019-02-22 11:23:52,448 - log/train6.log - INFO - iteration:92 step:700/10100, NER loss:      nan
2019-02-22 11:23:54,663 - log/train6.log - INFO - iteration:92 step:800/10100, NER loss:      nan
2019-02-22 11:23:56,887 - log/train6.log - INFO - iteration:92 step:900/10100, NER loss:      nan
2019-02-22 11:23:59,284 - log/train6.log - INFO - iteration:92 step:1000/10100, NER loss:      nan
2019-02-22 11:24:01,495 - log/train6.log - INFO - iteration:92 step:1100/10100, NER loss:      nan
2019-02-22 11:24:03,605 - log/train6.log - INFO - iteration:92 step:1200/10100, NER loss:      nan
2019-02-22 11:24:05,599 - log/train6.log - INFO - iteration:92 step:1300/10100, NER loss:      nan
2019-02-22 11:24:09,606 - log/train6.log - INFO - iteration:92 step:1400/10100, NER loss:      nan
2019-02-22 11:24:11,631 - log/train6.log - INFO - iteration:92 step:1500/10100, NER loss:      nan
2019-02-22 11:24:14,094 - log/train6.log - INFO - iteration:92 step:1600/10100, NER loss:      nan
2019-02-22 11:24:16,236 - log/train6.log - INFO - iteration:92 step:1700/10100, NER loss:      nan
2019-02-22 11:24:18,119 - log/train6.log - INFO - iteration:92 step:1800/10100, NER loss:      nan
2019-02-22 11:24:20,389 - log/train6.log - INFO - iteration:92 step:1900/10100, NER loss:      nan
2019-02-22 11:24:23,270 - log/train6.log - INFO - iteration:92 step:2000/10100, NER loss:      nan
2019-02-22 11:24:25,291 - log/train6.log - INFO - iteration:92 step:2100/10100, NER loss:      nan
2019-02-22 11:24:27,236 - log/train6.log - INFO - iteration:92 step:2200/10100, NER loss:      nan
2019-02-22 11:24:29,585 - log/train6.log - INFO - iteration:92 step:2300/10100, NER loss:      nan
2019-02-22 11:24:31,746 - log/train6.log - INFO - iteration:92 step:2400/10100, NER loss:      nan
2019-02-22 11:24:33,805 - log/train6.log - INFO - iteration:92 step:2500/10100, NER loss:      nan
2019-02-22 11:24:35,866 - log/train6.log - INFO - iteration:92 step:2600/10100, NER loss:      nan
2019-02-22 11:24:38,100 - log/train6.log - INFO - iteration:92 step:2700/10100, NER loss:      nan
2019-02-22 11:24:40,190 - log/train6.log - INFO - iteration:92 step:2800/10100, NER loss:      nan
2019-02-22 11:24:42,381 - log/train6.log - INFO - iteration:92 step:2900/10100, NER loss:      nan
2019-02-22 11:24:44,564 - log/train6.log - INFO - iteration:92 step:3000/10100, NER loss:      nan
2019-02-22 11:24:46,770 - log/train6.log - INFO - iteration:92 step:3100/10100, NER loss:      nan
2019-02-22 11:24:49,120 - log/train6.log - INFO - iteration:92 step:3200/10100, NER loss:      nan
2019-02-22 11:24:51,142 - log/train6.log - INFO - iteration:92 step:3300/10100, NER loss:      nan
2019-02-22 11:24:53,357 - log/train6.log - INFO - iteration:92 step:3400/10100, NER loss:      nan
2019-02-22 11:24:55,395 - log/train6.log - INFO - iteration:92 step:3500/10100, NER loss:      nan
2019-02-22 11:24:57,647 - log/train6.log - INFO - iteration:92 step:3600/10100, NER loss:      nan
2019-02-22 11:25:00,112 - log/train6.log - INFO - iteration:92 step:3700/10100, NER loss:      nan
2019-02-22 11:25:02,252 - log/train6.log - INFO - iteration:92 step:3800/10100, NER loss:      nan
2019-02-22 11:25:04,472 - log/train6.log - INFO - iteration:92 step:3900/10100, NER loss:      nan
2019-02-22 11:25:06,723 - log/train6.log - INFO - iteration:92 step:4000/10100, NER loss:      nan
2019-02-22 11:25:09,104 - log/train6.log - INFO - iteration:92 step:4100/10100, NER loss:      nan
2019-02-22 11:25:11,596 - log/train6.log - INFO - iteration:92 step:4200/10100, NER loss:      nan
2019-02-22 11:25:14,055 - log/train6.log - INFO - iteration:92 step:4300/10100, NER loss:      nan
2019-02-22 11:25:16,503 - log/train6.log - INFO - iteration:92 step:4400/10100, NER loss:      nan
2019-02-22 11:25:18,491 - log/train6.log - INFO - iteration:92 step:4500/10100, NER loss:      nan
2019-02-22 11:25:20,737 - log/train6.log - INFO - iteration:92 step:4600/10100, NER loss:      nan
2019-02-22 11:25:22,931 - log/train6.log - INFO - iteration:92 step:4700/10100, NER loss:      nan
2019-02-22 11:25:25,274 - log/train6.log - INFO - iteration:92 step:4800/10100, NER loss:      nan
2019-02-22 11:25:27,485 - log/train6.log - INFO - iteration:92 step:4900/10100, NER loss:      nan
2019-02-22 11:25:29,796 - log/train6.log - INFO - iteration:92 step:5000/10100, NER loss:      nan
2019-02-22 11:25:31,924 - log/train6.log - INFO - iteration:92 step:5100/10100, NER loss:      nan
2019-02-22 11:25:34,022 - log/train6.log - INFO - iteration:92 step:5200/10100, NER loss:      nan
2019-02-22 11:25:36,215 - log/train6.log - INFO - iteration:92 step:5300/10100, NER loss:      nan
2019-02-22 11:25:38,393 - log/train6.log - INFO - iteration:92 step:5400/10100, NER loss:      nan
2019-02-22 11:25:40,386 - log/train6.log - INFO - iteration:92 step:5500/10100, NER loss:      nan
2019-02-22 11:25:44,422 - log/train6.log - INFO - iteration:92 step:5600/10100, NER loss:      nan
2019-02-22 11:25:46,320 - log/train6.log - INFO - iteration:92 step:5700/10100, NER loss:      nan
2019-02-22 11:25:48,334 - log/train6.log - INFO - iteration:92 step:5800/10100, NER loss:      nan
2019-02-22 11:25:50,620 - log/train6.log - INFO - iteration:92 step:5900/10100, NER loss:      nan
2019-02-22 11:25:52,794 - log/train6.log - INFO - iteration:92 step:6000/10100, NER loss:      nan
2019-02-22 11:25:54,821 - log/train6.log - INFO - iteration:92 step:6100/10100, NER loss:      nan
2019-02-22 11:25:56,876 - log/train6.log - INFO - iteration:92 step:6200/10100, NER loss:      nan
2019-02-22 11:25:59,178 - log/train6.log - INFO - iteration:92 step:6300/10100, NER loss:      nan
2019-02-22 11:26:01,233 - log/train6.log - INFO - iteration:92 step:6400/10100, NER loss:      nan
2019-02-22 11:26:03,315 - log/train6.log - INFO - iteration:92 step:6500/10100, NER loss:      nan
2019-02-22 11:26:05,238 - log/train6.log - INFO - iteration:92 step:6600/10100, NER loss:      nan
2019-02-22 11:26:07,417 - log/train6.log - INFO - iteration:92 step:6700/10100, NER loss:      nan
2019-02-22 11:26:09,722 - log/train6.log - INFO - iteration:92 step:6800/10100, NER loss:      nan
2019-02-22 11:26:11,936 - log/train6.log - INFO - iteration:92 step:6900/10100, NER loss:      nan
2019-02-22 11:26:14,218 - log/train6.log - INFO - iteration:92 step:7000/10100, NER loss:      nan
2019-02-22 11:26:16,754 - log/train6.log - INFO - iteration:92 step:7100/10100, NER loss:      nan
2019-02-22 11:26:19,378 - log/train6.log - INFO - iteration:92 step:7200/10100, NER loss:      nan
2019-02-22 11:26:21,611 - log/train6.log - INFO - iteration:92 step:7300/10100, NER loss:      nan
2019-02-22 11:26:23,846 - log/train6.log - INFO - iteration:92 step:7400/10100, NER loss:      nan
2019-02-22 11:26:26,170 - log/train6.log - INFO - iteration:92 step:7500/10100, NER loss:      nan
2019-02-22 11:26:28,766 - log/train6.log - INFO - iteration:92 step:7600/10100, NER loss:      nan
2019-02-22 11:26:30,920 - log/train6.log - INFO - iteration:92 step:7700/10100, NER loss:      nan
2019-02-22 11:26:32,912 - log/train6.log - INFO - iteration:92 step:7800/10100, NER loss:      nan
2019-02-22 11:26:35,245 - log/train6.log - INFO - iteration:92 step:7900/10100, NER loss:      nan
2019-02-22 11:26:37,483 - log/train6.log - INFO - iteration:92 step:8000/10100, NER loss:      nan
2019-02-22 11:26:39,788 - log/train6.log - INFO - iteration:92 step:8100/10100, NER loss:      nan
2019-02-22 11:26:42,079 - log/train6.log - INFO - iteration:92 step:8200/10100, NER loss:      nan
2019-02-22 11:26:44,197 - log/train6.log - INFO - iteration:92 step:8300/10100, NER loss:      nan
2019-02-22 11:26:46,096 - log/train6.log - INFO - iteration:92 step:8400/10100, NER loss:      nan
2019-02-22 11:26:48,586 - log/train6.log - INFO - iteration:92 step:8500/10100, NER loss:      nan
2019-02-22 11:26:50,717 - log/train6.log - INFO - iteration:92 step:8600/10100, NER loss:      nan
2019-02-22 11:26:52,884 - log/train6.log - INFO - iteration:92 step:8700/10100, NER loss:      nan
2019-02-22 11:26:55,163 - log/train6.log - INFO - iteration:92 step:8800/10100, NER loss:      nan
2019-02-22 11:26:59,859 - log/train6.log - INFO - iteration:92 step:8900/10100, NER loss:      nan
2019-02-22 11:27:02,244 - log/train6.log - INFO - iteration:92 step:9000/10100, NER loss:      nan
2019-02-22 11:27:04,642 - log/train6.log - INFO - iteration:92 step:9100/10100, NER loss:      nan
2019-02-22 11:27:06,892 - log/train6.log - INFO - iteration:92 step:9200/10100, NER loss:      nan
2019-02-22 11:27:09,032 - log/train6.log - INFO - iteration:92 step:9300/10100, NER loss:      nan
2019-02-22 11:27:11,204 - log/train6.log - INFO - iteration:92 step:9400/10100, NER loss:      nan
2019-02-22 11:27:13,360 - log/train6.log - INFO - iteration:92 step:9500/10100, NER loss:      nan
2019-02-22 11:27:15,510 - log/train6.log - INFO - iteration:92 step:9600/10100, NER loss:      nan
2019-02-22 11:27:17,729 - log/train6.log - INFO - iteration:92 step:9700/10100, NER loss:      nan
2019-02-22 11:27:20,195 - log/train6.log - INFO - iteration:92 step:9800/10100, NER loss:      nan
2019-02-22 11:27:22,203 - log/train6.log - INFO - iteration:92 step:9900/10100, NER loss:      nan
2019-02-22 11:27:24,426 - log/train6.log - INFO - iteration:92 step:10000/10100, NER loss:      nan
2019-02-22 11:27:26,363 - log/train6.log - INFO - iteration:93 step:0/10100, NER loss:      nan
2019-02-22 11:27:26,364 - log/train6.log - INFO - evaluate:dev
2019-02-22 11:27:32,854 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:27:32,855 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:27:32,855 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:27:32,855 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:27:32,855 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:27:32,856 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:27:32,856 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:27:32,856 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:27:32,859 - log/train6.log - INFO - evaluate:test
2019-02-22 11:27:34,322 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:27:34,322 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:27:34,322 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:27:34,322 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:27:34,323 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:27:34,323 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:27:34,323 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:27:34,323 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:27:36,292 - log/train6.log - INFO - iteration:93 step:100/10100, NER loss:      nan
2019-02-22 11:27:38,501 - log/train6.log - INFO - iteration:93 step:200/10100, NER loss:      nan
2019-02-22 11:27:40,445 - log/train6.log - INFO - iteration:93 step:300/10100, NER loss:      nan
2019-02-22 11:27:42,666 - log/train6.log - INFO - iteration:93 step:400/10100, NER loss:      nan
2019-02-22 11:27:44,645 - log/train6.log - INFO - iteration:93 step:500/10100, NER loss:      nan
2019-02-22 11:27:46,970 - log/train6.log - INFO - iteration:93 step:600/10100, NER loss:      nan
2019-02-22 11:27:49,254 - log/train6.log - INFO - iteration:93 step:700/10100, NER loss:      nan
2019-02-22 11:27:51,423 - log/train6.log - INFO - iteration:93 step:800/10100, NER loss:      nan
2019-02-22 11:27:53,771 - log/train6.log - INFO - iteration:93 step:900/10100, NER loss:      nan
2019-02-22 11:27:56,058 - log/train6.log - INFO - iteration:93 step:1000/10100, NER loss:      nan
2019-02-22 11:27:58,085 - log/train6.log - INFO - iteration:93 step:1100/10100, NER loss:      nan
2019-02-22 11:28:02,179 - log/train6.log - INFO - iteration:93 step:1200/10100, NER loss:      nan
2019-02-22 11:28:04,292 - log/train6.log - INFO - iteration:93 step:1300/10100, NER loss:      nan
2019-02-22 11:28:06,466 - log/train6.log - INFO - iteration:93 step:1400/10100, NER loss:      nan
2019-02-22 11:28:08,727 - log/train6.log - INFO - iteration:93 step:1500/10100, NER loss:      nan
2019-02-22 11:28:10,931 - log/train6.log - INFO - iteration:93 step:1600/10100, NER loss:      nan
2019-02-22 11:28:13,205 - log/train6.log - INFO - iteration:93 step:1700/10100, NER loss:      nan
2019-02-22 11:28:15,250 - log/train6.log - INFO - iteration:93 step:1800/10100, NER loss:      nan
2019-02-22 11:28:17,351 - log/train6.log - INFO - iteration:93 step:1900/10100, NER loss:      nan
2019-02-22 11:28:19,591 - log/train6.log - INFO - iteration:93 step:2000/10100, NER loss:      nan
2019-02-22 11:28:21,909 - log/train6.log - INFO - iteration:93 step:2100/10100, NER loss:      nan
2019-02-22 11:28:23,942 - log/train6.log - INFO - iteration:93 step:2200/10100, NER loss:      nan
2019-02-22 11:28:25,930 - log/train6.log - INFO - iteration:93 step:2300/10100, NER loss:      nan
2019-02-22 11:28:28,283 - log/train6.log - INFO - iteration:93 step:2400/10100, NER loss:      nan
2019-02-22 11:28:30,665 - log/train6.log - INFO - iteration:93 step:2500/10100, NER loss:      nan
2019-02-22 11:28:35,092 - log/train6.log - INFO - iteration:93 step:2600/10100, NER loss:      nan
2019-02-22 11:28:37,403 - log/train6.log - INFO - iteration:93 step:2700/10100, NER loss:      nan
2019-02-22 11:28:39,607 - log/train6.log - INFO - iteration:93 step:2800/10100, NER loss:      nan
2019-02-22 11:28:42,024 - log/train6.log - INFO - iteration:93 step:2900/10100, NER loss:      nan
2019-02-22 11:28:44,308 - log/train6.log - INFO - iteration:93 step:3000/10100, NER loss:      nan
2019-02-22 11:28:46,579 - log/train6.log - INFO - iteration:93 step:3100/10100, NER loss:      nan
2019-02-22 11:28:48,720 - log/train6.log - INFO - iteration:93 step:3200/10100, NER loss:      nan
2019-02-22 11:28:50,934 - log/train6.log - INFO - iteration:93 step:3300/10100, NER loss:      nan
2019-02-22 11:28:53,419 - log/train6.log - INFO - iteration:93 step:3400/10100, NER loss:      nan
2019-02-22 11:28:56,078 - log/train6.log - INFO - iteration:93 step:3500/10100, NER loss:      nan
2019-02-22 11:28:58,431 - log/train6.log - INFO - iteration:93 step:3600/10100, NER loss:      nan
2019-02-22 11:29:00,306 - log/train6.log - INFO - iteration:93 step:3700/10100, NER loss:      nan
2019-02-22 11:29:03,217 - log/train6.log - INFO - iteration:93 step:3800/10100, NER loss:      nan
2019-02-22 11:29:05,560 - log/train6.log - INFO - iteration:93 step:3900/10100, NER loss:      nan
2019-02-22 11:29:08,087 - log/train6.log - INFO - iteration:93 step:4000/10100, NER loss:      nan
2019-02-22 11:29:10,353 - log/train6.log - INFO - iteration:93 step:4100/10100, NER loss:      nan
2019-02-22 11:29:14,947 - log/train6.log - INFO - iteration:93 step:4200/10100, NER loss:      nan
2019-02-22 11:29:17,559 - log/train6.log - INFO - iteration:93 step:4300/10100, NER loss:      nan
2019-02-22 11:29:20,246 - log/train6.log - INFO - iteration:93 step:4400/10100, NER loss:      nan
2019-02-22 11:29:23,471 - log/train6.log - INFO - iteration:93 step:4500/10100, NER loss:      nan
2019-02-22 11:29:25,841 - log/train6.log - INFO - iteration:93 step:4600/10100, NER loss:      nan
2019-02-22 11:29:28,142 - log/train6.log - INFO - iteration:93 step:4700/10100, NER loss:      nan
2019-02-22 11:29:30,406 - log/train6.log - INFO - iteration:93 step:4800/10100, NER loss:      nan
2019-02-22 11:29:32,513 - log/train6.log - INFO - iteration:93 step:4900/10100, NER loss:      nan
2019-02-22 11:29:34,842 - log/train6.log - INFO - iteration:93 step:5000/10100, NER loss:      nan
2019-02-22 11:29:36,967 - log/train6.log - INFO - iteration:93 step:5100/10100, NER loss:      nan
2019-02-22 11:29:39,292 - log/train6.log - INFO - iteration:93 step:5200/10100, NER loss:      nan
2019-02-22 11:29:41,750 - log/train6.log - INFO - iteration:93 step:5300/10100, NER loss:      nan
2019-02-22 11:29:44,387 - log/train6.log - INFO - iteration:93 step:5400/10100, NER loss:      nan
2019-02-22 11:29:46,527 - log/train6.log - INFO - iteration:93 step:5500/10100, NER loss:      nan
2019-02-22 11:29:48,455 - log/train6.log - INFO - iteration:93 step:5600/10100, NER loss:      nan
2019-02-22 11:29:50,707 - log/train6.log - INFO - iteration:93 step:5700/10100, NER loss:      nan
2019-02-22 11:29:52,745 - log/train6.log - INFO - iteration:93 step:5800/10100, NER loss:      nan
2019-02-22 11:29:55,240 - log/train6.log - INFO - iteration:93 step:5900/10100, NER loss:      nan
2019-02-22 11:29:57,789 - log/train6.log - INFO - iteration:93 step:6000/10100, NER loss:      nan
2019-02-22 11:30:00,013 - log/train6.log - INFO - iteration:93 step:6100/10100, NER loss:      nan
2019-02-22 11:30:02,582 - log/train6.log - INFO - iteration:93 step:6200/10100, NER loss:      nan
2019-02-22 11:30:04,928 - log/train6.log - INFO - iteration:93 step:6300/10100, NER loss:      nan
2019-02-22 11:30:07,380 - log/train6.log - INFO - iteration:93 step:6400/10100, NER loss:      nan
2019-02-22 11:30:09,492 - log/train6.log - INFO - iteration:93 step:6500/10100, NER loss:      nan
2019-02-22 11:30:12,099 - log/train6.log - INFO - iteration:93 step:6600/10100, NER loss:      nan
2019-02-22 11:30:14,551 - log/train6.log - INFO - iteration:93 step:6700/10100, NER loss:      nan
2019-02-22 11:30:16,886 - log/train6.log - INFO - iteration:93 step:6800/10100, NER loss:      nan
2019-02-22 11:30:19,076 - log/train6.log - INFO - iteration:93 step:6900/10100, NER loss:      nan
2019-02-22 11:30:21,300 - log/train6.log - INFO - iteration:93 step:7000/10100, NER loss:      nan
2019-02-22 11:30:23,479 - log/train6.log - INFO - iteration:93 step:7100/10100, NER loss:      nan
2019-02-22 11:30:25,766 - log/train6.log - INFO - iteration:93 step:7200/10100, NER loss:      nan
2019-02-22 11:30:27,969 - log/train6.log - INFO - iteration:93 step:7300/10100, NER loss:      nan
2019-02-22 11:30:30,371 - log/train6.log - INFO - iteration:93 step:7400/10100, NER loss:      nan
2019-02-22 11:30:32,976 - log/train6.log - INFO - iteration:93 step:7500/10100, NER loss:      nan
2019-02-22 11:30:35,347 - log/train6.log - INFO - iteration:93 step:7600/10100, NER loss:      nan
2019-02-22 11:30:37,718 - log/train6.log - INFO - iteration:93 step:7700/10100, NER loss:      nan
2019-02-22 11:30:39,967 - log/train6.log - INFO - iteration:93 step:7800/10100, NER loss:      nan
2019-02-22 11:30:42,503 - log/train6.log - INFO - iteration:93 step:7900/10100, NER loss:      nan
2019-02-22 11:30:44,749 - log/train6.log - INFO - iteration:93 step:8000/10100, NER loss:      nan
2019-02-22 11:30:47,108 - log/train6.log - INFO - iteration:93 step:8100/10100, NER loss:      nan
2019-02-22 11:30:49,401 - log/train6.log - INFO - iteration:93 step:8200/10100, NER loss:      nan
2019-02-22 11:30:51,465 - log/train6.log - INFO - iteration:93 step:8300/10100, NER loss:      nan
2019-02-22 11:30:53,756 - log/train6.log - INFO - iteration:93 step:8400/10100, NER loss:      nan
2019-02-22 11:30:55,975 - log/train6.log - INFO - iteration:93 step:8500/10100, NER loss:      nan
2019-02-22 11:30:58,338 - log/train6.log - INFO - iteration:93 step:8600/10100, NER loss:      nan
2019-02-22 11:31:00,800 - log/train6.log - INFO - iteration:93 step:8700/10100, NER loss:      nan
2019-02-22 11:31:03,181 - log/train6.log - INFO - iteration:93 step:8800/10100, NER loss:      nan
2019-02-22 11:31:05,366 - log/train6.log - INFO - iteration:93 step:8900/10100, NER loss:      nan
2019-02-22 11:31:07,640 - log/train6.log - INFO - iteration:93 step:9000/10100, NER loss:      nan
2019-02-22 11:31:09,742 - log/train6.log - INFO - iteration:93 step:9100/10100, NER loss:      nan
2019-02-22 11:31:11,964 - log/train6.log - INFO - iteration:93 step:9200/10100, NER loss:      nan
2019-02-22 11:31:14,121 - log/train6.log - INFO - iteration:93 step:9300/10100, NER loss:      nan
2019-02-22 11:31:16,336 - log/train6.log - INFO - iteration:93 step:9400/10100, NER loss:      nan
2019-02-22 11:31:18,631 - log/train6.log - INFO - iteration:93 step:9500/10100, NER loss:      nan
2019-02-22 11:31:20,700 - log/train6.log - INFO - iteration:93 step:9600/10100, NER loss:      nan
2019-02-22 11:31:22,973 - log/train6.log - INFO - iteration:93 step:9700/10100, NER loss:      nan
2019-02-22 11:31:24,987 - log/train6.log - INFO - iteration:93 step:9800/10100, NER loss:      nan
2019-02-22 11:31:27,011 - log/train6.log - INFO - iteration:93 step:9900/10100, NER loss:      nan
2019-02-22 11:31:29,425 - log/train6.log - INFO - iteration:93 step:10000/10100, NER loss:      nan
2019-02-22 11:31:31,403 - log/train6.log - INFO - iteration:94 step:0/10100, NER loss:      nan
2019-02-22 11:31:31,403 - log/train6.log - INFO - evaluate:dev
2019-02-22 11:31:38,010 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:31:38,011 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:31:38,011 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:31:38,011 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:31:38,011 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:31:38,011 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:31:38,011 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:31:38,011 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:31:38,014 - log/train6.log - INFO - evaluate:test
2019-02-22 11:31:39,535 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:31:39,535 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:31:39,535 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:31:39,535 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:31:39,535 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:31:39,535 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:31:39,535 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:31:39,535 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:31:41,563 - log/train6.log - INFO - iteration:94 step:100/10100, NER loss:      nan
2019-02-22 11:31:43,688 - log/train6.log - INFO - iteration:94 step:200/10100, NER loss:      nan
2019-02-22 11:31:45,727 - log/train6.log - INFO - iteration:94 step:300/10100, NER loss:      nan
2019-02-22 11:31:47,889 - log/train6.log - INFO - iteration:94 step:400/10100, NER loss:      nan
2019-02-22 11:31:50,123 - log/train6.log - INFO - iteration:94 step:500/10100, NER loss:      nan
2019-02-22 11:31:52,717 - log/train6.log - INFO - iteration:94 step:600/10100, NER loss:      nan
2019-02-22 11:31:54,804 - log/train6.log - INFO - iteration:94 step:700/10100, NER loss:      nan
2019-02-22 11:31:57,146 - log/train6.log - INFO - iteration:94 step:800/10100, NER loss:      nan
2019-02-22 11:31:59,474 - log/train6.log - INFO - iteration:94 step:900/10100, NER loss:      nan
2019-02-22 11:32:01,707 - log/train6.log - INFO - iteration:94 step:1000/10100, NER loss:      nan
2019-02-22 11:32:03,866 - log/train6.log - INFO - iteration:94 step:1100/10100, NER loss:      nan
2019-02-22 11:32:06,126 - log/train6.log - INFO - iteration:94 step:1200/10100, NER loss:      nan
2019-02-22 11:32:10,554 - log/train6.log - INFO - iteration:94 step:1300/10100, NER loss:      nan
2019-02-22 11:32:12,783 - log/train6.log - INFO - iteration:94 step:1400/10100, NER loss:      nan
2019-02-22 11:32:14,988 - log/train6.log - INFO - iteration:94 step:1500/10100, NER loss:      nan
2019-02-22 11:32:17,176 - log/train6.log - INFO - iteration:94 step:1600/10100, NER loss:      nan
2019-02-22 11:32:19,457 - log/train6.log - INFO - iteration:94 step:1700/10100, NER loss:      nan
2019-02-22 11:32:21,887 - log/train6.log - INFO - iteration:94 step:1800/10100, NER loss:      nan
2019-02-22 11:32:24,136 - log/train6.log - INFO - iteration:94 step:1900/10100, NER loss:      nan
2019-02-22 11:32:26,355 - log/train6.log - INFO - iteration:94 step:2000/10100, NER loss:      nan
2019-02-22 11:32:28,380 - log/train6.log - INFO - iteration:94 step:2100/10100, NER loss:      nan
2019-02-22 11:32:30,532 - log/train6.log - INFO - iteration:94 step:2200/10100, NER loss:      nan
2019-02-22 11:32:32,722 - log/train6.log - INFO - iteration:94 step:2300/10100, NER loss:      nan
2019-02-22 11:32:35,007 - log/train6.log - INFO - iteration:94 step:2400/10100, NER loss:      nan
2019-02-22 11:32:37,177 - log/train6.log - INFO - iteration:94 step:2500/10100, NER loss:      nan
2019-02-22 11:32:39,143 - log/train6.log - INFO - iteration:94 step:2600/10100, NER loss:      nan
2019-02-22 11:32:41,399 - log/train6.log - INFO - iteration:94 step:2700/10100, NER loss:      nan
2019-02-22 11:32:43,659 - log/train6.log - INFO - iteration:94 step:2800/10100, NER loss:      nan
2019-02-22 11:32:45,732 - log/train6.log - INFO - iteration:94 step:2900/10100, NER loss:      nan
2019-02-22 11:32:48,011 - log/train6.log - INFO - iteration:94 step:3000/10100, NER loss:      nan
2019-02-22 11:32:50,306 - log/train6.log - INFO - iteration:94 step:3100/10100, NER loss:      nan
2019-02-22 11:32:52,590 - log/train6.log - INFO - iteration:94 step:3200/10100, NER loss:      nan
2019-02-22 11:32:54,782 - log/train6.log - INFO - iteration:94 step:3300/10100, NER loss:      nan
2019-02-22 11:32:56,862 - log/train6.log - INFO - iteration:94 step:3400/10100, NER loss:      nan
2019-02-22 11:32:58,985 - log/train6.log - INFO - iteration:94 step:3500/10100, NER loss:      nan
2019-02-22 11:33:01,315 - log/train6.log - INFO - iteration:94 step:3600/10100, NER loss:      nan
2019-02-22 11:33:03,478 - log/train6.log - INFO - iteration:94 step:3700/10100, NER loss:      nan
2019-02-22 11:33:05,937 - log/train6.log - INFO - iteration:94 step:3800/10100, NER loss:      nan
2019-02-22 11:33:08,404 - log/train6.log - INFO - iteration:94 step:3900/10100, NER loss:      nan
2019-02-22 11:33:10,567 - log/train6.log - INFO - iteration:94 step:4000/10100, NER loss:      nan
2019-02-22 11:33:12,506 - log/train6.log - INFO - iteration:94 step:4100/10100, NER loss:      nan
2019-02-22 11:33:14,797 - log/train6.log - INFO - iteration:94 step:4200/10100, NER loss:      nan
2019-02-22 11:33:16,890 - log/train6.log - INFO - iteration:94 step:4300/10100, NER loss:      nan
2019-02-22 11:33:19,268 - log/train6.log - INFO - iteration:94 step:4400/10100, NER loss:      nan
2019-02-22 11:33:21,625 - log/train6.log - INFO - iteration:94 step:4500/10100, NER loss:      nan
2019-02-22 11:33:24,289 - log/train6.log - INFO - iteration:94 step:4600/10100, NER loss:      nan
2019-02-22 11:33:26,738 - log/train6.log - INFO - iteration:94 step:4700/10100, NER loss:      nan
2019-02-22 11:33:28,985 - log/train6.log - INFO - iteration:94 step:4800/10100, NER loss:      nan
2019-02-22 11:33:31,293 - log/train6.log - INFO - iteration:94 step:4900/10100, NER loss:      nan
2019-02-22 11:33:33,689 - log/train6.log - INFO - iteration:94 step:5000/10100, NER loss:      nan
2019-02-22 11:33:35,979 - log/train6.log - INFO - iteration:94 step:5100/10100, NER loss:      nan
2019-02-22 11:33:38,192 - log/train6.log - INFO - iteration:94 step:5200/10100, NER loss:      nan
2019-02-22 11:33:40,312 - log/train6.log - INFO - iteration:94 step:5300/10100, NER loss:      nan
2019-02-22 11:33:42,584 - log/train6.log - INFO - iteration:94 step:5400/10100, NER loss:      nan
2019-02-22 11:33:45,143 - log/train6.log - INFO - iteration:94 step:5500/10100, NER loss:      nan
2019-02-22 11:33:47,162 - log/train6.log - INFO - iteration:94 step:5600/10100, NER loss:      nan
2019-02-22 11:33:49,309 - log/train6.log - INFO - iteration:94 step:5700/10100, NER loss:      nan
2019-02-22 11:33:51,404 - log/train6.log - INFO - iteration:94 step:5800/10100, NER loss:      nan
2019-02-22 11:33:53,521 - log/train6.log - INFO - iteration:94 step:5900/10100, NER loss:      nan
2019-02-22 11:33:55,587 - log/train6.log - INFO - iteration:94 step:6000/10100, NER loss:      nan
2019-02-22 11:33:57,644 - log/train6.log - INFO - iteration:94 step:6100/10100, NER loss:      nan
2019-02-22 11:33:59,547 - log/train6.log - INFO - iteration:94 step:6200/10100, NER loss:      nan
2019-02-22 11:34:01,749 - log/train6.log - INFO - iteration:94 step:6300/10100, NER loss:      nan
2019-02-22 11:34:06,076 - log/train6.log - INFO - iteration:94 step:6400/10100, NER loss:      nan
2019-02-22 11:34:08,500 - log/train6.log - INFO - iteration:94 step:6500/10100, NER loss:      nan
2019-02-22 11:34:11,123 - log/train6.log - INFO - iteration:94 step:6600/10100, NER loss:      nan
2019-02-22 11:34:13,485 - log/train6.log - INFO - iteration:94 step:6700/10100, NER loss:      nan
2019-02-22 11:34:15,769 - log/train6.log - INFO - iteration:94 step:6800/10100, NER loss:      nan
2019-02-22 11:34:17,968 - log/train6.log - INFO - iteration:94 step:6900/10100, NER loss:      nan
2019-02-22 11:34:20,619 - log/train6.log - INFO - iteration:94 step:7000/10100, NER loss:      nan
2019-02-22 11:34:22,778 - log/train6.log - INFO - iteration:94 step:7100/10100, NER loss:      nan
2019-02-22 11:34:25,221 - log/train6.log - INFO - iteration:94 step:7200/10100, NER loss:      nan
2019-02-22 11:34:27,456 - log/train6.log - INFO - iteration:94 step:7300/10100, NER loss:      nan
2019-02-22 11:34:29,749 - log/train6.log - INFO - iteration:94 step:7400/10100, NER loss:      nan
2019-02-22 11:34:32,315 - log/train6.log - INFO - iteration:94 step:7500/10100, NER loss:      nan
2019-02-22 11:34:34,651 - log/train6.log - INFO - iteration:94 step:7600/10100, NER loss:      nan
2019-02-22 11:34:36,883 - log/train6.log - INFO - iteration:94 step:7700/10100, NER loss:      nan
2019-02-22 11:34:39,113 - log/train6.log - INFO - iteration:94 step:7800/10100, NER loss:      nan
2019-02-22 11:34:41,156 - log/train6.log - INFO - iteration:94 step:7900/10100, NER loss:      nan
2019-02-22 11:34:43,306 - log/train6.log - INFO - iteration:94 step:8000/10100, NER loss:      nan
2019-02-22 11:34:46,094 - log/train6.log - INFO - iteration:94 step:8100/10100, NER loss:      nan
2019-02-22 11:34:48,301 - log/train6.log - INFO - iteration:94 step:8200/10100, NER loss:      nan
2019-02-22 11:34:50,406 - log/train6.log - INFO - iteration:94 step:8300/10100, NER loss:      nan
2019-02-22 11:34:52,821 - log/train6.log - INFO - iteration:94 step:8400/10100, NER loss:      nan
2019-02-22 11:34:55,194 - log/train6.log - INFO - iteration:94 step:8500/10100, NER loss:      nan
2019-02-22 11:34:57,770 - log/train6.log - INFO - iteration:94 step:8600/10100, NER loss:      nan
2019-02-22 11:35:00,369 - log/train6.log - INFO - iteration:94 step:8700/10100, NER loss:      nan
2019-02-22 11:35:05,017 - log/train6.log - INFO - iteration:94 step:8800/10100, NER loss:      nan
2019-02-22 11:35:07,686 - log/train6.log - INFO - iteration:94 step:8900/10100, NER loss:      nan
2019-02-22 11:35:09,920 - log/train6.log - INFO - iteration:94 step:9000/10100, NER loss:      nan
2019-02-22 11:35:12,126 - log/train6.log - INFO - iteration:94 step:9100/10100, NER loss:      nan
2019-02-22 11:35:14,512 - log/train6.log - INFO - iteration:94 step:9200/10100, NER loss:      nan
2019-02-22 11:35:16,757 - log/train6.log - INFO - iteration:94 step:9300/10100, NER loss:      nan
2019-02-22 11:35:18,911 - log/train6.log - INFO - iteration:94 step:9400/10100, NER loss:      nan
2019-02-22 11:35:21,343 - log/train6.log - INFO - iteration:94 step:9500/10100, NER loss:      nan
2019-02-22 11:35:23,734 - log/train6.log - INFO - iteration:94 step:9600/10100, NER loss:      nan
2019-02-22 11:35:25,694 - log/train6.log - INFO - iteration:94 step:9700/10100, NER loss:      nan
2019-02-22 11:35:28,093 - log/train6.log - INFO - iteration:94 step:9800/10100, NER loss:      nan
2019-02-22 11:35:30,546 - log/train6.log - INFO - iteration:94 step:9900/10100, NER loss:      nan
2019-02-22 11:35:32,992 - log/train6.log - INFO - iteration:94 step:10000/10100, NER loss:      nan
2019-02-22 11:35:35,299 - log/train6.log - INFO - iteration:95 step:0/10100, NER loss:      nan
2019-02-22 11:35:35,299 - log/train6.log - INFO - evaluate:dev
2019-02-22 11:35:42,209 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:35:42,210 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:35:42,211 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:35:42,211 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:35:42,211 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:35:42,211 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:35:42,211 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:35:42,211 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:35:42,215 - log/train6.log - INFO - evaluate:test
2019-02-22 11:35:43,718 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:35:43,718 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:35:43,718 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:35:43,719 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:35:43,719 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:35:43,719 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:35:43,719 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:35:43,719 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:35:45,996 - log/train6.log - INFO - iteration:95 step:100/10100, NER loss:      nan
2019-02-22 11:35:48,073 - log/train6.log - INFO - iteration:95 step:200/10100, NER loss:      nan
2019-02-22 11:35:50,417 - log/train6.log - INFO - iteration:95 step:300/10100, NER loss:      nan
2019-02-22 11:35:52,569 - log/train6.log - INFO - iteration:95 step:400/10100, NER loss:      nan
2019-02-22 11:35:54,717 - log/train6.log - INFO - iteration:95 step:500/10100, NER loss:      nan
2019-02-22 11:35:56,976 - log/train6.log - INFO - iteration:95 step:600/10100, NER loss:      nan
2019-02-22 11:35:59,346 - log/train6.log - INFO - iteration:95 step:700/10100, NER loss:      nan
2019-02-22 11:36:01,822 - log/train6.log - INFO - iteration:95 step:800/10100, NER loss:      nan
2019-02-22 11:36:04,379 - log/train6.log - INFO - iteration:95 step:900/10100, NER loss:      nan
2019-02-22 11:36:08,606 - log/train6.log - INFO - iteration:95 step:1000/10100, NER loss:      nan
2019-02-22 11:36:10,835 - log/train6.log - INFO - iteration:95 step:1100/10100, NER loss:      nan
2019-02-22 11:36:12,829 - log/train6.log - INFO - iteration:95 step:1200/10100, NER loss:      nan
2019-02-22 11:36:14,791 - log/train6.log - INFO - iteration:95 step:1300/10100, NER loss:      nan
2019-02-22 11:36:16,847 - log/train6.log - INFO - iteration:95 step:1400/10100, NER loss:      nan
2019-02-22 11:36:19,087 - log/train6.log - INFO - iteration:95 step:1500/10100, NER loss:      nan
2019-02-22 11:36:21,404 - log/train6.log - INFO - iteration:95 step:1600/10100, NER loss:      nan
2019-02-22 11:36:24,089 - log/train6.log - INFO - iteration:95 step:1700/10100, NER loss:      nan
2019-02-22 11:36:26,100 - log/train6.log - INFO - iteration:95 step:1800/10100, NER loss:      nan
2019-02-22 11:36:28,091 - log/train6.log - INFO - iteration:95 step:1900/10100, NER loss:      nan
2019-02-22 11:36:30,411 - log/train6.log - INFO - iteration:95 step:2000/10100, NER loss:      nan
2019-02-22 11:36:32,531 - log/train6.log - INFO - iteration:95 step:2100/10100, NER loss:      nan
2019-02-22 11:36:34,947 - log/train6.log - INFO - iteration:95 step:2200/10100, NER loss:      nan
2019-02-22 11:36:37,110 - log/train6.log - INFO - iteration:95 step:2300/10100, NER loss:      nan
2019-02-22 11:36:39,471 - log/train6.log - INFO - iteration:95 step:2400/10100, NER loss:      nan
2019-02-22 11:36:41,772 - log/train6.log - INFO - iteration:95 step:2500/10100, NER loss:      nan
2019-02-22 11:36:44,522 - log/train6.log - INFO - iteration:95 step:2600/10100, NER loss:      nan
2019-02-22 11:36:46,887 - log/train6.log - INFO - iteration:95 step:2700/10100, NER loss:      nan
2019-02-22 11:36:48,943 - log/train6.log - INFO - iteration:95 step:2800/10100, NER loss:      nan
2019-02-22 11:36:51,049 - log/train6.log - INFO - iteration:95 step:2900/10100, NER loss:      nan
2019-02-22 11:36:53,141 - log/train6.log - INFO - iteration:95 step:3000/10100, NER loss:      nan
2019-02-22 11:36:55,435 - log/train6.log - INFO - iteration:95 step:3100/10100, NER loss:      nan
2019-02-22 11:36:57,573 - log/train6.log - INFO - iteration:95 step:3200/10100, NER loss:      nan
2019-02-22 11:36:59,689 - log/train6.log - INFO - iteration:95 step:3300/10100, NER loss:      nan
2019-02-22 11:37:01,951 - log/train6.log - INFO - iteration:95 step:3400/10100, NER loss:      nan
2019-02-22 11:37:04,098 - log/train6.log - INFO - iteration:95 step:3500/10100, NER loss:      nan
2019-02-22 11:37:06,245 - log/train6.log - INFO - iteration:95 step:3600/10100, NER loss:      nan
2019-02-22 11:37:08,879 - log/train6.log - INFO - iteration:95 step:3700/10100, NER loss:      nan
2019-02-22 11:37:11,214 - log/train6.log - INFO - iteration:95 step:3800/10100, NER loss:      nan
2019-02-22 11:37:13,643 - log/train6.log - INFO - iteration:95 step:3900/10100, NER loss:      nan
2019-02-22 11:37:15,902 - log/train6.log - INFO - iteration:95 step:4000/10100, NER loss:      nan
2019-02-22 11:37:18,157 - log/train6.log - INFO - iteration:95 step:4100/10100, NER loss:      nan
2019-02-22 11:37:20,175 - log/train6.log - INFO - iteration:95 step:4200/10100, NER loss:      nan
2019-02-22 11:37:22,387 - log/train6.log - INFO - iteration:95 step:4300/10100, NER loss:      nan
2019-02-22 11:37:24,734 - log/train6.log - INFO - iteration:95 step:4400/10100, NER loss:      nan
2019-02-22 11:37:26,980 - log/train6.log - INFO - iteration:95 step:4500/10100, NER loss:      nan
2019-02-22 11:37:29,289 - log/train6.log - INFO - iteration:95 step:4600/10100, NER loss:      nan
2019-02-22 11:37:31,680 - log/train6.log - INFO - iteration:95 step:4700/10100, NER loss:      nan
2019-02-22 11:37:33,965 - log/train6.log - INFO - iteration:95 step:4800/10100, NER loss:      nan
2019-02-22 11:37:35,995 - log/train6.log - INFO - iteration:95 step:4900/10100, NER loss:      nan
2019-02-22 11:37:38,391 - log/train6.log - INFO - iteration:95 step:5000/10100, NER loss:      nan
2019-02-22 11:37:40,437 - log/train6.log - INFO - iteration:95 step:5100/10100, NER loss:      nan
2019-02-22 11:37:42,422 - log/train6.log - INFO - iteration:95 step:5200/10100, NER loss:      nan
2019-02-22 11:37:44,528 - log/train6.log - INFO - iteration:95 step:5300/10100, NER loss:      nan
2019-02-22 11:37:46,747 - log/train6.log - INFO - iteration:95 step:5400/10100, NER loss:      nan
2019-02-22 11:37:49,369 - log/train6.log - INFO - iteration:95 step:5500/10100, NER loss:      nan
2019-02-22 11:37:51,521 - log/train6.log - INFO - iteration:95 step:5600/10100, NER loss:      nan
2019-02-22 11:37:53,721 - log/train6.log - INFO - iteration:95 step:5700/10100, NER loss:      nan
2019-02-22 11:37:55,870 - log/train6.log - INFO - iteration:95 step:5800/10100, NER loss:      nan
2019-02-22 11:37:58,183 - log/train6.log - INFO - iteration:95 step:5900/10100, NER loss:      nan
2019-02-22 11:38:00,201 - log/train6.log - INFO - iteration:95 step:6000/10100, NER loss:      nan
2019-02-22 11:38:02,404 - log/train6.log - INFO - iteration:95 step:6100/10100, NER loss:      nan
2019-02-22 11:38:04,667 - log/train6.log - INFO - iteration:95 step:6200/10100, NER loss:      nan
2019-02-22 11:38:07,097 - log/train6.log - INFO - iteration:95 step:6300/10100, NER loss:      nan
2019-02-22 11:38:09,198 - log/train6.log - INFO - iteration:95 step:6400/10100, NER loss:      nan
2019-02-22 11:38:11,585 - log/train6.log - INFO - iteration:95 step:6500/10100, NER loss:      nan
2019-02-22 11:38:13,921 - log/train6.log - INFO - iteration:95 step:6600/10100, NER loss:      nan
2019-02-22 11:38:15,935 - log/train6.log - INFO - iteration:95 step:6700/10100, NER loss:      nan
2019-02-22 11:38:18,136 - log/train6.log - INFO - iteration:95 step:6800/10100, NER loss:      nan
2019-02-22 11:38:20,346 - log/train6.log - INFO - iteration:95 step:6900/10100, NER loss:      nan
2019-02-22 11:38:22,870 - log/train6.log - INFO - iteration:95 step:7000/10100, NER loss:      nan
2019-02-22 11:38:27,359 - log/train6.log - INFO - iteration:95 step:7100/10100, NER loss:      nan
2019-02-22 11:38:29,895 - log/train6.log - INFO - iteration:95 step:7200/10100, NER loss:      nan
2019-02-22 11:38:32,001 - log/train6.log - INFO - iteration:95 step:7300/10100, NER loss:      nan
2019-02-22 11:38:34,042 - log/train6.log - INFO - iteration:95 step:7400/10100, NER loss:      nan
2019-02-22 11:38:36,472 - log/train6.log - INFO - iteration:95 step:7500/10100, NER loss:      nan
2019-02-22 11:38:38,677 - log/train6.log - INFO - iteration:95 step:7600/10100, NER loss:      nan
2019-02-22 11:38:41,003 - log/train6.log - INFO - iteration:95 step:7700/10100, NER loss:      nan
2019-02-22 11:38:43,306 - log/train6.log - INFO - iteration:95 step:7800/10100, NER loss:      nan
2019-02-22 11:38:45,820 - log/train6.log - INFO - iteration:95 step:7900/10100, NER loss:      nan
2019-02-22 11:38:48,228 - log/train6.log - INFO - iteration:95 step:8000/10100, NER loss:      nan
2019-02-22 11:38:50,312 - log/train6.log - INFO - iteration:95 step:8100/10100, NER loss:      nan
2019-02-22 11:38:52,561 - log/train6.log - INFO - iteration:95 step:8200/10100, NER loss:      nan
2019-02-22 11:38:56,647 - log/train6.log - INFO - iteration:95 step:8300/10100, NER loss:      nan
2019-02-22 11:38:58,972 - log/train6.log - INFO - iteration:95 step:8400/10100, NER loss:      nan
2019-02-22 11:39:01,337 - log/train6.log - INFO - iteration:95 step:8500/10100, NER loss:      nan
2019-02-22 11:39:03,899 - log/train6.log - INFO - iteration:95 step:8600/10100, NER loss:      nan
2019-02-22 11:39:06,293 - log/train6.log - INFO - iteration:95 step:8700/10100, NER loss:      nan
2019-02-22 11:39:08,561 - log/train6.log - INFO - iteration:95 step:8800/10100, NER loss:      nan
2019-02-22 11:39:11,164 - log/train6.log - INFO - iteration:95 step:8900/10100, NER loss:      nan
2019-02-22 11:39:13,692 - log/train6.log - INFO - iteration:95 step:9000/10100, NER loss:      nan
2019-02-22 11:39:16,054 - log/train6.log - INFO - iteration:95 step:9100/10100, NER loss:      nan
2019-02-22 11:39:18,566 - log/train6.log - INFO - iteration:95 step:9200/10100, NER loss:      nan
2019-02-22 11:39:21,152 - log/train6.log - INFO - iteration:95 step:9300/10100, NER loss:      nan
2019-02-22 11:39:23,308 - log/train6.log - INFO - iteration:95 step:9400/10100, NER loss:      nan
2019-02-22 11:39:25,273 - log/train6.log - INFO - iteration:95 step:9500/10100, NER loss:      nan
2019-02-22 11:39:27,533 - log/train6.log - INFO - iteration:95 step:9600/10100, NER loss:      nan
2019-02-22 11:39:29,690 - log/train6.log - INFO - iteration:95 step:9700/10100, NER loss:      nan
2019-02-22 11:39:31,960 - log/train6.log - INFO - iteration:95 step:9800/10100, NER loss:      nan
2019-02-22 11:39:34,389 - log/train6.log - INFO - iteration:95 step:9900/10100, NER loss:      nan
2019-02-22 11:39:36,507 - log/train6.log - INFO - iteration:95 step:10000/10100, NER loss:      nan
2019-02-22 11:39:38,920 - log/train6.log - INFO - iteration:96 step:0/10100, NER loss:      nan
2019-02-22 11:39:38,920 - log/train6.log - INFO - evaluate:dev
2019-02-22 11:39:45,673 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:39:45,674 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:39:45,674 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:39:45,674 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:39:45,674 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:39:45,674 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:39:45,674 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:39:45,674 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:39:45,677 - log/train6.log - INFO - evaluate:test
2019-02-22 11:39:47,211 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:39:47,211 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:39:47,211 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:39:47,211 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:39:47,211 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:39:47,211 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:39:47,211 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:39:47,211 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:39:49,489 - log/train6.log - INFO - iteration:96 step:100/10100, NER loss:      nan
2019-02-22 11:39:51,818 - log/train6.log - INFO - iteration:96 step:200/10100, NER loss:      nan
2019-02-22 11:39:54,057 - log/train6.log - INFO - iteration:96 step:300/10100, NER loss:      nan
2019-02-22 11:39:56,160 - log/train6.log - INFO - iteration:96 step:400/10100, NER loss:      nan
2019-02-22 11:39:58,285 - log/train6.log - INFO - iteration:96 step:500/10100, NER loss:      nan
2019-02-22 11:40:00,377 - log/train6.log - INFO - iteration:96 step:600/10100, NER loss:      nan
2019-02-22 11:40:02,595 - log/train6.log - INFO - iteration:96 step:700/10100, NER loss:      nan
2019-02-22 11:40:04,672 - log/train6.log - INFO - iteration:96 step:800/10100, NER loss:      nan
2019-02-22 11:40:06,944 - log/train6.log - INFO - iteration:96 step:900/10100, NER loss:      nan
2019-02-22 11:40:09,279 - log/train6.log - INFO - iteration:96 step:1000/10100, NER loss:      nan
2019-02-22 11:40:11,509 - log/train6.log - INFO - iteration:96 step:1100/10100, NER loss:      nan
2019-02-22 11:40:13,809 - log/train6.log - INFO - iteration:96 step:1200/10100, NER loss:      nan
2019-02-22 11:40:16,040 - log/train6.log - INFO - iteration:96 step:1300/10100, NER loss:      nan
2019-02-22 11:40:18,149 - log/train6.log - INFO - iteration:96 step:1400/10100, NER loss:      nan
2019-02-22 11:40:20,253 - log/train6.log - INFO - iteration:96 step:1500/10100, NER loss:      nan
2019-02-22 11:40:22,489 - log/train6.log - INFO - iteration:96 step:1600/10100, NER loss:      nan
2019-02-22 11:40:24,738 - log/train6.log - INFO - iteration:96 step:1700/10100, NER loss:      nan
2019-02-22 11:40:27,156 - log/train6.log - INFO - iteration:96 step:1800/10100, NER loss:      nan
2019-02-22 11:40:29,424 - log/train6.log - INFO - iteration:96 step:1900/10100, NER loss:      nan
2019-02-22 11:40:31,622 - log/train6.log - INFO - iteration:96 step:2000/10100, NER loss:      nan
2019-02-22 11:40:33,903 - log/train6.log - INFO - iteration:96 step:2100/10100, NER loss:      nan
2019-02-22 11:40:36,096 - log/train6.log - INFO - iteration:96 step:2200/10100, NER loss:      nan
2019-02-22 11:40:38,182 - log/train6.log - INFO - iteration:96 step:2300/10100, NER loss:      nan
2019-02-22 11:40:40,532 - log/train6.log - INFO - iteration:96 step:2400/10100, NER loss:      nan
2019-02-22 11:40:43,005 - log/train6.log - INFO - iteration:96 step:2500/10100, NER loss:      nan
2019-02-22 11:40:45,277 - log/train6.log - INFO - iteration:96 step:2600/10100, NER loss:      nan
2019-02-22 11:40:47,714 - log/train6.log - INFO - iteration:96 step:2700/10100, NER loss:      nan
2019-02-22 11:40:49,838 - log/train6.log - INFO - iteration:96 step:2800/10100, NER loss:      nan
2019-02-22 11:40:52,254 - log/train6.log - INFO - iteration:96 step:2900/10100, NER loss:      nan
2019-02-22 11:40:54,489 - log/train6.log - INFO - iteration:96 step:3000/10100, NER loss:      nan
2019-02-22 11:40:56,661 - log/train6.log - INFO - iteration:96 step:3100/10100, NER loss:      nan
2019-02-22 11:40:58,711 - log/train6.log - INFO - iteration:96 step:3200/10100, NER loss:      nan
2019-02-22 11:41:00,977 - log/train6.log - INFO - iteration:96 step:3300/10100, NER loss:      nan
2019-02-22 11:41:03,262 - log/train6.log - INFO - iteration:96 step:3400/10100, NER loss:      nan
2019-02-22 11:41:05,483 - log/train6.log - INFO - iteration:96 step:3500/10100, NER loss:      nan
2019-02-22 11:41:07,484 - log/train6.log - INFO - iteration:96 step:3600/10100, NER loss:      nan
2019-02-22 11:41:09,677 - log/train6.log - INFO - iteration:96 step:3700/10100, NER loss:      nan
2019-02-22 11:41:11,772 - log/train6.log - INFO - iteration:96 step:3800/10100, NER loss:      nan
2019-02-22 11:41:14,340 - log/train6.log - INFO - iteration:96 step:3900/10100, NER loss:      nan
2019-02-22 11:41:16,783 - log/train6.log - INFO - iteration:96 step:4000/10100, NER loss:      nan
2019-02-22 11:41:19,317 - log/train6.log - INFO - iteration:96 step:4100/10100, NER loss:      nan
2019-02-22 11:41:21,860 - log/train6.log - INFO - iteration:96 step:4200/10100, NER loss:      nan
2019-02-22 11:41:24,219 - log/train6.log - INFO - iteration:96 step:4300/10100, NER loss:      nan
2019-02-22 11:41:26,155 - log/train6.log - INFO - iteration:96 step:4400/10100, NER loss:      nan
2019-02-22 11:41:28,311 - log/train6.log - INFO - iteration:96 step:4500/10100, NER loss:      nan
2019-02-22 11:41:30,616 - log/train6.log - INFO - iteration:96 step:4600/10100, NER loss:      nan
2019-02-22 11:41:33,102 - log/train6.log - INFO - iteration:96 step:4700/10100, NER loss:      nan
2019-02-22 11:41:35,215 - log/train6.log - INFO - iteration:96 step:4800/10100, NER loss:      nan
2019-02-22 11:41:37,442 - log/train6.log - INFO - iteration:96 step:4900/10100, NER loss:      nan
2019-02-22 11:41:39,493 - log/train6.log - INFO - iteration:96 step:5000/10100, NER loss:      nan
2019-02-22 11:41:43,946 - log/train6.log - INFO - iteration:96 step:5100/10100, NER loss:      nan
2019-02-22 11:41:46,167 - log/train6.log - INFO - iteration:96 step:5200/10100, NER loss:      nan
2019-02-22 11:41:48,522 - log/train6.log - INFO - iteration:96 step:5300/10100, NER loss:      nan
2019-02-22 11:41:50,636 - log/train6.log - INFO - iteration:96 step:5400/10100, NER loss:      nan
2019-02-22 11:41:52,948 - log/train6.log - INFO - iteration:96 step:5500/10100, NER loss:      nan
2019-02-22 11:41:55,256 - log/train6.log - INFO - iteration:96 step:5600/10100, NER loss:      nan
2019-02-22 11:41:57,601 - log/train6.log - INFO - iteration:96 step:5700/10100, NER loss:      nan
2019-02-22 11:42:02,248 - log/train6.log - INFO - iteration:96 step:5800/10100, NER loss:      nan
2019-02-22 11:42:04,657 - log/train6.log - INFO - iteration:96 step:5900/10100, NER loss:      nan
2019-02-22 11:42:06,902 - log/train6.log - INFO - iteration:96 step:6000/10100, NER loss:      nan
2019-02-22 11:42:09,127 - log/train6.log - INFO - iteration:96 step:6100/10100, NER loss:      nan
2019-02-22 11:42:11,196 - log/train6.log - INFO - iteration:96 step:6200/10100, NER loss:      nan
2019-02-22 11:42:13,297 - log/train6.log - INFO - iteration:96 step:6300/10100, NER loss:      nan
2019-02-22 11:42:15,517 - log/train6.log - INFO - iteration:96 step:6400/10100, NER loss:      nan
2019-02-22 11:42:17,684 - log/train6.log - INFO - iteration:96 step:6500/10100, NER loss:      nan
2019-02-22 11:42:19,803 - log/train6.log - INFO - iteration:96 step:6600/10100, NER loss:      nan
2019-02-22 11:42:22,002 - log/train6.log - INFO - iteration:96 step:6700/10100, NER loss:      nan
2019-02-22 11:42:24,106 - log/train6.log - INFO - iteration:96 step:6800/10100, NER loss:      nan
2019-02-22 11:42:26,664 - log/train6.log - INFO - iteration:96 step:6900/10100, NER loss:      nan
2019-02-22 11:42:30,729 - log/train6.log - INFO - iteration:96 step:7000/10100, NER loss:      nan
2019-02-22 11:42:32,912 - log/train6.log - INFO - iteration:96 step:7100/10100, NER loss:      nan
2019-02-22 11:42:35,118 - log/train6.log - INFO - iteration:96 step:7200/10100, NER loss:      nan
2019-02-22 11:42:37,303 - log/train6.log - INFO - iteration:96 step:7300/10100, NER loss:      nan
2019-02-22 11:42:39,983 - log/train6.log - INFO - iteration:96 step:7400/10100, NER loss:      nan
2019-02-22 11:42:42,109 - log/train6.log - INFO - iteration:96 step:7500/10100, NER loss:      nan
2019-02-22 11:42:44,374 - log/train6.log - INFO - iteration:96 step:7600/10100, NER loss:      nan
2019-02-22 11:42:46,781 - log/train6.log - INFO - iteration:96 step:7700/10100, NER loss:      nan
2019-02-22 11:42:49,154 - log/train6.log - INFO - iteration:96 step:7800/10100, NER loss:      nan
2019-02-22 11:42:51,351 - log/train6.log - INFO - iteration:96 step:7900/10100, NER loss:      nan
2019-02-22 11:42:53,660 - log/train6.log - INFO - iteration:96 step:8000/10100, NER loss:      nan
2019-02-22 11:42:56,144 - log/train6.log - INFO - iteration:96 step:8100/10100, NER loss:      nan
2019-02-22 11:42:58,967 - log/train6.log - INFO - iteration:96 step:8200/10100, NER loss:      nan
2019-02-22 11:43:01,159 - log/train6.log - INFO - iteration:96 step:8300/10100, NER loss:      nan
2019-02-22 11:43:03,539 - log/train6.log - INFO - iteration:96 step:8400/10100, NER loss:      nan
2019-02-22 11:43:05,661 - log/train6.log - INFO - iteration:96 step:8500/10100, NER loss:      nan
2019-02-22 11:43:07,994 - log/train6.log - INFO - iteration:96 step:8600/10100, NER loss:      nan
2019-02-22 11:43:10,041 - log/train6.log - INFO - iteration:96 step:8700/10100, NER loss:      nan
2019-02-22 11:43:12,247 - log/train6.log - INFO - iteration:96 step:8800/10100, NER loss:      nan
2019-02-22 11:43:14,886 - log/train6.log - INFO - iteration:96 step:8900/10100, NER loss:      nan
2019-02-22 11:43:17,070 - log/train6.log - INFO - iteration:96 step:9000/10100, NER loss:      nan
2019-02-22 11:43:19,245 - log/train6.log - INFO - iteration:96 step:9100/10100, NER loss:      nan
2019-02-22 11:43:21,449 - log/train6.log - INFO - iteration:96 step:9200/10100, NER loss:      nan
2019-02-22 11:43:23,738 - log/train6.log - INFO - iteration:96 step:9300/10100, NER loss:      nan
2019-02-22 11:43:25,979 - log/train6.log - INFO - iteration:96 step:9400/10100, NER loss:      nan
2019-02-22 11:43:28,239 - log/train6.log - INFO - iteration:96 step:9500/10100, NER loss:      nan
2019-02-22 11:43:30,340 - log/train6.log - INFO - iteration:96 step:9600/10100, NER loss:      nan
2019-02-22 11:43:32,570 - log/train6.log - INFO - iteration:96 step:9700/10100, NER loss:      nan
2019-02-22 11:43:34,641 - log/train6.log - INFO - iteration:96 step:9800/10100, NER loss:      nan
2019-02-22 11:43:36,820 - log/train6.log - INFO - iteration:96 step:9900/10100, NER loss:      nan
2019-02-22 11:43:38,892 - log/train6.log - INFO - iteration:96 step:10000/10100, NER loss:      nan
2019-02-22 11:43:41,166 - log/train6.log - INFO - iteration:97 step:0/10100, NER loss:      nan
2019-02-22 11:43:41,167 - log/train6.log - INFO - evaluate:dev
2019-02-22 11:43:47,792 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:43:47,792 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:43:47,792 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:43:47,792 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:43:47,792 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:43:47,792 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:43:47,792 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:43:47,792 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:43:47,795 - log/train6.log - INFO - evaluate:test
2019-02-22 11:43:49,276 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:43:49,276 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:43:49,276 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:43:49,276 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:43:49,277 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:43:49,277 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:43:49,277 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:43:49,277 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:43:51,572 - log/train6.log - INFO - iteration:97 step:100/10100, NER loss:      nan
2019-02-22 11:43:53,913 - log/train6.log - INFO - iteration:97 step:200/10100, NER loss:      nan
2019-02-22 11:43:56,216 - log/train6.log - INFO - iteration:97 step:300/10100, NER loss:      nan
2019-02-22 11:43:58,343 - log/train6.log - INFO - iteration:97 step:400/10100, NER loss:      nan
2019-02-22 11:44:00,540 - log/train6.log - INFO - iteration:97 step:500/10100, NER loss:      nan
2019-02-22 11:44:02,950 - log/train6.log - INFO - iteration:97 step:600/10100, NER loss:      nan
2019-02-22 11:44:06,998 - log/train6.log - INFO - iteration:97 step:700/10100, NER loss:      nan
2019-02-22 11:44:09,370 - log/train6.log - INFO - iteration:97 step:800/10100, NER loss:      nan
2019-02-22 11:44:11,425 - log/train6.log - INFO - iteration:97 step:900/10100, NER loss:      nan
2019-02-22 11:44:13,419 - log/train6.log - INFO - iteration:97 step:1000/10100, NER loss:      nan
2019-02-22 11:44:15,511 - log/train6.log - INFO - iteration:97 step:1100/10100, NER loss:      nan
2019-02-22 11:44:17,779 - log/train6.log - INFO - iteration:97 step:1200/10100, NER loss:      nan
2019-02-22 11:44:20,109 - log/train6.log - INFO - iteration:97 step:1300/10100, NER loss:      nan
2019-02-22 11:44:22,451 - log/train6.log - INFO - iteration:97 step:1400/10100, NER loss:      nan
2019-02-22 11:44:24,650 - log/train6.log - INFO - iteration:97 step:1500/10100, NER loss:      nan
2019-02-22 11:44:26,720 - log/train6.log - INFO - iteration:97 step:1600/10100, NER loss:      nan
2019-02-22 11:44:28,765 - log/train6.log - INFO - iteration:97 step:1700/10100, NER loss:      nan
2019-02-22 11:44:31,081 - log/train6.log - INFO - iteration:97 step:1800/10100, NER loss:      nan
2019-02-22 11:44:33,135 - log/train6.log - INFO - iteration:97 step:1900/10100, NER loss:      nan
2019-02-22 11:44:35,245 - log/train6.log - INFO - iteration:97 step:2000/10100, NER loss:      nan
2019-02-22 11:44:37,213 - log/train6.log - INFO - iteration:97 step:2100/10100, NER loss:      nan
2019-02-22 11:44:39,558 - log/train6.log - INFO - iteration:97 step:2200/10100, NER loss:      nan
2019-02-22 11:44:41,667 - log/train6.log - INFO - iteration:97 step:2300/10100, NER loss:      nan
2019-02-22 11:44:43,937 - log/train6.log - INFO - iteration:97 step:2400/10100, NER loss:      nan
2019-02-22 11:44:45,916 - log/train6.log - INFO - iteration:97 step:2500/10100, NER loss:      nan
2019-02-22 11:44:48,080 - log/train6.log - INFO - iteration:97 step:2600/10100, NER loss:      nan
2019-02-22 11:44:50,403 - log/train6.log - INFO - iteration:97 step:2700/10100, NER loss:      nan
2019-02-22 11:44:52,505 - log/train6.log - INFO - iteration:97 step:2800/10100, NER loss:      nan
2019-02-22 11:44:54,654 - log/train6.log - INFO - iteration:97 step:2900/10100, NER loss:      nan
2019-02-22 11:44:56,747 - log/train6.log - INFO - iteration:97 step:3000/10100, NER loss:      nan
2019-02-22 11:44:58,750 - log/train6.log - INFO - iteration:97 step:3100/10100, NER loss:      nan
2019-02-22 11:45:00,906 - log/train6.log - INFO - iteration:97 step:3200/10100, NER loss:      nan
2019-02-22 11:45:03,104 - log/train6.log - INFO - iteration:97 step:3300/10100, NER loss:      nan
2019-02-22 11:45:05,085 - log/train6.log - INFO - iteration:97 step:3400/10100, NER loss:      nan
2019-02-22 11:45:07,475 - log/train6.log - INFO - iteration:97 step:3500/10100, NER loss:      nan
2019-02-22 11:45:09,626 - log/train6.log - INFO - iteration:97 step:3600/10100, NER loss:      nan
2019-02-22 11:45:11,881 - log/train6.log - INFO - iteration:97 step:3700/10100, NER loss:      nan
2019-02-22 11:45:14,067 - log/train6.log - INFO - iteration:97 step:3800/10100, NER loss:      nan
2019-02-22 11:45:16,236 - log/train6.log - INFO - iteration:97 step:3900/10100, NER loss:      nan
2019-02-22 11:45:18,371 - log/train6.log - INFO - iteration:97 step:4000/10100, NER loss:      nan
2019-02-22 11:45:20,743 - log/train6.log - INFO - iteration:97 step:4100/10100, NER loss:      nan
2019-02-22 11:45:22,808 - log/train6.log - INFO - iteration:97 step:4200/10100, NER loss:      nan
2019-02-22 11:45:24,909 - log/train6.log - INFO - iteration:97 step:4300/10100, NER loss:      nan
2019-02-22 11:45:27,057 - log/train6.log - INFO - iteration:97 step:4400/10100, NER loss:      nan
2019-02-22 11:45:29,065 - log/train6.log - INFO - iteration:97 step:4500/10100, NER loss:      nan
2019-02-22 11:45:31,240 - log/train6.log - INFO - iteration:97 step:4600/10100, NER loss:      nan
2019-02-22 11:45:33,555 - log/train6.log - INFO - iteration:97 step:4700/10100, NER loss:      nan
2019-02-22 11:45:35,651 - log/train6.log - INFO - iteration:97 step:4800/10100, NER loss:      nan
2019-02-22 11:45:37,742 - log/train6.log - INFO - iteration:97 step:4900/10100, NER loss:      nan
2019-02-22 11:45:40,033 - log/train6.log - INFO - iteration:97 step:5000/10100, NER loss:      nan
2019-02-22 11:45:42,080 - log/train6.log - INFO - iteration:97 step:5100/10100, NER loss:      nan
2019-02-22 11:45:44,320 - log/train6.log - INFO - iteration:97 step:5200/10100, NER loss:      nan
2019-02-22 11:45:46,693 - log/train6.log - INFO - iteration:97 step:5300/10100, NER loss:      nan
2019-02-22 11:45:48,903 - log/train6.log - INFO - iteration:97 step:5400/10100, NER loss:      nan
2019-02-22 11:45:50,877 - log/train6.log - INFO - iteration:97 step:5500/10100, NER loss:      nan
2019-02-22 11:45:52,999 - log/train6.log - INFO - iteration:97 step:5600/10100, NER loss:      nan
2019-02-22 11:45:55,416 - log/train6.log - INFO - iteration:97 step:5700/10100, NER loss:      nan
2019-02-22 11:45:57,649 - log/train6.log - INFO - iteration:97 step:5800/10100, NER loss:      nan
2019-02-22 11:45:59,828 - log/train6.log - INFO - iteration:97 step:5900/10100, NER loss:      nan
2019-02-22 11:46:01,865 - log/train6.log - INFO - iteration:97 step:6000/10100, NER loss:      nan
2019-02-22 11:46:04,138 - log/train6.log - INFO - iteration:97 step:6100/10100, NER loss:      nan
2019-02-22 11:46:06,372 - log/train6.log - INFO - iteration:97 step:6200/10100, NER loss:      nan
2019-02-22 11:46:08,783 - log/train6.log - INFO - iteration:97 step:6300/10100, NER loss:      nan
2019-02-22 11:46:10,743 - log/train6.log - INFO - iteration:97 step:6400/10100, NER loss:      nan
2019-02-22 11:46:12,964 - log/train6.log - INFO - iteration:97 step:6500/10100, NER loss:      nan
2019-02-22 11:46:15,034 - log/train6.log - INFO - iteration:97 step:6600/10100, NER loss:      nan
2019-02-22 11:46:17,160 - log/train6.log - INFO - iteration:97 step:6700/10100, NER loss:      nan
2019-02-22 11:46:19,267 - log/train6.log - INFO - iteration:97 step:6800/10100, NER loss:      nan
2019-02-22 11:46:21,587 - log/train6.log - INFO - iteration:97 step:6900/10100, NER loss:      nan
2019-02-22 11:46:23,597 - log/train6.log - INFO - iteration:97 step:7000/10100, NER loss:      nan
2019-02-22 11:46:25,633 - log/train6.log - INFO - iteration:97 step:7100/10100, NER loss:      nan
2019-02-22 11:46:27,974 - log/train6.log - INFO - iteration:97 step:7200/10100, NER loss:      nan
2019-02-22 11:46:30,055 - log/train6.log - INFO - iteration:97 step:7300/10100, NER loss:      nan
2019-02-22 11:46:32,209 - log/train6.log - INFO - iteration:97 step:7400/10100, NER loss:      nan
2019-02-22 11:46:34,424 - log/train6.log - INFO - iteration:97 step:7500/10100, NER loss:      nan
2019-02-22 11:46:38,865 - log/train6.log - INFO - iteration:97 step:7600/10100, NER loss:      nan
2019-02-22 11:46:42,978 - log/train6.log - INFO - iteration:97 step:7700/10100, NER loss:      nan
2019-02-22 11:46:45,118 - log/train6.log - INFO - iteration:97 step:7800/10100, NER loss:      nan
2019-02-22 11:46:47,248 - log/train6.log - INFO - iteration:97 step:7900/10100, NER loss:      nan
2019-02-22 11:46:49,459 - log/train6.log - INFO - iteration:97 step:8000/10100, NER loss:      nan
2019-02-22 11:46:51,707 - log/train6.log - INFO - iteration:97 step:8100/10100, NER loss:      nan
2019-02-22 11:46:54,040 - log/train6.log - INFO - iteration:97 step:8200/10100, NER loss:      nan
2019-02-22 11:46:56,320 - log/train6.log - INFO - iteration:97 step:8300/10100, NER loss:      nan
2019-02-22 11:46:58,606 - log/train6.log - INFO - iteration:97 step:8400/10100, NER loss:      nan
2019-02-22 11:47:01,145 - log/train6.log - INFO - iteration:97 step:8500/10100, NER loss:      nan
2019-02-22 11:47:03,151 - log/train6.log - INFO - iteration:97 step:8600/10100, NER loss:      nan
2019-02-22 11:47:05,197 - log/train6.log - INFO - iteration:97 step:8700/10100, NER loss:      nan
2019-02-22 11:47:07,516 - log/train6.log - INFO - iteration:97 step:8800/10100, NER loss:      nan
2019-02-22 11:47:09,598 - log/train6.log - INFO - iteration:97 step:8900/10100, NER loss:      nan
2019-02-22 11:47:11,733 - log/train6.log - INFO - iteration:97 step:9000/10100, NER loss:      nan
2019-02-22 11:47:13,999 - log/train6.log - INFO - iteration:97 step:9100/10100, NER loss:      nan
2019-02-22 11:47:15,985 - log/train6.log - INFO - iteration:97 step:9200/10100, NER loss:      nan
2019-02-22 11:47:18,029 - log/train6.log - INFO - iteration:97 step:9300/10100, NER loss:      nan
2019-02-22 11:47:20,416 - log/train6.log - INFO - iteration:97 step:9400/10100, NER loss:      nan
2019-02-22 11:47:22,683 - log/train6.log - INFO - iteration:97 step:9500/10100, NER loss:      nan
2019-02-22 11:47:24,881 - log/train6.log - INFO - iteration:97 step:9600/10100, NER loss:      nan
2019-02-22 11:47:27,013 - log/train6.log - INFO - iteration:97 step:9700/10100, NER loss:      nan
2019-02-22 11:47:29,116 - log/train6.log - INFO - iteration:97 step:9800/10100, NER loss:      nan
2019-02-22 11:47:31,281 - log/train6.log - INFO - iteration:97 step:9900/10100, NER loss:      nan
2019-02-22 11:47:33,420 - log/train6.log - INFO - iteration:97 step:10000/10100, NER loss:      nan
2019-02-22 11:47:35,623 - log/train6.log - INFO - iteration:98 step:0/10100, NER loss:      nan
2019-02-22 11:47:35,623 - log/train6.log - INFO - evaluate:dev
2019-02-22 11:47:42,205 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:47:42,205 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:47:42,205 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:47:42,205 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:47:42,205 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:47:42,205 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:47:42,206 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:47:42,206 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:47:42,209 - log/train6.log - INFO - evaluate:test
2019-02-22 11:47:43,688 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:47:43,688 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:47:43,688 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:47:43,688 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:47:43,688 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:47:43,688 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:47:43,688 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:47:43,688 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:47:45,649 - log/train6.log - INFO - iteration:98 step:100/10100, NER loss:      nan
2019-02-22 11:47:47,819 - log/train6.log - INFO - iteration:98 step:200/10100, NER loss:      nan
2019-02-22 11:47:50,341 - log/train6.log - INFO - iteration:98 step:300/10100, NER loss:      nan
2019-02-22 11:47:52,690 - log/train6.log - INFO - iteration:98 step:400/10100, NER loss:      nan
2019-02-22 11:47:54,817 - log/train6.log - INFO - iteration:98 step:500/10100, NER loss:      nan
2019-02-22 11:47:57,008 - log/train6.log - INFO - iteration:98 step:600/10100, NER loss:      nan
2019-02-22 11:47:59,161 - log/train6.log - INFO - iteration:98 step:700/10100, NER loss:      nan
2019-02-22 11:48:01,500 - log/train6.log - INFO - iteration:98 step:800/10100, NER loss:      nan
2019-02-22 11:48:03,747 - log/train6.log - INFO - iteration:98 step:900/10100, NER loss:      nan
2019-02-22 11:48:05,857 - log/train6.log - INFO - iteration:98 step:1000/10100, NER loss:      nan
2019-02-22 11:48:07,938 - log/train6.log - INFO - iteration:98 step:1100/10100, NER loss:      nan
2019-02-22 11:48:10,222 - log/train6.log - INFO - iteration:98 step:1200/10100, NER loss:      nan
2019-02-22 11:48:12,326 - log/train6.log - INFO - iteration:98 step:1300/10100, NER loss:      nan
2019-02-22 11:48:14,590 - log/train6.log - INFO - iteration:98 step:1400/10100, NER loss:      nan
2019-02-22 11:48:16,453 - log/train6.log - INFO - iteration:98 step:1500/10100, NER loss:      nan
2019-02-22 11:48:18,798 - log/train6.log - INFO - iteration:98 step:1600/10100, NER loss:      nan
2019-02-22 11:48:20,995 - log/train6.log - INFO - iteration:98 step:1700/10100, NER loss:      nan
2019-02-22 11:48:23,132 - log/train6.log - INFO - iteration:98 step:1800/10100, NER loss:      nan
2019-02-22 11:48:25,581 - log/train6.log - INFO - iteration:98 step:1900/10100, NER loss:      nan
2019-02-22 11:48:27,738 - log/train6.log - INFO - iteration:98 step:2000/10100, NER loss:      nan
2019-02-22 11:48:30,147 - log/train6.log - INFO - iteration:98 step:2100/10100, NER loss:      nan
2019-02-22 11:48:32,241 - log/train6.log - INFO - iteration:98 step:2200/10100, NER loss:      nan
2019-02-22 11:48:34,187 - log/train6.log - INFO - iteration:98 step:2300/10100, NER loss:      nan
2019-02-22 11:48:36,263 - log/train6.log - INFO - iteration:98 step:2400/10100, NER loss:      nan
2019-02-22 11:48:38,706 - log/train6.log - INFO - iteration:98 step:2500/10100, NER loss:      nan
2019-02-22 11:48:40,893 - log/train6.log - INFO - iteration:98 step:2600/10100, NER loss:      nan
2019-02-22 11:48:42,852 - log/train6.log - INFO - iteration:98 step:2700/10100, NER loss:      nan
2019-02-22 11:48:44,960 - log/train6.log - INFO - iteration:98 step:2800/10100, NER loss:      nan
2019-02-22 11:48:47,115 - log/train6.log - INFO - iteration:98 step:2900/10100, NER loss:      nan
2019-02-22 11:48:49,488 - log/train6.log - INFO - iteration:98 step:3000/10100, NER loss:      nan
2019-02-22 11:48:51,593 - log/train6.log - INFO - iteration:98 step:3100/10100, NER loss:      nan
2019-02-22 11:48:53,939 - log/train6.log - INFO - iteration:98 step:3200/10100, NER loss:      nan
2019-02-22 11:48:55,952 - log/train6.log - INFO - iteration:98 step:3300/10100, NER loss:      nan
2019-02-22 11:48:58,550 - log/train6.log - INFO - iteration:98 step:3400/10100, NER loss:      nan
2019-02-22 11:49:00,765 - log/train6.log - INFO - iteration:98 step:3500/10100, NER loss:      nan
2019-02-22 11:49:03,051 - log/train6.log - INFO - iteration:98 step:3600/10100, NER loss:      nan
2019-02-22 11:49:05,261 - log/train6.log - INFO - iteration:98 step:3700/10100, NER loss:      nan
2019-02-22 11:49:07,500 - log/train6.log - INFO - iteration:98 step:3800/10100, NER loss:      nan
2019-02-22 11:49:09,930 - log/train6.log - INFO - iteration:98 step:3900/10100, NER loss:      nan
2019-02-22 11:49:11,956 - log/train6.log - INFO - iteration:98 step:4000/10100, NER loss:      nan
2019-02-22 11:49:14,261 - log/train6.log - INFO - iteration:98 step:4100/10100, NER loss:      nan
2019-02-22 11:49:16,587 - log/train6.log - INFO - iteration:98 step:4200/10100, NER loss:      nan
2019-02-22 11:49:18,620 - log/train6.log - INFO - iteration:98 step:4300/10100, NER loss:      nan
2019-02-22 11:49:20,718 - log/train6.log - INFO - iteration:98 step:4400/10100, NER loss:      nan
2019-02-22 11:49:22,944 - log/train6.log - INFO - iteration:98 step:4500/10100, NER loss:      nan
2019-02-22 11:49:26,989 - log/train6.log - INFO - iteration:98 step:4600/10100, NER loss:      nan
2019-02-22 11:49:29,159 - log/train6.log - INFO - iteration:98 step:4700/10100, NER loss:      nan
2019-02-22 11:49:31,509 - log/train6.log - INFO - iteration:98 step:4800/10100, NER loss:      nan
2019-02-22 11:49:33,815 - log/train6.log - INFO - iteration:98 step:4900/10100, NER loss:      nan
2019-02-22 11:49:36,002 - log/train6.log - INFO - iteration:98 step:5000/10100, NER loss:      nan
2019-02-22 11:49:38,121 - log/train6.log - INFO - iteration:98 step:5100/10100, NER loss:      nan
2019-02-22 11:49:40,414 - log/train6.log - INFO - iteration:98 step:5200/10100, NER loss:      nan
2019-02-22 11:49:42,522 - log/train6.log - INFO - iteration:98 step:5300/10100, NER loss:      nan
2019-02-22 11:49:44,949 - log/train6.log - INFO - iteration:98 step:5400/10100, NER loss:      nan
2019-02-22 11:49:47,049 - log/train6.log - INFO - iteration:98 step:5500/10100, NER loss:      nan
2019-02-22 11:49:49,528 - log/train6.log - INFO - iteration:98 step:5600/10100, NER loss:      nan
2019-02-22 11:49:51,867 - log/train6.log - INFO - iteration:98 step:5700/10100, NER loss:      nan
2019-02-22 11:49:54,447 - log/train6.log - INFO - iteration:98 step:5800/10100, NER loss:      nan
2019-02-22 11:49:56,660 - log/train6.log - INFO - iteration:98 step:5900/10100, NER loss:      nan
2019-02-22 11:49:58,914 - log/train6.log - INFO - iteration:98 step:6000/10100, NER loss:      nan
2019-02-22 11:50:03,981 - log/train6.log - INFO - iteration:98 step:6100/10100, NER loss:      nan
2019-02-22 11:50:06,077 - log/train6.log - INFO - iteration:98 step:6200/10100, NER loss:      nan
2019-02-22 11:50:08,125 - log/train6.log - INFO - iteration:98 step:6300/10100, NER loss:      nan
2019-02-22 11:50:10,176 - log/train6.log - INFO - iteration:98 step:6400/10100, NER loss:      nan
2019-02-22 11:50:12,751 - log/train6.log - INFO - iteration:98 step:6500/10100, NER loss:      nan
2019-02-22 11:50:14,844 - log/train6.log - INFO - iteration:98 step:6600/10100, NER loss:      nan
2019-02-22 11:50:17,292 - log/train6.log - INFO - iteration:98 step:6700/10100, NER loss:      nan
2019-02-22 11:50:19,494 - log/train6.log - INFO - iteration:98 step:6800/10100, NER loss:      nan
2019-02-22 11:50:21,675 - log/train6.log - INFO - iteration:98 step:6900/10100, NER loss:      nan
2019-02-22 11:50:23,727 - log/train6.log - INFO - iteration:98 step:7000/10100, NER loss:      nan
2019-02-22 11:50:25,798 - log/train6.log - INFO - iteration:98 step:7100/10100, NER loss:      nan
2019-02-22 11:50:27,971 - log/train6.log - INFO - iteration:98 step:7200/10100, NER loss:      nan
2019-02-22 11:50:29,888 - log/train6.log - INFO - iteration:98 step:7300/10100, NER loss:      nan
2019-02-22 11:50:32,031 - log/train6.log - INFO - iteration:98 step:7400/10100, NER loss:      nan
2019-02-22 11:50:34,120 - log/train6.log - INFO - iteration:98 step:7500/10100, NER loss:      nan
2019-02-22 11:50:36,407 - log/train6.log - INFO - iteration:98 step:7600/10100, NER loss:      nan
2019-02-22 11:50:40,438 - log/train6.log - INFO - iteration:98 step:7700/10100, NER loss:      nan
2019-02-22 11:50:42,575 - log/train6.log - INFO - iteration:98 step:7800/10100, NER loss:      nan
2019-02-22 11:50:44,781 - log/train6.log - INFO - iteration:98 step:7900/10100, NER loss:      nan
2019-02-22 11:50:47,000 - log/train6.log - INFO - iteration:98 step:8000/10100, NER loss:      nan
2019-02-22 11:50:49,148 - log/train6.log - INFO - iteration:98 step:8100/10100, NER loss:      nan
2019-02-22 11:50:51,209 - log/train6.log - INFO - iteration:98 step:8200/10100, NER loss:      nan
2019-02-22 11:50:53,446 - log/train6.log - INFO - iteration:98 step:8300/10100, NER loss:      nan
2019-02-22 11:50:55,446 - log/train6.log - INFO - iteration:98 step:8400/10100, NER loss:      nan
2019-02-22 11:50:57,547 - log/train6.log - INFO - iteration:98 step:8500/10100, NER loss:      nan
2019-02-22 11:50:59,502 - log/train6.log - INFO - iteration:98 step:8600/10100, NER loss:      nan
2019-02-22 11:51:01,463 - log/train6.log - INFO - iteration:98 step:8700/10100, NER loss:      nan
2019-02-22 11:51:03,595 - log/train6.log - INFO - iteration:98 step:8800/10100, NER loss:      nan
2019-02-22 11:51:05,613 - log/train6.log - INFO - iteration:98 step:8900/10100, NER loss:      nan
2019-02-22 11:51:07,650 - log/train6.log - INFO - iteration:98 step:9000/10100, NER loss:      nan
2019-02-22 11:51:09,660 - log/train6.log - INFO - iteration:98 step:9100/10100, NER loss:      nan
2019-02-22 11:51:11,816 - log/train6.log - INFO - iteration:98 step:9200/10100, NER loss:      nan
2019-02-22 11:51:13,942 - log/train6.log - INFO - iteration:98 step:9300/10100, NER loss:      nan
2019-02-22 11:51:16,286 - log/train6.log - INFO - iteration:98 step:9400/10100, NER loss:      nan
2019-02-22 11:51:18,467 - log/train6.log - INFO - iteration:98 step:9500/10100, NER loss:      nan
2019-02-22 11:51:20,730 - log/train6.log - INFO - iteration:98 step:9600/10100, NER loss:      nan
2019-02-22 11:51:23,041 - log/train6.log - INFO - iteration:98 step:9700/10100, NER loss:      nan
2019-02-22 11:51:25,767 - log/train6.log - INFO - iteration:98 step:9800/10100, NER loss:      nan
2019-02-22 11:51:28,093 - log/train6.log - INFO - iteration:98 step:9900/10100, NER loss:      nan
2019-02-22 11:51:30,192 - log/train6.log - INFO - iteration:98 step:10000/10100, NER loss:      nan
2019-02-22 11:51:32,595 - log/train6.log - INFO - iteration:99 step:0/10100, NER loss:      nan
2019-02-22 11:51:32,595 - log/train6.log - INFO - evaluate:dev
2019-02-22 11:51:39,188 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:51:39,189 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:51:39,189 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:51:39,189 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:51:39,189 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:51:39,189 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:51:39,189 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:51:39,189 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:51:39,192 - log/train6.log - INFO - evaluate:test
2019-02-22 11:51:40,657 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:51:40,657 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:51:40,657 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:51:40,657 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:51:40,657 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:51:40,657 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:51:40,657 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:51:40,657 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:51:42,713 - log/train6.log - INFO - iteration:99 step:100/10100, NER loss:      nan
2019-02-22 11:51:44,690 - log/train6.log - INFO - iteration:99 step:200/10100, NER loss:      nan
2019-02-22 11:51:46,831 - log/train6.log - INFO - iteration:99 step:300/10100, NER loss:      nan
2019-02-22 11:51:48,838 - log/train6.log - INFO - iteration:99 step:400/10100, NER loss:      nan
2019-02-22 11:51:51,214 - log/train6.log - INFO - iteration:99 step:500/10100, NER loss:      nan
2019-02-22 11:51:53,357 - log/train6.log - INFO - iteration:99 step:600/10100, NER loss:      nan
2019-02-22 11:51:55,388 - log/train6.log - INFO - iteration:99 step:700/10100, NER loss:      nan
2019-02-22 11:51:57,650 - log/train6.log - INFO - iteration:99 step:800/10100, NER loss:      nan
2019-02-22 11:51:59,918 - log/train6.log - INFO - iteration:99 step:900/10100, NER loss:      nan
2019-02-22 11:52:02,056 - log/train6.log - INFO - iteration:99 step:1000/10100, NER loss:      nan
2019-02-22 11:52:04,193 - log/train6.log - INFO - iteration:99 step:1100/10100, NER loss:      nan
2019-02-22 11:52:06,191 - log/train6.log - INFO - iteration:99 step:1200/10100, NER loss:      nan
2019-02-22 11:52:08,369 - log/train6.log - INFO - iteration:99 step:1300/10100, NER loss:      nan
2019-02-22 11:52:10,662 - log/train6.log - INFO - iteration:99 step:1400/10100, NER loss:      nan
2019-02-22 11:52:13,007 - log/train6.log - INFO - iteration:99 step:1500/10100, NER loss:      nan
2019-02-22 11:52:14,949 - log/train6.log - INFO - iteration:99 step:1600/10100, NER loss:      nan
2019-02-22 11:52:16,976 - log/train6.log - INFO - iteration:99 step:1700/10100, NER loss:      nan
2019-02-22 11:52:19,123 - log/train6.log - INFO - iteration:99 step:1800/10100, NER loss:      nan
2019-02-22 11:52:21,174 - log/train6.log - INFO - iteration:99 step:1900/10100, NER loss:      nan
2019-02-22 11:52:23,301 - log/train6.log - INFO - iteration:99 step:2000/10100, NER loss:      nan
2019-02-22 11:52:25,723 - log/train6.log - INFO - iteration:99 step:2100/10100, NER loss:      nan
2019-02-22 11:52:28,029 - log/train6.log - INFO - iteration:99 step:2200/10100, NER loss:      nan
2019-02-22 11:52:30,289 - log/train6.log - INFO - iteration:99 step:2300/10100, NER loss:      nan
2019-02-22 11:52:32,425 - log/train6.log - INFO - iteration:99 step:2400/10100, NER loss:      nan
2019-02-22 11:52:34,548 - log/train6.log - INFO - iteration:99 step:2500/10100, NER loss:      nan
2019-02-22 11:52:36,370 - log/train6.log - INFO - iteration:99 step:2600/10100, NER loss:      nan
2019-02-22 11:52:38,452 - log/train6.log - INFO - iteration:99 step:2700/10100, NER loss:      nan
2019-02-22 11:52:40,679 - log/train6.log - INFO - iteration:99 step:2800/10100, NER loss:      nan
2019-02-22 11:52:42,946 - log/train6.log - INFO - iteration:99 step:2900/10100, NER loss:      nan
2019-02-22 11:52:45,423 - log/train6.log - INFO - iteration:99 step:3000/10100, NER loss:      nan
2019-02-22 11:52:47,894 - log/train6.log - INFO - iteration:99 step:3100/10100, NER loss:      nan
2019-02-22 11:52:50,122 - log/train6.log - INFO - iteration:99 step:3200/10100, NER loss:      nan
2019-02-22 11:52:52,190 - log/train6.log - INFO - iteration:99 step:3300/10100, NER loss:      nan
2019-02-22 11:52:54,229 - log/train6.log - INFO - iteration:99 step:3400/10100, NER loss:      nan
2019-02-22 11:52:56,407 - log/train6.log - INFO - iteration:99 step:3500/10100, NER loss:      nan
2019-02-22 11:52:58,735 - log/train6.log - INFO - iteration:99 step:3600/10100, NER loss:      nan
2019-02-22 11:53:00,793 - log/train6.log - INFO - iteration:99 step:3700/10100, NER loss:      nan
2019-02-22 11:53:02,818 - log/train6.log - INFO - iteration:99 step:3800/10100, NER loss:      nan
2019-02-22 11:53:04,915 - log/train6.log - INFO - iteration:99 step:3900/10100, NER loss:      nan
2019-02-22 11:53:07,146 - log/train6.log - INFO - iteration:99 step:4000/10100, NER loss:      nan
2019-02-22 11:53:09,136 - log/train6.log - INFO - iteration:99 step:4100/10100, NER loss:      nan
2019-02-22 11:53:11,370 - log/train6.log - INFO - iteration:99 step:4200/10100, NER loss:      nan
2019-02-22 11:53:13,605 - log/train6.log - INFO - iteration:99 step:4300/10100, NER loss:      nan
2019-02-22 11:53:16,078 - log/train6.log - INFO - iteration:99 step:4400/10100, NER loss:      nan
2019-02-22 11:53:18,351 - log/train6.log - INFO - iteration:99 step:4500/10100, NER loss:      nan
2019-02-22 11:53:20,380 - log/train6.log - INFO - iteration:99 step:4600/10100, NER loss:      nan
2019-02-22 11:53:22,332 - log/train6.log - INFO - iteration:99 step:4700/10100, NER loss:      nan
2019-02-22 11:53:24,566 - log/train6.log - INFO - iteration:99 step:4800/10100, NER loss:      nan
2019-02-22 11:53:29,091 - log/train6.log - INFO - iteration:99 step:4900/10100, NER loss:      nan
2019-02-22 11:53:31,610 - log/train6.log - INFO - iteration:99 step:5000/10100, NER loss:      nan
2019-02-22 11:53:33,744 - log/train6.log - INFO - iteration:99 step:5100/10100, NER loss:      nan
2019-02-22 11:53:35,989 - log/train6.log - INFO - iteration:99 step:5200/10100, NER loss:      nan
2019-02-22 11:53:38,054 - log/train6.log - INFO - iteration:99 step:5300/10100, NER loss:      nan
2019-02-22 11:53:40,207 - log/train6.log - INFO - iteration:99 step:5400/10100, NER loss:      nan
2019-02-22 11:53:42,462 - log/train6.log - INFO - iteration:99 step:5500/10100, NER loss:      nan
2019-02-22 11:53:44,536 - log/train6.log - INFO - iteration:99 step:5600/10100, NER loss:      nan
2019-02-22 11:53:46,698 - log/train6.log - INFO - iteration:99 step:5700/10100, NER loss:      nan
2019-02-22 11:53:48,829 - log/train6.log - INFO - iteration:99 step:5800/10100, NER loss:      nan
2019-02-22 11:53:51,123 - log/train6.log - INFO - iteration:99 step:5900/10100, NER loss:      nan
2019-02-22 11:53:53,117 - log/train6.log - INFO - iteration:99 step:6000/10100, NER loss:      nan
2019-02-22 11:53:55,356 - log/train6.log - INFO - iteration:99 step:6100/10100, NER loss:      nan
2019-02-22 11:53:57,360 - log/train6.log - INFO - iteration:99 step:6200/10100, NER loss:      nan
2019-02-22 11:53:59,475 - log/train6.log - INFO - iteration:99 step:6300/10100, NER loss:      nan
2019-02-22 11:54:04,065 - log/train6.log - INFO - iteration:99 step:6400/10100, NER loss:      nan
2019-02-22 11:54:06,273 - log/train6.log - INFO - iteration:99 step:6500/10100, NER loss:      nan
2019-02-22 11:54:08,343 - log/train6.log - INFO - iteration:99 step:6600/10100, NER loss:      nan
2019-02-22 11:54:10,437 - log/train6.log - INFO - iteration:99 step:6700/10100, NER loss:      nan
2019-02-22 11:54:12,466 - log/train6.log - INFO - iteration:99 step:6800/10100, NER loss:      nan
2019-02-22 11:54:14,629 - log/train6.log - INFO - iteration:99 step:6900/10100, NER loss:      nan
2019-02-22 11:54:16,889 - log/train6.log - INFO - iteration:99 step:7000/10100, NER loss:      nan
2019-02-22 11:54:18,855 - log/train6.log - INFO - iteration:99 step:7100/10100, NER loss:      nan
2019-02-22 11:54:21,109 - log/train6.log - INFO - iteration:99 step:7200/10100, NER loss:      nan
2019-02-22 11:54:23,121 - log/train6.log - INFO - iteration:99 step:7300/10100, NER loss:      nan
2019-02-22 11:54:25,257 - log/train6.log - INFO - iteration:99 step:7400/10100, NER loss:      nan
2019-02-22 11:54:27,436 - log/train6.log - INFO - iteration:99 step:7500/10100, NER loss:      nan
2019-02-22 11:54:29,480 - log/train6.log - INFO - iteration:99 step:7600/10100, NER loss:      nan
2019-02-22 11:54:31,738 - log/train6.log - INFO - iteration:99 step:7700/10100, NER loss:      nan
2019-02-22 11:54:33,739 - log/train6.log - INFO - iteration:99 step:7800/10100, NER loss:      nan
2019-02-22 11:54:35,826 - log/train6.log - INFO - iteration:99 step:7900/10100, NER loss:      nan
2019-02-22 11:54:38,160 - log/train6.log - INFO - iteration:99 step:8000/10100, NER loss:      nan
2019-02-22 11:54:40,362 - log/train6.log - INFO - iteration:99 step:8100/10100, NER loss:      nan
2019-02-22 11:54:42,468 - log/train6.log - INFO - iteration:99 step:8200/10100, NER loss:      nan
2019-02-22 11:54:44,651 - log/train6.log - INFO - iteration:99 step:8300/10100, NER loss:      nan
2019-02-22 11:54:46,716 - log/train6.log - INFO - iteration:99 step:8400/10100, NER loss:      nan
2019-02-22 11:54:49,204 - log/train6.log - INFO - iteration:99 step:8500/10100, NER loss:      nan
2019-02-22 11:54:51,294 - log/train6.log - INFO - iteration:99 step:8600/10100, NER loss:      nan
2019-02-22 11:54:53,437 - log/train6.log - INFO - iteration:99 step:8700/10100, NER loss:      nan
2019-02-22 11:54:55,734 - log/train6.log - INFO - iteration:99 step:8800/10100, NER loss:      nan
2019-02-22 11:54:57,800 - log/train6.log - INFO - iteration:99 step:8900/10100, NER loss:      nan
2019-02-22 11:54:59,880 - log/train6.log - INFO - iteration:99 step:9000/10100, NER loss:      nan
2019-02-22 11:55:02,093 - log/train6.log - INFO - iteration:99 step:9100/10100, NER loss:      nan
2019-02-22 11:55:04,290 - log/train6.log - INFO - iteration:99 step:9200/10100, NER loss:      nan
2019-02-22 11:55:06,668 - log/train6.log - INFO - iteration:99 step:9300/10100, NER loss:      nan
2019-02-22 11:55:08,779 - log/train6.log - INFO - iteration:99 step:9400/10100, NER loss:      nan
2019-02-22 11:55:11,086 - log/train6.log - INFO - iteration:99 step:9500/10100, NER loss:      nan
2019-02-22 11:55:13,387 - log/train6.log - INFO - iteration:99 step:9600/10100, NER loss:      nan
2019-02-22 11:55:18,760 - log/train6.log - INFO - iteration:99 step:9700/10100, NER loss:      nan
2019-02-22 11:55:21,231 - log/train6.log - INFO - iteration:99 step:9800/10100, NER loss:      nan
2019-02-22 11:55:23,654 - log/train6.log - INFO - iteration:99 step:9900/10100, NER loss:      nan
2019-02-22 11:55:26,014 - log/train6.log - INFO - iteration:99 step:10000/10100, NER loss:      nan
2019-02-22 11:55:28,385 - log/train6.log - INFO - iteration:100 step:0/10100, NER loss:      nan
2019-02-22 11:55:28,385 - log/train6.log - INFO - evaluate:dev
2019-02-22 11:55:34,867 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:55:34,868 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:55:34,868 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:55:34,868 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:55:34,868 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:55:34,868 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:55:34,868 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:55:34,868 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:55:34,871 - log/train6.log - INFO - evaluate:test
2019-02-22 11:55:36,348 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:55:36,348 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:55:36,348 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:55:36,348 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:55:36,349 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:55:36,349 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:55:36,349 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:55:36,349 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:55:38,495 - log/train6.log - INFO - iteration:100 step:100/10100, NER loss:      nan
2019-02-22 11:55:40,661 - log/train6.log - INFO - iteration:100 step:200/10100, NER loss:      nan
2019-02-22 11:55:42,938 - log/train6.log - INFO - iteration:100 step:300/10100, NER loss:      nan
2019-02-22 11:55:44,942 - log/train6.log - INFO - iteration:100 step:400/10100, NER loss:      nan
2019-02-22 11:55:46,963 - log/train6.log - INFO - iteration:100 step:500/10100, NER loss:      nan
2019-02-22 11:55:49,251 - log/train6.log - INFO - iteration:100 step:600/10100, NER loss:      nan
2019-02-22 11:55:51,477 - log/train6.log - INFO - iteration:100 step:700/10100, NER loss:      nan
2019-02-22 11:55:53,573 - log/train6.log - INFO - iteration:100 step:800/10100, NER loss:      nan
2019-02-22 11:55:55,538 - log/train6.log - INFO - iteration:100 step:900/10100, NER loss:      nan
2019-02-22 11:55:57,945 - log/train6.log - INFO - iteration:100 step:1000/10100, NER loss:      nan
2019-02-22 11:55:59,981 - log/train6.log - INFO - iteration:100 step:1100/10100, NER loss:      nan
2019-02-22 11:56:02,334 - log/train6.log - INFO - iteration:100 step:1200/10100, NER loss:      nan
2019-02-22 11:56:04,304 - log/train6.log - INFO - iteration:100 step:1300/10100, NER loss:      nan
2019-02-22 11:56:06,696 - log/train6.log - INFO - iteration:100 step:1400/10100, NER loss:      nan
2019-02-22 11:56:08,850 - log/train6.log - INFO - iteration:100 step:1500/10100, NER loss:      nan
2019-02-22 11:56:11,148 - log/train6.log - INFO - iteration:100 step:1600/10100, NER loss:      nan
2019-02-22 11:56:14,920 - log/train6.log - INFO - iteration:100 step:1700/10100, NER loss:      nan
2019-02-22 11:56:17,219 - log/train6.log - INFO - iteration:100 step:1800/10100, NER loss:      nan
2019-02-22 11:56:19,174 - log/train6.log - INFO - iteration:100 step:1900/10100, NER loss:      nan
2019-02-22 11:56:21,398 - log/train6.log - INFO - iteration:100 step:2000/10100, NER loss:      nan
2019-02-22 11:56:23,403 - log/train6.log - INFO - iteration:100 step:2100/10100, NER loss:      nan
2019-02-22 11:56:25,655 - log/train6.log - INFO - iteration:100 step:2200/10100, NER loss:      nan
2019-02-22 11:56:27,750 - log/train6.log - INFO - iteration:100 step:2300/10100, NER loss:      nan
2019-02-22 11:56:29,960 - log/train6.log - INFO - iteration:100 step:2400/10100, NER loss:      nan
2019-02-22 11:56:31,924 - log/train6.log - INFO - iteration:100 step:2500/10100, NER loss:      nan
2019-02-22 11:56:34,063 - log/train6.log - INFO - iteration:100 step:2600/10100, NER loss:      nan
2019-02-22 11:56:36,083 - log/train6.log - INFO - iteration:100 step:2700/10100, NER loss:      nan
2019-02-22 11:56:38,297 - log/train6.log - INFO - iteration:100 step:2800/10100, NER loss:      nan
2019-02-22 11:56:40,294 - log/train6.log - INFO - iteration:100 step:2900/10100, NER loss:      nan
2019-02-22 11:56:42,679 - log/train6.log - INFO - iteration:100 step:3000/10100, NER loss:      nan
2019-02-22 11:56:44,716 - log/train6.log - INFO - iteration:100 step:3100/10100, NER loss:      nan
2019-02-22 11:56:46,783 - log/train6.log - INFO - iteration:100 step:3200/10100, NER loss:      nan
2019-02-22 11:56:48,864 - log/train6.log - INFO - iteration:100 step:3300/10100, NER loss:      nan
2019-02-22 11:56:50,771 - log/train6.log - INFO - iteration:100 step:3400/10100, NER loss:      nan
2019-02-22 11:56:53,108 - log/train6.log - INFO - iteration:100 step:3500/10100, NER loss:      nan
2019-02-22 11:56:55,415 - log/train6.log - INFO - iteration:100 step:3600/10100, NER loss:      nan
2019-02-22 11:56:57,516 - log/train6.log - INFO - iteration:100 step:3700/10100, NER loss:      nan
2019-02-22 11:56:59,773 - log/train6.log - INFO - iteration:100 step:3800/10100, NER loss:      nan
2019-02-22 11:57:01,885 - log/train6.log - INFO - iteration:100 step:3900/10100, NER loss:      nan
2019-02-22 11:57:04,068 - log/train6.log - INFO - iteration:100 step:4000/10100, NER loss:      nan
2019-02-22 11:57:08,421 - log/train6.log - INFO - iteration:100 step:4100/10100, NER loss:      nan
2019-02-22 11:57:10,690 - log/train6.log - INFO - iteration:100 step:4200/10100, NER loss:      nan
2019-02-22 11:57:12,865 - log/train6.log - INFO - iteration:100 step:4300/10100, NER loss:      nan
2019-02-22 11:57:14,842 - log/train6.log - INFO - iteration:100 step:4400/10100, NER loss:      nan
2019-02-22 11:57:16,970 - log/train6.log - INFO - iteration:100 step:4500/10100, NER loss:      nan
2019-02-22 11:57:19,158 - log/train6.log - INFO - iteration:100 step:4600/10100, NER loss:      nan
2019-02-22 11:57:21,223 - log/train6.log - INFO - iteration:100 step:4700/10100, NER loss:      nan
2019-02-22 11:57:23,225 - log/train6.log - INFO - iteration:100 step:4800/10100, NER loss:      nan
2019-02-22 11:57:25,749 - log/train6.log - INFO - iteration:100 step:4900/10100, NER loss:      nan
2019-02-22 11:57:27,837 - log/train6.log - INFO - iteration:100 step:5000/10100, NER loss:      nan
2019-02-22 11:57:30,187 - log/train6.log - INFO - iteration:100 step:5100/10100, NER loss:      nan
2019-02-22 11:57:32,564 - log/train6.log - INFO - iteration:100 step:5200/10100, NER loss:      nan
2019-02-22 11:57:34,784 - log/train6.log - INFO - iteration:100 step:5300/10100, NER loss:      nan
2019-02-22 11:57:37,010 - log/train6.log - INFO - iteration:100 step:5400/10100, NER loss:      nan
2019-02-22 11:57:39,304 - log/train6.log - INFO - iteration:100 step:5500/10100, NER loss:      nan
2019-02-22 11:57:41,407 - log/train6.log - INFO - iteration:100 step:5600/10100, NER loss:      nan
2019-02-22 11:57:43,533 - log/train6.log - INFO - iteration:100 step:5700/10100, NER loss:      nan
2019-02-22 11:57:45,596 - log/train6.log - INFO - iteration:100 step:5800/10100, NER loss:      nan
2019-02-22 11:57:47,646 - log/train6.log - INFO - iteration:100 step:5900/10100, NER loss:      nan
2019-02-22 11:57:49,749 - log/train6.log - INFO - iteration:100 step:6000/10100, NER loss:      nan
2019-02-22 11:57:53,906 - log/train6.log - INFO - iteration:100 step:6100/10100, NER loss:      nan
2019-02-22 11:57:55,930 - log/train6.log - INFO - iteration:100 step:6200/10100, NER loss:      nan
2019-02-22 11:57:58,099 - log/train6.log - INFO - iteration:100 step:6300/10100, NER loss:      nan
2019-02-22 11:58:00,271 - log/train6.log - INFO - iteration:100 step:6400/10100, NER loss:      nan
2019-02-22 11:58:02,533 - log/train6.log - INFO - iteration:100 step:6500/10100, NER loss:      nan
2019-02-22 11:58:04,914 - log/train6.log - INFO - iteration:100 step:6600/10100, NER loss:      nan
2019-02-22 11:58:06,973 - log/train6.log - INFO - iteration:100 step:6700/10100, NER loss:      nan
2019-02-22 11:58:09,168 - log/train6.log - INFO - iteration:100 step:6800/10100, NER loss:      nan
2019-02-22 11:58:11,308 - log/train6.log - INFO - iteration:100 step:6900/10100, NER loss:      nan
2019-02-22 11:58:13,354 - log/train6.log - INFO - iteration:100 step:7000/10100, NER loss:      nan
2019-02-22 11:58:15,925 - log/train6.log - INFO - iteration:100 step:7100/10100, NER loss:      nan
2019-02-22 11:58:17,997 - log/train6.log - INFO - iteration:100 step:7200/10100, NER loss:      nan
2019-02-22 11:58:20,280 - log/train6.log - INFO - iteration:100 step:7300/10100, NER loss:      nan
2019-02-22 11:58:22,238 - log/train6.log - INFO - iteration:100 step:7400/10100, NER loss:      nan
2019-02-22 11:58:24,477 - log/train6.log - INFO - iteration:100 step:7500/10100, NER loss:      nan
2019-02-22 11:58:26,766 - log/train6.log - INFO - iteration:100 step:7600/10100, NER loss:      nan
2019-02-22 11:58:29,007 - log/train6.log - INFO - iteration:100 step:7700/10100, NER loss:      nan
2019-02-22 11:58:31,117 - log/train6.log - INFO - iteration:100 step:7800/10100, NER loss:      nan
2019-02-22 11:58:33,452 - log/train6.log - INFO - iteration:100 step:7900/10100, NER loss:      nan
2019-02-22 11:58:35,661 - log/train6.log - INFO - iteration:100 step:8000/10100, NER loss:      nan
2019-02-22 11:58:37,928 - log/train6.log - INFO - iteration:100 step:8100/10100, NER loss:      nan
2019-02-22 11:58:40,037 - log/train6.log - INFO - iteration:100 step:8200/10100, NER loss:      nan
2019-02-22 11:58:42,197 - log/train6.log - INFO - iteration:100 step:8300/10100, NER loss:      nan
2019-02-22 11:58:44,608 - log/train6.log - INFO - iteration:100 step:8400/10100, NER loss:      nan
2019-02-22 11:58:46,723 - log/train6.log - INFO - iteration:100 step:8500/10100, NER loss:      nan
2019-02-22 11:58:48,776 - log/train6.log - INFO - iteration:100 step:8600/10100, NER loss:      nan
2019-02-22 11:58:50,961 - log/train6.log - INFO - iteration:100 step:8700/10100, NER loss:      nan
2019-02-22 11:58:53,163 - log/train6.log - INFO - iteration:100 step:8800/10100, NER loss:      nan
2019-02-22 11:58:55,392 - log/train6.log - INFO - iteration:100 step:8900/10100, NER loss:      nan
2019-02-22 11:58:57,438 - log/train6.log - INFO - iteration:100 step:9000/10100, NER loss:      nan
2019-02-22 11:58:59,468 - log/train6.log - INFO - iteration:100 step:9100/10100, NER loss:      nan
2019-02-22 11:59:01,635 - log/train6.log - INFO - iteration:100 step:9200/10100, NER loss:      nan
2019-02-22 11:59:03,685 - log/train6.log - INFO - iteration:100 step:9300/10100, NER loss:      nan
2019-02-22 11:59:05,808 - log/train6.log - INFO - iteration:100 step:9400/10100, NER loss:      nan
2019-02-22 11:59:08,000 - log/train6.log - INFO - iteration:100 step:9500/10100, NER loss:      nan
2019-02-22 11:59:10,146 - log/train6.log - INFO - iteration:100 step:9600/10100, NER loss:      nan
2019-02-22 11:59:12,340 - log/train6.log - INFO - iteration:100 step:9700/10100, NER loss:      nan
2019-02-22 11:59:14,344 - log/train6.log - INFO - iteration:100 step:9800/10100, NER loss:      nan
2019-02-22 11:59:16,509 - log/train6.log - INFO - iteration:100 step:9900/10100, NER loss:      nan
2019-02-22 11:59:18,659 - log/train6.log - INFO - iteration:100 step:10000/10100, NER loss:      nan
2019-02-22 11:59:20,979 - log/train6.log - INFO - iteration:101 step:0/10100, NER loss:      nan
2019-02-22 11:59:20,980 - log/train6.log - INFO - evaluate:dev
2019-02-22 11:59:27,539 - log/train6.log - INFO - processed 169541 tokens with 5847 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:59:27,539 - log/train6.log - INFO - accuracy:  85.13%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:59:27,539 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:59:27,539 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:59:27,539 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:59:27,540 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:59:27,540 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:59:27,540 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:59:27,542 - log/train6.log - INFO - evaluate:test
2019-02-22 11:59:29,012 - log/train6.log - INFO - processed 43239 tokens with 1647 phrases; found: 0 phrases; correct: 0.

2019-02-22 11:59:29,012 - log/train6.log - INFO - accuracy:  84.57%; precision:   0.00%; recall:   0.00%; FB1:   0.00

2019-02-22 11:59:29,012 - log/train6.log - INFO -                 C: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:59:29,013 - log/train6.log - INFO -               IND: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:59:29,013 - log/train6.log - INFO -               INS: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:59:29,013 - log/train6.log - INFO -                 L: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:59:29,013 - log/train6.log - INFO -                 P: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

2019-02-22 11:59:29,013 - log/train6.log - INFO -               PRO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0

